2024-06-22 08:47:55,694 ==================================================
2024-06-22 08:47:55,694 Training with Guassian Noise of 1 length...
2024-06-22 08:47:57,208 Epoch [1/8], Batch [1/748], Loss: 1.6309
2024-06-22 08:48:21,592 Epoch [1/8], Batch [51/748], Loss: 1.5795
2024-06-22 08:48:46,236 Epoch [1/8], Batch [101/748], Loss: 1.5978
2024-06-22 08:49:10,617 Epoch [1/8], Batch [151/748], Loss: 1.6197
2024-06-22 08:49:35,402 Epoch [1/8], Batch [201/748], Loss: 1.6121
2024-06-22 08:50:00,258 Epoch [1/8], Batch [251/748], Loss: 1.5556
2024-06-22 08:50:24,930 Epoch [1/8], Batch [301/748], Loss: 1.5435
2024-06-22 08:50:50,301 Epoch [1/8], Batch [351/748], Loss: 1.5389
2024-06-22 08:51:15,021 Epoch [1/8], Batch [401/748], Loss: 1.5790
2024-06-22 08:51:39,958 Epoch [1/8], Batch [451/748], Loss: 1.6348
2024-06-22 08:52:04,515 Epoch [1/8], Batch [501/748], Loss: 1.6184
2024-06-22 08:52:29,427 Epoch [1/8], Batch [551/748], Loss: 1.5580
2024-06-22 08:52:54,529 Epoch [1/8], Batch [601/748], Loss: 1.5328
2024-06-22 08:53:19,452 Epoch [1/8], Batch [651/748], Loss: 1.5003
2024-06-22 08:53:44,396 Epoch [1/8], Batch [701/748], Loss: 1.5472
2024-06-22 08:54:07,430 Epoch 1/8, Train Loss: 1.5753, Train Accuracy: 0.2667
2024-06-22 08:55:37,175 Epoch 1/8, Val Loss: 1.5333, Val Accuracy: 0.3125
2024-06-22 08:55:37,711 Epoch [2/8], Batch [1/748], Loss: 1.4685
2024-06-22 08:56:02,204 Epoch [2/8], Batch [51/748], Loss: 1.5072
2024-06-22 08:56:27,071 Epoch [2/8], Batch [101/748], Loss: 1.5637
2024-06-22 08:56:52,025 Epoch [2/8], Batch [151/748], Loss: 1.5169
2024-06-22 08:57:16,875 Epoch [2/8], Batch [201/748], Loss: 1.5803
2024-06-22 08:57:41,525 Epoch [2/8], Batch [251/748], Loss: 1.5357
2024-06-22 08:58:06,153 Epoch [2/8], Batch [301/748], Loss: 1.5761
2024-06-22 08:58:31,291 Epoch [2/8], Batch [351/748], Loss: 1.4746
2024-06-22 08:58:56,043 Epoch [2/8], Batch [401/748], Loss: 1.5553
2024-06-22 08:59:21,006 Epoch [2/8], Batch [451/748], Loss: 1.5120
2024-06-22 08:59:46,093 Epoch [2/8], Batch [501/748], Loss: 1.5364
2024-06-22 09:00:10,985 Epoch [2/8], Batch [551/748], Loss: 1.5653
2024-06-22 09:00:35,700 Epoch [2/8], Batch [601/748], Loss: 1.5129
2024-06-22 09:01:00,490 Epoch [2/8], Batch [651/748], Loss: 1.6044
2024-06-22 09:01:25,480 Epoch [2/8], Batch [701/748], Loss: 1.3962
2024-06-22 09:01:48,702 Epoch 2/8, Train Loss: 1.5279, Train Accuracy: 0.3305
2024-06-22 09:03:18,389 Epoch 2/8, Val Loss: 1.4867, Val Accuracy: 0.3690
2024-06-22 09:03:18,870 Epoch [3/8], Batch [1/748], Loss: 1.5102
2024-06-22 09:03:43,153 Epoch [3/8], Batch [51/748], Loss: 1.5210
2024-06-22 09:04:07,652 Epoch [3/8], Batch [101/748], Loss: 1.5707
2024-06-22 09:04:32,263 Epoch [3/8], Batch [151/748], Loss: 1.6005
2024-06-22 09:04:56,787 Epoch [3/8], Batch [201/748], Loss: 1.3900
2024-06-22 09:05:21,421 Epoch [3/8], Batch [251/748], Loss: 1.5557
2024-06-22 09:05:45,767 Epoch [3/8], Batch [301/748], Loss: 1.5165
2024-06-22 09:06:09,941 Epoch [3/8], Batch [351/748], Loss: 1.5254
2024-06-22 09:06:34,495 Epoch [3/8], Batch [401/748], Loss: 1.5179
2024-06-22 09:06:59,090 Epoch [3/8], Batch [451/748], Loss: 1.4401
2024-06-22 09:07:23,453 Epoch [3/8], Batch [501/748], Loss: 1.4805
2024-06-22 09:07:48,121 Epoch [3/8], Batch [551/748], Loss: 1.4671
2024-06-22 09:08:12,449 Epoch [3/8], Batch [601/748], Loss: 1.5289
2024-06-22 09:08:37,292 Epoch [3/8], Batch [651/748], Loss: 1.4655
2024-06-22 09:09:01,645 Epoch [3/8], Batch [701/748], Loss: 1.4286
2024-06-22 09:09:24,380 Epoch 3/8, Train Loss: 1.4934, Train Accuracy: 0.3668
2024-06-22 09:10:53,497 Epoch 3/8, Val Loss: 1.4457, Val Accuracy: 0.4125
2024-06-22 09:10:53,976 Epoch [4/8], Batch [1/748], Loss: 1.4247
2024-06-22 09:11:18,486 Epoch [4/8], Batch [51/748], Loss: 1.4692
2024-06-22 09:11:43,071 Epoch [4/8], Batch [101/748], Loss: 1.5225
2024-06-22 09:12:07,777 Epoch [4/8], Batch [151/748], Loss: 1.4436
