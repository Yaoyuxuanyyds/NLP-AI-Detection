2024-06-23 16:02:49,185 ==================================================
2024-06-23 16:02:49,186 Training BERT + TF-IDF features with Dimension-4096...
2024-06-23 16:02:51,000 Epoch [1/8], Batch [1/748], Loss: 1.6043
2024-06-23 16:03:40,064 Epoch [1/8], Batch [51/748], Loss: 1.5688
2024-06-23 16:04:30,193 Epoch [1/8], Batch [101/748], Loss: 1.3628
2024-06-23 16:05:20,690 Epoch [1/8], Batch [151/748], Loss: 1.3361
2024-06-23 16:06:11,017 Epoch [1/8], Batch [201/748], Loss: 1.2770
2024-06-23 16:07:01,798 Epoch [1/8], Batch [251/748], Loss: 0.9839
2024-06-23 16:07:52,293 Epoch [1/8], Batch [301/748], Loss: 1.0429
2024-06-23 16:08:42,708 Epoch [1/8], Batch [351/748], Loss: 1.0235
2024-06-23 16:09:33,285 Epoch [1/8], Batch [401/748], Loss: 0.9958
2024-06-23 16:10:23,928 Epoch [1/8], Batch [451/748], Loss: 1.0011
2024-06-23 16:11:14,531 Epoch [1/8], Batch [501/748], Loss: 0.9191
2024-06-23 16:12:05,507 Epoch [1/8], Batch [551/748], Loss: 1.0187
2024-06-23 16:12:56,484 Epoch [1/8], Batch [601/748], Loss: 0.8703
2024-06-23 16:13:46,931 Epoch [1/8], Batch [651/748], Loss: 0.7106
2024-06-23 16:14:37,396 Epoch [1/8], Batch [701/748], Loss: 0.6072
2024-06-23 16:15:24,747 Epoch 1/8, Train Loss: 1.0957, Train Accuracy: 0.5395
2024-06-23 16:16:49,338 Epoch 1/8, Val Loss: 0.9200, Val Accuracy: 0.5952
2024-06-23 16:16:50,361 Epoch [2/8], Batch [1/748], Loss: 0.8043
2024-06-23 16:17:40,852 Epoch [2/8], Batch [51/748], Loss: 0.7355
2024-06-23 16:18:31,835 Epoch [2/8], Batch [101/748], Loss: 0.7132
2024-06-23 16:19:22,628 Epoch [2/8], Batch [151/748], Loss: 0.7560
2024-06-23 16:20:13,209 Epoch [2/8], Batch [201/748], Loss: 0.9016
2024-06-23 16:21:03,583 Epoch [2/8], Batch [251/748], Loss: 0.9075
2024-06-23 16:21:54,413 Epoch [2/8], Batch [301/748], Loss: 1.2599
2024-06-23 16:22:44,891 Epoch [2/8], Batch [351/748], Loss: 0.8304
2024-06-23 16:23:35,621 Epoch [2/8], Batch [401/748], Loss: 1.0818
2024-06-23 16:24:26,335 Epoch [2/8], Batch [451/748], Loss: 0.7139
2024-06-23 16:25:17,010 Epoch [2/8], Batch [501/748], Loss: 1.0659
2024-06-23 16:26:07,506 Epoch [2/8], Batch [551/748], Loss: 0.8348
2024-06-23 16:26:58,332 Epoch [2/8], Batch [601/748], Loss: 0.6911
2024-06-23 16:27:49,147 Epoch [2/8], Batch [651/748], Loss: 0.7950
2024-06-23 16:28:40,099 Epoch [2/8], Batch [701/748], Loss: 0.7007
2024-06-23 16:29:27,612 Epoch 2/8, Train Loss: 0.8105, Train Accuracy: 0.6434
2024-06-23 16:30:52,199 Epoch 2/8, Val Loss: 0.8456, Val Accuracy: 0.6195
2024-06-23 16:30:53,227 Epoch [3/8], Batch [1/748], Loss: 0.7870
2024-06-23 16:31:43,670 Epoch [3/8], Batch [51/748], Loss: 0.8568
2024-06-23 16:32:34,646 Epoch [3/8], Batch [101/748], Loss: 0.6644
2024-06-23 16:33:25,480 Epoch [3/8], Batch [151/748], Loss: 0.8279
2024-06-23 16:34:16,094 Epoch [3/8], Batch [201/748], Loss: 0.8575
2024-06-23 16:35:06,548 Epoch [3/8], Batch [251/748], Loss: 0.5560
2024-06-23 16:35:57,148 Epoch [3/8], Batch [301/748], Loss: 0.6595
2024-06-23 16:36:47,888 Epoch [3/8], Batch [351/748], Loss: 0.9506
2024-06-23 16:37:38,404 Epoch [3/8], Batch [401/748], Loss: 0.8708
2024-06-23 16:38:29,172 Epoch [3/8], Batch [451/748], Loss: 0.7744
2024-06-23 16:39:19,890 Epoch [3/8], Batch [501/748], Loss: 0.4975
2024-06-23 16:40:10,914 Epoch [3/8], Batch [551/748], Loss: 0.5585
2024-06-23 16:41:02,001 Epoch [3/8], Batch [601/748], Loss: 0.6651
2024-06-23 16:41:52,874 Epoch [3/8], Batch [651/748], Loss: 0.6737
2024-06-23 16:42:43,949 Epoch [3/8], Batch [701/748], Loss: 0.8788
2024-06-23 16:43:31,275 Epoch 3/8, Train Loss: 0.7062, Train Accuracy: 0.6881
2024-06-23 16:44:56,453 Epoch 3/8, Val Loss: 0.8401, Val Accuracy: 0.6288
2024-06-23 16:44:57,501 Epoch [4/8], Batch [1/748], Loss: 0.5576
2024-06-23 16:45:48,104 Epoch [4/8], Batch [51/748], Loss: 0.6792
2024-06-23 16:46:39,209 Epoch [4/8], Batch [101/748], Loss: 0.4999
2024-06-23 16:47:30,446 Epoch [4/8], Batch [151/748], Loss: 0.5102
2024-06-23 16:48:21,161 Epoch [4/8], Batch [201/748], Loss: 0.8192
2024-06-23 16:49:12,190 Epoch [4/8], Batch [251/748], Loss: 0.6797
2024-06-23 16:50:02,872 Epoch [4/8], Batch [301/748], Loss: 0.8848
2024-06-23 16:50:53,823 Epoch [4/8], Batch [351/748], Loss: 0.4297
2024-06-23 16:51:44,782 Epoch [4/8], Batch [401/748], Loss: 0.4586
2024-06-23 16:52:35,850 Epoch [4/8], Batch [451/748], Loss: 0.7408
2024-06-23 16:53:26,523 Epoch [4/8], Batch [501/748], Loss: 0.6725
2024-06-23 16:54:17,569 Epoch [4/8], Batch [551/748], Loss: 0.5798
2024-06-23 16:55:08,341 Epoch [4/8], Batch [601/748], Loss: 0.8126
2024-06-23 16:55:58,892 Epoch [4/8], Batch [651/748], Loss: 0.4134
2024-06-23 16:56:49,614 Epoch [4/8], Batch [701/748], Loss: 0.6370
2024-06-23 16:57:36,820 Epoch 4/8, Train Loss: 0.6118, Train Accuracy: 0.7350
2024-06-23 16:59:02,282 Epoch 4/8, Val Loss: 0.8739, Val Accuracy: 0.6374
2024-06-23 16:59:03,269 Epoch [5/8], Batch [1/748], Loss: 0.3541
2024-06-23 16:59:54,062 Epoch [5/8], Batch [51/748], Loss: 0.5036
2024-06-23 17:00:44,763 Epoch [5/8], Batch [101/748], Loss: 0.5059
2024-06-23 17:01:35,572 Epoch [5/8], Batch [151/748], Loss: 0.3315
2024-06-23 17:02:26,554 Epoch [5/8], Batch [201/748], Loss: 0.5165
2024-06-23 17:03:17,588 Epoch [5/8], Batch [251/748], Loss: 0.5210
2024-06-23 17:04:08,400 Epoch [5/8], Batch [301/748], Loss: 0.3757
2024-06-23 17:04:59,367 Epoch [5/8], Batch [351/748], Loss: 0.4459
2024-06-23 17:05:50,165 Epoch [5/8], Batch [401/748], Loss: 0.4332
2024-06-23 17:06:41,336 Epoch [5/8], Batch [451/748], Loss: 0.6490
2024-06-23 17:07:32,268 Epoch [5/8], Batch [501/748], Loss: 0.5234
2024-06-23 17:08:23,097 Epoch [5/8], Batch [551/748], Loss: 0.3330
2024-06-23 17:09:14,063 Epoch [5/8], Batch [601/748], Loss: 0.4959
2024-06-23 17:10:05,025 Epoch [5/8], Batch [651/748], Loss: 0.4989
2024-06-23 17:10:55,903 Epoch [5/8], Batch [701/748], Loss: 0.3394
2024-06-23 17:11:43,454 Epoch 5/8, Train Loss: 0.5109, Train Accuracy: 0.7844
2024-06-23 17:13:08,702 Epoch 5/8, Val Loss: 0.8792, Val Accuracy: 0.6544
2024-06-23 17:13:09,715 Epoch [6/8], Batch [1/748], Loss: 0.3526
2024-06-23 17:14:00,389 Epoch [6/8], Batch [51/748], Loss: 0.3984
2024-06-23 17:14:51,186 Epoch [6/8], Batch [101/748], Loss: 0.3543
2024-06-23 17:15:42,253 Epoch [6/8], Batch [151/748], Loss: 0.3700
2024-06-23 17:16:33,427 Epoch [6/8], Batch [201/748], Loss: 0.3931
2024-06-23 17:17:24,155 Epoch [6/8], Batch [251/748], Loss: 0.3015
2024-06-23 17:18:15,056 Epoch [6/8], Batch [301/748], Loss: 0.3442
2024-06-23 17:19:06,270 Epoch [6/8], Batch [351/748], Loss: 0.7296
2024-06-23 17:19:57,009 Epoch [6/8], Batch [401/748], Loss: 0.7487
2024-06-23 17:20:47,937 Epoch [6/8], Batch [451/748], Loss: 0.3349
2024-06-23 17:21:38,851 Epoch [6/8], Batch [501/748], Loss: 0.3168
2024-06-23 17:22:30,061 Epoch [6/8], Batch [551/748], Loss: 0.2073
2024-06-23 17:23:20,862 Epoch [6/8], Batch [601/748], Loss: 0.2999
2024-06-23 17:24:11,766 Epoch [6/8], Batch [651/748], Loss: 0.5200
2024-06-23 17:25:02,842 Epoch [6/8], Batch [701/748], Loss: 0.5414
2024-06-23 17:25:50,318 Epoch 6/8, Train Loss: 0.4186, Train Accuracy: 0.8285
2024-06-23 17:27:15,676 Epoch 6/8, Val Loss: 0.9563, Val Accuracy: 0.6541
2024-06-23 17:27:16,662 Epoch [7/8], Batch [1/748], Loss: 0.1759
2024-06-23 17:28:07,208 Epoch [7/8], Batch [51/748], Loss: 0.3157
2024-06-23 17:28:58,115 Epoch [7/8], Batch [101/748], Loss: 0.3672
2024-06-23 17:29:49,086 Epoch [7/8], Batch [151/748], Loss: 0.3339
2024-06-23 17:30:40,194 Epoch [7/8], Batch [201/748], Loss: 0.4668
2024-06-23 17:31:31,094 Epoch [7/8], Batch [251/748], Loss: 0.3817
2024-06-23 17:32:21,981 Epoch [7/8], Batch [301/748], Loss: 0.2880
2024-06-23 17:33:12,879 Epoch [7/8], Batch [351/748], Loss: 0.2807
2024-06-23 17:34:03,980 Epoch [7/8], Batch [401/748], Loss: 0.6320
2024-06-23 17:34:54,783 Epoch [7/8], Batch [451/748], Loss: 0.7601
2024-06-23 17:35:45,870 Epoch [7/8], Batch [501/748], Loss: 0.3876
2024-06-23 17:36:36,858 Epoch [7/8], Batch [551/748], Loss: 0.3764
2024-06-23 17:37:27,722 Epoch [7/8], Batch [601/748], Loss: 0.5025
2024-06-23 17:38:18,678 Epoch [7/8], Batch [651/748], Loss: 0.2462
2024-06-23 17:39:09,603 Epoch [7/8], Batch [701/748], Loss: 0.4173
2024-06-23 17:39:57,128 Epoch 7/8, Train Loss: 0.3536, Train Accuracy: 0.8590
2024-06-23 17:41:22,599 Epoch 7/8, Val Loss: 0.9858, Val Accuracy: 0.6646
2024-06-23 17:41:23,592 Epoch [8/8], Batch [1/748], Loss: 0.1543
2024-06-23 17:42:13,962 Epoch [8/8], Batch [51/748], Loss: 0.2427
2024-06-23 17:43:04,911 Epoch [8/8], Batch [101/748], Loss: 0.1363
2024-06-23 17:43:55,838 Epoch [8/8], Batch [151/748], Loss: 0.2973
2024-06-23 17:44:46,851 Epoch [8/8], Batch [201/748], Loss: 0.3351
2024-06-23 17:45:37,706 Epoch [8/8], Batch [251/748], Loss: 0.3421
2024-06-23 17:46:28,690 Epoch [8/8], Batch [301/748], Loss: 0.0990
2024-06-23 17:47:19,369 Epoch [8/8], Batch [351/748], Loss: 0.2987
2024-06-23 17:48:09,853 Epoch [8/8], Batch [401/748], Loss: 0.3398
2024-06-23 17:49:00,535 Epoch [8/8], Batch [451/748], Loss: 0.2139
2024-06-23 17:49:51,047 Epoch [8/8], Batch [501/748], Loss: 0.3236
2024-06-23 17:50:41,940 Epoch [8/8], Batch [551/748], Loss: 0.3190
2024-06-23 17:51:32,458 Epoch [8/8], Batch [601/748], Loss: 0.1641
2024-06-23 17:52:22,998 Epoch [8/8], Batch [651/748], Loss: 0.4335
2024-06-23 17:53:13,976 Epoch [8/8], Batch [701/748], Loss: 0.3610
2024-06-23 17:54:00,923 Epoch 8/8, Train Loss: 0.2893, Train Accuracy: 0.8855
2024-06-23 17:55:25,320 Epoch 8/8, Val Loss: 1.0870, Val Accuracy: 0.6554
2024-06-23 17:55:25,322 Training finished!
2024-06-23 17:55:25,322 ==================================================
2024-06-23 17:55:31,296 ==================================================
2024-06-23 17:55:31,297 Training BERT + TF-IDF features with Dimension-2048...
2024-06-23 17:55:32,300 Epoch [1/8], Batch [1/748], Loss: 1.6117
2024-06-23 17:56:22,549 Epoch [1/8], Batch [51/748], Loss: 1.5431
2024-06-23 17:57:13,199 Epoch [1/8], Batch [101/748], Loss: 1.2855
2024-06-23 17:58:03,687 Epoch [1/8], Batch [151/748], Loss: 1.1031
2024-06-23 17:58:54,396 Epoch [1/8], Batch [201/748], Loss: 1.2629
2024-06-23 17:59:45,036 Epoch [1/8], Batch [251/748], Loss: 1.0177
2024-06-23 18:00:35,714 Epoch [1/8], Batch [301/748], Loss: 0.9976
2024-06-23 18:01:26,197 Epoch [1/8], Batch [351/748], Loss: 0.9819
2024-06-23 18:02:16,697 Epoch [1/8], Batch [401/748], Loss: 1.2102
2024-06-23 18:03:07,617 Epoch [1/8], Batch [451/748], Loss: 0.9247
2024-06-23 18:03:57,955 Epoch [1/8], Batch [501/748], Loss: 0.9089
2024-06-23 18:04:48,406 Epoch [1/8], Batch [551/748], Loss: 0.9853
2024-06-23 18:05:38,853 Epoch [1/8], Batch [601/748], Loss: 0.7694
2024-06-23 18:06:29,452 Epoch [1/8], Batch [651/748], Loss: 0.7630
2024-06-23 18:07:19,746 Epoch [1/8], Batch [701/748], Loss: 0.8383
2024-06-23 18:08:06,875 Epoch 1/8, Train Loss: 1.0831, Train Accuracy: 0.5307
2024-06-23 18:09:31,386 Epoch 1/8, Val Loss: 0.9850, Val Accuracy: 0.5962
2024-06-23 18:09:32,413 Epoch [2/8], Batch [1/748], Loss: 0.9662
2024-06-23 18:10:22,806 Epoch [2/8], Batch [51/748], Loss: 0.8296
2024-06-23 18:11:13,511 Epoch [2/8], Batch [101/748], Loss: 0.8285
2024-06-23 18:12:03,978 Epoch [2/8], Batch [151/748], Loss: 0.6083
2024-06-23 18:12:54,645 Epoch [2/8], Batch [201/748], Loss: 0.9252
2024-06-23 18:13:45,061 Epoch [2/8], Batch [251/748], Loss: 0.7090
2024-06-23 18:14:35,608 Epoch [2/8], Batch [301/748], Loss: 0.9758
2024-06-23 18:15:25,910 Epoch [2/8], Batch [351/748], Loss: 0.9650
2024-06-23 18:16:16,440 Epoch [2/8], Batch [401/748], Loss: 0.4501
2024-06-23 18:17:07,133 Epoch [2/8], Batch [451/748], Loss: 0.4586
2024-06-23 18:17:57,434 Epoch [2/8], Batch [501/748], Loss: 0.6633
2024-06-23 18:18:48,345 Epoch [2/8], Batch [551/748], Loss: 0.7063
2024-06-23 18:19:38,846 Epoch [2/8], Batch [601/748], Loss: 0.8491
2024-06-23 18:20:29,363 Epoch [2/8], Batch [651/748], Loss: 0.9802
2024-06-23 18:21:19,854 Epoch [2/8], Batch [701/748], Loss: 0.7260
2024-06-23 18:22:06,685 Epoch 2/8, Train Loss: 0.8090, Train Accuracy: 0.6406
2024-06-23 18:23:31,434 Epoch 2/8, Val Loss: 0.8222, Val Accuracy: 0.6422
2024-06-23 18:23:32,458 Epoch [3/8], Batch [1/748], Loss: 0.7402
2024-06-23 18:24:22,593 Epoch [3/8], Batch [51/748], Loss: 0.4584
2024-06-23 18:25:13,329 Epoch [3/8], Batch [101/748], Loss: 0.6510
2024-06-23 18:26:03,580 Epoch [3/8], Batch [151/748], Loss: 0.7770
2024-06-23 18:26:54,404 Epoch [3/8], Batch [201/748], Loss: 0.6151
2024-06-23 18:27:45,200 Epoch [3/8], Batch [251/748], Loss: 0.8241
2024-06-23 18:28:35,721 Epoch [3/8], Batch [301/748], Loss: 0.7650
2024-06-23 18:29:26,323 Epoch [3/8], Batch [351/748], Loss: 0.7371
2024-06-23 18:30:16,810 Epoch [3/8], Batch [401/748], Loss: 0.6166
2024-06-23 18:31:07,275 Epoch [3/8], Batch [451/748], Loss: 0.6486
2024-06-23 18:31:57,634 Epoch [3/8], Batch [501/748], Loss: 0.4739
2024-06-23 18:32:48,302 Epoch [3/8], Batch [551/748], Loss: 0.6801
2024-06-23 18:33:39,020 Epoch [3/8], Batch [601/748], Loss: 0.5913
2024-06-23 18:34:29,608 Epoch [3/8], Batch [651/748], Loss: 0.9442
2024-06-23 18:35:19,789 Epoch [3/8], Batch [701/748], Loss: 0.6192
2024-06-23 18:36:06,841 Epoch 3/8, Train Loss: 0.7019, Train Accuracy: 0.6924
2024-06-23 18:37:31,217 Epoch 3/8, Val Loss: 0.8509, Val Accuracy: 0.6439
2024-06-23 18:37:32,208 Epoch [4/8], Batch [1/748], Loss: 0.8150
2024-06-23 18:38:22,245 Epoch [4/8], Batch [51/748], Loss: 0.4499
2024-06-23 18:39:12,668 Epoch [4/8], Batch [101/748], Loss: 0.7327
2024-06-23 18:40:03,249 Epoch [4/8], Batch [151/748], Loss: 0.7086
2024-06-23 18:40:54,056 Epoch [4/8], Batch [201/748], Loss: 0.5991
2024-06-23 18:41:44,366 Epoch [4/8], Batch [251/748], Loss: 0.3714
2024-06-23 18:42:35,343 Epoch [4/8], Batch [301/748], Loss: 0.5556
2024-06-23 18:43:25,949 Epoch [4/8], Batch [351/748], Loss: 0.6213
2024-06-23 18:44:16,797 Epoch [4/8], Batch [401/748], Loss: 0.5482
2024-06-23 18:45:07,296 Epoch [4/8], Batch [451/748], Loss: 0.5996
2024-06-23 18:45:57,780 Epoch [4/8], Batch [501/748], Loss: 0.5116
2024-06-23 18:46:48,693 Epoch [4/8], Batch [551/748], Loss: 0.5557
2024-06-23 18:47:39,163 Epoch [4/8], Batch [601/748], Loss: 0.5920
2024-06-23 18:48:29,892 Epoch [4/8], Batch [651/748], Loss: 0.6920
2024-06-23 18:49:20,718 Epoch [4/8], Batch [701/748], Loss: 0.7065
2024-06-23 18:50:07,828 Epoch 4/8, Train Loss: 0.5958, Train Accuracy: 0.7485
2024-06-23 18:51:32,425 Epoch 4/8, Val Loss: 0.8609, Val Accuracy: 0.6542
2024-06-23 18:51:33,433 Epoch [5/8], Batch [1/748], Loss: 0.4056
2024-06-23 18:52:23,743 Epoch [5/8], Batch [51/748], Loss: 0.4525
2024-06-23 18:53:14,886 Epoch [5/8], Batch [101/748], Loss: 0.4945
2024-06-23 18:54:05,952 Epoch [5/8], Batch [151/748], Loss: 0.3674
2024-06-23 18:54:56,951 Epoch [5/8], Batch [201/748], Loss: 0.8069
2024-06-23 18:55:47,929 Epoch [5/8], Batch [251/748], Loss: 0.6521
2024-06-23 18:56:38,793 Epoch [5/8], Batch [301/748], Loss: 0.5003
2024-06-23 18:57:29,687 Epoch [5/8], Batch [351/748], Loss: 0.3420
2024-06-23 18:58:20,564 Epoch [5/8], Batch [401/748], Loss: 0.5800
2024-06-23 18:59:11,592 Epoch [5/8], Batch [451/748], Loss: 0.5789
2024-06-23 19:00:02,496 Epoch [5/8], Batch [501/748], Loss: 0.4195
2024-06-23 19:00:53,482 Epoch [5/8], Batch [551/748], Loss: 0.5555
2024-06-23 19:01:44,424 Epoch [5/8], Batch [601/748], Loss: 0.5492
2024-06-23 19:02:35,595 Epoch [5/8], Batch [651/748], Loss: 0.6713
2024-06-23 19:03:26,445 Epoch [5/8], Batch [701/748], Loss: 0.3316
2024-06-23 19:04:13,803 Epoch 5/8, Train Loss: 0.5056, Train Accuracy: 0.7913
2024-06-23 19:05:38,875 Epoch 5/8, Val Loss: 0.9263, Val Accuracy: 0.6572
2024-06-23 19:05:39,879 Epoch [6/8], Batch [1/748], Loss: 0.3907
2024-06-23 19:06:30,819 Epoch [6/8], Batch [51/748], Loss: 0.2668
2024-06-23 19:07:21,692 Epoch [6/8], Batch [101/748], Loss: 0.4391
2024-06-23 19:08:12,670 Epoch [6/8], Batch [151/748], Loss: 0.3669
2024-06-23 19:09:03,595 Epoch [6/8], Batch [201/748], Loss: 0.1701
2024-06-23 19:09:54,536 Epoch [6/8], Batch [251/748], Loss: 0.4348
2024-06-23 19:10:45,311 Epoch [6/8], Batch [301/748], Loss: 0.1539
2024-06-23 19:11:36,354 Epoch [6/8], Batch [351/748], Loss: 0.4984
2024-06-23 19:12:27,277 Epoch [6/8], Batch [401/748], Loss: 0.3470
2024-06-23 19:13:18,253 Epoch [6/8], Batch [451/748], Loss: 0.5300
2024-06-23 19:14:09,168 Epoch [6/8], Batch [501/748], Loss: 0.4454
2024-06-23 19:15:00,088 Epoch [6/8], Batch [551/748], Loss: 0.4224
2024-06-23 19:15:51,032 Epoch [6/8], Batch [601/748], Loss: 0.4327
2024-06-23 19:16:41,887 Epoch [6/8], Batch [651/748], Loss: 0.2087
2024-06-23 19:17:32,807 Epoch [6/8], Batch [701/748], Loss: 0.3232
2024-06-23 19:18:20,338 Epoch 6/8, Train Loss: 0.4125, Train Accuracy: 0.8371
2024-06-23 19:19:45,568 Epoch 6/8, Val Loss: 0.9358, Val Accuracy: 0.6644
2024-06-23 19:19:46,584 Epoch [7/8], Batch [1/748], Loss: 0.3510
2024-06-23 19:20:37,445 Epoch [7/8], Batch [51/748], Loss: 0.4417
2024-06-23 19:21:28,290 Epoch [7/8], Batch [101/748], Loss: 0.2959
2024-06-23 19:22:19,125 Epoch [7/8], Batch [151/748], Loss: 0.3263
2024-06-23 19:23:10,433 Epoch [7/8], Batch [201/748], Loss: 0.2859
2024-06-23 19:24:01,307 Epoch [7/8], Batch [251/748], Loss: 0.3682
2024-06-23 19:24:51,971 Epoch [7/8], Batch [301/748], Loss: 0.2685
2024-06-23 19:25:42,820 Epoch [7/8], Batch [351/748], Loss: 0.3495
2024-06-23 19:26:33,832 Epoch [7/8], Batch [401/748], Loss: 0.1575
2024-06-23 19:27:24,661 Epoch [7/8], Batch [451/748], Loss: 0.5379
2024-06-23 19:28:15,574 Epoch [7/8], Batch [501/748], Loss: 0.2405
2024-06-23 19:29:06,360 Epoch [7/8], Batch [551/748], Loss: 0.2540
2024-06-23 19:29:56,913 Epoch [7/8], Batch [601/748], Loss: 0.2187
2024-06-23 19:30:47,617 Epoch [7/8], Batch [651/748], Loss: 0.2293
2024-06-23 19:31:38,355 Epoch [7/8], Batch [701/748], Loss: 0.3309
2024-06-23 19:32:25,933 Epoch 7/8, Train Loss: 0.3306, Train Accuracy: 0.8744
2024-06-23 19:33:51,158 Epoch 7/8, Val Loss: 1.0277, Val Accuracy: 0.6628
2024-06-23 19:33:52,160 Epoch [8/8], Batch [1/748], Loss: 0.1092
2024-06-23 19:34:42,826 Epoch [8/8], Batch [51/748], Loss: 0.2818
2024-06-23 19:35:33,754 Epoch [8/8], Batch [101/748], Loss: 0.1925
2024-06-23 19:36:24,876 Epoch [8/8], Batch [151/748], Loss: 0.1908
2024-06-23 19:37:15,656 Epoch [8/8], Batch [201/748], Loss: 0.2831
2024-06-23 19:38:06,612 Epoch [8/8], Batch [251/748], Loss: 0.2939
2024-06-23 19:38:57,515 Epoch [8/8], Batch [301/748], Loss: 0.5352
2024-06-23 19:39:48,438 Epoch [8/8], Batch [351/748], Loss: 0.4681
2024-06-23 19:40:39,681 Epoch [8/8], Batch [401/748], Loss: 0.1041
2024-06-23 19:41:30,280 Epoch [8/8], Batch [451/748], Loss: 0.3971
2024-06-23 19:42:21,248 Epoch [8/8], Batch [501/748], Loss: 0.2503
2024-06-23 19:43:12,415 Epoch [8/8], Batch [551/748], Loss: 0.1318
2024-06-23 19:44:03,213 Epoch [8/8], Batch [601/748], Loss: 0.3335
2024-06-23 19:44:54,288 Epoch [8/8], Batch [651/748], Loss: 0.5315
2024-06-23 19:45:45,087 Epoch [8/8], Batch [701/748], Loss: 0.4607
2024-06-23 19:46:32,756 Epoch 8/8, Train Loss: 0.2609, Train Accuracy: 0.9062
2024-06-23 19:47:57,803 Epoch 8/8, Val Loss: 1.1062, Val Accuracy: 0.6634
2024-06-23 19:47:57,805 Training finished!
2024-06-23 19:47:57,805 ==================================================
2024-06-23 19:48:03,820 ==================================================
2024-06-23 19:48:03,820 Training BERT + TF-IDF features with Dimension-1024...
2024-06-23 19:48:04,855 Epoch [1/8], Batch [1/748], Loss: 1.6254
2024-06-23 19:48:55,698 Epoch [1/8], Batch [51/748], Loss: 1.5792
2024-06-23 19:49:46,657 Epoch [1/8], Batch [101/748], Loss: 1.4162
2024-06-23 19:50:37,627 Epoch [1/8], Batch [151/748], Loss: 1.1415
2024-06-23 19:51:28,588 Epoch [1/8], Batch [201/748], Loss: 1.1351
2024-06-23 19:52:19,604 Epoch [1/8], Batch [251/748], Loss: 1.1353
2024-06-23 19:53:10,407 Epoch [1/8], Batch [301/748], Loss: 1.3458
2024-06-23 19:54:01,407 Epoch [1/8], Batch [351/748], Loss: 1.1906
2024-06-23 19:54:52,176 Epoch [1/8], Batch [401/748], Loss: 0.9021
2024-06-23 19:55:43,077 Epoch [1/8], Batch [451/748], Loss: 1.2432
2024-06-23 19:56:34,406 Epoch [1/8], Batch [501/748], Loss: 1.0780
2024-06-23 19:57:25,053 Epoch [1/8], Batch [551/748], Loss: 0.7355
2024-06-23 19:58:16,086 Epoch [1/8], Batch [601/748], Loss: 0.8618
2024-06-23 19:59:06,984 Epoch [1/8], Batch [651/748], Loss: 0.9124
2024-06-23 19:59:58,013 Epoch [1/8], Batch [701/748], Loss: 0.7429
2024-06-23 20:00:45,600 Epoch 1/8, Train Loss: 1.1215, Train Accuracy: 0.5022
2024-06-23 20:02:10,616 Epoch 1/8, Val Loss: 0.9339, Val Accuracy: 0.5899
2024-06-23 20:02:11,607 Epoch [2/8], Batch [1/748], Loss: 1.1274
2024-06-23 20:03:02,276 Epoch [2/8], Batch [51/748], Loss: 0.7201
2024-06-23 20:03:53,120 Epoch [2/8], Batch [101/748], Loss: 0.8039
2024-06-23 20:04:43,715 Epoch [2/8], Batch [151/748], Loss: 0.9502
2024-06-23 20:05:34,249 Epoch [2/8], Batch [201/748], Loss: 0.6988
2024-06-23 20:06:24,837 Epoch [2/8], Batch [251/748], Loss: 0.7994
2024-06-23 20:07:15,602 Epoch [2/8], Batch [301/748], Loss: 0.7083
2024-06-23 20:08:06,180 Epoch [2/8], Batch [351/748], Loss: 0.7843
2024-06-23 20:08:57,063 Epoch [2/8], Batch [401/748], Loss: 0.7432
2024-06-23 20:09:47,260 Epoch [2/8], Batch [451/748], Loss: 0.8291
2024-06-23 20:10:38,004 Epoch [2/8], Batch [501/748], Loss: 0.8836
2024-06-23 20:11:28,493 Epoch [2/8], Batch [551/748], Loss: 1.1749
2024-06-23 20:12:18,994 Epoch [2/8], Batch [601/748], Loss: 0.7113
2024-06-23 20:13:09,857 Epoch [2/8], Batch [651/748], Loss: 0.9051
2024-06-23 20:14:00,421 Epoch [2/8], Batch [701/748], Loss: 0.8584
2024-06-23 20:14:47,567 Epoch 2/8, Train Loss: 0.8624, Train Accuracy: 0.6143
2024-06-23 20:16:11,683 Epoch 2/8, Val Loss: 0.9175, Val Accuracy: 0.5932
2024-06-23 20:16:12,682 Epoch [3/8], Batch [1/748], Loss: 0.8634
2024-06-23 20:17:03,052 Epoch [3/8], Batch [51/748], Loss: 0.6805
2024-06-23 20:17:53,295 Epoch [3/8], Batch [101/748], Loss: 0.8119
2024-06-23 20:18:44,270 Epoch [3/8], Batch [151/748], Loss: 0.8559
2024-06-23 20:19:35,067 Epoch [3/8], Batch [201/748], Loss: 0.6593
2024-06-23 20:20:25,578 Epoch [3/8], Batch [251/748], Loss: 0.9025
2024-06-23 20:21:16,069 Epoch [3/8], Batch [301/748], Loss: 0.6172
2024-06-23 20:22:06,881 Epoch [3/8], Batch [351/748], Loss: 0.6630
2024-06-23 20:22:57,857 Epoch [3/8], Batch [401/748], Loss: 0.9536
2024-06-23 20:23:48,421 Epoch [3/8], Batch [451/748], Loss: 0.7507
2024-06-23 20:24:38,864 Epoch [3/8], Batch [501/748], Loss: 0.7849
2024-06-23 20:25:29,689 Epoch [3/8], Batch [551/748], Loss: 0.7358
2024-06-23 20:26:20,236 Epoch [3/8], Batch [601/748], Loss: 0.6542
2024-06-23 20:27:10,672 Epoch [3/8], Batch [651/748], Loss: 0.7798
2024-06-23 20:28:01,543 Epoch [3/8], Batch [701/748], Loss: 0.8727
2024-06-23 20:28:48,997 Epoch 3/8, Train Loss: 0.7602, Train Accuracy: 0.6554
2024-06-23 20:30:13,248 Epoch 3/8, Val Loss: 0.8880, Val Accuracy: 0.6111
2024-06-23 20:30:14,265 Epoch [4/8], Batch [1/748], Loss: 0.7095
2024-06-23 20:31:04,524 Epoch [4/8], Batch [51/748], Loss: 0.9450
2024-06-23 20:31:55,039 Epoch [4/8], Batch [101/748], Loss: 0.7666
2024-06-23 20:32:46,248 Epoch [4/8], Batch [151/748], Loss: 0.7243
2024-06-23 20:33:36,665 Epoch [4/8], Batch [201/748], Loss: 0.8786
2024-06-23 20:34:27,287 Epoch [4/8], Batch [251/748], Loss: 0.5732
2024-06-23 20:35:17,947 Epoch [4/8], Batch [301/748], Loss: 0.6662
2024-06-23 20:36:08,530 Epoch [4/8], Batch [351/748], Loss: 0.5816
2024-06-23 20:36:59,197 Epoch [4/8], Batch [401/748], Loss: 0.6635
2024-06-23 20:37:49,803 Epoch [4/8], Batch [451/748], Loss: 0.7867
2024-06-23 20:38:40,724 Epoch [4/8], Batch [501/748], Loss: 0.4616
2024-06-23 20:39:31,201 Epoch [4/8], Batch [551/748], Loss: 0.5407
2024-06-23 20:40:21,643 Epoch [4/8], Batch [601/748], Loss: 0.8736
2024-06-23 20:41:12,440 Epoch [4/8], Batch [651/748], Loss: 0.6621
2024-06-23 20:42:03,051 Epoch [4/8], Batch [701/748], Loss: 0.7187
2024-06-23 20:42:50,381 Epoch 4/8, Train Loss: 0.6852, Train Accuracy: 0.6891
2024-06-23 20:44:14,791 Epoch 4/8, Val Loss: 0.8377, Val Accuracy: 0.6348
2024-06-23 20:44:15,764 Epoch [5/8], Batch [1/748], Loss: 0.5325
2024-06-23 20:45:06,100 Epoch [5/8], Batch [51/748], Loss: 0.5991
2024-06-23 20:45:56,748 Epoch [5/8], Batch [101/748], Loss: 0.6836
2024-06-23 20:46:47,249 Epoch [5/8], Batch [151/748], Loss: 0.5501
2024-06-23 20:47:37,902 Epoch [5/8], Batch [201/748], Loss: 0.7800
2024-06-23 20:48:28,761 Epoch [5/8], Batch [251/748], Loss: 0.6989
2024-06-23 20:49:19,593 Epoch [5/8], Batch [301/748], Loss: 0.4886
2024-06-23 20:50:10,583 Epoch [5/8], Batch [351/748], Loss: 0.5078
2024-06-23 20:51:01,488 Epoch [5/8], Batch [401/748], Loss: 0.5989
2024-06-23 20:51:52,373 Epoch [5/8], Batch [451/748], Loss: 0.7914
2024-06-23 20:52:42,919 Epoch [5/8], Batch [501/748], Loss: 0.5431
2024-06-23 20:53:33,355 Epoch [5/8], Batch [551/748], Loss: 0.4738
2024-06-23 20:54:23,701 Epoch [5/8], Batch [601/748], Loss: 0.5099
2024-06-23 20:55:14,217 Epoch [5/8], Batch [651/748], Loss: 0.5395
2024-06-23 20:56:04,644 Epoch [5/8], Batch [701/748], Loss: 0.5305
2024-06-23 20:56:51,513 Epoch 5/8, Train Loss: 0.6032, Train Accuracy: 0.7288
2024-06-23 20:58:15,852 Epoch 5/8, Val Loss: 0.8758, Val Accuracy: 0.6449
2024-06-23 20:58:16,885 Epoch [6/8], Batch [1/748], Loss: 0.3829
2024-06-23 20:59:07,631 Epoch [6/8], Batch [51/748], Loss: 0.5319
2024-06-23 20:59:58,182 Epoch [6/8], Batch [101/748], Loss: 0.3716
2024-06-23 21:00:48,737 Epoch [6/8], Batch [151/748], Loss: 0.5019
2024-06-23 21:01:39,509 Epoch [6/8], Batch [201/748], Loss: 0.4946
2024-06-23 21:02:30,368 Epoch [6/8], Batch [251/748], Loss: 0.5416
2024-06-23 21:03:20,559 Epoch [6/8], Batch [301/748], Loss: 0.5619
2024-06-23 21:04:11,127 Epoch [6/8], Batch [351/748], Loss: 0.6166
2024-06-23 21:05:01,540 Epoch [6/8], Batch [401/748], Loss: 0.5795
2024-06-23 21:05:52,078 Epoch [6/8], Batch [451/748], Loss: 0.5582
2024-06-23 21:06:42,570 Epoch [6/8], Batch [501/748], Loss: 0.5837
2024-06-23 21:07:33,166 Epoch [6/8], Batch [551/748], Loss: 0.5200
2024-06-23 21:08:24,229 Epoch [6/8], Batch [601/748], Loss: 0.4372
2024-06-23 21:09:15,055 Epoch [6/8], Batch [651/748], Loss: 0.9638
2024-06-23 21:10:05,849 Epoch [6/8], Batch [701/748], Loss: 0.5097
2024-06-23 21:10:53,382 Epoch 6/8, Train Loss: 0.5244, Train Accuracy: 0.7671
2024-06-23 21:12:18,417 Epoch 6/8, Val Loss: 0.8493, Val Accuracy: 0.6552
2024-06-23 21:12:19,427 Epoch [7/8], Batch [1/748], Loss: 0.3566
2024-06-23 21:13:10,183 Epoch [7/8], Batch [51/748], Loss: 0.6746
2024-06-23 21:14:01,115 Epoch [7/8], Batch [101/748], Loss: 0.4713
2024-06-23 21:14:52,034 Epoch [7/8], Batch [151/748], Loss: 0.6001
2024-06-23 21:15:43,026 Epoch [7/8], Batch [201/748], Loss: 0.4893
2024-06-23 21:16:33,968 Epoch [7/8], Batch [251/748], Loss: 0.2942
2024-06-23 21:17:24,775 Epoch [7/8], Batch [301/748], Loss: 0.4686
2024-06-23 21:18:15,804 Epoch [7/8], Batch [351/748], Loss: 0.3075
2024-06-23 21:19:06,750 Epoch [7/8], Batch [401/748], Loss: 0.3101
2024-06-23 21:19:57,687 Epoch [7/8], Batch [451/748], Loss: 0.5013
2024-06-23 21:20:48,589 Epoch [7/8], Batch [501/748], Loss: 0.3787
2024-06-23 21:21:39,585 Epoch [7/8], Batch [551/748], Loss: 0.5806
2024-06-23 21:22:30,499 Epoch [7/8], Batch [601/748], Loss: 0.2864
2024-06-23 21:23:21,311 Epoch [7/8], Batch [651/748], Loss: 0.5002
2024-06-23 21:24:12,257 Epoch [7/8], Batch [701/748], Loss: 0.3608
2024-06-23 21:24:59,812 Epoch 7/8, Train Loss: 0.4456, Train Accuracy: 0.8061
2024-06-23 21:26:25,409 Epoch 7/8, Val Loss: 0.9068, Val Accuracy: 0.6700
2024-06-23 21:26:26,432 Epoch [8/8], Batch [1/748], Loss: 0.3633
2024-06-23 21:27:17,635 Epoch [8/8], Batch [51/748], Loss: 0.3530
2024-06-23 21:28:08,634 Epoch [8/8], Batch [101/748], Loss: 0.2031
2024-06-23 21:28:59,560 Epoch [8/8], Batch [151/748], Loss: 0.4017
2024-06-23 21:29:50,439 Epoch [8/8], Batch [201/748], Loss: 0.4183
2024-06-23 21:30:41,490 Epoch [8/8], Batch [251/748], Loss: 0.3828
2024-06-23 21:31:32,378 Epoch [8/8], Batch [301/748], Loss: 0.3851
2024-06-23 21:32:23,324 Epoch [8/8], Batch [351/748], Loss: 0.2914
2024-06-23 21:33:14,418 Epoch [8/8], Batch [401/748], Loss: 0.3585
2024-06-23 21:34:05,253 Epoch [8/8], Batch [451/748], Loss: 0.3962
2024-06-23 21:34:56,261 Epoch [8/8], Batch [501/748], Loss: 0.3294
2024-06-23 21:35:47,096 Epoch [8/8], Batch [551/748], Loss: 0.3110
2024-06-23 21:36:38,082 Epoch [8/8], Batch [601/748], Loss: 0.3446
2024-06-23 21:37:28,986 Epoch [8/8], Batch [651/748], Loss: 0.3981
2024-06-23 21:38:19,931 Epoch [8/8], Batch [701/748], Loss: 0.2420
2024-06-23 21:39:07,389 Epoch 8/8, Train Loss: 0.3660, Train Accuracy: 0.8488
2024-06-23 21:40:33,138 Epoch 8/8, Val Loss: 0.9678, Val Accuracy: 0.6728
2024-06-23 21:40:33,139 Training finished!
2024-06-23 21:40:33,140 ==================================================
2024-06-23 21:40:38,802 ==================================================
2024-06-23 21:40:38,802 Training BERT + TF-IDF features with Dimension-512...
2024-06-23 21:40:39,813 Epoch [1/8], Batch [1/748], Loss: 1.6365
2024-06-23 21:41:30,350 Epoch [1/8], Batch [51/748], Loss: 1.4807
2024-06-23 21:42:21,280 Epoch [1/8], Batch [101/748], Loss: 1.3389
2024-06-23 21:43:12,358 Epoch [1/8], Batch [151/748], Loss: 1.1690
2024-06-23 21:44:03,409 Epoch [1/8], Batch [201/748], Loss: 0.9779
2024-06-23 21:44:54,366 Epoch [1/8], Batch [251/748], Loss: 0.8446
2024-06-23 21:45:45,153 Epoch [1/8], Batch [301/748], Loss: 1.1374
2024-06-23 21:46:36,071 Epoch [1/8], Batch [351/748], Loss: 1.2289
2024-06-23 21:47:26,967 Epoch [1/8], Batch [401/748], Loss: 1.0646
2024-06-23 21:48:17,940 Epoch [1/8], Batch [451/748], Loss: 0.9364
2024-06-23 21:49:09,052 Epoch [1/8], Batch [501/748], Loss: 0.8745
2024-06-23 21:49:59,789 Epoch [1/8], Batch [551/748], Loss: 0.7708
2024-06-23 21:50:50,759 Epoch [1/8], Batch [601/748], Loss: 1.0319
2024-06-23 21:51:41,704 Epoch [1/8], Batch [651/748], Loss: 0.9982
2024-06-23 21:52:32,732 Epoch [1/8], Batch [701/748], Loss: 1.0733
2024-06-23 21:53:20,146 Epoch 1/8, Train Loss: 1.0734, Train Accuracy: 0.5317
2024-06-23 21:54:45,809 Epoch 1/8, Val Loss: 0.9145, Val Accuracy: 0.5999
2024-06-23 21:54:46,838 Epoch [2/8], Batch [1/748], Loss: 0.7970
2024-06-23 21:55:37,224 Epoch [2/8], Batch [51/748], Loss: 0.5629
2024-06-23 21:56:28,145 Epoch [2/8], Batch [101/748], Loss: 1.0323
2024-06-23 21:57:18,809 Epoch [2/8], Batch [151/748], Loss: 1.0853
2024-06-23 21:58:09,790 Epoch [2/8], Batch [201/748], Loss: 0.6104
2024-06-23 21:59:00,845 Epoch [2/8], Batch [251/748], Loss: 0.7587
2024-06-23 21:59:51,590 Epoch [2/8], Batch [301/748], Loss: 0.6512
2024-06-23 22:00:42,582 Epoch [2/8], Batch [351/748], Loss: 1.0214
2024-06-23 22:01:33,496 Epoch [2/8], Batch [401/748], Loss: 0.5796
2024-06-23 22:02:24,486 Epoch [2/8], Batch [451/748], Loss: 0.9203
2024-06-23 22:03:15,244 Epoch [2/8], Batch [501/748], Loss: 0.7279
2024-06-23 22:04:06,305 Epoch [2/8], Batch [551/748], Loss: 0.6999
2024-06-23 22:04:57,305 Epoch [2/8], Batch [601/748], Loss: 0.7008
2024-06-23 22:05:48,236 Epoch [2/8], Batch [651/748], Loss: 0.8802
2024-06-23 22:06:39,107 Epoch [2/8], Batch [701/748], Loss: 0.8555
2024-06-23 22:07:26,658 Epoch 2/8, Train Loss: 0.8122, Train Accuracy: 0.6402
2024-06-23 22:08:52,378 Epoch 2/8, Val Loss: 0.8231, Val Accuracy: 0.6424
2024-06-23 22:08:53,433 Epoch [3/8], Batch [1/748], Loss: 0.7315
2024-06-23 22:09:43,764 Epoch [3/8], Batch [51/748], Loss: 0.6731
2024-06-23 22:10:34,563 Epoch [3/8], Batch [101/748], Loss: 0.5266
2024-06-23 22:11:25,604 Epoch [3/8], Batch [151/748], Loss: 0.5151
2024-06-23 22:12:16,485 Epoch [3/8], Batch [201/748], Loss: 0.7685
2024-06-23 22:13:07,526 Epoch [3/8], Batch [251/748], Loss: 0.6894
2024-06-23 22:13:58,359 Epoch [3/8], Batch [301/748], Loss: 0.5506
2024-06-23 22:14:49,328 Epoch [3/8], Batch [351/748], Loss: 0.6854
2024-06-23 22:15:40,276 Epoch [3/8], Batch [401/748], Loss: 0.5608
2024-06-23 22:16:31,249 Epoch [3/8], Batch [451/748], Loss: 0.7100
2024-06-23 22:17:22,073 Epoch [3/8], Batch [501/748], Loss: 1.0951
2024-06-23 22:18:12,912 Epoch [3/8], Batch [551/748], Loss: 0.9028
2024-06-23 22:19:03,925 Epoch [3/8], Batch [601/748], Loss: 0.6755
2024-06-23 22:19:54,811 Epoch [3/8], Batch [651/748], Loss: 0.7163
2024-06-23 22:20:45,748 Epoch [3/8], Batch [701/748], Loss: 0.5962
2024-06-23 22:21:32,895 Epoch 3/8, Train Loss: 0.7090, Train Accuracy: 0.6891
2024-06-23 22:22:57,763 Epoch 3/8, Val Loss: 0.8333, Val Accuracy: 0.6365
2024-06-23 22:22:58,765 Epoch [4/8], Batch [1/748], Loss: 0.6992
2024-06-23 22:23:49,234 Epoch [4/8], Batch [51/748], Loss: 0.6097
2024-06-23 22:24:40,160 Epoch [4/8], Batch [101/748], Loss: 0.5883
2024-06-23 22:25:31,218 Epoch [4/8], Batch [151/748], Loss: 0.5826
2024-06-23 22:26:21,709 Epoch [4/8], Batch [201/748], Loss: 0.5233
2024-06-23 22:27:12,190 Epoch [4/8], Batch [251/748], Loss: 0.4791
2024-06-23 22:28:02,915 Epoch [4/8], Batch [301/748], Loss: 0.5484
2024-06-23 22:28:53,405 Epoch [4/8], Batch [351/748], Loss: 0.4870
2024-06-23 22:29:44,010 Epoch [4/8], Batch [401/748], Loss: 0.7713
2024-06-23 22:30:34,511 Epoch [4/8], Batch [451/748], Loss: 0.6628
2024-06-23 22:31:24,779 Epoch [4/8], Batch [501/748], Loss: 0.5548
2024-06-23 22:32:15,209 Epoch [4/8], Batch [551/748], Loss: 0.3896
2024-06-23 22:33:05,720 Epoch [4/8], Batch [601/748], Loss: 0.6810
2024-06-23 22:33:56,613 Epoch [4/8], Batch [651/748], Loss: 0.5670
2024-06-23 22:34:47,503 Epoch [4/8], Batch [701/748], Loss: 0.6384
2024-06-23 22:35:34,794 Epoch 4/8, Train Loss: 0.6056, Train Accuracy: 0.7354
2024-06-23 22:36:59,269 Epoch 4/8, Val Loss: 0.9287, Val Accuracy: 0.6151
2024-06-23 22:37:00,263 Epoch [5/8], Batch [1/748], Loss: 0.3903
2024-06-23 22:37:50,877 Epoch [5/8], Batch [51/748], Loss: 0.5392
2024-06-23 22:38:41,335 Epoch [5/8], Batch [101/748], Loss: 0.5006
2024-06-23 22:39:31,698 Epoch [5/8], Batch [151/748], Loss: 0.6861
2024-06-23 22:40:22,303 Epoch [5/8], Batch [201/748], Loss: 0.4675
2024-06-23 22:41:12,976 Epoch [5/8], Batch [251/748], Loss: 0.4901
2024-06-23 22:42:03,795 Epoch [5/8], Batch [301/748], Loss: 0.6079
2024-06-23 22:42:54,755 Epoch [5/8], Batch [351/748], Loss: 0.4321
2024-06-23 22:43:45,706 Epoch [5/8], Batch [401/748], Loss: 0.5267
2024-06-23 22:44:36,657 Epoch [5/8], Batch [451/748], Loss: 0.4125
2024-06-23 22:45:27,451 Epoch [5/8], Batch [501/748], Loss: 0.5317
2024-06-23 22:46:17,989 Epoch [5/8], Batch [551/748], Loss: 0.3215
2024-06-23 22:47:08,631 Epoch [5/8], Batch [601/748], Loss: 0.6150
2024-06-23 22:47:59,379 Epoch [5/8], Batch [651/748], Loss: 0.5145
2024-06-23 22:48:49,714 Epoch [5/8], Batch [701/748], Loss: 0.4489
2024-06-23 22:49:36,802 Epoch 5/8, Train Loss: 0.5041, Train Accuracy: 0.7925
2024-06-23 22:51:01,404 Epoch 5/8, Val Loss: 0.8675, Val Accuracy: 0.6695
2024-06-23 22:51:02,425 Epoch [6/8], Batch [1/748], Loss: 0.5542
2024-06-23 22:51:52,832 Epoch [6/8], Batch [51/748], Loss: 0.4916
2024-06-23 22:52:43,812 Epoch [6/8], Batch [101/748], Loss: 0.3165
2024-06-23 22:53:34,636 Epoch [6/8], Batch [151/748], Loss: 0.3556
2024-06-23 22:54:25,329 Epoch [6/8], Batch [201/748], Loss: 0.4009
2024-06-23 22:55:15,948 Epoch [6/8], Batch [251/748], Loss: 0.3091
2024-06-23 22:56:06,535 Epoch [6/8], Batch [301/748], Loss: 0.4855
2024-06-23 22:56:57,493 Epoch [6/8], Batch [351/748], Loss: 0.3086
2024-06-23 22:57:48,331 Epoch [6/8], Batch [401/748], Loss: 0.3140
2024-06-23 22:58:38,933 Epoch [6/8], Batch [451/748], Loss: 0.4736
2024-06-23 22:59:29,446 Epoch [6/8], Batch [501/748], Loss: 0.3234
2024-06-23 23:00:20,405 Epoch [6/8], Batch [551/748], Loss: 0.3469
2024-06-23 23:01:11,374 Epoch [6/8], Batch [601/748], Loss: 0.2615
2024-06-23 23:02:01,691 Epoch [6/8], Batch [651/748], Loss: 0.4644
2024-06-23 23:02:52,351 Epoch [6/8], Batch [701/748], Loss: 0.4339
2024-06-23 23:03:39,547 Epoch 6/8, Train Loss: 0.4089, Train Accuracy: 0.8325
2024-06-23 23:05:04,292 Epoch 6/8, Val Loss: 0.9416, Val Accuracy: 0.6613
2024-06-23 23:05:05,316 Epoch [7/8], Batch [1/748], Loss: 0.2550
2024-06-23 23:05:55,676 Epoch [7/8], Batch [51/748], Loss: 0.1287
2024-06-23 23:06:46,398 Epoch [7/8], Batch [101/748], Loss: 0.4484
2024-06-23 23:07:37,141 Epoch [7/8], Batch [151/748], Loss: 0.3324
2024-06-23 23:08:27,754 Epoch [7/8], Batch [201/748], Loss: 0.4148
2024-06-23 23:09:18,539 Epoch [7/8], Batch [251/748], Loss: 0.4532
2024-06-23 23:10:08,968 Epoch [7/8], Batch [301/748], Loss: 0.5781
2024-06-23 23:10:59,490 Epoch [7/8], Batch [351/748], Loss: 0.5152
2024-06-23 23:11:50,409 Epoch [7/8], Batch [401/748], Loss: 0.2917
2024-06-23 23:12:41,347 Epoch [7/8], Batch [451/748], Loss: 0.2527
2024-06-23 23:13:32,326 Epoch [7/8], Batch [501/748], Loss: 0.1305
2024-06-23 23:14:23,021 Epoch [7/8], Batch [551/748], Loss: 0.3232
2024-06-23 23:15:13,627 Epoch [7/8], Batch [601/748], Loss: 0.5917
2024-06-23 23:16:04,164 Epoch [7/8], Batch [651/748], Loss: 0.2546
2024-06-23 23:16:55,081 Epoch [7/8], Batch [701/748], Loss: 0.3063
2024-06-23 23:17:42,135 Epoch 7/8, Train Loss: 0.3211, Train Accuracy: 0.8758
2024-06-23 23:19:06,481 Epoch 7/8, Val Loss: 1.0296, Val Accuracy: 0.6676
2024-06-23 23:19:07,472 Epoch [8/8], Batch [1/748], Loss: 0.2257
2024-06-23 23:19:57,763 Epoch [8/8], Batch [51/748], Loss: 0.2896
2024-06-23 23:20:48,683 Epoch [8/8], Batch [101/748], Loss: 0.4210
2024-06-23 23:21:39,307 Epoch [8/8], Batch [151/748], Loss: 0.3127
2024-06-23 23:22:29,850 Epoch [8/8], Batch [201/748], Loss: 0.3329
2024-06-23 23:23:20,494 Epoch [8/8], Batch [251/748], Loss: 0.2073
2024-06-23 23:24:11,361 Epoch [8/8], Batch [301/748], Loss: 0.2548
2024-06-23 23:25:02,424 Epoch [8/8], Batch [351/748], Loss: 0.1846
2024-06-23 23:25:53,162 Epoch [8/8], Batch [401/748], Loss: 0.4904
2024-06-23 23:26:44,158 Epoch [8/8], Batch [451/748], Loss: 0.1436
2024-06-23 23:27:35,063 Epoch [8/8], Batch [501/748], Loss: 0.1277
2024-06-23 23:28:26,096 Epoch [8/8], Batch [551/748], Loss: 0.3011
2024-06-23 23:29:17,062 Epoch [8/8], Batch [601/748], Loss: 0.1932
2024-06-23 23:30:07,908 Epoch [8/8], Batch [651/748], Loss: 0.2414
2024-06-23 23:30:58,850 Epoch [8/8], Batch [701/748], Loss: 0.3122
2024-06-23 23:31:46,300 Epoch 8/8, Train Loss: 0.2488, Train Accuracy: 0.9068
2024-06-23 23:33:11,731 Epoch 8/8, Val Loss: 1.2073, Val Accuracy: 0.6486
2024-06-23 23:33:11,733 Training finished!
2024-06-23 23:33:11,733 ==================================================
2024-06-23 23:33:17,417 ==================================================
2024-06-23 23:33:17,417 Training BERT + TF-IDF features with Dimension-256...
2024-06-23 23:33:18,467 Epoch [1/8], Batch [1/748], Loss: 1.7093
2024-06-23 23:34:08,688 Epoch [1/8], Batch [51/748], Loss: 1.5727
2024-06-23 23:34:59,506 Epoch [1/8], Batch [101/748], Loss: 1.3418
2024-06-23 23:35:50,270 Epoch [1/8], Batch [151/748], Loss: 1.2746
2024-06-23 23:36:41,386 Epoch [1/8], Batch [201/748], Loss: 1.1561
2024-06-23 23:37:32,229 Epoch [1/8], Batch [251/748], Loss: 1.0352
2024-06-23 23:38:23,291 Epoch [1/8], Batch [301/748], Loss: 0.9685
2024-06-23 23:39:14,130 Epoch [1/8], Batch [351/748], Loss: 0.9797
2024-06-23 23:40:04,998 Epoch [1/8], Batch [401/748], Loss: 0.9370
2024-06-23 23:40:55,978 Epoch [1/8], Batch [451/748], Loss: 0.8589
2024-06-23 23:41:46,928 Epoch [1/8], Batch [501/748], Loss: 0.9929
2024-06-23 23:42:38,110 Epoch [1/8], Batch [551/748], Loss: 0.9040
2024-06-23 23:43:28,850 Epoch [1/8], Batch [601/748], Loss: 0.7543
2024-06-23 23:44:19,851 Epoch [1/8], Batch [651/748], Loss: 1.0842
2024-06-23 23:45:10,864 Epoch [1/8], Batch [701/748], Loss: 0.8892
2024-06-23 23:45:58,331 Epoch 1/8, Train Loss: 1.1106, Train Accuracy: 0.5278
2024-06-23 23:47:23,763 Epoch 1/8, Val Loss: 0.9196, Val Accuracy: 0.6073
2024-06-23 23:47:24,810 Epoch [2/8], Batch [1/748], Loss: 0.7654
2024-06-23 23:48:15,157 Epoch [2/8], Batch [51/748], Loss: 0.5367
2024-06-23 23:49:06,116 Epoch [2/8], Batch [101/748], Loss: 0.7035
2024-06-23 23:49:57,048 Epoch [2/8], Batch [151/748], Loss: 1.1758
2024-06-23 23:50:48,019 Epoch [2/8], Batch [201/748], Loss: 0.5349
2024-06-23 23:51:39,000 Epoch [2/8], Batch [251/748], Loss: 0.9233
2024-06-23 23:52:30,101 Epoch [2/8], Batch [301/748], Loss: 0.9842
2024-06-23 23:53:20,871 Epoch [2/8], Batch [351/748], Loss: 0.9970
2024-06-23 23:54:11,790 Epoch [2/8], Batch [401/748], Loss: 0.8661
2024-06-23 23:55:02,712 Epoch [2/8], Batch [451/748], Loss: 0.8920
2024-06-23 23:55:53,582 Epoch [2/8], Batch [501/748], Loss: 0.8008
2024-06-23 23:56:44,539 Epoch [2/8], Batch [551/748], Loss: 0.7991
2024-06-23 23:57:35,610 Epoch [2/8], Batch [601/748], Loss: 0.9564
2024-06-23 23:58:26,528 Epoch [2/8], Batch [651/748], Loss: 0.9661
2024-06-23 23:59:17,464 Epoch [2/8], Batch [701/748], Loss: 1.0107
2024-06-24 00:00:04,993 Epoch 2/8, Train Loss: 0.8405, Train Accuracy: 0.6313
2024-06-24 00:01:30,143 Epoch 2/8, Val Loss: 0.8545, Val Accuracy: 0.6251
2024-06-24 00:01:31,131 Epoch [3/8], Batch [1/748], Loss: 0.9134
2024-06-24 00:02:21,800 Epoch [3/8], Batch [51/748], Loss: 0.8643
2024-06-24 00:03:12,764 Epoch [3/8], Batch [101/748], Loss: 0.6988
2024-06-24 00:04:03,715 Epoch [3/8], Batch [151/748], Loss: 0.5555
2024-06-24 00:04:54,578 Epoch [3/8], Batch [201/748], Loss: 0.8560
2024-06-24 00:05:45,584 Epoch [3/8], Batch [251/748], Loss: 0.8188
2024-06-24 00:06:36,534 Epoch [3/8], Batch [301/748], Loss: 0.6554
2024-06-24 00:07:27,633 Epoch [3/8], Batch [351/748], Loss: 0.6319
2024-06-24 00:08:18,355 Epoch [3/8], Batch [401/748], Loss: 0.8699
2024-06-24 00:09:09,472 Epoch [3/8], Batch [451/748], Loss: 0.8285
2024-06-24 00:10:00,371 Epoch [3/8], Batch [501/748], Loss: 0.8022
2024-06-24 00:10:51,295 Epoch [3/8], Batch [551/748], Loss: 0.7308
2024-06-24 00:11:42,198 Epoch [3/8], Batch [601/748], Loss: 0.8596
2024-06-24 00:12:33,457 Epoch [3/8], Batch [651/748], Loss: 0.7721
2024-06-24 00:13:24,238 Epoch [3/8], Batch [701/748], Loss: 0.7210
2024-06-24 00:14:11,717 Epoch 3/8, Train Loss: 0.7337, Train Accuracy: 0.6778
2024-06-24 00:15:37,100 Epoch 3/8, Val Loss: 0.8467, Val Accuracy: 0.6322
2024-06-24 00:15:38,096 Epoch [4/8], Batch [1/748], Loss: 0.6187
2024-06-24 00:16:28,650 Epoch [4/8], Batch [51/748], Loss: 0.8450
2024-06-24 00:17:19,653 Epoch [4/8], Batch [101/748], Loss: 0.5519
2024-06-24 00:18:10,627 Epoch [4/8], Batch [151/748], Loss: 0.7440
2024-06-24 00:19:01,735 Epoch [4/8], Batch [201/748], Loss: 0.4024
2024-06-24 00:19:52,425 Epoch [4/8], Batch [251/748], Loss: 0.8333
2024-06-24 00:20:43,424 Epoch [4/8], Batch [301/748], Loss: 0.3876
2024-06-24 00:21:34,406 Epoch [4/8], Batch [351/748], Loss: 0.6067
2024-06-24 00:22:25,424 Epoch [4/8], Batch [401/748], Loss: 0.8339
2024-06-24 00:23:16,363 Epoch [4/8], Batch [451/748], Loss: 0.7041
2024-06-24 00:24:07,476 Epoch [4/8], Batch [501/748], Loss: 0.5486
2024-06-24 00:24:58,372 Epoch [4/8], Batch [551/748], Loss: 0.6840
2024-06-24 00:25:49,265 Epoch [4/8], Batch [601/748], Loss: 0.8154
2024-06-24 00:26:40,154 Epoch [4/8], Batch [651/748], Loss: 0.9462
2024-06-24 00:27:31,024 Epoch [4/8], Batch [701/748], Loss: 0.6464
2024-06-24 00:28:18,506 Epoch 4/8, Train Loss: 0.6326, Train Accuracy: 0.7274
2024-06-24 00:29:43,943 Epoch 4/8, Val Loss: 0.7731, Val Accuracy: 0.6690
2024-06-24 00:29:44,956 Epoch [5/8], Batch [1/748], Loss: 0.3239
2024-06-24 00:30:35,740 Epoch [5/8], Batch [51/748], Loss: 0.5413
2024-06-24 00:31:26,571 Epoch [5/8], Batch [101/748], Loss: 0.4167
2024-06-24 00:32:17,400 Epoch [5/8], Batch [151/748], Loss: 0.6280
2024-06-24 00:33:08,313 Epoch [5/8], Batch [201/748], Loss: 0.7192
2024-06-24 00:33:59,131 Epoch [5/8], Batch [251/748], Loss: 0.6471
2024-06-24 00:34:50,146 Epoch [5/8], Batch [301/748], Loss: 0.5895
2024-06-24 00:35:41,026 Epoch [5/8], Batch [351/748], Loss: 0.4179
2024-06-24 00:36:32,095 Epoch [5/8], Batch [401/748], Loss: 0.5501
2024-06-24 00:37:22,440 Epoch [5/8], Batch [451/748], Loss: 0.5569
2024-06-24 00:38:13,040 Epoch [5/8], Batch [501/748], Loss: 0.5185
2024-06-24 00:39:03,764 Epoch [5/8], Batch [551/748], Loss: 0.5230
2024-06-24 00:39:54,443 Epoch [5/8], Batch [601/748], Loss: 0.4376
2024-06-24 00:40:44,889 Epoch [5/8], Batch [651/748], Loss: 0.5767
2024-06-24 00:41:35,438 Epoch [5/8], Batch [701/748], Loss: 0.6055
2024-06-24 00:42:22,434 Epoch 5/8, Train Loss: 0.5339, Train Accuracy: 0.7731
2024-06-24 00:43:47,204 Epoch 5/8, Val Loss: 0.8503, Val Accuracy: 0.6579
2024-06-24 00:43:48,235 Epoch [6/8], Batch [1/748], Loss: 0.4195
2024-06-24 00:44:38,710 Epoch [6/8], Batch [51/748], Loss: 0.5158
2024-06-24 00:45:29,221 Epoch [6/8], Batch [101/748], Loss: 0.4025
2024-06-24 00:46:20,191 Epoch [6/8], Batch [151/748], Loss: 0.4845
2024-06-24 00:47:11,043 Epoch [6/8], Batch [201/748], Loss: 0.4087
2024-06-24 00:48:01,586 Epoch [6/8], Batch [251/748], Loss: 0.4586
2024-06-24 00:48:52,215 Epoch [6/8], Batch [301/748], Loss: 0.4718
2024-06-24 00:49:43,103 Epoch [6/8], Batch [351/748], Loss: 0.3297
2024-06-24 00:50:33,689 Epoch [6/8], Batch [401/748], Loss: 0.3905
2024-06-24 00:51:24,198 Epoch [6/8], Batch [451/748], Loss: 0.5060
2024-06-24 00:52:14,760 Epoch [6/8], Batch [501/748], Loss: 0.5373
2024-06-24 00:53:05,641 Epoch [6/8], Batch [551/748], Loss: 0.6748
2024-06-24 00:53:55,981 Epoch [6/8], Batch [601/748], Loss: 0.4366
2024-06-24 00:54:46,699 Epoch [6/8], Batch [651/748], Loss: 0.4254
2024-06-24 00:55:37,336 Epoch [6/8], Batch [701/748], Loss: 0.3435
2024-06-24 00:56:24,158 Epoch 6/8, Train Loss: 0.4395, Train Accuracy: 0.8211
2024-06-24 00:57:48,569 Epoch 6/8, Val Loss: 0.8828, Val Accuracy: 0.6696
2024-06-24 00:57:49,597 Epoch [7/8], Batch [1/748], Loss: 0.4459
2024-06-24 00:58:40,187 Epoch [7/8], Batch [51/748], Loss: 0.2653
2024-06-24 00:59:30,445 Epoch [7/8], Batch [101/748], Loss: 0.2973
2024-06-24 01:00:20,887 Epoch [7/8], Batch [151/748], Loss: 0.3675
2024-06-24 01:01:11,626 Epoch [7/8], Batch [201/748], Loss: 0.2152
2024-06-24 01:02:01,940 Epoch [7/8], Batch [251/748], Loss: 0.4721
2024-06-24 01:02:52,898 Epoch [7/8], Batch [301/748], Loss: 0.1499
2024-06-24 01:03:43,886 Epoch [7/8], Batch [351/748], Loss: 0.3145
2024-06-24 01:04:34,963 Epoch [7/8], Batch [401/748], Loss: 0.3440
2024-06-24 01:05:25,817 Epoch [7/8], Batch [451/748], Loss: 0.3299
2024-06-24 01:06:16,457 Epoch [7/8], Batch [501/748], Loss: 0.5183
2024-06-24 01:07:06,919 Epoch [7/8], Batch [551/748], Loss: 0.3078
2024-06-24 01:07:57,725 Epoch [7/8], Batch [601/748], Loss: 0.2482
2024-06-24 01:08:48,605 Epoch [7/8], Batch [651/748], Loss: 0.2647
2024-06-24 01:09:39,543 Epoch [7/8], Batch [701/748], Loss: 0.4305
2024-06-24 01:10:26,920 Epoch 7/8, Train Loss: 0.3603, Train Accuracy: 0.8606
2024-06-24 01:11:51,901 Epoch 7/8, Val Loss: 0.9165, Val Accuracy: 0.6775
2024-06-24 01:11:52,918 Epoch [8/8], Batch [1/748], Loss: 0.5019
2024-06-24 01:12:43,825 Epoch [8/8], Batch [51/748], Loss: 0.3144
2024-06-24 01:13:34,844 Epoch [8/8], Batch [101/748], Loss: 0.1444
2024-06-24 01:14:25,773 Epoch [8/8], Batch [151/748], Loss: 0.1186
2024-06-24 01:15:16,704 Epoch [8/8], Batch [201/748], Loss: 0.2338
2024-06-24 01:16:07,603 Epoch [8/8], Batch [251/748], Loss: 0.2517
2024-06-24 01:16:58,629 Epoch [8/8], Batch [301/748], Loss: 0.1956
2024-06-24 01:17:49,464 Epoch [8/8], Batch [351/748], Loss: 0.3987
2024-06-24 01:18:40,434 Epoch [8/8], Batch [401/748], Loss: 0.3270
2024-06-24 01:19:31,350 Epoch [8/8], Batch [451/748], Loss: 0.2584
2024-06-24 01:20:22,208 Epoch [8/8], Batch [501/748], Loss: 0.2470
2024-06-24 01:21:13,297 Epoch [8/8], Batch [551/748], Loss: 0.4971
2024-06-24 01:22:04,078 Epoch [8/8], Batch [601/748], Loss: 0.3984
2024-06-24 01:22:55,107 Epoch [8/8], Batch [651/748], Loss: 0.3526
2024-06-24 01:23:46,015 Epoch [8/8], Batch [701/748], Loss: 0.5128
2024-06-24 01:24:33,616 Epoch 8/8, Train Loss: 0.2925, Train Accuracy: 0.8885
2024-06-24 01:25:58,466 Epoch 8/8, Val Loss: 0.9894, Val Accuracy: 0.6786
2024-06-24 01:25:58,468 Training finished!
2024-06-24 01:25:58,468 ==================================================
2024-06-24 01:26:04,005 ==================================================
2024-06-24 01:26:04,005 Training BERT + TF-IDF features with Dimension-64...
2024-06-24 01:26:04,999 Epoch [1/8], Batch [1/748], Loss: 1.6461
2024-06-24 01:26:55,508 Epoch [1/8], Batch [51/748], Loss: 1.5227
2024-06-24 01:27:46,410 Epoch [1/8], Batch [101/748], Loss: 1.3201
2024-06-24 01:28:37,326 Epoch [1/8], Batch [151/748], Loss: 1.1407
2024-06-24 01:29:28,255 Epoch [1/8], Batch [201/748], Loss: 1.1855
2024-06-24 01:30:19,300 Epoch [1/8], Batch [251/748], Loss: 0.9821
2024-06-24 01:31:10,358 Epoch [1/8], Batch [301/748], Loss: 1.0021
2024-06-24 01:32:01,140 Epoch [1/8], Batch [351/748], Loss: 0.9675
2024-06-24 01:32:52,129 Epoch [1/8], Batch [401/748], Loss: 0.9481
2024-06-24 01:33:42,960 Epoch [1/8], Batch [451/748], Loss: 0.7169
2024-06-24 01:34:33,932 Epoch [1/8], Batch [501/748], Loss: 1.1058
2024-06-24 01:35:24,987 Epoch [1/8], Batch [551/748], Loss: 1.1531
2024-06-24 01:36:16,374 Epoch [1/8], Batch [601/748], Loss: 1.0597
2024-06-24 01:37:07,623 Epoch [1/8], Batch [651/748], Loss: 0.9647
2024-06-24 01:37:58,385 Epoch [1/8], Batch [701/748], Loss: 1.1662
2024-06-24 01:38:46,071 Epoch 1/8, Train Loss: 1.0698, Train Accuracy: 0.5446
2024-06-24 01:40:11,545 Epoch 1/8, Val Loss: 0.8782, Val Accuracy: 0.6235
2024-06-24 01:40:12,548 Epoch [2/8], Batch [1/748], Loss: 0.8766
2024-06-24 01:41:03,149 Epoch [2/8], Batch [51/748], Loss: 0.6152
2024-06-24 01:41:54,053 Epoch [2/8], Batch [101/748], Loss: 0.8064
2024-06-24 01:42:44,963 Epoch [2/8], Batch [151/748], Loss: 0.8351
2024-06-24 01:43:35,728 Epoch [2/8], Batch [201/748], Loss: 0.6215
2024-06-24 01:44:26,812 Epoch [2/8], Batch [251/748], Loss: 0.6955
2024-06-24 01:45:17,597 Epoch [2/8], Batch [301/748], Loss: 0.8324
2024-06-24 01:46:08,576 Epoch [2/8], Batch [351/748], Loss: 0.7437
2024-06-24 01:46:59,541 Epoch [2/8], Batch [401/748], Loss: 0.6627
2024-06-24 01:47:50,450 Epoch [2/8], Batch [451/748], Loss: 0.8405
2024-06-24 01:48:41,346 Epoch [2/8], Batch [501/748], Loss: 0.7323
2024-06-24 01:49:32,321 Epoch [2/8], Batch [551/748], Loss: 0.6458
2024-06-24 01:50:23,070 Epoch [2/8], Batch [601/748], Loss: 0.6260
2024-06-24 01:51:14,300 Epoch [2/8], Batch [651/748], Loss: 0.5940
2024-06-24 01:52:05,719 Epoch [2/8], Batch [701/748], Loss: 0.6695
2024-06-24 01:52:53,324 Epoch 2/8, Train Loss: 0.8176, Train Accuracy: 0.6377
2024-06-24 01:54:19,247 Epoch 2/8, Val Loss: 0.8345, Val Accuracy: 0.6390
2024-06-24 01:54:20,270 Epoch [3/8], Batch [1/748], Loss: 0.5919
2024-06-24 01:55:10,758 Epoch [3/8], Batch [51/748], Loss: 0.7216
2024-06-24 01:56:01,620 Epoch [3/8], Batch [101/748], Loss: 0.7772
2024-06-24 01:56:52,549 Epoch [3/8], Batch [151/748], Loss: 0.8299
2024-06-24 01:57:43,587 Epoch [3/8], Batch [201/748], Loss: 0.8671
2024-06-24 01:58:34,496 Epoch [3/8], Batch [251/748], Loss: 0.7926
2024-06-24 01:59:25,454 Epoch [3/8], Batch [301/748], Loss: 0.6996
2024-06-24 02:00:16,405 Epoch [3/8], Batch [351/748], Loss: 0.8362
2024-06-24 02:01:07,261 Epoch [3/8], Batch [401/748], Loss: 0.7929
2024-06-24 02:01:58,170 Epoch [3/8], Batch [451/748], Loss: 0.8490
2024-06-24 02:02:49,200 Epoch [3/8], Batch [501/748], Loss: 0.5099
2024-06-24 02:03:40,251 Epoch [3/8], Batch [551/748], Loss: 0.7554
2024-06-24 02:04:31,080 Epoch [3/8], Batch [601/748], Loss: 0.6183
2024-06-24 02:05:22,016 Epoch [3/8], Batch [651/748], Loss: 0.8139
2024-06-24 02:06:12,988 Epoch [3/8], Batch [701/748], Loss: 0.5613
2024-06-24 02:07:00,904 Epoch 3/8, Train Loss: 0.7112, Train Accuracy: 0.6888
2024-06-24 02:08:26,692 Epoch 3/8, Val Loss: 0.7838, Val Accuracy: 0.6668
2024-06-24 02:08:27,718 Epoch [4/8], Batch [1/748], Loss: 0.6302
2024-06-24 02:09:18,578 Epoch [4/8], Batch [51/748], Loss: 0.6733
2024-06-24 02:10:09,604 Epoch [4/8], Batch [101/748], Loss: 0.5239
2024-06-24 02:11:00,659 Epoch [4/8], Batch [151/748], Loss: 0.6040
2024-06-24 02:11:51,518 Epoch [4/8], Batch [201/748], Loss: 0.5651
2024-06-24 02:12:42,633 Epoch [4/8], Batch [251/748], Loss: 0.6730
2024-06-24 02:13:33,314 Epoch [4/8], Batch [301/748], Loss: 0.6644
2024-06-24 02:14:24,305 Epoch [4/8], Batch [351/748], Loss: 0.5605
2024-06-24 02:15:15,314 Epoch [4/8], Batch [401/748], Loss: 0.6899
2024-06-24 02:16:06,183 Epoch [4/8], Batch [451/748], Loss: 0.6318
2024-06-24 02:16:57,074 Epoch [4/8], Batch [501/748], Loss: 0.4930
2024-06-24 02:17:47,425 Epoch [4/8], Batch [551/748], Loss: 0.4527
2024-06-24 02:18:37,904 Epoch [4/8], Batch [601/748], Loss: 0.5748
2024-06-24 02:19:28,268 Epoch [4/8], Batch [651/748], Loss: 0.5373
2024-06-24 02:20:18,966 Epoch [4/8], Batch [701/748], Loss: 0.4617
2024-06-24 02:21:06,138 Epoch 4/8, Train Loss: 0.5982, Train Accuracy: 0.7455
2024-06-24 02:22:31,186 Epoch 4/8, Val Loss: 0.7694, Val Accuracy: 0.6803
2024-06-24 02:22:32,206 Epoch [5/8], Batch [1/748], Loss: 0.4958
2024-06-24 02:23:22,556 Epoch [5/8], Batch [51/748], Loss: 0.3965
2024-06-24 02:24:13,250 Epoch [5/8], Batch [101/748], Loss: 0.3292
2024-06-24 02:25:04,238 Epoch [5/8], Batch [151/748], Loss: 0.3969
2024-06-24 02:25:55,224 Epoch [5/8], Batch [201/748], Loss: 0.4531
2024-06-24 02:26:45,781 Epoch [5/8], Batch [251/748], Loss: 0.3859
2024-06-24 02:27:36,632 Epoch [5/8], Batch [301/748], Loss: 0.3049
2024-06-24 02:28:27,327 Epoch [5/8], Batch [351/748], Loss: 0.5878
2024-06-24 02:29:17,806 Epoch [5/8], Batch [401/748], Loss: 0.5326
2024-06-24 02:30:08,269 Epoch [5/8], Batch [451/748], Loss: 0.4812
2024-06-24 02:30:58,690 Epoch [5/8], Batch [501/748], Loss: 0.5348
2024-06-24 02:31:49,294 Epoch [5/8], Batch [551/748], Loss: 0.6461
2024-06-24 02:32:40,150 Epoch [5/8], Batch [601/748], Loss: 0.5509
2024-06-24 02:33:30,864 Epoch [5/8], Batch [651/748], Loss: 0.5762
2024-06-24 02:34:21,095 Epoch [5/8], Batch [701/748], Loss: 0.4644
2024-06-24 02:35:08,330 Epoch 5/8, Train Loss: 0.5036, Train Accuracy: 0.7892
2024-06-24 02:36:33,169 Epoch 5/8, Val Loss: 0.7977, Val Accuracy: 0.6893
2024-06-24 02:36:34,178 Epoch [6/8], Batch [1/748], Loss: 0.4737
2024-06-24 02:37:24,264 Epoch [6/8], Batch [51/748], Loss: 0.3913
2024-06-24 02:38:14,654 Epoch [6/8], Batch [101/748], Loss: 0.5529
2024-06-24 02:39:05,433 Epoch [6/8], Batch [151/748], Loss: 0.3399
2024-06-24 02:39:56,078 Epoch [6/8], Batch [201/748], Loss: 0.2526
2024-06-24 02:40:46,985 Epoch [6/8], Batch [251/748], Loss: 0.4129
2024-06-24 02:41:37,365 Epoch [6/8], Batch [301/748], Loss: 0.4762
2024-06-24 02:42:28,105 Epoch [6/8], Batch [351/748], Loss: 0.5138
2024-06-24 02:43:18,842 Epoch [6/8], Batch [401/748], Loss: 0.5780
2024-06-24 02:44:09,400 Epoch [6/8], Batch [451/748], Loss: 0.4910
2024-06-24 02:45:00,119 Epoch [6/8], Batch [501/748], Loss: 0.4986
2024-06-24 02:45:50,593 Epoch [6/8], Batch [551/748], Loss: 0.2668
2024-06-24 02:46:41,183 Epoch [6/8], Batch [601/748], Loss: 0.3266
2024-06-24 02:47:31,758 Epoch [6/8], Batch [651/748], Loss: 0.4189
2024-06-24 02:48:22,335 Epoch [6/8], Batch [701/748], Loss: 0.6557
2024-06-24 02:49:09,428 Epoch 6/8, Train Loss: 0.4123, Train Accuracy: 0.8313
2024-06-24 02:50:34,073 Epoch 6/8, Val Loss: 0.8955, Val Accuracy: 0.6795
2024-06-24 02:50:35,076 Epoch [7/8], Batch [1/748], Loss: 0.2585
2024-06-24 02:51:25,246 Epoch [7/8], Batch [51/748], Loss: 0.3672
2024-06-24 02:52:15,984 Epoch [7/8], Batch [101/748], Loss: 0.4096
2024-06-24 02:53:06,803 Epoch [7/8], Batch [151/748], Loss: 0.3217
2024-06-24 02:53:57,418 Epoch [7/8], Batch [201/748], Loss: 0.3336
2024-06-24 02:54:47,788 Epoch [7/8], Batch [251/748], Loss: 0.6025
2024-06-24 02:55:38,714 Epoch [7/8], Batch [301/748], Loss: 0.1458
2024-06-24 02:56:29,796 Epoch [7/8], Batch [351/748], Loss: 0.1163
2024-06-24 02:57:20,688 Epoch [7/8], Batch [401/748], Loss: 0.2468
2024-06-24 02:58:11,624 Epoch [7/8], Batch [451/748], Loss: 0.1295
2024-06-24 02:59:02,610 Epoch [7/8], Batch [501/748], Loss: 0.4729
2024-06-24 02:59:53,430 Epoch [7/8], Batch [551/748], Loss: 0.3832
2024-06-24 03:00:44,618 Epoch [7/8], Batch [601/748], Loss: 0.3071
2024-06-24 03:01:35,562 Epoch [7/8], Batch [651/748], Loss: 0.2483
2024-06-24 03:02:26,601 Epoch [7/8], Batch [701/748], Loss: 0.1826
2024-06-24 03:03:13,970 Epoch 7/8, Train Loss: 0.3312, Train Accuracy: 0.8706
2024-06-24 03:04:38,700 Epoch 7/8, Val Loss: 0.9558, Val Accuracy: 0.6818
2024-06-24 03:04:39,731 Epoch [8/8], Batch [1/748], Loss: 0.2083
2024-06-24 03:05:30,052 Epoch [8/8], Batch [51/748], Loss: 0.2625
2024-06-24 03:06:20,908 Epoch [8/8], Batch [101/748], Loss: 0.1959
2024-06-24 03:07:11,823 Epoch [8/8], Batch [151/748], Loss: 0.2230
2024-06-24 03:08:02,787 Epoch [8/8], Batch [201/748], Loss: 0.1452
2024-06-24 03:08:53,673 Epoch [8/8], Batch [251/748], Loss: 0.1829
2024-06-24 03:09:44,620 Epoch [8/8], Batch [301/748], Loss: 0.0893
2024-06-24 03:10:35,538 Epoch [8/8], Batch [351/748], Loss: 0.3214
2024-06-24 03:11:26,499 Epoch [8/8], Batch [401/748], Loss: 0.2963
2024-06-24 03:12:17,549 Epoch [8/8], Batch [451/748], Loss: 0.1818
2024-06-24 03:13:08,475 Epoch [8/8], Batch [501/748], Loss: 0.1614
2024-06-24 03:13:59,135 Epoch [8/8], Batch [551/748], Loss: 0.2911
2024-06-24 03:14:49,551 Epoch [8/8], Batch [601/748], Loss: 0.1566
2024-06-24 03:15:40,307 Epoch [8/8], Batch [651/748], Loss: 0.2065
2024-06-24 03:16:30,848 Epoch [8/8], Batch [701/748], Loss: 0.5381
2024-06-24 03:17:17,859 Epoch 8/8, Train Loss: 0.2670, Train Accuracy: 0.8984
2024-06-24 03:18:42,775 Epoch 8/8, Val Loss: 1.0674, Val Accuracy: 0.6674
2024-06-24 03:18:42,777 Training finished!
2024-06-24 03:18:42,777 ==================================================
2024-06-24 03:18:48,186 ==================================================
2024-06-24 03:18:48,186 Training BERT + TF-IDF features with Dimension-8...
2024-06-24 03:18:49,179 Epoch [1/8], Batch [1/748], Loss: 1.6700
2024-06-24 03:19:39,349 Epoch [1/8], Batch [51/748], Loss: 1.5489
2024-06-24 03:20:30,125 Epoch [1/8], Batch [101/748], Loss: 1.4046
2024-06-24 03:21:20,840 Epoch [1/8], Batch [151/748], Loss: 1.2535
2024-06-24 03:22:11,737 Epoch [1/8], Batch [201/748], Loss: 1.0019
2024-06-24 03:23:02,695 Epoch [1/8], Batch [251/748], Loss: 1.0920
2024-06-24 03:23:53,106 Epoch [1/8], Batch [301/748], Loss: 1.0760
2024-06-24 03:24:43,691 Epoch [1/8], Batch [351/748], Loss: 1.0650
2024-06-24 03:25:34,502 Epoch [1/8], Batch [401/748], Loss: 1.1026
2024-06-24 03:26:25,031 Epoch [1/8], Batch [451/748], Loss: 0.9363
2024-06-24 03:27:15,617 Epoch [1/8], Batch [501/748], Loss: 0.8585
2024-06-24 03:28:06,386 Epoch [1/8], Batch [551/748], Loss: 0.8459
2024-06-24 03:28:57,512 Epoch [1/8], Batch [601/748], Loss: 1.0791
2024-06-24 03:29:48,396 Epoch [1/8], Batch [651/748], Loss: 1.0313
2024-06-24 03:30:39,417 Epoch [1/8], Batch [701/748], Loss: 0.9679
2024-06-24 03:31:26,699 Epoch 1/8, Train Loss: 1.1006, Train Accuracy: 0.5299
2024-06-24 03:32:51,944 Epoch 1/8, Val Loss: 0.8632, Val Accuracy: 0.6258
2024-06-24 03:32:53,013 Epoch [2/8], Batch [1/748], Loss: 0.8955
2024-06-24 03:33:43,773 Epoch [2/8], Batch [51/748], Loss: 0.8922
2024-06-24 03:34:34,907 Epoch [2/8], Batch [101/748], Loss: 0.8734
2024-06-24 03:35:25,787 Epoch [2/8], Batch [151/748], Loss: 0.8226
2024-06-24 03:36:16,772 Epoch [2/8], Batch [201/748], Loss: 0.7080
2024-06-24 03:37:07,669 Epoch [2/8], Batch [251/748], Loss: 0.5374
2024-06-24 03:37:58,589 Epoch [2/8], Batch [301/748], Loss: 0.9686
2024-06-24 03:38:49,182 Epoch [2/8], Batch [351/748], Loss: 1.0539
2024-06-24 03:39:39,604 Epoch [2/8], Batch [401/748], Loss: 1.0674
2024-06-24 03:40:30,190 Epoch [2/8], Batch [451/748], Loss: 0.8209
2024-06-24 03:41:20,714 Epoch [2/8], Batch [501/748], Loss: 0.8393
2024-06-24 03:42:11,405 Epoch [2/8], Batch [551/748], Loss: 0.7026
2024-06-24 03:43:02,257 Epoch [2/8], Batch [601/748], Loss: 0.6845
2024-06-24 03:43:52,849 Epoch [2/8], Batch [651/748], Loss: 0.6670
2024-06-24 03:44:43,497 Epoch [2/8], Batch [701/748], Loss: 0.8515
2024-06-24 03:45:30,780 Epoch 2/8, Train Loss: 0.8080, Train Accuracy: 0.6480
2024-06-24 03:46:56,101 Epoch 2/8, Val Loss: 0.8044, Val Accuracy: 0.6387
2024-06-24 03:46:57,125 Epoch [3/8], Batch [1/748], Loss: 0.7382
2024-06-24 03:47:47,760 Epoch [3/8], Batch [51/748], Loss: 0.3846
2024-06-24 03:48:38,403 Epoch [3/8], Batch [101/748], Loss: 0.8134
2024-06-24 03:49:28,852 Epoch [3/8], Batch [151/748], Loss: 0.5653
2024-06-24 03:50:19,465 Epoch [3/8], Batch [201/748], Loss: 0.7809
2024-06-24 03:51:10,265 Epoch [3/8], Batch [251/748], Loss: 0.7574
2024-06-24 03:52:00,629 Epoch [3/8], Batch [301/748], Loss: 0.8287
2024-06-24 03:52:51,543 Epoch [3/8], Batch [351/748], Loss: 0.7202
2024-06-24 03:53:42,387 Epoch [3/8], Batch [401/748], Loss: 0.5412
2024-06-24 03:54:33,125 Epoch [3/8], Batch [451/748], Loss: 0.6502
2024-06-24 03:55:23,784 Epoch [3/8], Batch [501/748], Loss: 0.7356
2024-06-24 03:56:14,207 Epoch [3/8], Batch [551/748], Loss: 0.7563
2024-06-24 03:57:05,189 Epoch [3/8], Batch [601/748], Loss: 0.7189
2024-06-24 03:57:56,220 Epoch [3/8], Batch [651/748], Loss: 0.7502
2024-06-24 03:58:46,818 Epoch [3/8], Batch [701/748], Loss: 0.6930
2024-06-24 03:59:33,837 Epoch 3/8, Train Loss: 0.6834, Train Accuracy: 0.7052
2024-06-24 04:00:58,807 Epoch 3/8, Val Loss: 0.7975, Val Accuracy: 0.6636
2024-06-24 04:00:59,790 Epoch [4/8], Batch [1/748], Loss: 0.4950
2024-06-24 04:01:50,236 Epoch [4/8], Batch [51/748], Loss: 0.4260
2024-06-24 04:02:40,975 Epoch [4/8], Batch [101/748], Loss: 0.6168
2024-06-24 04:03:31,509 Epoch [4/8], Batch [151/748], Loss: 0.5729
2024-06-24 04:04:21,771 Epoch [4/8], Batch [201/748], Loss: 0.4413
2024-06-24 04:05:12,539 Epoch [4/8], Batch [251/748], Loss: 0.4475
2024-06-24 04:06:03,041 Epoch [4/8], Batch [301/748], Loss: 0.5940
2024-06-24 04:06:53,506 Epoch [4/8], Batch [351/748], Loss: 0.4322
2024-06-24 04:07:44,395 Epoch [4/8], Batch [401/748], Loss: 0.3357
2024-06-24 04:08:34,753 Epoch [4/8], Batch [451/748], Loss: 0.7267
2024-06-24 04:09:25,441 Epoch [4/8], Batch [501/748], Loss: 0.5177
2024-06-24 04:10:16,221 Epoch [4/8], Batch [551/748], Loss: 0.5696
2024-06-24 04:11:06,539 Epoch [4/8], Batch [601/748], Loss: 0.6584
2024-06-24 04:11:57,222 Epoch [4/8], Batch [651/748], Loss: 0.8781
2024-06-24 04:12:47,818 Epoch [4/8], Batch [701/748], Loss: 0.5255
2024-06-24 04:13:34,889 Epoch 4/8, Train Loss: 0.5722, Train Accuracy: 0.7567
2024-06-24 04:14:59,755 Epoch 4/8, Val Loss: 0.8145, Val Accuracy: 0.6616
2024-06-24 04:15:00,769 Epoch [5/8], Batch [1/748], Loss: 0.8226
2024-06-24 04:15:51,489 Epoch [5/8], Batch [51/748], Loss: 0.3899
2024-06-24 04:16:41,983 Epoch [5/8], Batch [101/748], Loss: 0.5525
2024-06-24 04:17:32,658 Epoch [5/8], Batch [151/748], Loss: 0.6273
2024-06-24 04:18:23,487 Epoch [5/8], Batch [201/748], Loss: 0.2213
2024-06-24 04:19:14,364 Epoch [5/8], Batch [251/748], Loss: 0.6452
2024-06-24 04:20:05,030 Epoch [5/8], Batch [301/748], Loss: 0.4168
2024-06-24 04:20:55,428 Epoch [5/8], Batch [351/748], Loss: 0.8331
2024-06-24 04:21:46,272 Epoch [5/8], Batch [401/748], Loss: 0.4237
2024-06-24 04:22:37,048 Epoch [5/8], Batch [451/748], Loss: 0.4446
2024-06-24 04:23:27,483 Epoch [5/8], Batch [501/748], Loss: 0.5139
2024-06-24 04:24:18,103 Epoch [5/8], Batch [551/748], Loss: 0.4079
2024-06-24 04:25:08,359 Epoch [5/8], Batch [601/748], Loss: 0.4452
2024-06-24 04:25:58,728 Epoch [5/8], Batch [651/748], Loss: 0.5898
2024-06-24 04:26:49,048 Epoch [5/8], Batch [701/748], Loss: 0.4944
2024-06-24 04:27:36,174 Epoch 5/8, Train Loss: 0.4724, Train Accuracy: 0.8021
2024-06-24 04:29:01,376 Epoch 5/8, Val Loss: 0.8496, Val Accuracy: 0.6730
2024-06-24 04:29:02,409 Epoch [6/8], Batch [1/748], Loss: 0.3649
2024-06-24 04:29:52,744 Epoch [6/8], Batch [51/748], Loss: 0.3227
2024-06-24 04:30:43,461 Epoch [6/8], Batch [101/748], Loss: 0.2377
2024-06-24 04:31:33,742 Epoch [6/8], Batch [151/748], Loss: 0.2998
2024-06-24 04:32:24,113 Epoch [6/8], Batch [201/748], Loss: 0.4508
2024-06-24 04:33:14,624 Epoch [6/8], Batch [251/748], Loss: 0.2449
2024-06-24 04:34:05,176 Epoch [6/8], Batch [301/748], Loss: 0.3339
2024-06-24 04:34:55,856 Epoch [6/8], Batch [351/748], Loss: 0.3080
2024-06-24 04:35:46,439 Epoch [6/8], Batch [401/748], Loss: 0.4038
2024-06-24 04:36:37,141 Epoch [6/8], Batch [451/748], Loss: 0.3128
2024-06-24 04:37:27,647 Epoch [6/8], Batch [501/748], Loss: 0.2970
2024-06-24 04:38:17,938 Epoch [6/8], Batch [551/748], Loss: 0.3789
2024-06-24 04:39:08,578 Epoch [6/8], Batch [601/748], Loss: 0.4484
2024-06-24 04:39:59,021 Epoch [6/8], Batch [651/748], Loss: 0.2545
2024-06-24 04:40:49,749 Epoch [6/8], Batch [701/748], Loss: 0.1971
2024-06-24 04:41:36,695 Epoch 6/8, Train Loss: 0.3828, Train Accuracy: 0.8422
2024-06-24 04:43:02,258 Epoch 6/8, Val Loss: 0.9578, Val Accuracy: 0.6574
2024-06-24 04:43:03,268 Epoch [7/8], Batch [1/748], Loss: 0.5836
2024-06-24 04:43:53,957 Epoch [7/8], Batch [51/748], Loss: 0.1713
2024-06-24 04:44:44,193 Epoch [7/8], Batch [101/748], Loss: 0.2925
2024-06-24 04:45:35,079 Epoch [7/8], Batch [151/748], Loss: 0.4734
2024-06-24 04:46:26,060 Epoch [7/8], Batch [201/748], Loss: 0.5170
2024-06-24 04:47:16,984 Epoch [7/8], Batch [251/748], Loss: 0.5259
2024-06-24 04:48:07,853 Epoch [7/8], Batch [301/748], Loss: 0.4913
2024-06-24 04:48:58,477 Epoch [7/8], Batch [351/748], Loss: 0.1748
2024-06-24 04:49:48,732 Epoch [7/8], Batch [401/748], Loss: 0.2952
2024-06-24 04:50:39,275 Epoch [7/8], Batch [451/748], Loss: 0.2412
2024-06-24 04:51:29,842 Epoch [7/8], Batch [501/748], Loss: 0.3041
2024-06-24 04:52:20,779 Epoch [7/8], Batch [551/748], Loss: 0.2715
2024-06-24 04:53:11,778 Epoch [7/8], Batch [601/748], Loss: 0.3305
2024-06-24 04:54:02,114 Epoch [7/8], Batch [651/748], Loss: 0.3010
2024-06-24 04:54:52,581 Epoch [7/8], Batch [701/748], Loss: 0.3491
2024-06-24 04:55:40,090 Epoch 7/8, Train Loss: 0.3150, Train Accuracy: 0.8742
2024-06-24 04:57:05,177 Epoch 7/8, Val Loss: 0.9735, Val Accuracy: 0.6773
2024-06-24 04:57:06,175 Epoch [8/8], Batch [1/748], Loss: 0.4026
2024-06-24 04:57:56,716 Epoch [8/8], Batch [51/748], Loss: 0.3620
2024-06-24 04:58:47,317 Epoch [8/8], Batch [101/748], Loss: 0.1830
2024-06-24 04:59:37,956 Epoch [8/8], Batch [151/748], Loss: 0.1620
2024-06-24 05:00:28,769 Epoch [8/8], Batch [201/748], Loss: 0.1793
2024-06-24 05:01:19,328 Epoch [8/8], Batch [251/748], Loss: 0.5143
2024-06-24 05:02:09,783 Epoch [8/8], Batch [301/748], Loss: 0.2015
2024-06-24 05:03:00,779 Epoch [8/8], Batch [351/748], Loss: 0.1633
2024-06-24 05:03:51,331 Epoch [8/8], Batch [401/748], Loss: 0.3184
2024-06-24 05:04:41,835 Epoch [8/8], Batch [451/748], Loss: 0.2076
2024-06-24 05:05:32,308 Epoch [8/8], Batch [501/748], Loss: 0.1800
2024-06-24 05:06:22,618 Epoch [8/8], Batch [551/748], Loss: 0.2265
2024-06-24 05:07:13,360 Epoch [8/8], Batch [601/748], Loss: 0.3943
2024-06-24 05:08:03,665 Epoch [8/8], Batch [651/748], Loss: 0.1037
2024-06-24 05:08:54,334 Epoch [8/8], Batch [701/748], Loss: 0.1942
2024-06-24 05:09:41,156 Epoch 8/8, Train Loss: 0.2531, Train Accuracy: 0.9026
2024-06-24 05:11:06,183 Epoch 8/8, Val Loss: 1.0459, Val Accuracy: 0.6781
2024-06-24 05:11:06,185 Training finished!
2024-06-24 05:11:06,185 ==================================================
2024-06-24 05:11:12,294 ==================================================
2024-06-24 05:11:12,294 Training BERT + TF-IDF features with Dimension-4096...
2024-06-24 05:11:13,322 Epoch [1/8], Batch [1/748], Loss: 1.6101
2024-06-24 05:12:03,603 Epoch [1/8], Batch [51/748], Loss: 1.5641
2024-06-24 05:12:54,209 Epoch [1/8], Batch [101/748], Loss: 1.3014
2024-06-24 05:13:44,941 Epoch [1/8], Batch [151/748], Loss: 1.1570
2024-06-24 05:14:36,050 Epoch [1/8], Batch [201/748], Loss: 1.1206
2024-06-24 05:15:26,903 Epoch [1/8], Batch [251/748], Loss: 0.9471
2024-06-24 05:16:17,924 Epoch [1/8], Batch [301/748], Loss: 1.1770
2024-06-24 05:17:08,768 Epoch [1/8], Batch [351/748], Loss: 0.9786
2024-06-24 05:17:59,355 Epoch [1/8], Batch [401/748], Loss: 0.7026
2024-06-24 05:18:50,097 Epoch [1/8], Batch [451/748], Loss: 0.9991
2024-06-24 05:19:40,674 Epoch [1/8], Batch [501/748], Loss: 1.0446
2024-06-24 05:20:31,697 Epoch [1/8], Batch [551/748], Loss: 0.7262
2024-06-24 05:21:22,564 Epoch [1/8], Batch [601/748], Loss: 1.0344
2024-06-24 05:22:13,029 Epoch [1/8], Batch [651/748], Loss: 0.9672
2024-06-24 05:23:03,616 Epoch [1/8], Batch [701/748], Loss: 0.9335
2024-06-24 05:23:51,072 Epoch 1/8, Train Loss: 1.0854, Train Accuracy: 0.5331
2024-06-24 05:25:15,425 Epoch 1/8, Val Loss: 0.9016, Val Accuracy: 0.5986
2024-06-24 05:25:16,431 Epoch [2/8], Batch [1/748], Loss: 0.9638
2024-06-24 05:26:06,901 Epoch [2/8], Batch [51/748], Loss: 1.0540
2024-06-24 05:26:57,782 Epoch [2/8], Batch [101/748], Loss: 0.9879
2024-06-24 05:27:48,293 Epoch [2/8], Batch [151/748], Loss: 0.9107
2024-06-24 05:28:38,822 Epoch [2/8], Batch [201/748], Loss: 0.7039
2024-06-24 05:29:29,793 Epoch [2/8], Batch [251/748], Loss: 0.7816
2024-06-24 05:30:20,654 Epoch [2/8], Batch [301/748], Loss: 0.7304
2024-06-24 05:31:11,376 Epoch [2/8], Batch [351/748], Loss: 1.0084
2024-06-24 05:32:01,802 Epoch [2/8], Batch [401/748], Loss: 0.6938
2024-06-24 05:32:52,746 Epoch [2/8], Batch [451/748], Loss: 0.8072
2024-06-24 05:33:43,506 Epoch [2/8], Batch [501/748], Loss: 0.8361
2024-06-24 05:34:34,158 Epoch [2/8], Batch [551/748], Loss: 1.0811
2024-06-24 05:35:24,827 Epoch [2/8], Batch [601/748], Loss: 0.7510
2024-06-24 05:36:15,417 Epoch [2/8], Batch [651/748], Loss: 0.6456
2024-06-24 05:37:06,412 Epoch [2/8], Batch [701/748], Loss: 1.0817
2024-06-24 05:37:53,768 Epoch 2/8, Train Loss: 0.8211, Train Accuracy: 0.6344
2024-06-24 05:39:18,040 Epoch 2/8, Val Loss: 0.8206, Val Accuracy: 0.6342
2024-06-24 05:39:19,065 Epoch [3/8], Batch [1/748], Loss: 0.7914
2024-06-24 05:40:09,458 Epoch [3/8], Batch [51/748], Loss: 0.5308
2024-06-24 05:41:00,227 Epoch [3/8], Batch [101/748], Loss: 0.7260
2024-06-24 05:41:50,789 Epoch [3/8], Batch [151/748], Loss: 0.8415
2024-06-24 05:42:41,832 Epoch [3/8], Batch [201/748], Loss: 0.8900
2024-06-24 05:43:32,784 Epoch [3/8], Batch [251/748], Loss: 1.0488
2024-06-24 05:44:23,657 Epoch [3/8], Batch [301/748], Loss: 0.7920
2024-06-24 05:45:14,303 Epoch [3/8], Batch [351/748], Loss: 0.6026
2024-06-24 05:46:04,647 Epoch [3/8], Batch [401/748], Loss: 0.5919
2024-06-24 05:46:55,541 Epoch [3/8], Batch [451/748], Loss: 1.0412
2024-06-24 05:47:46,437 Epoch [3/8], Batch [501/748], Loss: 0.7808
2024-06-24 05:48:37,447 Epoch [3/8], Batch [551/748], Loss: 0.6927
2024-06-24 05:49:28,208 Epoch [3/8], Batch [601/748], Loss: 0.7822
2024-06-24 05:50:18,649 Epoch [3/8], Batch [651/748], Loss: 0.7528
2024-06-24 05:51:09,495 Epoch [3/8], Batch [701/748], Loss: 0.5366
2024-06-24 05:51:56,960 Epoch 3/8, Train Loss: 0.7279, Train Accuracy: 0.6786
2024-06-24 05:53:21,446 Epoch 3/8, Val Loss: 0.8528, Val Accuracy: 0.6303
2024-06-24 05:53:22,442 Epoch [4/8], Batch [1/748], Loss: 0.6175
2024-06-24 05:54:12,763 Epoch [4/8], Batch [51/748], Loss: 0.5612
2024-06-24 05:55:03,600 Epoch [4/8], Batch [101/748], Loss: 0.7301
2024-06-24 05:55:53,979 Epoch [4/8], Batch [151/748], Loss: 0.5007
2024-06-24 05:56:44,691 Epoch [4/8], Batch [201/748], Loss: 0.7235
2024-06-24 05:57:35,535 Epoch [4/8], Batch [251/748], Loss: 0.7577
2024-06-24 05:58:26,394 Epoch [4/8], Batch [301/748], Loss: 0.8282
2024-06-24 05:59:17,378 Epoch [4/8], Batch [351/748], Loss: 0.7877
2024-06-24 06:00:07,992 Epoch [4/8], Batch [401/748], Loss: 0.7210
2024-06-24 06:00:58,447 Epoch [4/8], Batch [451/748], Loss: 0.7045
2024-06-24 06:01:49,279 Epoch [4/8], Batch [501/748], Loss: 0.5015
2024-06-24 06:02:40,470 Epoch [4/8], Batch [551/748], Loss: 0.7984
2024-06-24 06:03:31,017 Epoch [4/8], Batch [601/748], Loss: 0.6077
2024-06-24 06:04:22,072 Epoch [4/8], Batch [651/748], Loss: 0.4772
2024-06-24 06:05:13,081 Epoch [4/8], Batch [701/748], Loss: 0.7180
2024-06-24 06:06:00,621 Epoch 4/8, Train Loss: 0.6504, Train Accuracy: 0.7115
2024-06-24 06:07:25,194 Epoch 4/8, Val Loss: 0.7995, Val Accuracy: 0.6554
2024-06-24 06:07:26,168 Epoch [5/8], Batch [1/748], Loss: 0.6991
2024-06-24 06:08:16,482 Epoch [5/8], Batch [51/748], Loss: 0.4576
2024-06-24 06:09:06,964 Epoch [5/8], Batch [101/748], Loss: 0.5555
2024-06-24 06:09:57,412 Epoch [5/8], Batch [151/748], Loss: 0.6967
2024-06-24 06:10:48,432 Epoch [5/8], Batch [201/748], Loss: 0.6822
2024-06-24 06:11:39,419 Epoch [5/8], Batch [251/748], Loss: 0.5605
2024-06-24 06:12:30,263 Epoch [5/8], Batch [301/748], Loss: 0.3288
2024-06-24 06:13:21,228 Epoch [5/8], Batch [351/748], Loss: 0.4500
2024-06-24 06:14:12,276 Epoch [5/8], Batch [401/748], Loss: 0.5280
2024-06-24 06:15:03,253 Epoch [5/8], Batch [451/748], Loss: 0.3961
2024-06-24 06:15:53,629 Epoch [5/8], Batch [501/748], Loss: 0.3933
2024-06-24 06:16:44,427 Epoch [5/8], Batch [551/748], Loss: 0.5878
2024-06-24 06:17:35,099 Epoch [5/8], Batch [601/748], Loss: 0.5544
2024-06-24 06:18:26,038 Epoch [5/8], Batch [651/748], Loss: 0.7508
2024-06-24 06:19:16,993 Epoch [5/8], Batch [701/748], Loss: 0.4685
2024-06-24 06:20:04,437 Epoch 5/8, Train Loss: 0.5586, Train Accuracy: 0.7580
2024-06-24 06:21:29,089 Epoch 5/8, Val Loss: 0.8968, Val Accuracy: 0.6522
2024-06-24 06:21:30,101 Epoch [6/8], Batch [1/748], Loss: 0.5833
2024-06-24 06:22:20,584 Epoch [6/8], Batch [51/748], Loss: 0.3864
2024-06-24 06:23:11,494 Epoch [6/8], Batch [101/748], Loss: 0.3832
2024-06-24 06:24:01,994 Epoch [6/8], Batch [151/748], Loss: 0.3051
2024-06-24 06:24:52,589 Epoch [6/8], Batch [201/748], Loss: 0.4207
2024-06-24 06:25:43,205 Epoch [6/8], Batch [251/748], Loss: 0.4331
2024-06-24 06:26:34,007 Epoch [6/8], Batch [301/748], Loss: 0.4550
2024-06-24 06:27:24,414 Epoch [6/8], Batch [351/748], Loss: 0.5989
2024-06-24 06:28:15,062 Epoch [6/8], Batch [401/748], Loss: 0.4534
2024-06-24 06:29:06,018 Epoch [6/8], Batch [451/748], Loss: 0.4752
2024-06-24 06:29:56,954 Epoch [6/8], Batch [501/748], Loss: 0.6360
2024-06-24 06:30:48,023 Epoch [6/8], Batch [551/748], Loss: 0.3875
2024-06-24 06:31:38,921 Epoch [6/8], Batch [601/748], Loss: 0.6155
2024-06-24 06:32:29,654 Epoch [6/8], Batch [651/748], Loss: 0.4702
2024-06-24 06:33:20,021 Epoch [6/8], Batch [701/748], Loss: 0.6811
2024-06-24 06:34:07,297 Epoch 6/8, Train Loss: 0.4762, Train Accuracy: 0.7961
2024-06-24 06:35:32,396 Epoch 6/8, Val Loss: 0.9560, Val Accuracy: 0.6467
2024-06-24 06:35:33,396 Epoch [7/8], Batch [1/748], Loss: 0.3551
2024-06-24 06:36:24,064 Epoch [7/8], Batch [51/748], Loss: 0.6261
2024-06-24 06:37:14,571 Epoch [7/8], Batch [101/748], Loss: 0.3057
2024-06-24 06:38:05,093 Epoch [7/8], Batch [151/748], Loss: 0.3046
2024-06-24 06:38:56,170 Epoch [7/8], Batch [201/748], Loss: 0.3054
2024-06-24 06:39:47,098 Epoch [7/8], Batch [251/748], Loss: 0.3454
2024-06-24 06:40:37,712 Epoch [7/8], Batch [301/748], Loss: 0.4412
2024-06-24 06:41:28,160 Epoch [7/8], Batch [351/748], Loss: 0.2807
2024-06-24 06:42:18,936 Epoch [7/8], Batch [401/748], Loss: 0.4663
2024-06-24 06:43:09,888 Epoch [7/8], Batch [451/748], Loss: 0.3986
2024-06-24 06:44:00,535 Epoch [7/8], Batch [501/748], Loss: 0.4970
2024-06-24 06:44:51,404 Epoch [7/8], Batch [551/748], Loss: 0.5243
2024-06-24 06:45:42,038 Epoch [7/8], Batch [601/748], Loss: 0.4240
2024-06-24 06:46:32,737 Epoch [7/8], Batch [651/748], Loss: 0.3539
2024-06-24 06:47:23,609 Epoch [7/8], Batch [701/748], Loss: 0.6200
2024-06-24 06:48:10,864 Epoch 7/8, Train Loss: 0.3987, Train Accuracy: 0.8338
2024-06-24 06:49:35,499 Epoch 7/8, Val Loss: 1.0044, Val Accuracy: 0.6492
2024-06-24 06:49:36,526 Epoch [8/8], Batch [1/748], Loss: 0.2105
2024-06-24 06:50:26,820 Epoch [8/8], Batch [51/748], Loss: 0.2387
2024-06-24 06:51:17,452 Epoch [8/8], Batch [101/748], Loss: 0.2565
2024-06-24 06:52:08,017 Epoch [8/8], Batch [151/748], Loss: 0.3116
2024-06-24 06:52:58,961 Epoch [8/8], Batch [201/748], Loss: 0.4109
2024-06-24 06:53:49,341 Epoch [8/8], Batch [251/748], Loss: 0.6619
2024-06-24 06:54:39,830 Epoch [8/8], Batch [301/748], Loss: 0.1975
2024-06-24 06:55:30,215 Epoch [8/8], Batch [351/748], Loss: 0.3550
2024-06-24 06:56:20,750 Epoch [8/8], Batch [401/748], Loss: 0.4731
2024-06-24 06:57:11,714 Epoch [8/8], Batch [451/748], Loss: 0.3077
2024-06-24 06:58:02,528 Epoch [8/8], Batch [501/748], Loss: 0.2490
2024-06-24 06:58:53,270 Epoch [8/8], Batch [551/748], Loss: 0.2869
2024-06-24 06:59:44,000 Epoch [8/8], Batch [601/748], Loss: 0.2050
2024-06-24 07:00:34,740 Epoch [8/8], Batch [651/748], Loss: 0.2315
2024-06-24 07:01:25,536 Epoch [8/8], Batch [701/748], Loss: 0.3187
2024-06-24 07:02:12,496 Epoch 8/8, Train Loss: 0.3329, Train Accuracy: 0.8680
2024-06-24 07:03:37,314 Epoch 8/8, Val Loss: 1.0133, Val Accuracy: 0.6577
2024-06-24 07:03:37,316 Training finished!
2024-06-24 07:03:37,316 ==================================================
2024-06-24 07:03:43,198 ==================================================
2024-06-24 07:03:43,198 Training BERT + TF-IDF features with Dimension-2048...
2024-06-24 07:03:44,219 Epoch [1/8], Batch [1/748], Loss: 1.5867
2024-06-24 07:04:34,853 Epoch [1/8], Batch [51/748], Loss: 1.5389
2024-06-24 07:05:25,526 Epoch [1/8], Batch [101/748], Loss: 1.3083
2024-06-24 07:06:16,323 Epoch [1/8], Batch [151/748], Loss: 1.1565
2024-06-24 07:07:06,895 Epoch [1/8], Batch [201/748], Loss: 1.3343
2024-06-24 07:07:57,701 Epoch [1/8], Batch [251/748], Loss: 1.1000
2024-06-24 07:08:48,798 Epoch [1/8], Batch [301/748], Loss: 1.0882
2024-06-24 07:09:39,940 Epoch [1/8], Batch [351/748], Loss: 0.9214
2024-06-24 07:10:31,174 Epoch [1/8], Batch [401/748], Loss: 1.0616
2024-06-24 07:11:22,107 Epoch [1/8], Batch [451/748], Loss: 0.7362
2024-06-24 07:12:13,204 Epoch [1/8], Batch [501/748], Loss: 0.8372
2024-06-24 07:13:04,372 Epoch [1/8], Batch [551/748], Loss: 0.7833
2024-06-24 07:13:55,485 Epoch [1/8], Batch [601/748], Loss: 1.1301
2024-06-24 07:14:46,603 Epoch [1/8], Batch [651/748], Loss: 1.0405
2024-06-24 07:15:37,096 Epoch [1/8], Batch [701/748], Loss: 1.2068
2024-06-24 07:16:24,268 Epoch 1/8, Train Loss: 1.0949, Train Accuracy: 0.5246
2024-06-24 07:17:49,020 Epoch 1/8, Val Loss: 0.9243, Val Accuracy: 0.6026
2024-06-24 07:17:50,017 Epoch [2/8], Batch [1/748], Loss: 1.0524
2024-06-24 07:18:40,500 Epoch [2/8], Batch [51/748], Loss: 0.8329
2024-06-24 07:19:31,012 Epoch [2/8], Batch [101/748], Loss: 1.0864
2024-06-24 07:20:21,891 Epoch [2/8], Batch [151/748], Loss: 0.6054
2024-06-24 07:21:12,584 Epoch [2/8], Batch [201/748], Loss: 0.8113
2024-06-24 07:22:03,166 Epoch [2/8], Batch [251/748], Loss: 0.8057
2024-06-24 07:22:54,069 Epoch [2/8], Batch [301/748], Loss: 0.9795
2024-06-24 07:23:44,651 Epoch [2/8], Batch [351/748], Loss: 0.8844
2024-06-24 07:24:35,120 Epoch [2/8], Batch [401/748], Loss: 0.6497
2024-06-24 07:25:25,852 Epoch [2/8], Batch [451/748], Loss: 0.8522
2024-06-24 07:26:16,397 Epoch [2/8], Batch [501/748], Loss: 0.7283
2024-06-24 07:27:07,185 Epoch [2/8], Batch [551/748], Loss: 1.0066
2024-06-24 07:27:57,830 Epoch [2/8], Batch [601/748], Loss: 0.7282
2024-06-24 07:28:48,617 Epoch [2/8], Batch [651/748], Loss: 0.9229
2024-06-24 07:29:39,072 Epoch [2/8], Batch [701/748], Loss: 0.6847
2024-06-24 07:30:26,244 Epoch 2/8, Train Loss: 0.8212, Train Accuracy: 0.6367
2024-06-24 07:31:51,409 Epoch 2/8, Val Loss: 0.8413, Val Accuracy: 0.6313
2024-06-24 07:31:52,422 Epoch [3/8], Batch [1/748], Loss: 0.8845
2024-06-24 07:32:43,397 Epoch [3/8], Batch [51/748], Loss: 0.7730
2024-06-24 07:33:34,201 Epoch [3/8], Batch [101/748], Loss: 0.6079
2024-06-24 07:34:25,269 Epoch [3/8], Batch [151/748], Loss: 0.8228
2024-06-24 07:35:16,148 Epoch [3/8], Batch [201/748], Loss: 0.7048
2024-06-24 07:36:07,064 Epoch [3/8], Batch [251/748], Loss: 0.7462
2024-06-24 07:36:58,035 Epoch [3/8], Batch [301/748], Loss: 0.6144
2024-06-24 07:37:48,634 Epoch [3/8], Batch [351/748], Loss: 0.8683
2024-06-24 07:38:39,284 Epoch [3/8], Batch [401/748], Loss: 0.7466
2024-06-24 07:39:29,836 Epoch [3/8], Batch [451/748], Loss: 0.5718
2024-06-24 07:40:20,773 Epoch [3/8], Batch [501/748], Loss: 0.7495
2024-06-24 07:41:11,787 Epoch [3/8], Batch [551/748], Loss: 0.7440
2024-06-24 07:42:02,589 Epoch [3/8], Batch [601/748], Loss: 0.7162
2024-06-24 07:42:53,302 Epoch [3/8], Batch [651/748], Loss: 0.5868
2024-06-24 07:43:43,854 Epoch [3/8], Batch [701/748], Loss: 0.8352
2024-06-24 07:44:31,432 Epoch 3/8, Train Loss: 0.7205, Train Accuracy: 0.6759
2024-06-24 07:45:56,294 Epoch 3/8, Val Loss: 0.9341, Val Accuracy: 0.6061
2024-06-24 07:45:57,290 Epoch [4/8], Batch [1/748], Loss: 0.6819
2024-06-24 07:46:48,258 Epoch [4/8], Batch [51/748], Loss: 0.4672
2024-06-24 07:47:38,891 Epoch [4/8], Batch [101/748], Loss: 0.6549
2024-06-24 07:48:29,610 Epoch [4/8], Batch [151/748], Loss: 0.8318
2024-06-24 07:49:20,095 Epoch [4/8], Batch [201/748], Loss: 0.9056
2024-06-24 07:50:11,002 Epoch [4/8], Batch [251/748], Loss: 0.5903
2024-06-24 07:51:01,832 Epoch [4/8], Batch [301/748], Loss: 0.7107
2024-06-24 07:51:52,239 Epoch [4/8], Batch [351/748], Loss: 0.6366
2024-06-24 07:52:43,129 Epoch [4/8], Batch [401/748], Loss: 0.7966
2024-06-24 07:53:33,711 Epoch [4/8], Batch [451/748], Loss: 0.5704
2024-06-24 07:54:24,311 Epoch [4/8], Batch [501/748], Loss: 0.5272
2024-06-24 07:55:14,857 Epoch [4/8], Batch [551/748], Loss: 0.5156
2024-06-24 07:56:05,645 Epoch [4/8], Batch [601/748], Loss: 0.5668
2024-06-24 07:56:56,731 Epoch [4/8], Batch [651/748], Loss: 0.5137
2024-06-24 07:57:47,651 Epoch [4/8], Batch [701/748], Loss: 0.5890
2024-06-24 07:58:35,128 Epoch 4/8, Train Loss: 0.6255, Train Accuracy: 0.7193
2024-06-24 08:00:00,005 Epoch 4/8, Val Loss: 0.9190, Val Accuracy: 0.6320
2024-06-24 08:00:01,004 Epoch [5/8], Batch [1/748], Loss: 0.5705
2024-06-24 08:00:51,250 Epoch [5/8], Batch [51/748], Loss: 0.3653
2024-06-24 08:01:41,647 Epoch [5/8], Batch [101/748], Loss: 0.5135
2024-06-24 08:02:32,805 Epoch [5/8], Batch [151/748], Loss: 0.6479
2024-06-24 08:03:23,347 Epoch [5/8], Batch [201/748], Loss: 0.4343
2024-06-24 08:04:13,620 Epoch [5/8], Batch [251/748], Loss: 0.3910
2024-06-24 08:05:04,394 Epoch [5/8], Batch [301/748], Loss: 0.4202
2024-06-24 08:05:54,913 Epoch [5/8], Batch [351/748], Loss: 0.6193
2024-06-24 08:06:45,875 Epoch [5/8], Batch [401/748], Loss: 0.5337
2024-06-24 08:07:36,815 Epoch [5/8], Batch [451/748], Loss: 0.5182
2024-06-24 08:08:27,537 Epoch [5/8], Batch [501/748], Loss: 0.6051
2024-06-24 08:09:18,115 Epoch [5/8], Batch [551/748], Loss: 0.3593
2024-06-24 08:10:08,658 Epoch [5/8], Batch [601/748], Loss: 0.6854
2024-06-24 08:10:59,661 Epoch [5/8], Batch [651/748], Loss: 0.8293
2024-06-24 08:11:50,506 Epoch [5/8], Batch [701/748], Loss: 0.7961
2024-06-24 08:12:38,237 Epoch 5/8, Train Loss: 0.5366, Train Accuracy: 0.7618
2024-06-24 08:14:02,868 Epoch 5/8, Val Loss: 0.8566, Val Accuracy: 0.6567
2024-06-24 08:14:03,875 Epoch [6/8], Batch [1/748], Loss: 0.4623
2024-06-24 08:14:54,366 Epoch [6/8], Batch [51/748], Loss: 0.4987
2024-06-24 08:15:45,009 Epoch [6/8], Batch [101/748], Loss: 0.4488
2024-06-24 08:16:36,098 Epoch [6/8], Batch [151/748], Loss: 0.3143
2024-06-24 08:17:26,856 Epoch [6/8], Batch [201/748], Loss: 0.3607
2024-06-24 08:18:17,516 Epoch [6/8], Batch [251/748], Loss: 0.2619
2024-06-24 08:19:08,225 Epoch [6/8], Batch [301/748], Loss: 0.6105
2024-06-24 08:19:58,854 Epoch [6/8], Batch [351/748], Loss: 0.4941
2024-06-24 08:20:49,762 Epoch [6/8], Batch [401/748], Loss: 0.4984
2024-06-24 08:21:40,632 Epoch [6/8], Batch [451/748], Loss: 0.2542
2024-06-24 08:22:31,652 Epoch [6/8], Batch [501/748], Loss: 0.6123
2024-06-24 08:23:22,496 Epoch [6/8], Batch [551/748], Loss: 0.6607
2024-06-24 08:24:13,469 Epoch [6/8], Batch [601/748], Loss: 0.5850
2024-06-24 08:25:04,431 Epoch [6/8], Batch [651/748], Loss: 0.4687
2024-06-24 08:25:55,376 Epoch [6/8], Batch [701/748], Loss: 0.3642
2024-06-24 08:26:42,887 Epoch 6/8, Train Loss: 0.4494, Train Accuracy: 0.8065
2024-06-24 08:28:07,641 Epoch 6/8, Val Loss: 0.9708, Val Accuracy: 0.6496
2024-06-24 08:28:08,640 Epoch [7/8], Batch [1/748], Loss: 0.3557
2024-06-24 08:28:59,253 Epoch [7/8], Batch [51/748], Loss: 0.4389
2024-06-24 08:29:49,787 Epoch [7/8], Batch [101/748], Loss: 0.2974
2024-06-24 08:30:40,931 Epoch [7/8], Batch [151/748], Loss: 0.3777
2024-06-24 08:31:32,101 Epoch [7/8], Batch [201/748], Loss: 0.4416
2024-06-24 08:32:22,883 Epoch [7/8], Batch [251/748], Loss: 0.3281
2024-06-24 08:33:13,954 Epoch [7/8], Batch [301/748], Loss: 0.3859
2024-06-24 08:34:04,497 Epoch [7/8], Batch [351/748], Loss: 0.4666
2024-06-24 08:34:55,336 Epoch [7/8], Batch [401/748], Loss: 0.3897
2024-06-24 08:35:46,229 Epoch [7/8], Batch [451/748], Loss: 0.1699
2024-06-24 08:36:36,820 Epoch [7/8], Batch [501/748], Loss: 0.2213
2024-06-24 08:37:27,487 Epoch [7/8], Batch [551/748], Loss: 0.5574
2024-06-24 08:38:18,334 Epoch [7/8], Batch [601/748], Loss: 0.3817
2024-06-24 08:39:08,816 Epoch [7/8], Batch [651/748], Loss: 0.4521
2024-06-24 08:39:59,483 Epoch [7/8], Batch [701/748], Loss: 0.4111
2024-06-24 08:40:46,747 Epoch 7/8, Train Loss: 0.3790, Train Accuracy: 0.8391
2024-06-24 08:42:11,613 Epoch 7/8, Val Loss: 0.9904, Val Accuracy: 0.6593
2024-06-24 08:42:12,633 Epoch [8/8], Batch [1/748], Loss: 0.3172
2024-06-24 08:43:03,648 Epoch [8/8], Batch [51/748], Loss: 0.2610
2024-06-24 08:43:53,966 Epoch [8/8], Batch [101/748], Loss: 0.4702
2024-06-24 08:44:45,056 Epoch [8/8], Batch [151/748], Loss: 0.2917
2024-06-24 08:45:35,962 Epoch [8/8], Batch [201/748], Loss: 0.2773
2024-06-24 08:46:26,780 Epoch [8/8], Batch [251/748], Loss: 0.3026
2024-06-24 08:47:17,317 Epoch [8/8], Batch [301/748], Loss: 0.1286
2024-06-24 08:48:08,257 Epoch [8/8], Batch [351/748], Loss: 0.2316
2024-06-24 08:48:59,398 Epoch [8/8], Batch [401/748], Loss: 0.4356
2024-06-24 08:49:50,548 Epoch [8/8], Batch [451/748], Loss: 0.3130
2024-06-24 08:50:41,569 Epoch [8/8], Batch [501/748], Loss: 0.2655
2024-06-24 08:51:32,709 Epoch [8/8], Batch [551/748], Loss: 0.5581
2024-06-24 08:52:23,809 Epoch [8/8], Batch [601/748], Loss: 0.2629
2024-06-24 08:53:14,900 Epoch [8/8], Batch [651/748], Loss: 0.1708
2024-06-24 08:54:05,818 Epoch [8/8], Batch [701/748], Loss: 0.4595
2024-06-24 08:54:53,251 Epoch 8/8, Train Loss: 0.3191, Train Accuracy: 0.8686
2024-06-24 08:56:18,085 Epoch 8/8, Val Loss: 0.9876, Val Accuracy: 0.6701
2024-06-24 08:56:18,087 Training finished!
2024-06-24 08:56:18,088 ==================================================
2024-06-24 08:56:23,928 ==================================================
2024-06-24 08:56:23,928 Training BERT + TF-IDF features with Dimension-1024...
2024-06-24 08:56:24,962 Epoch [1/8], Batch [1/748], Loss: 1.6278
2024-06-24 08:57:15,232 Epoch [1/8], Batch [51/748], Loss: 1.6212
2024-06-24 08:58:05,761 Epoch [1/8], Batch [101/748], Loss: 1.3187
2024-06-24 08:58:56,489 Epoch [1/8], Batch [151/748], Loss: 1.2265
2024-06-24 08:59:47,627 Epoch [1/8], Batch [201/748], Loss: 1.2386
2024-06-24 09:00:38,808 Epoch [1/8], Batch [251/748], Loss: 0.8629
2024-06-24 09:01:29,424 Epoch [1/8], Batch [301/748], Loss: 1.1436
2024-06-24 09:02:19,926 Epoch [1/8], Batch [351/748], Loss: 1.1578
2024-06-24 09:03:11,008 Epoch [1/8], Batch [401/748], Loss: 0.8566
2024-06-24 09:04:01,918 Epoch [1/8], Batch [451/748], Loss: 1.0685
2024-06-24 09:04:52,688 Epoch [1/8], Batch [501/748], Loss: 0.7898
2024-06-24 09:05:43,365 Epoch [1/8], Batch [551/748], Loss: 0.9007
2024-06-24 09:06:33,931 Epoch [1/8], Batch [601/748], Loss: 1.0787
2024-06-24 09:07:24,654 Epoch [1/8], Batch [651/748], Loss: 1.2187
2024-06-24 09:08:14,973 Epoch [1/8], Batch [701/748], Loss: 0.9682
2024-06-24 09:09:02,386 Epoch 1/8, Train Loss: 1.0989, Train Accuracy: 0.5200
2024-06-24 09:10:26,964 Epoch 1/8, Val Loss: 0.8638, Val Accuracy: 0.6255
2024-06-24 09:10:28,051 Epoch [2/8], Batch [1/748], Loss: 0.9992
2024-06-24 09:11:18,539 Epoch [2/8], Batch [51/748], Loss: 0.8627
2024-06-24 09:12:09,148 Epoch [2/8], Batch [101/748], Loss: 1.0059
2024-06-24 09:12:59,879 Epoch [2/8], Batch [151/748], Loss: 0.7477
2024-06-24 09:13:50,567 Epoch [2/8], Batch [201/748], Loss: 1.3079
2024-06-24 09:14:41,219 Epoch [2/8], Batch [251/748], Loss: 0.7536
2024-06-24 09:15:31,779 Epoch [2/8], Batch [301/748], Loss: 0.6833
2024-06-24 09:16:22,377 Epoch [2/8], Batch [351/748], Loss: 0.8440
2024-06-24 09:17:13,383 Epoch [2/8], Batch [401/748], Loss: 0.7828
2024-06-24 09:18:03,823 Epoch [2/8], Batch [451/748], Loss: 0.7797
2024-06-24 09:18:54,760 Epoch [2/8], Batch [501/748], Loss: 0.7326
2024-06-24 09:19:45,793 Epoch [2/8], Batch [551/748], Loss: 0.9005
2024-06-24 09:20:36,884 Epoch [2/8], Batch [601/748], Loss: 0.8277
2024-06-24 09:21:27,704 Epoch [2/8], Batch [651/748], Loss: 0.7975
2024-06-24 09:22:18,303 Epoch [2/8], Batch [701/748], Loss: 0.7126
2024-06-24 09:23:05,845 Epoch 2/8, Train Loss: 0.8299, Train Accuracy: 0.6324
2024-06-24 09:24:30,890 Epoch 2/8, Val Loss: 0.8013, Val Accuracy: 0.6522
2024-06-24 09:24:31,864 Epoch [3/8], Batch [1/748], Loss: 1.0831
2024-06-24 09:25:22,389 Epoch [3/8], Batch [51/748], Loss: 0.5399
2024-06-24 09:26:13,272 Epoch [3/8], Batch [101/748], Loss: 0.9059
2024-06-24 09:27:04,394 Epoch [3/8], Batch [151/748], Loss: 0.9006
2024-06-24 09:27:55,358 Epoch [3/8], Batch [201/748], Loss: 0.7385
2024-06-24 09:28:46,510 Epoch [3/8], Batch [251/748], Loss: 0.6814
2024-06-24 09:29:37,128 Epoch [3/8], Batch [301/748], Loss: 0.7415
2024-06-24 09:30:28,290 Epoch [3/8], Batch [351/748], Loss: 1.0755
2024-06-24 09:31:19,195 Epoch [3/8], Batch [401/748], Loss: 0.6650
2024-06-24 09:32:09,834 Epoch [3/8], Batch [451/748], Loss: 0.7700
2024-06-24 09:33:00,980 Epoch [3/8], Batch [501/748], Loss: 0.6796
2024-06-24 09:33:51,205 Epoch [3/8], Batch [551/748], Loss: 0.5564
2024-06-24 09:34:41,904 Epoch [3/8], Batch [601/748], Loss: 0.9835
2024-06-24 09:35:32,672 Epoch [3/8], Batch [651/748], Loss: 0.7889
2024-06-24 09:36:23,521 Epoch [3/8], Batch [701/748], Loss: 0.7655
2024-06-24 09:37:11,156 Epoch 3/8, Train Loss: 0.7299, Train Accuracy: 0.6795
2024-06-24 09:38:35,801 Epoch 3/8, Val Loss: 0.8348, Val Accuracy: 0.6407
2024-06-24 09:38:36,781 Epoch [4/8], Batch [1/748], Loss: 0.5384
2024-06-24 09:39:27,470 Epoch [4/8], Batch [51/748], Loss: 0.7155
2024-06-24 09:40:18,025 Epoch [4/8], Batch [101/748], Loss: 0.6133
2024-06-24 09:41:08,645 Epoch [4/8], Batch [151/748], Loss: 0.7290
2024-06-24 09:41:59,295 Epoch [4/8], Batch [201/748], Loss: 0.5278
2024-06-24 09:42:50,010 Epoch [4/8], Batch [251/748], Loss: 0.5113
2024-06-24 09:43:40,676 Epoch [4/8], Batch [301/748], Loss: 0.6170
2024-06-24 09:44:31,435 Epoch [4/8], Batch [351/748], Loss: 0.6735
2024-06-24 09:45:22,294 Epoch [4/8], Batch [401/748], Loss: 0.6152
2024-06-24 09:46:13,482 Epoch [4/8], Batch [451/748], Loss: 0.5813
2024-06-24 09:47:04,398 Epoch [4/8], Batch [501/748], Loss: 0.6306
2024-06-24 09:47:54,813 Epoch [4/8], Batch [551/748], Loss: 0.6773
2024-06-24 09:48:45,666 Epoch [4/8], Batch [601/748], Loss: 0.4060
2024-06-24 09:49:36,573 Epoch [4/8], Batch [651/748], Loss: 0.5330
2024-06-24 09:50:27,050 Epoch [4/8], Batch [701/748], Loss: 0.6564
2024-06-24 09:51:14,594 Epoch 4/8, Train Loss: 0.6341, Train Accuracy: 0.7222
2024-06-24 09:52:39,427 Epoch 4/8, Val Loss: 0.8198, Val Accuracy: 0.6598
2024-06-24 09:52:40,440 Epoch [5/8], Batch [1/748], Loss: 0.3783
2024-06-24 09:53:30,871 Epoch [5/8], Batch [51/748], Loss: 0.6249
2024-06-24 09:54:21,322 Epoch [5/8], Batch [101/748], Loss: 0.4657
2024-06-24 09:55:11,883 Epoch [5/8], Batch [151/748], Loss: 0.5389
2024-06-24 09:56:02,760 Epoch [5/8], Batch [201/748], Loss: 0.4043
2024-06-24 09:56:53,492 Epoch [5/8], Batch [251/748], Loss: 0.2923
2024-06-24 09:57:44,403 Epoch [5/8], Batch [301/748], Loss: 0.8077
2024-06-24 09:58:35,470 Epoch [5/8], Batch [351/748], Loss: 0.4238
2024-06-24 09:59:26,327 Epoch [5/8], Batch [401/748], Loss: 0.6266
2024-06-24 10:00:17,185 Epoch [5/8], Batch [451/748], Loss: 0.5473
2024-06-24 10:01:08,242 Epoch [5/8], Batch [501/748], Loss: 0.5698
2024-06-24 10:01:59,145 Epoch [5/8], Batch [551/748], Loss: 0.4827
2024-06-24 10:02:50,188 Epoch [5/8], Batch [601/748], Loss: 0.4489
2024-06-24 10:03:41,025 Epoch [5/8], Batch [651/748], Loss: 0.2612
2024-06-24 10:04:32,013 Epoch [5/8], Batch [701/748], Loss: 0.5576
2024-06-24 10:05:19,537 Epoch 5/8, Train Loss: 0.5309, Train Accuracy: 0.7710
2024-06-24 10:06:44,076 Epoch 5/8, Val Loss: 0.9414, Val Accuracy: 0.6599
2024-06-24 10:06:45,095 Epoch [6/8], Batch [1/748], Loss: 0.3852
2024-06-24 10:07:35,549 Epoch [6/8], Batch [51/748], Loss: 0.5886
2024-06-24 10:08:26,494 Epoch [6/8], Batch [101/748], Loss: 0.3238
2024-06-24 10:09:17,464 Epoch [6/8], Batch [151/748], Loss: 0.4898
2024-06-24 10:10:08,432 Epoch [6/8], Batch [201/748], Loss: 0.4399
2024-06-24 10:10:59,434 Epoch [6/8], Batch [251/748], Loss: 0.4611
2024-06-24 10:11:50,399 Epoch [6/8], Batch [301/748], Loss: 0.3723
2024-06-24 10:12:41,628 Epoch [6/8], Batch [351/748], Loss: 0.5994
2024-06-24 10:13:32,295 Epoch [6/8], Batch [401/748], Loss: 0.6431
2024-06-24 10:14:23,253 Epoch [6/8], Batch [451/748], Loss: 0.3331
2024-06-24 10:15:14,109 Epoch [6/8], Batch [501/748], Loss: 0.5305
2024-06-24 10:16:05,093 Epoch [6/8], Batch [551/748], Loss: 0.3147
2024-06-24 10:16:56,111 Epoch [6/8], Batch [601/748], Loss: 0.3981
2024-06-24 10:17:47,042 Epoch [6/8], Batch [651/748], Loss: 0.5112
2024-06-24 10:18:37,980 Epoch [6/8], Batch [701/748], Loss: 0.3154
2024-06-24 10:19:25,523 Epoch 6/8, Train Loss: 0.4370, Train Accuracy: 0.8162
2024-06-24 10:20:50,427 Epoch 6/8, Val Loss: 0.9071, Val Accuracy: 0.6740
2024-06-24 10:20:51,432 Epoch [7/8], Batch [1/748], Loss: 0.2846
2024-06-24 10:21:41,587 Epoch [7/8], Batch [51/748], Loss: 0.3633
2024-06-24 10:22:32,507 Epoch [7/8], Batch [101/748], Loss: 0.3465
2024-06-24 10:23:23,333 Epoch [7/8], Batch [151/748], Loss: 0.3282
2024-06-24 10:24:14,253 Epoch [7/8], Batch [201/748], Loss: 0.2517
2024-06-24 10:25:05,195 Epoch [7/8], Batch [251/748], Loss: 0.3017
2024-06-24 10:25:55,884 Epoch [7/8], Batch [301/748], Loss: 0.5420
2024-06-24 10:26:46,562 Epoch [7/8], Batch [351/748], Loss: 0.3104
2024-06-24 10:27:37,189 Epoch [7/8], Batch [401/748], Loss: 0.2646
2024-06-24 10:28:27,866 Epoch [7/8], Batch [451/748], Loss: 0.3731
2024-06-24 10:29:18,305 Epoch [7/8], Batch [501/748], Loss: 0.5052
2024-06-24 10:30:08,898 Epoch [7/8], Batch [551/748], Loss: 0.1811
2024-06-24 10:30:59,795 Epoch [7/8], Batch [601/748], Loss: 0.3481
2024-06-24 10:31:50,192 Epoch [7/8], Batch [651/748], Loss: 0.3061
2024-06-24 10:32:40,954 Epoch [7/8], Batch [701/748], Loss: 0.2734
2024-06-24 10:33:27,869 Epoch 7/8, Train Loss: 0.3625, Train Accuracy: 0.8519
2024-06-24 10:34:52,291 Epoch 7/8, Val Loss: 0.9541, Val Accuracy: 0.6825
2024-06-24 10:34:53,291 Epoch [8/8], Batch [1/748], Loss: 0.3356
2024-06-24 10:35:43,647 Epoch [8/8], Batch [51/748], Loss: 0.4199
2024-06-24 10:36:34,250 Epoch [8/8], Batch [101/748], Loss: 0.2491
2024-06-24 10:37:24,951 Epoch [8/8], Batch [151/748], Loss: 0.4334
2024-06-24 10:38:15,251 Epoch [8/8], Batch [201/748], Loss: 0.3048
2024-06-24 10:39:06,102 Epoch [8/8], Batch [251/748], Loss: 0.1995
2024-06-24 10:39:56,989 Epoch [8/8], Batch [301/748], Loss: 0.3125
2024-06-24 10:40:47,690 Epoch [8/8], Batch [351/748], Loss: 0.4107
2024-06-24 10:41:38,140 Epoch [8/8], Batch [401/748], Loss: 0.2717
2024-06-24 10:42:29,064 Epoch [8/8], Batch [451/748], Loss: 0.4175
2024-06-24 10:43:19,844 Epoch [8/8], Batch [501/748], Loss: 0.2209
2024-06-24 10:44:10,749 Epoch [8/8], Batch [551/748], Loss: 0.4444
2024-06-24 10:45:01,750 Epoch [8/8], Batch [601/748], Loss: 0.1934
2024-06-24 10:45:52,580 Epoch [8/8], Batch [651/748], Loss: 0.0766
2024-06-24 10:46:43,632 Epoch [8/8], Batch [701/748], Loss: 0.2420
2024-06-24 10:47:30,761 Epoch 8/8, Train Loss: 0.2970, Train Accuracy: 0.8797
2024-06-24 10:48:55,681 Epoch 8/8, Val Loss: 1.0384, Val Accuracy: 0.6668
2024-06-24 10:48:55,684 Training finished!
2024-06-24 10:48:55,684 ==================================================
2024-06-24 10:49:01,193 ==================================================
2024-06-24 10:49:01,194 Training BERT + TF-IDF features with Dimension-512...
2024-06-24 10:49:02,204 Epoch [1/8], Batch [1/748], Loss: 1.5974
2024-06-24 10:49:52,282 Epoch [1/8], Batch [51/748], Loss: 1.4341
2024-06-24 10:50:43,127 Epoch [1/8], Batch [101/748], Loss: 1.3554
2024-06-24 10:51:34,055 Epoch [1/8], Batch [151/748], Loss: 1.2579
2024-06-24 10:52:25,033 Epoch [1/8], Batch [201/748], Loss: 1.1264
2024-06-24 10:53:15,845 Epoch [1/8], Batch [251/748], Loss: 1.0818
2024-06-24 10:54:06,540 Epoch [1/8], Batch [301/748], Loss: 1.0736
2024-06-24 10:54:57,193 Epoch [1/8], Batch [351/748], Loss: 1.0960
2024-06-24 10:55:47,829 Epoch [1/8], Batch [401/748], Loss: 0.9316
2024-06-24 10:56:38,423 Epoch [1/8], Batch [451/748], Loss: 1.1661
2024-06-24 10:57:28,843 Epoch [1/8], Batch [501/748], Loss: 0.8746
2024-06-24 10:58:19,585 Epoch [1/8], Batch [551/748], Loss: 1.0180
2024-06-24 10:59:10,592 Epoch [1/8], Batch [601/748], Loss: 1.0900
2024-06-24 11:00:01,165 Epoch [1/8], Batch [651/748], Loss: 0.7991
2024-06-24 11:00:51,591 Epoch [1/8], Batch [701/748], Loss: 0.7233
2024-06-24 11:01:38,963 Epoch 1/8, Train Loss: 1.0614, Train Accuracy: 0.5455
2024-06-24 11:03:04,233 Epoch 1/8, Val Loss: 0.9096, Val Accuracy: 0.5847
2024-06-24 11:03:05,224 Epoch [2/8], Batch [1/748], Loss: 0.8041
2024-06-24 11:03:55,536 Epoch [2/8], Batch [51/748], Loss: 0.7823
2024-06-24 11:04:46,119 Epoch [2/8], Batch [101/748], Loss: 0.8724
2024-06-24 11:05:36,536 Epoch [2/8], Batch [151/748], Loss: 0.8628
2024-06-24 11:06:27,110 Epoch [2/8], Batch [201/748], Loss: 0.6989
2024-06-24 11:07:17,893 Epoch [2/8], Batch [251/748], Loss: 0.9719
2024-06-24 11:08:08,506 Epoch [2/8], Batch [301/748], Loss: 0.6696
2024-06-24 11:08:59,036 Epoch [2/8], Batch [351/748], Loss: 0.9562
2024-06-24 11:09:49,682 Epoch [2/8], Batch [401/748], Loss: 0.7878
2024-06-24 11:10:40,780 Epoch [2/8], Batch [451/748], Loss: 0.7517
2024-06-24 11:11:31,601 Epoch [2/8], Batch [501/748], Loss: 0.5494
2024-06-24 11:12:22,134 Epoch [2/8], Batch [551/748], Loss: 0.7385
2024-06-24 11:13:13,163 Epoch [2/8], Batch [601/748], Loss: 0.7434
2024-06-24 11:14:03,942 Epoch [2/8], Batch [651/748], Loss: 1.0347
2024-06-24 11:14:54,500 Epoch [2/8], Batch [701/748], Loss: 0.6924
2024-06-24 11:15:42,038 Epoch 2/8, Train Loss: 0.8034, Train Accuracy: 0.6445
2024-06-24 11:17:06,894 Epoch 2/8, Val Loss: 0.8424, Val Accuracy: 0.6208
2024-06-24 11:17:07,903 Epoch [3/8], Batch [1/748], Loss: 0.6871
2024-06-24 11:17:58,326 Epoch [3/8], Batch [51/748], Loss: 0.5057
2024-06-24 11:18:48,914 Epoch [3/8], Batch [101/748], Loss: 0.6039
2024-06-24 11:19:39,919 Epoch [3/8], Batch [151/748], Loss: 0.6609
2024-06-24 11:20:30,772 Epoch [3/8], Batch [201/748], Loss: 0.8291
2024-06-24 11:21:21,412 Epoch [3/8], Batch [251/748], Loss: 0.6567
2024-06-24 11:22:11,861 Epoch [3/8], Batch [301/748], Loss: 0.8346
2024-06-24 11:23:02,634 Epoch [3/8], Batch [351/748], Loss: 0.9136
2024-06-24 11:23:53,215 Epoch [3/8], Batch [401/748], Loss: 0.7458
2024-06-24 11:24:43,689 Epoch [3/8], Batch [451/748], Loss: 0.6386
2024-06-24 11:25:34,294 Epoch [3/8], Batch [501/748], Loss: 0.6347
2024-06-24 11:26:24,751 Epoch [3/8], Batch [551/748], Loss: 0.7512
2024-06-24 11:27:15,346 Epoch [3/8], Batch [601/748], Loss: 0.7254
2024-06-24 11:28:06,240 Epoch [3/8], Batch [651/748], Loss: 0.7423
2024-06-24 11:28:57,279 Epoch [3/8], Batch [701/748], Loss: 0.6161
2024-06-24 11:29:44,711 Epoch 3/8, Train Loss: 0.6940, Train Accuracy: 0.6896
2024-06-24 11:31:10,322 Epoch 3/8, Val Loss: 0.8115, Val Accuracy: 0.6437
2024-06-24 11:31:11,315 Epoch [4/8], Batch [1/748], Loss: 0.7505
2024-06-24 11:32:02,261 Epoch [4/8], Batch [51/748], Loss: 0.6115
2024-06-24 11:32:53,589 Epoch [4/8], Batch [101/748], Loss: 0.7355
2024-06-24 11:33:44,414 Epoch [4/8], Batch [151/748], Loss: 0.5467
2024-06-24 11:34:35,581 Epoch [4/8], Batch [201/748], Loss: 0.6990
2024-06-24 11:35:26,133 Epoch [4/8], Batch [251/748], Loss: 0.5761
2024-06-24 11:36:16,578 Epoch [4/8], Batch [301/748], Loss: 0.6288
2024-06-24 11:37:07,566 Epoch [4/8], Batch [351/748], Loss: 0.6999
2024-06-24 11:37:58,361 Epoch [4/8], Batch [401/748], Loss: 0.5836
2024-06-24 11:38:49,234 Epoch [4/8], Batch [451/748], Loss: 0.6328
2024-06-24 11:39:39,930 Epoch [4/8], Batch [501/748], Loss: 0.6995
2024-06-24 11:40:30,979 Epoch [4/8], Batch [551/748], Loss: 0.7338
2024-06-24 11:41:21,791 Epoch [4/8], Batch [601/748], Loss: 0.6747
2024-06-24 11:42:12,586 Epoch [4/8], Batch [651/748], Loss: 0.5232
2024-06-24 11:43:03,469 Epoch [4/8], Batch [701/748], Loss: 0.5802
2024-06-24 11:43:50,842 Epoch 4/8, Train Loss: 0.6036, Train Accuracy: 0.7299
2024-06-24 11:45:16,668 Epoch 4/8, Val Loss: 0.8999, Val Accuracy: 0.6270
2024-06-24 11:45:17,690 Epoch [5/8], Batch [1/748], Loss: 0.5127
2024-06-24 11:46:08,176 Epoch [5/8], Batch [51/748], Loss: 0.3386
2024-06-24 11:46:58,867 Epoch [5/8], Batch [101/748], Loss: 0.3892
2024-06-24 11:47:49,493 Epoch [5/8], Batch [151/748], Loss: 0.4838
2024-06-24 11:48:40,429 Epoch [5/8], Batch [201/748], Loss: 0.5334
2024-06-24 11:49:31,385 Epoch [5/8], Batch [251/748], Loss: 0.7586
2024-06-24 11:50:21,886 Epoch [5/8], Batch [301/748], Loss: 0.5092
2024-06-24 11:51:12,737 Epoch [5/8], Batch [351/748], Loss: 0.6013
2024-06-24 11:52:03,603 Epoch [5/8], Batch [401/748], Loss: 0.4828
2024-06-24 11:52:54,582 Epoch [5/8], Batch [451/748], Loss: 0.5705
2024-06-24 11:53:45,320 Epoch [5/8], Batch [501/748], Loss: 0.6406
2024-06-24 11:54:36,212 Epoch [5/8], Batch [551/748], Loss: 0.3851
2024-06-24 11:55:26,961 Epoch [5/8], Batch [601/748], Loss: 0.4206
2024-06-24 11:56:17,894 Epoch [5/8], Batch [651/748], Loss: 0.4935
2024-06-24 11:57:08,673 Epoch [5/8], Batch [701/748], Loss: 0.4568
2024-06-24 11:57:56,058 Epoch 5/8, Train Loss: 0.5166, Train Accuracy: 0.7706
2024-06-24 11:59:21,216 Epoch 5/8, Val Loss: 0.8415, Val Accuracy: 0.6711
2024-06-24 11:59:22,220 Epoch [6/8], Batch [1/748], Loss: 0.4188
2024-06-24 12:00:12,389 Epoch [6/8], Batch [51/748], Loss: 0.3985
2024-06-24 12:01:02,867 Epoch [6/8], Batch [101/748], Loss: 0.4254
2024-06-24 12:01:53,180 Epoch [6/8], Batch [151/748], Loss: 0.4094
2024-06-24 12:02:44,176 Epoch [6/8], Batch [201/748], Loss: 0.4791
2024-06-24 12:03:34,784 Epoch [6/8], Batch [251/748], Loss: 0.5211
2024-06-24 12:04:25,229 Epoch [6/8], Batch [301/748], Loss: 0.4710
2024-06-24 12:05:15,917 Epoch [6/8], Batch [351/748], Loss: 0.3295
2024-06-24 12:06:06,893 Epoch [6/8], Batch [401/748], Loss: 0.4486
2024-06-24 12:06:57,400 Epoch [6/8], Batch [451/748], Loss: 0.4209
2024-06-24 12:07:48,070 Epoch [6/8], Batch [501/748], Loss: 0.4327
2024-06-24 12:08:38,607 Epoch [6/8], Batch [551/748], Loss: 0.4603
2024-06-24 12:09:29,193 Epoch [6/8], Batch [601/748], Loss: 0.7278
2024-06-24 12:10:19,552 Epoch [6/8], Batch [651/748], Loss: 0.5517
2024-06-24 12:11:10,068 Epoch [6/8], Batch [701/748], Loss: 0.2926
2024-06-24 12:11:57,055 Epoch 6/8, Train Loss: 0.4362, Train Accuracy: 0.8086
2024-06-24 12:13:22,234 Epoch 6/8, Val Loss: 0.9076, Val Accuracy: 0.6557
2024-06-24 12:13:23,267 Epoch [7/8], Batch [1/748], Loss: 0.3171
2024-06-24 12:14:13,974 Epoch [7/8], Batch [51/748], Loss: 0.4145
2024-06-24 12:15:05,052 Epoch [7/8], Batch [101/748], Loss: 0.2735
2024-06-24 12:15:55,263 Epoch [7/8], Batch [151/748], Loss: 0.4266
2024-06-24 12:16:45,981 Epoch [7/8], Batch [201/748], Loss: 0.3529
2024-06-24 12:17:36,624 Epoch [7/8], Batch [251/748], Loss: 0.2555
2024-06-24 12:18:27,135 Epoch [7/8], Batch [301/748], Loss: 0.4684
2024-06-24 12:19:17,705 Epoch [7/8], Batch [351/748], Loss: 0.5101
2024-06-24 12:20:08,076 Epoch [7/8], Batch [401/748], Loss: 0.2350
2024-06-24 12:20:58,636 Epoch [7/8], Batch [451/748], Loss: 0.2848
2024-06-24 12:21:48,948 Epoch [7/8], Batch [501/748], Loss: 0.4362
2024-06-24 12:22:39,828 Epoch [7/8], Batch [551/748], Loss: 0.3223
2024-06-24 12:23:30,567 Epoch [7/8], Batch [601/748], Loss: 0.3438
2024-06-24 12:24:20,972 Epoch [7/8], Batch [651/748], Loss: 0.2623
2024-06-24 12:25:11,572 Epoch [7/8], Batch [701/748], Loss: 0.5208
2024-06-24 12:25:58,952 Epoch 7/8, Train Loss: 0.3640, Train Accuracy: 0.8422
2024-06-24 12:27:23,567 Epoch 7/8, Val Loss: 0.9975, Val Accuracy: 0.6604
2024-06-24 12:27:24,581 Epoch [8/8], Batch [1/748], Loss: 0.4718
2024-06-24 12:28:14,896 Epoch [8/8], Batch [51/748], Loss: 0.3005
2024-06-24 12:29:05,734 Epoch [8/8], Batch [101/748], Loss: 0.2999
2024-06-24 12:29:56,025 Epoch [8/8], Batch [151/748], Loss: 0.3242
2024-06-24 12:30:46,765 Epoch [8/8], Batch [201/748], Loss: 0.2290
2024-06-24 12:31:37,737 Epoch [8/8], Batch [251/748], Loss: 0.2946
2024-06-24 12:32:28,440 Epoch [8/8], Batch [301/748], Loss: 0.2801
2024-06-24 12:33:18,764 Epoch [8/8], Batch [351/748], Loss: 0.2941
2024-06-24 12:34:09,457 Epoch [8/8], Batch [401/748], Loss: 0.3474
2024-06-24 12:34:59,651 Epoch [8/8], Batch [451/748], Loss: 0.1949
2024-06-24 12:35:50,042 Epoch [8/8], Batch [501/748], Loss: 0.3736
2024-06-24 12:36:40,642 Epoch [8/8], Batch [551/748], Loss: 0.2585
2024-06-24 12:37:31,395 Epoch [8/8], Batch [601/748], Loss: 0.2758
2024-06-24 12:38:21,775 Epoch [8/8], Batch [651/748], Loss: 0.1944
2024-06-24 12:39:12,631 Epoch [8/8], Batch [701/748], Loss: 0.4517
2024-06-24 12:39:59,719 Epoch 8/8, Train Loss: 0.3119, Train Accuracy: 0.8667
2024-06-24 12:41:24,667 Epoch 8/8, Val Loss: 1.0226, Val Accuracy: 0.6700
2024-06-24 12:41:24,669 Training finished!
2024-06-24 12:41:24,669 ==================================================
2024-06-24 12:41:30,195 ==================================================
2024-06-24 12:41:30,196 Training BERT + TF-IDF features with Dimension-256...
2024-06-24 12:41:31,211 Epoch [1/8], Batch [1/748], Loss: 1.5961
2024-06-24 12:42:21,481 Epoch [1/8], Batch [51/748], Loss: 1.4553
2024-06-24 12:43:12,115 Epoch [1/8], Batch [101/748], Loss: 1.4160
2024-06-24 12:44:02,594 Epoch [1/8], Batch [151/748], Loss: 1.2778
2024-06-24 12:44:53,257 Epoch [1/8], Batch [201/748], Loss: 1.1030
2024-06-24 12:45:43,860 Epoch [1/8], Batch [251/748], Loss: 1.2681
2024-06-24 12:46:34,728 Epoch [1/8], Batch [301/748], Loss: 1.1024
2024-06-24 12:47:25,304 Epoch [1/8], Batch [351/748], Loss: 1.0512
2024-06-24 12:48:15,629 Epoch [1/8], Batch [401/748], Loss: 0.9959
2024-06-24 12:49:06,248 Epoch [1/8], Batch [451/748], Loss: 1.0653
2024-06-24 12:49:56,550 Epoch [1/8], Batch [501/748], Loss: 1.0138
2024-06-24 12:50:47,218 Epoch [1/8], Batch [551/748], Loss: 0.8508
2024-06-24 12:51:37,533 Epoch [1/8], Batch [601/748], Loss: 1.1028
2024-06-24 12:52:28,246 Epoch [1/8], Batch [651/748], Loss: 0.7098
2024-06-24 12:53:19,151 Epoch [1/8], Batch [701/748], Loss: 0.8956
2024-06-24 12:54:06,176 Epoch 1/8, Train Loss: 1.0966, Train Accuracy: 0.5218
2024-06-24 12:55:30,950 Epoch 1/8, Val Loss: 0.9974, Val Accuracy: 0.5720
2024-06-24 12:55:31,966 Epoch [2/8], Batch [1/748], Loss: 0.8057
2024-06-24 12:56:22,590 Epoch [2/8], Batch [51/748], Loss: 0.8586
2024-06-24 12:57:13,573 Epoch [2/8], Batch [101/748], Loss: 0.8238
2024-06-24 12:58:03,988 Epoch [2/8], Batch [151/748], Loss: 0.7188
2024-06-24 12:58:54,679 Epoch [2/8], Batch [201/748], Loss: 0.9469
2024-06-24 12:59:45,439 Epoch [2/8], Batch [251/748], Loss: 1.0662
2024-06-24 13:00:35,949 Epoch [2/8], Batch [301/748], Loss: 1.0377
2024-06-24 13:01:26,293 Epoch [2/8], Batch [351/748], Loss: 0.9363
2024-06-24 13:02:17,302 Epoch [2/8], Batch [401/748], Loss: 0.8755
2024-06-24 13:03:08,248 Epoch [2/8], Batch [451/748], Loss: 0.8308
2024-06-24 13:03:59,183 Epoch [2/8], Batch [501/748], Loss: 1.0912
2024-06-24 13:04:50,077 Epoch [2/8], Batch [551/748], Loss: 0.7127
2024-06-24 13:05:41,008 Epoch [2/8], Batch [601/748], Loss: 0.7685
2024-06-24 13:06:31,595 Epoch [2/8], Batch [651/748], Loss: 0.7140
2024-06-24 13:07:21,938 Epoch [2/8], Batch [701/748], Loss: 0.9024
2024-06-24 13:08:09,030 Epoch 2/8, Train Loss: 0.8427, Train Accuracy: 0.6237
2024-06-24 13:09:33,440 Epoch 2/8, Val Loss: 0.8295, Val Accuracy: 0.6251
2024-06-24 13:09:34,474 Epoch [3/8], Batch [1/748], Loss: 0.9731
2024-06-24 13:10:24,607 Epoch [3/8], Batch [51/748], Loss: 0.6842
2024-06-24 13:11:15,274 Epoch [3/8], Batch [101/748], Loss: 0.6382
2024-06-24 13:12:05,588 Epoch [3/8], Batch [151/748], Loss: 0.6135
2024-06-24 13:12:56,653 Epoch [3/8], Batch [201/748], Loss: 0.7574
2024-06-24 13:13:47,422 Epoch [3/8], Batch [251/748], Loss: 0.7751
2024-06-24 13:14:38,493 Epoch [3/8], Batch [301/748], Loss: 0.8151
2024-06-24 13:15:29,151 Epoch [3/8], Batch [351/748], Loss: 0.5810
2024-06-24 13:16:20,014 Epoch [3/8], Batch [401/748], Loss: 0.4090
2024-06-24 13:17:10,867 Epoch [3/8], Batch [451/748], Loss: 0.7994
2024-06-24 13:18:01,556 Epoch [3/8], Batch [501/748], Loss: 0.7573
2024-06-24 13:18:52,323 Epoch [3/8], Batch [551/748], Loss: 0.8666
2024-06-24 13:19:42,800 Epoch [3/8], Batch [601/748], Loss: 0.7759
2024-06-24 13:20:33,824 Epoch [3/8], Batch [651/748], Loss: 0.7731
2024-06-24 13:21:24,563 Epoch [3/8], Batch [701/748], Loss: 0.7902
2024-06-24 13:22:11,536 Epoch 3/8, Train Loss: 0.7449, Train Accuracy: 0.6685
2024-06-24 13:23:36,492 Epoch 3/8, Val Loss: 0.7971, Val Accuracy: 0.6519
2024-06-24 13:23:37,495 Epoch [4/8], Batch [1/748], Loss: 0.7050
2024-06-24 13:24:28,167 Epoch [4/8], Batch [51/748], Loss: 0.6014
2024-06-24 13:25:18,894 Epoch [4/8], Batch [101/748], Loss: 0.5492
2024-06-24 13:26:09,370 Epoch [4/8], Batch [151/748], Loss: 0.5721
2024-06-24 13:26:59,836 Epoch [4/8], Batch [201/748], Loss: 0.5744
2024-06-24 13:27:50,903 Epoch [4/8], Batch [251/748], Loss: 0.4819
2024-06-24 13:28:41,883 Epoch [4/8], Batch [301/748], Loss: 0.6063
2024-06-24 13:29:32,803 Epoch [4/8], Batch [351/748], Loss: 0.7303
2024-06-24 13:30:23,835 Epoch [4/8], Batch [401/748], Loss: 0.7532
2024-06-24 13:31:14,661 Epoch [4/8], Batch [451/748], Loss: 0.6860
2024-06-24 13:32:05,240 Epoch [4/8], Batch [501/748], Loss: 0.6164
2024-06-24 13:32:55,928 Epoch [4/8], Batch [551/748], Loss: 0.5308
2024-06-24 13:33:46,463 Epoch [4/8], Batch [601/748], Loss: 0.5570
2024-06-24 13:34:37,455 Epoch [4/8], Batch [651/748], Loss: 0.8929
2024-06-24 13:35:27,808 Epoch [4/8], Batch [701/748], Loss: 0.6506
2024-06-24 13:36:14,709 Epoch 4/8, Train Loss: 0.6463, Train Accuracy: 0.7145
2024-06-24 13:37:39,109 Epoch 4/8, Val Loss: 0.8931, Val Accuracy: 0.6382
2024-06-24 13:37:40,104 Epoch [5/8], Batch [1/748], Loss: 0.5283
2024-06-24 13:38:30,257 Epoch [5/8], Batch [51/748], Loss: 0.5500
2024-06-24 13:39:20,805 Epoch [5/8], Batch [101/748], Loss: 0.3828
2024-06-24 13:40:11,686 Epoch [5/8], Batch [151/748], Loss: 0.4270
2024-06-24 13:41:01,870 Epoch [5/8], Batch [201/748], Loss: 0.5363
2024-06-24 13:41:52,600 Epoch [5/8], Batch [251/748], Loss: 0.5698
2024-06-24 13:42:43,613 Epoch [5/8], Batch [301/748], Loss: 0.7765
2024-06-24 13:43:33,860 Epoch [5/8], Batch [351/748], Loss: 0.7353
2024-06-24 13:44:24,608 Epoch [5/8], Batch [401/748], Loss: 0.3545
2024-06-24 13:45:15,507 Epoch [5/8], Batch [451/748], Loss: 0.5118
2024-06-24 13:46:06,032 Epoch [5/8], Batch [501/748], Loss: 0.5053
2024-06-24 13:46:56,581 Epoch [5/8], Batch [551/748], Loss: 0.6376
2024-06-24 13:47:47,422 Epoch [5/8], Batch [601/748], Loss: 0.5277
2024-06-24 13:48:38,331 Epoch [5/8], Batch [651/748], Loss: 0.5649
2024-06-24 13:49:28,747 Epoch [5/8], Batch [701/748], Loss: 0.4624
2024-06-24 13:50:15,761 Epoch 5/8, Train Loss: 0.5534, Train Accuracy: 0.7614
2024-06-24 13:51:40,628 Epoch 5/8, Val Loss: 0.8307, Val Accuracy: 0.6713
2024-06-24 13:51:41,618 Epoch [6/8], Batch [1/748], Loss: 0.7289
2024-06-24 13:52:32,106 Epoch [6/8], Batch [51/748], Loss: 0.4935
2024-06-24 13:53:22,697 Epoch [6/8], Batch [101/748], Loss: 0.6188
2024-06-24 13:54:13,400 Epoch [6/8], Batch [151/748], Loss: 0.4427
2024-06-24 13:55:03,929 Epoch [6/8], Batch [201/748], Loss: 0.4135
2024-06-24 13:55:54,473 Epoch [6/8], Batch [251/748], Loss: 0.6130
2024-06-24 13:56:44,981 Epoch [6/8], Batch [301/748], Loss: 0.4669
2024-06-24 13:57:35,470 Epoch [6/8], Batch [351/748], Loss: 0.3831
2024-06-24 13:58:26,073 Epoch [6/8], Batch [401/748], Loss: 0.3687
2024-06-24 13:59:16,379 Epoch [6/8], Batch [451/748], Loss: 0.5236
2024-06-24 14:00:06,710 Epoch [6/8], Batch [501/748], Loss: 0.5064
2024-06-24 14:00:57,222 Epoch [6/8], Batch [551/748], Loss: 0.4261
2024-06-24 14:01:47,931 Epoch [6/8], Batch [601/748], Loss: 0.4950
2024-06-24 14:02:38,417 Epoch [6/8], Batch [651/748], Loss: 0.4646
2024-06-24 14:03:28,969 Epoch [6/8], Batch [701/748], Loss: 0.5333
2024-06-24 14:04:15,779 Epoch 6/8, Train Loss: 0.4590, Train Accuracy: 0.8067
2024-06-24 14:05:40,503 Epoch 6/8, Val Loss: 0.8832, Val Accuracy: 0.6701
2024-06-24 14:05:41,530 Epoch [7/8], Batch [1/748], Loss: 0.3875
2024-06-24 14:06:31,611 Epoch [7/8], Batch [51/748], Loss: 0.2641
2024-06-24 14:07:21,968 Epoch [7/8], Batch [101/748], Loss: 0.5782
2024-06-24 14:08:12,438 Epoch [7/8], Batch [151/748], Loss: 0.2995
2024-06-24 14:09:03,428 Epoch [7/8], Batch [201/748], Loss: 0.4977
2024-06-24 14:09:53,920 Epoch [7/8], Batch [251/748], Loss: 0.1618
2024-06-24 14:10:44,379 Epoch [7/8], Batch [301/748], Loss: 0.4797
2024-06-24 14:11:34,983 Epoch [7/8], Batch [351/748], Loss: 0.3215
2024-06-24 14:12:25,567 Epoch [7/8], Batch [401/748], Loss: 0.4391
2024-06-24 14:13:16,298 Epoch [7/8], Batch [451/748], Loss: 0.4097
2024-06-24 14:14:07,056 Epoch [7/8], Batch [501/748], Loss: 0.4161
2024-06-24 14:14:57,483 Epoch [7/8], Batch [551/748], Loss: 0.3044
2024-06-24 14:15:48,114 Epoch [7/8], Batch [601/748], Loss: 0.1631
2024-06-24 14:16:39,077 Epoch [7/8], Batch [651/748], Loss: 0.3047
2024-06-24 14:17:29,772 Epoch [7/8], Batch [701/748], Loss: 0.4743
2024-06-24 14:18:16,758 Epoch 7/8, Train Loss: 0.3758, Train Accuracy: 0.8448
2024-06-24 14:19:41,214 Epoch 7/8, Val Loss: 0.9856, Val Accuracy: 0.6546
2024-06-24 14:19:42,233 Epoch [8/8], Batch [1/748], Loss: 0.2890
2024-06-24 14:20:32,698 Epoch [8/8], Batch [51/748], Loss: 0.2097
2024-06-24 14:21:23,356 Epoch [8/8], Batch [101/748], Loss: 0.1498
2024-06-24 14:22:13,675 Epoch [8/8], Batch [151/748], Loss: 0.4618
2024-06-24 14:23:04,371 Epoch [8/8], Batch [201/748], Loss: 0.1983
2024-06-24 14:23:54,868 Epoch [8/8], Batch [251/748], Loss: 0.1943
2024-06-24 14:24:45,292 Epoch [8/8], Batch [301/748], Loss: 0.1997
2024-06-24 14:25:35,462 Epoch [8/8], Batch [351/748], Loss: 0.3674
2024-06-24 14:26:25,958 Epoch [8/8], Batch [401/748], Loss: 0.1948
2024-06-24 14:27:16,300 Epoch [8/8], Batch [451/748], Loss: 0.2948
2024-06-24 14:28:06,763 Epoch [8/8], Batch [501/748], Loss: 0.4018
2024-06-24 14:28:57,341 Epoch [8/8], Batch [551/748], Loss: 0.2497
2024-06-24 14:29:47,928 Epoch [8/8], Batch [601/748], Loss: 0.3055
2024-06-24 14:30:38,385 Epoch [8/8], Batch [651/748], Loss: 0.1953
2024-06-24 14:31:29,031 Epoch [8/8], Batch [701/748], Loss: 0.2855
2024-06-24 14:32:16,320 Epoch 8/8, Train Loss: 0.2991, Train Accuracy: 0.8793
2024-06-24 14:33:41,201 Epoch 8/8, Val Loss: 1.0885, Val Accuracy: 0.6649
2024-06-24 14:33:41,203 Training finished!
2024-06-24 14:33:41,203 ==================================================
2024-06-24 14:33:46,626 ==================================================
2024-06-24 14:33:46,627 Training BERT + TF-IDF features with Dimension-64...
2024-06-24 14:33:47,645 Epoch [1/8], Batch [1/748], Loss: 1.6488
2024-06-24 14:34:38,088 Epoch [1/8], Batch [51/748], Loss: 1.4116
2024-06-24 14:35:28,324 Epoch [1/8], Batch [101/748], Loss: 1.2277
2024-06-24 14:36:18,904 Epoch [1/8], Batch [151/748], Loss: 1.1146
2024-06-24 14:37:09,359 Epoch [1/8], Batch [201/748], Loss: 0.9271
2024-06-24 14:38:00,196 Epoch [1/8], Batch [251/748], Loss: 0.9314
2024-06-24 14:38:51,078 Epoch [1/8], Batch [301/748], Loss: 0.9642
2024-06-24 14:39:41,678 Epoch [1/8], Batch [351/748], Loss: 0.9619
2024-06-24 14:40:32,172 Epoch [1/8], Batch [401/748], Loss: 1.1243
2024-06-24 14:41:22,959 Epoch [1/8], Batch [451/748], Loss: 0.6107
2024-06-24 14:42:13,408 Epoch [1/8], Batch [501/748], Loss: 0.8117
2024-06-24 14:43:04,041 Epoch [1/8], Batch [551/748], Loss: 0.7746
2024-06-24 14:43:54,653 Epoch [1/8], Batch [601/748], Loss: 0.8769
2024-06-24 14:44:44,927 Epoch [1/8], Batch [651/748], Loss: 0.9846
2024-06-24 14:45:35,596 Epoch [1/8], Batch [701/748], Loss: 0.8536
2024-06-24 14:46:22,578 Epoch 1/8, Train Loss: 1.0273, Train Accuracy: 0.5580
2024-06-24 14:47:47,285 Epoch 1/8, Val Loss: 0.8919, Val Accuracy: 0.6136
2024-06-24 14:47:48,315 Epoch [2/8], Batch [1/748], Loss: 0.6565
2024-06-24 14:48:38,670 Epoch [2/8], Batch [51/748], Loss: 0.8090
2024-06-24 14:49:29,038 Epoch [2/8], Batch [101/748], Loss: 0.8786
2024-06-24 14:50:19,966 Epoch [2/8], Batch [151/748], Loss: 0.5438
2024-06-24 14:51:10,955 Epoch [2/8], Batch [201/748], Loss: 0.7284
2024-06-24 14:52:01,634 Epoch [2/8], Batch [251/748], Loss: 0.7283
2024-06-24 14:52:52,081 Epoch [2/8], Batch [301/748], Loss: 0.6378
2024-06-24 14:53:42,817 Epoch [2/8], Batch [351/748], Loss: 0.8016
2024-06-24 14:54:33,417 Epoch [2/8], Batch [401/748], Loss: 0.8222
2024-06-24 14:55:23,959 Epoch [2/8], Batch [451/748], Loss: 0.6688
2024-06-24 14:56:14,716 Epoch [2/8], Batch [501/748], Loss: 0.7063
2024-06-24 14:57:05,547 Epoch [2/8], Batch [551/748], Loss: 0.7414
2024-06-24 14:57:55,696 Epoch [2/8], Batch [601/748], Loss: 0.7574
2024-06-24 14:58:46,538 Epoch [2/8], Batch [651/748], Loss: 0.6369
2024-06-24 14:59:36,750 Epoch [2/8], Batch [701/748], Loss: 0.7711
2024-06-24 15:00:23,752 Epoch 2/8, Train Loss: 0.7921, Train Accuracy: 0.6495
2024-06-24 15:01:48,256 Epoch 2/8, Val Loss: 0.8482, Val Accuracy: 0.6449
2024-06-24 15:01:49,272 Epoch [3/8], Batch [1/748], Loss: 0.5935
2024-06-24 15:02:39,999 Epoch [3/8], Batch [51/748], Loss: 0.6387
2024-06-24 15:03:30,438 Epoch [3/8], Batch [101/748], Loss: 0.4713
2024-06-24 15:04:21,108 Epoch [3/8], Batch [151/748], Loss: 0.5283
2024-06-24 15:05:12,023 Epoch [3/8], Batch [201/748], Loss: 0.4404
2024-06-24 15:06:02,794 Epoch [3/8], Batch [251/748], Loss: 0.7671
2024-06-24 15:06:53,588 Epoch [3/8], Batch [301/748], Loss: 0.5638
2024-06-24 15:07:43,816 Epoch [3/8], Batch [351/748], Loss: 0.4871
2024-06-24 15:08:34,377 Epoch [3/8], Batch [401/748], Loss: 0.3206
2024-06-24 15:09:24,749 Epoch [3/8], Batch [451/748], Loss: 0.5979
2024-06-24 15:10:15,377 Epoch [3/8], Batch [501/748], Loss: 0.4641
2024-06-24 15:11:05,943 Epoch [3/8], Batch [551/748], Loss: 0.5868
2024-06-24 15:11:56,456 Epoch [3/8], Batch [601/748], Loss: 0.5592
2024-06-24 15:12:47,506 Epoch [3/8], Batch [651/748], Loss: 0.6776
2024-06-24 15:13:38,340 Epoch [3/8], Batch [701/748], Loss: 0.6832
2024-06-24 15:14:25,611 Epoch 3/8, Train Loss: 0.6871, Train Accuracy: 0.7026
2024-06-24 15:15:50,571 Epoch 3/8, Val Loss: 0.8374, Val Accuracy: 0.6360
2024-06-24 15:15:51,582 Epoch [4/8], Batch [1/748], Loss: 0.6941
2024-06-24 15:16:42,051 Epoch [4/8], Batch [51/748], Loss: 0.3049
2024-06-24 15:17:32,575 Epoch [4/8], Batch [101/748], Loss: 0.3636
2024-06-24 15:18:23,111 Epoch [4/8], Batch [151/748], Loss: 0.5866
2024-06-24 15:19:13,377 Epoch [4/8], Batch [201/748], Loss: 0.5470
2024-06-24 15:20:03,739 Epoch [4/8], Batch [251/748], Loss: 0.4700
2024-06-24 15:20:54,662 Epoch [4/8], Batch [301/748], Loss: 0.7370
2024-06-24 15:21:45,173 Epoch [4/8], Batch [351/748], Loss: 0.2185
2024-06-24 15:22:35,503 Epoch [4/8], Batch [401/748], Loss: 0.4172
2024-06-24 15:23:26,421 Epoch [4/8], Batch [451/748], Loss: 0.5118
2024-06-24 15:24:17,234 Epoch [4/8], Batch [501/748], Loss: 0.7410
2024-06-24 15:25:08,238 Epoch [4/8], Batch [551/748], Loss: 0.6491
2024-06-24 15:25:58,703 Epoch [4/8], Batch [601/748], Loss: 0.5449
2024-06-24 15:26:49,227 Epoch [4/8], Batch [651/748], Loss: 0.5711
2024-06-24 15:27:40,053 Epoch [4/8], Batch [701/748], Loss: 0.6099
2024-06-24 15:28:27,609 Epoch 4/8, Train Loss: 0.5785, Train Accuracy: 0.7534
2024-06-24 15:29:52,664 Epoch 4/8, Val Loss: 0.8465, Val Accuracy: 0.6730
2024-06-24 15:29:53,674 Epoch [5/8], Batch [1/748], Loss: 0.5339
2024-06-24 15:30:44,331 Epoch [5/8], Batch [51/748], Loss: 0.3744
2024-06-24 15:31:34,865 Epoch [5/8], Batch [101/748], Loss: 0.3347
2024-06-24 15:32:25,512 Epoch [5/8], Batch [151/748], Loss: 0.3040
2024-06-24 15:33:16,167 Epoch [5/8], Batch [201/748], Loss: 0.4432
2024-06-24 15:34:06,533 Epoch [5/8], Batch [251/748], Loss: 0.5275
2024-06-24 15:34:57,452 Epoch [5/8], Batch [301/748], Loss: 0.5282
2024-06-24 15:35:48,196 Epoch [5/8], Batch [351/748], Loss: 0.4649
2024-06-24 15:36:38,914 Epoch [5/8], Batch [401/748], Loss: 0.5301
2024-06-24 15:37:29,230 Epoch [5/8], Batch [451/748], Loss: 0.3779
2024-06-24 15:38:19,656 Epoch [5/8], Batch [501/748], Loss: 0.3265
2024-06-24 15:39:10,163 Epoch [5/8], Batch [551/748], Loss: 0.4205
2024-06-24 15:40:01,117 Epoch [5/8], Batch [601/748], Loss: 0.4786
2024-06-24 15:40:51,902 Epoch [5/8], Batch [651/748], Loss: 0.5937
2024-06-24 15:41:42,408 Epoch [5/8], Batch [701/748], Loss: 0.5535
2024-06-24 15:42:29,557 Epoch 5/8, Train Loss: 0.4780, Train Accuracy: 0.8014
2024-06-24 15:43:54,228 Epoch 5/8, Val Loss: 0.8653, Val Accuracy: 0.6731
2024-06-24 15:43:55,235 Epoch [6/8], Batch [1/748], Loss: 0.4131
2024-06-24 15:44:45,396 Epoch [6/8], Batch [51/748], Loss: 0.4112
2024-06-24 15:45:35,506 Epoch [6/8], Batch [101/748], Loss: 0.4253
2024-06-24 15:46:25,925 Epoch [6/8], Batch [151/748], Loss: 0.3253
2024-06-24 15:47:16,384 Epoch [6/8], Batch [201/748], Loss: 0.3025
2024-06-24 15:48:07,097 Epoch [6/8], Batch [251/748], Loss: 0.2978
2024-06-24 15:48:57,612 Epoch [6/8], Batch [301/748], Loss: 0.2661
2024-06-24 15:49:48,285 Epoch [6/8], Batch [351/748], Loss: 0.3360
2024-06-24 15:50:39,048 Epoch [6/8], Batch [401/748], Loss: 0.4472
2024-06-24 15:51:29,496 Epoch [6/8], Batch [451/748], Loss: 0.3650
2024-06-24 15:52:20,081 Epoch [6/8], Batch [501/748], Loss: 0.3953
2024-06-24 15:53:11,045 Epoch [6/8], Batch [551/748], Loss: 0.6074
2024-06-24 15:54:02,023 Epoch [6/8], Batch [601/748], Loss: 0.3828
2024-06-24 15:54:52,764 Epoch [6/8], Batch [651/748], Loss: 0.3908
2024-06-24 15:55:43,019 Epoch [6/8], Batch [701/748], Loss: 0.3523
2024-06-24 15:56:30,595 Epoch 6/8, Train Loss: 0.3818, Train Accuracy: 0.8465
2024-06-24 15:57:55,325 Epoch 6/8, Val Loss: 1.1094, Val Accuracy: 0.6385
2024-06-24 15:57:56,350 Epoch [7/8], Batch [1/748], Loss: 0.3452
2024-06-24 15:58:46,727 Epoch [7/8], Batch [51/748], Loss: 0.2484
2024-06-24 15:59:37,332 Epoch [7/8], Batch [101/748], Loss: 0.3792
2024-06-24 16:00:28,385 Epoch [7/8], Batch [151/748], Loss: 0.1918
2024-06-24 16:01:18,762 Epoch [7/8], Batch [201/748], Loss: 0.4294
2024-06-24 16:02:09,169 Epoch [7/8], Batch [251/748], Loss: 0.2858
2024-06-24 16:03:00,238 Epoch [7/8], Batch [301/748], Loss: 0.2325
2024-06-24 16:03:50,824 Epoch [7/8], Batch [351/748], Loss: 0.3211
2024-06-24 16:04:41,556 Epoch [7/8], Batch [401/748], Loss: 0.1603
2024-06-24 16:05:32,095 Epoch [7/8], Batch [451/748], Loss: 0.3266
2024-06-24 16:06:22,871 Epoch [7/8], Batch [501/748], Loss: 0.2546
2024-06-24 16:07:13,251 Epoch [7/8], Batch [551/748], Loss: 0.6788
2024-06-24 16:08:03,491 Epoch [7/8], Batch [601/748], Loss: 0.3776
2024-06-24 16:08:53,815 Epoch [7/8], Batch [651/748], Loss: 0.4217
2024-06-24 16:09:44,715 Epoch [7/8], Batch [701/748], Loss: 0.2190
2024-06-24 16:10:32,046 Epoch 7/8, Train Loss: 0.3147, Train Accuracy: 0.8771
2024-06-24 16:11:56,401 Epoch 7/8, Val Loss: 1.1095, Val Accuracy: 0.6527
2024-06-24 16:11:57,416 Epoch [8/8], Batch [1/748], Loss: 0.2103
2024-06-24 16:12:47,650 Epoch [8/8], Batch [51/748], Loss: 0.2408
2024-06-24 16:13:38,116 Epoch [8/8], Batch [101/748], Loss: 0.3263
2024-06-24 16:14:28,718 Epoch [8/8], Batch [151/748], Loss: 0.1771
2024-06-24 16:15:19,278 Epoch [8/8], Batch [201/748], Loss: 0.2104
2024-06-24 16:16:10,004 Epoch [8/8], Batch [251/748], Loss: 0.3173
2024-06-24 16:17:00,985 Epoch [8/8], Batch [301/748], Loss: 0.2535
2024-06-24 16:17:51,274 Epoch [8/8], Batch [351/748], Loss: 0.1819
2024-06-24 16:18:42,011 Epoch [8/8], Batch [401/748], Loss: 0.2687
2024-06-24 16:19:32,953 Epoch [8/8], Batch [451/748], Loss: 0.5615
2024-06-24 16:20:23,459 Epoch [8/8], Batch [501/748], Loss: 0.4452
2024-06-24 16:21:13,927 Epoch [8/8], Batch [551/748], Loss: 0.2657
2024-06-24 16:22:04,419 Epoch [8/8], Batch [601/748], Loss: 0.1192
2024-06-24 16:22:55,096 Epoch [8/8], Batch [651/748], Loss: 0.0598
2024-06-24 16:23:45,587 Epoch [8/8], Batch [701/748], Loss: 0.1947
2024-06-24 16:24:33,141 Epoch 8/8, Train Loss: 0.2433, Train Accuracy: 0.9085
2024-06-24 16:25:57,606 Epoch 8/8, Val Loss: 1.1645, Val Accuracy: 0.6636
2024-06-24 16:25:57,608 Training finished!
2024-06-24 16:25:57,608 ==================================================
2024-06-24 16:26:02,997 ==================================================
2024-06-24 16:26:02,997 Training BERT + TF-IDF features with Dimension-8...
2024-06-24 16:26:03,998 Epoch [1/8], Batch [1/748], Loss: 1.6511
2024-06-24 16:26:54,010 Epoch [1/8], Batch [51/748], Loss: 1.5451
2024-06-24 16:27:44,857 Epoch [1/8], Batch [101/748], Loss: 1.3706
2024-06-24 16:28:35,454 Epoch [1/8], Batch [151/748], Loss: 1.1335
2024-06-24 16:29:26,095 Epoch [1/8], Batch [201/748], Loss: 1.0782
2024-06-24 16:30:16,947 Epoch [1/8], Batch [251/748], Loss: 0.9828
2024-06-24 16:31:07,692 Epoch [1/8], Batch [301/748], Loss: 1.1479
2024-06-24 16:31:58,780 Epoch [1/8], Batch [351/748], Loss: 0.8923
2024-06-24 16:32:49,794 Epoch [1/8], Batch [401/748], Loss: 1.0004
2024-06-24 16:33:40,247 Epoch [1/8], Batch [451/748], Loss: 1.0982
2024-06-24 16:34:30,655 Epoch [1/8], Batch [501/748], Loss: 1.1617
2024-06-24 16:35:21,476 Epoch [1/8], Batch [551/748], Loss: 0.8182
2024-06-24 16:36:11,933 Epoch [1/8], Batch [601/748], Loss: 0.9179
2024-06-24 16:37:02,416 Epoch [1/8], Batch [651/748], Loss: 1.1478
2024-06-24 16:37:53,307 Epoch [1/8], Batch [701/748], Loss: 0.8008
2024-06-24 16:38:40,883 Epoch 1/8, Train Loss: 1.0491, Train Accuracy: 0.5596
2024-06-24 16:40:05,287 Epoch 1/8, Val Loss: 0.8615, Val Accuracy: 0.6267
2024-06-24 16:40:06,279 Epoch [2/8], Batch [1/748], Loss: 0.7907
2024-06-24 16:40:56,820 Epoch [2/8], Batch [51/748], Loss: 0.6718
2024-06-24 16:41:47,291 Epoch [2/8], Batch [101/748], Loss: 0.7490
2024-06-24 16:42:38,044 Epoch [2/8], Batch [151/748], Loss: 0.6945
2024-06-24 16:43:28,541 Epoch [2/8], Batch [201/748], Loss: 0.5753
2024-06-24 16:44:18,986 Epoch [2/8], Batch [251/748], Loss: 0.9246
2024-06-24 16:45:09,521 Epoch [2/8], Batch [301/748], Loss: 0.9168
2024-06-24 16:46:00,008 Epoch [2/8], Batch [351/748], Loss: 0.6275
2024-06-24 16:46:50,645 Epoch [2/8], Batch [401/748], Loss: 1.1565
2024-06-24 16:47:41,336 Epoch [2/8], Batch [451/748], Loss: 0.7518
2024-06-24 16:48:31,863 Epoch [2/8], Batch [501/748], Loss: 0.6259
2024-06-24 16:49:22,359 Epoch [2/8], Batch [551/748], Loss: 0.7377
2024-06-24 16:50:13,068 Epoch [2/8], Batch [601/748], Loss: 0.7443
2024-06-24 16:51:03,443 Epoch [2/8], Batch [651/748], Loss: 0.7125
2024-06-24 16:51:54,158 Epoch [2/8], Batch [701/748], Loss: 0.8645
2024-06-24 16:52:41,410 Epoch 2/8, Train Loss: 0.7894, Train Accuracy: 0.6582
2024-06-24 16:54:05,816 Epoch 2/8, Val Loss: 0.8585, Val Accuracy: 0.6298
2024-06-24 16:54:06,835 Epoch [3/8], Batch [1/748], Loss: 0.7203
2024-06-24 16:54:57,562 Epoch [3/8], Batch [51/748], Loss: 0.4525
2024-06-24 16:55:48,041 Epoch [3/8], Batch [101/748], Loss: 0.6149
2024-06-24 16:56:38,542 Epoch [3/8], Batch [151/748], Loss: 0.9072
2024-06-24 16:57:28,881 Epoch [3/8], Batch [201/748], Loss: 0.5483
2024-06-24 16:58:19,257 Epoch [3/8], Batch [251/748], Loss: 0.7301
2024-06-24 16:59:09,833 Epoch [3/8], Batch [301/748], Loss: 0.8709
2024-06-24 17:00:00,430 Epoch [3/8], Batch [351/748], Loss: 0.3768
2024-06-24 17:00:51,175 Epoch [3/8], Batch [401/748], Loss: 0.6770
2024-06-24 17:01:41,421 Epoch [3/8], Batch [451/748], Loss: 0.6655
2024-06-24 17:02:32,312 Epoch [3/8], Batch [501/748], Loss: 0.7147
2024-06-24 17:03:23,074 Epoch [3/8], Batch [551/748], Loss: 0.8047
2024-06-24 17:04:13,597 Epoch [3/8], Batch [601/748], Loss: 0.7611
2024-06-24 17:05:03,999 Epoch [3/8], Batch [651/748], Loss: 0.5423
2024-06-24 17:05:54,291 Epoch [3/8], Batch [701/748], Loss: 0.8832
2024-06-24 17:06:41,509 Epoch 3/8, Train Loss: 0.6737, Train Accuracy: 0.7057
2024-06-24 17:08:06,074 Epoch 3/8, Val Loss: 0.8236, Val Accuracy: 0.6537
2024-06-24 17:08:07,088 Epoch [4/8], Batch [1/748], Loss: 0.6794
2024-06-24 17:08:57,456 Epoch [4/8], Batch [51/748], Loss: 0.9019
2024-06-24 17:09:48,071 Epoch [4/8], Batch [101/748], Loss: 0.6294
2024-06-24 17:10:38,676 Epoch [4/8], Batch [151/748], Loss: 0.4918
2024-06-24 17:11:29,401 Epoch [4/8], Batch [201/748], Loss: 0.7492
2024-06-24 17:12:19,702 Epoch [4/8], Batch [251/748], Loss: 0.5404
2024-06-24 17:13:10,388 Epoch [4/8], Batch [301/748], Loss: 0.4847
2024-06-24 17:14:00,968 Epoch [4/8], Batch [351/748], Loss: 0.3210
2024-06-24 17:14:51,487 Epoch [4/8], Batch [401/748], Loss: 0.5628
2024-06-24 17:15:41,666 Epoch [4/8], Batch [451/748], Loss: 0.4282
2024-06-24 17:16:32,256 Epoch [4/8], Batch [501/748], Loss: 0.5928
2024-06-24 17:17:22,900 Epoch [4/8], Batch [551/748], Loss: 0.5486
2024-06-24 17:18:13,269 Epoch [4/8], Batch [601/748], Loss: 0.7973
2024-06-24 17:19:03,874 Epoch [4/8], Batch [651/748], Loss: 0.4700
2024-06-24 17:19:54,263 Epoch [4/8], Batch [701/748], Loss: 0.6221
2024-06-24 17:20:41,417 Epoch 4/8, Train Loss: 0.5681, Train Accuracy: 0.7579
2024-06-24 17:22:06,109 Epoch 4/8, Val Loss: 0.8193, Val Accuracy: 0.6708
2024-06-24 17:22:07,100 Epoch [5/8], Batch [1/748], Loss: 0.4930
2024-06-24 17:22:57,539 Epoch [5/8], Batch [51/748], Loss: 0.3970
2024-06-24 17:23:48,094 Epoch [5/8], Batch [101/748], Loss: 0.3432
2024-06-24 17:24:38,426 Epoch [5/8], Batch [151/748], Loss: 0.4989
2024-06-24 17:25:29,067 Epoch [5/8], Batch [201/748], Loss: 0.3954
2024-06-24 17:26:19,584 Epoch [5/8], Batch [251/748], Loss: 0.4083
2024-06-24 17:27:10,158 Epoch [5/8], Batch [301/748], Loss: 0.7200
2024-06-24 17:28:00,750 Epoch [5/8], Batch [351/748], Loss: 0.5940
2024-06-24 17:28:51,274 Epoch [5/8], Batch [401/748], Loss: 0.3754
2024-06-24 17:29:41,623 Epoch [5/8], Batch [451/748], Loss: 0.6157
2024-06-24 17:30:31,694 Epoch [5/8], Batch [501/748], Loss: 0.5280
2024-06-24 17:31:22,177 Epoch [5/8], Batch [551/748], Loss: 0.5491
2024-06-24 17:32:12,538 Epoch [5/8], Batch [601/748], Loss: 0.5442
2024-06-24 17:33:03,161 Epoch [5/8], Batch [651/748], Loss: 0.5929
2024-06-24 17:33:53,834 Epoch [5/8], Batch [701/748], Loss: 0.2778
2024-06-24 17:34:41,090 Epoch 5/8, Train Loss: 0.4662, Train Accuracy: 0.8053
2024-06-24 17:36:05,729 Epoch 5/8, Val Loss: 0.9393, Val Accuracy: 0.6629
2024-06-24 17:36:06,754 Epoch [6/8], Batch [1/748], Loss: 0.2983
2024-06-24 17:36:57,194 Epoch [6/8], Batch [51/748], Loss: 0.3088
2024-06-24 17:37:47,655 Epoch [6/8], Batch [101/748], Loss: 0.4357
2024-06-24 17:38:38,205 Epoch [6/8], Batch [151/748], Loss: 0.4369
2024-06-24 17:39:28,765 Epoch [6/8], Batch [201/748], Loss: 0.3742
2024-06-24 17:40:19,148 Epoch [6/8], Batch [251/748], Loss: 0.3726
2024-06-24 17:41:09,969 Epoch [6/8], Batch [301/748], Loss: 0.5621
2024-06-24 17:42:00,490 Epoch [6/8], Batch [351/748], Loss: 0.4579
2024-06-24 17:42:50,950 Epoch [6/8], Batch [401/748], Loss: 0.3758
2024-06-24 17:43:41,183 Epoch [6/8], Batch [451/748], Loss: 0.4688
2024-06-24 17:44:31,885 Epoch [6/8], Batch [501/748], Loss: 0.3595
2024-06-24 17:45:22,776 Epoch [6/8], Batch [551/748], Loss: 0.5684
2024-06-24 17:46:13,565 Epoch [6/8], Batch [601/748], Loss: 0.5060
2024-06-24 17:47:03,948 Epoch [6/8], Batch [651/748], Loss: 0.3482
2024-06-24 17:47:54,479 Epoch [6/8], Batch [701/748], Loss: 0.2804
2024-06-24 17:48:41,748 Epoch 6/8, Train Loss: 0.3879, Train Accuracy: 0.8403
2024-06-24 17:50:06,002 Epoch 6/8, Val Loss: 0.8645, Val Accuracy: 0.6882
2024-06-24 17:50:07,019 Epoch [7/8], Batch [1/748], Loss: 0.3229
2024-06-24 17:50:57,638 Epoch [7/8], Batch [51/748], Loss: 0.2424
2024-06-24 17:51:47,979 Epoch [7/8], Batch [101/748], Loss: 0.2533
2024-06-24 17:52:39,093 Epoch [7/8], Batch [151/748], Loss: 0.1914
2024-06-24 17:53:29,594 Epoch [7/8], Batch [201/748], Loss: 0.2796
2024-06-24 17:54:19,862 Epoch [7/8], Batch [251/748], Loss: 0.2212
2024-06-24 17:55:10,385 Epoch [7/8], Batch [301/748], Loss: 0.4064
2024-06-24 17:56:00,654 Epoch [7/8], Batch [351/748], Loss: 0.4862
2024-06-24 17:56:51,653 Epoch [7/8], Batch [401/748], Loss: 0.2959
2024-06-24 17:57:42,293 Epoch [7/8], Batch [451/748], Loss: 0.4007
2024-06-24 17:58:32,544 Epoch [7/8], Batch [501/748], Loss: 0.2494
2024-06-24 17:59:23,374 Epoch [7/8], Batch [551/748], Loss: 0.1660
2024-06-24 18:00:14,325 Epoch [7/8], Batch [601/748], Loss: 0.3112
2024-06-24 18:01:05,224 Epoch [7/8], Batch [651/748], Loss: 0.3050
2024-06-24 18:01:55,560 Epoch [7/8], Batch [701/748], Loss: 0.1855
2024-06-24 18:02:42,823 Epoch 7/8, Train Loss: 0.3178, Train Accuracy: 0.8706
2024-06-24 18:04:07,193 Epoch 7/8, Val Loss: 0.9962, Val Accuracy: 0.6741
2024-06-24 18:04:08,196 Epoch [8/8], Batch [1/748], Loss: 0.2411
2024-06-24 18:04:58,610 Epoch [8/8], Batch [51/748], Loss: 0.2273
2024-06-24 18:05:49,301 Epoch [8/8], Batch [101/748], Loss: 0.1777
2024-06-24 18:06:39,762 Epoch [8/8], Batch [151/748], Loss: 0.1728
2024-06-24 18:07:30,344 Epoch [8/8], Batch [201/748], Loss: 0.3399
2024-06-24 18:08:20,622 Epoch [8/8], Batch [251/748], Loss: 0.1729
2024-06-24 18:09:11,335 Epoch [8/8], Batch [301/748], Loss: 0.1440
2024-06-24 18:10:01,658 Epoch [8/8], Batch [351/748], Loss: 0.1970
2024-06-24 18:10:52,230 Epoch [8/8], Batch [401/748], Loss: 0.3739
2024-06-24 18:11:43,135 Epoch [8/8], Batch [451/748], Loss: 0.2216
2024-06-24 18:12:33,792 Epoch [8/8], Batch [501/748], Loss: 0.1730
2024-06-24 18:13:24,092 Epoch [8/8], Batch [551/748], Loss: 0.3006
2024-06-24 18:14:14,799 Epoch [8/8], Batch [601/748], Loss: 0.3916
2024-06-24 18:15:05,300 Epoch [8/8], Batch [651/748], Loss: 0.2200
2024-06-24 18:15:55,662 Epoch [8/8], Batch [701/748], Loss: 0.2288
2024-06-24 18:16:42,984 Epoch 8/8, Train Loss: 0.2567, Train Accuracy: 0.9008
2024-06-24 18:18:07,628 Epoch 8/8, Val Loss: 1.0702, Val Accuracy: 0.6735
2024-06-24 18:18:07,630 Training finished!
2024-06-24 18:18:07,630 ==================================================
