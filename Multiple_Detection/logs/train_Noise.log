2024-06-22 23:33:37,299 ==================================================
2024-06-22 23:33:37,299 Training with Guassian Noise of 10000 length...
2024-06-22 23:33:39,077 Epoch [1/8], Batch [1/748], Loss: 1.6052
2024-06-22 23:34:28,210 Epoch [1/8], Batch [51/748], Loss: 1.6378
2024-06-22 23:35:18,539 Epoch [1/8], Batch [101/748], Loss: 1.4925
2024-06-22 23:36:08,890 Epoch [1/8], Batch [151/748], Loss: 1.2789
2024-06-22 23:36:59,594 Epoch [1/8], Batch [201/748], Loss: 1.1730
2024-06-22 23:37:50,328 Epoch [1/8], Batch [251/748], Loss: 1.2723
2024-06-22 23:38:40,883 Epoch [1/8], Batch [301/748], Loss: 1.1272
2024-06-22 23:39:31,572 Epoch [1/8], Batch [351/748], Loss: 0.9287
2024-06-22 23:40:22,607 Epoch [1/8], Batch [401/748], Loss: 0.9491
2024-06-22 23:41:13,514 Epoch [1/8], Batch [451/748], Loss: 1.2341
2024-06-22 23:42:04,540 Epoch [1/8], Batch [501/748], Loss: 0.7623
2024-06-22 23:42:55,680 Epoch [1/8], Batch [551/748], Loss: 0.9400
2024-06-22 23:43:46,938 Epoch [1/8], Batch [601/748], Loss: 0.8817
2024-06-22 23:44:38,089 Epoch [1/8], Batch [651/748], Loss: 1.0888
2024-06-22 23:45:29,381 Epoch [1/8], Batch [701/748], Loss: 1.0436
2024-06-22 23:46:17,041 Epoch 1/8, Train Loss: 1.1282, Train Accuracy: 0.4816
2024-06-22 23:47:39,667 Epoch 1/8, Val Loss: 0.9973, Val Accuracy: 0.5446
2024-06-22 23:47:40,701 Epoch [2/8], Batch [1/748], Loss: 0.8126
2024-06-22 23:48:32,181 Epoch [2/8], Batch [51/748], Loss: 0.8140
2024-06-22 23:49:23,278 Epoch [2/8], Batch [101/748], Loss: 0.9222
2024-06-22 23:50:14,779 Epoch [2/8], Batch [151/748], Loss: 0.9191
2024-06-22 23:51:05,938 Epoch [2/8], Batch [201/748], Loss: 0.7097
2024-06-22 23:51:57,402 Epoch [2/8], Batch [251/748], Loss: 0.8750
2024-06-22 23:52:48,672 Epoch [2/8], Batch [301/748], Loss: 0.8157
2024-06-22 23:53:39,982 Epoch [2/8], Batch [351/748], Loss: 0.8961
2024-06-22 23:54:31,217 Epoch [2/8], Batch [401/748], Loss: 0.7636
2024-06-22 23:55:22,590 Epoch [2/8], Batch [451/748], Loss: 0.7077
2024-06-22 23:56:13,679 Epoch [2/8], Batch [501/748], Loss: 0.6288
2024-06-22 23:57:05,042 Epoch [2/8], Batch [551/748], Loss: 0.7294
2024-06-22 23:57:56,369 Epoch [2/8], Batch [601/748], Loss: 0.7767
2024-06-22 23:58:47,544 Epoch [2/8], Batch [651/748], Loss: 0.8872
2024-06-22 23:59:38,780 Epoch [2/8], Batch [701/748], Loss: 1.0383
2024-06-23 00:00:26,719 Epoch 2/8, Train Loss: 0.8319, Train Accuracy: 0.6312
2024-06-23 00:01:49,699 Epoch 2/8, Val Loss: 0.8132, Val Accuracy: 0.6303
2024-06-23 00:01:50,730 Epoch [3/8], Batch [1/748], Loss: 0.9041
2024-06-23 00:02:41,755 Epoch [3/8], Batch [51/748], Loss: 0.6820
2024-06-23 00:03:33,023 Epoch [3/8], Batch [101/748], Loss: 0.6838
2024-06-23 00:04:24,070 Epoch [3/8], Batch [151/748], Loss: 0.7790
2024-06-23 00:05:15,296 Epoch [3/8], Batch [201/748], Loss: 0.7013
2024-06-23 00:06:06,449 Epoch [3/8], Batch [251/748], Loss: 0.8382
2024-06-23 00:06:57,756 Epoch [3/8], Batch [301/748], Loss: 0.6565
2024-06-23 00:07:48,988 Epoch [3/8], Batch [351/748], Loss: 0.5313
2024-06-23 00:08:40,303 Epoch [3/8], Batch [401/748], Loss: 0.8801
2024-06-23 00:09:31,710 Epoch [3/8], Batch [451/748], Loss: 0.6907
2024-06-23 00:10:22,914 Epoch [3/8], Batch [501/748], Loss: 0.5539
2024-06-23 00:11:14,231 Epoch [3/8], Batch [551/748], Loss: 0.9405
2024-06-23 00:12:05,527 Epoch [3/8], Batch [601/748], Loss: 0.6579
2024-06-23 00:12:56,932 Epoch [3/8], Batch [651/748], Loss: 0.5477
2024-06-23 00:13:48,325 Epoch [3/8], Batch [701/748], Loss: 0.5282
2024-06-23 00:14:36,109 Epoch 3/8, Train Loss: 0.6959, Train Accuracy: 0.7098
2024-06-23 00:15:59,282 Epoch 3/8, Val Loss: 0.8165, Val Accuracy: 0.6327
2024-06-23 00:16:00,300 Epoch [4/8], Batch [1/748], Loss: 0.5501
2024-06-23 00:16:51,443 Epoch [4/8], Batch [51/748], Loss: 0.6196
2024-06-23 00:17:42,617 Epoch [4/8], Batch [101/748], Loss: 0.6137
2024-06-23 00:18:33,976 Epoch [4/8], Batch [151/748], Loss: 0.6091
2024-06-23 00:19:25,306 Epoch [4/8], Batch [201/748], Loss: 0.4599
2024-06-23 00:20:16,662 Epoch [4/8], Batch [251/748], Loss: 0.3616
2024-06-23 00:21:07,933 Epoch [4/8], Batch [301/748], Loss: 0.6985
2024-06-23 00:21:59,554 Epoch [4/8], Batch [351/748], Loss: 0.6640
2024-06-23 00:22:51,095 Epoch [4/8], Batch [401/748], Loss: 0.5084
2024-06-23 00:23:42,491 Epoch [4/8], Batch [451/748], Loss: 0.6132
2024-06-23 00:24:33,742 Epoch [4/8], Batch [501/748], Loss: 0.6169
2024-06-23 00:25:25,076 Epoch [4/8], Batch [551/748], Loss: 0.4982
2024-06-23 00:26:16,480 Epoch [4/8], Batch [601/748], Loss: 0.6491
2024-06-23 00:27:07,884 Epoch [4/8], Batch [651/748], Loss: 0.5041
2024-06-23 00:27:59,298 Epoch [4/8], Batch [701/748], Loss: 0.7391
2024-06-23 00:28:47,276 Epoch 4/8, Train Loss: 0.5797, Train Accuracy: 0.7713
2024-06-23 00:30:11,093 Epoch 4/8, Val Loss: 0.8516, Val Accuracy: 0.6243
2024-06-23 00:30:12,112 Epoch [5/8], Batch [1/748], Loss: 0.4883
2024-06-23 00:31:03,352 Epoch [5/8], Batch [51/748], Loss: 0.5855
2024-06-23 00:31:54,734 Epoch [5/8], Batch [101/748], Loss: 0.5591
2024-06-23 00:32:45,995 Epoch [5/8], Batch [151/748], Loss: 0.7852
2024-06-23 00:33:37,441 Epoch [5/8], Batch [201/748], Loss: 0.4778
2024-06-23 00:34:28,873 Epoch [5/8], Batch [251/748], Loss: 0.4497
2024-06-23 00:35:20,375 Epoch [5/8], Batch [301/748], Loss: 0.5223
2024-06-23 00:36:11,659 Epoch [5/8], Batch [351/748], Loss: 0.3762
2024-06-23 00:37:03,067 Epoch [5/8], Batch [401/748], Loss: 0.4980
2024-06-23 00:37:54,717 Epoch [5/8], Batch [451/748], Loss: 0.4535
2024-06-23 00:38:46,575 Epoch [5/8], Batch [501/748], Loss: 0.5232
2024-06-23 00:39:38,525 Epoch [5/8], Batch [551/748], Loss: 0.5286
2024-06-23 00:40:30,395 Epoch [5/8], Batch [601/748], Loss: 0.4252
2024-06-23 00:41:22,060 Epoch [5/8], Batch [651/748], Loss: 0.5339
2024-06-23 00:42:13,908 Epoch [5/8], Batch [701/748], Loss: 0.4306
2024-06-23 00:43:02,121 Epoch 5/8, Train Loss: 0.4726, Train Accuracy: 0.8255
2024-06-23 00:44:26,445 Epoch 5/8, Val Loss: 0.9267, Val Accuracy: 0.6218
2024-06-23 00:44:27,458 Epoch [6/8], Batch [1/748], Loss: 0.4359
2024-06-23 00:45:18,896 Epoch [6/8], Batch [51/748], Loss: 0.3543
2024-06-23 00:46:10,566 Epoch [6/8], Batch [101/748], Loss: 0.3735
2024-06-23 00:47:02,226 Epoch [6/8], Batch [151/748], Loss: 0.3665
2024-06-23 00:47:53,957 Epoch [6/8], Batch [201/748], Loss: 0.3505
2024-06-23 00:48:45,517 Epoch [6/8], Batch [251/748], Loss: 0.5572
2024-06-23 00:49:37,161 Epoch [6/8], Batch [301/748], Loss: 0.2575
2024-06-23 00:50:28,653 Epoch [6/8], Batch [351/748], Loss: 0.3565
2024-06-23 00:51:20,378 Epoch [6/8], Batch [401/748], Loss: 0.2927
2024-06-23 00:52:12,029 Epoch [6/8], Batch [451/748], Loss: 0.3659
2024-06-23 00:53:03,653 Epoch [6/8], Batch [501/748], Loss: 0.3104
2024-06-23 00:53:54,819 Epoch [6/8], Batch [551/748], Loss: 0.3979
2024-06-23 00:54:46,210 Epoch [6/8], Batch [601/748], Loss: 0.3833
2024-06-23 00:55:37,976 Epoch [6/8], Batch [651/748], Loss: 0.3717
2024-06-23 00:56:29,139 Epoch [6/8], Batch [701/748], Loss: 0.3924
2024-06-23 00:57:17,219 Epoch 6/8, Train Loss: 0.3770, Train Accuracy: 0.8677
2024-06-23 00:58:40,400 Epoch 6/8, Val Loss: 0.8589, Val Accuracy: 0.6726
2024-06-23 00:58:41,415 Epoch [7/8], Batch [1/748], Loss: 0.3391
2024-06-23 00:59:32,729 Epoch [7/8], Batch [51/748], Loss: 0.2960
2024-06-23 01:00:24,262 Epoch [7/8], Batch [101/748], Loss: 0.1919
2024-06-23 01:01:15,729 Epoch [7/8], Batch [151/748], Loss: 0.2064
2024-06-23 01:02:07,248 Epoch [7/8], Batch [201/748], Loss: 0.2917
2024-06-23 01:02:58,621 Epoch [7/8], Batch [251/748], Loss: 0.1899
2024-06-23 01:03:50,168 Epoch [7/8], Batch [301/748], Loss: 0.2072
2024-06-23 01:04:41,489 Epoch [7/8], Batch [351/748], Loss: 0.2309
2024-06-23 01:05:32,887 Epoch [7/8], Batch [401/748], Loss: 0.4649
2024-06-23 01:06:24,354 Epoch [7/8], Batch [451/748], Loss: 0.2302
2024-06-23 01:07:15,721 Epoch [7/8], Batch [501/748], Loss: 0.1565
2024-06-23 01:08:07,069 Epoch [7/8], Batch [551/748], Loss: 0.3393
2024-06-23 01:08:58,499 Epoch [7/8], Batch [601/748], Loss: 0.2553
2024-06-23 01:09:49,798 Epoch [7/8], Batch [651/748], Loss: 0.1227
2024-06-23 01:10:41,249 Epoch [7/8], Batch [701/748], Loss: 0.2807
2024-06-23 01:11:29,280 Epoch 7/8, Train Loss: 0.2861, Train Accuracy: 0.9047
2024-06-23 01:12:52,826 Epoch 7/8, Val Loss: 0.9611, Val Accuracy: 0.6577
2024-06-23 01:12:53,850 Epoch [8/8], Batch [1/748], Loss: 0.1419
2024-06-23 01:13:45,151 Epoch [8/8], Batch [51/748], Loss: 0.1913
2024-06-23 01:14:36,503 Epoch [8/8], Batch [101/748], Loss: 0.1398
2024-06-23 01:15:27,958 Epoch [8/8], Batch [151/748], Loss: 0.1717
2024-06-23 01:16:19,260 Epoch [8/8], Batch [201/748], Loss: 0.2107
2024-06-23 01:17:10,717 Epoch [8/8], Batch [251/748], Loss: 0.2247
2024-06-23 01:18:01,846 Epoch [8/8], Batch [301/748], Loss: 0.1714
2024-06-23 01:18:53,055 Epoch [8/8], Batch [351/748], Loss: 0.0999
2024-06-23 01:19:44,350 Epoch [8/8], Batch [401/748], Loss: 0.3496
2024-06-23 01:20:35,638 Epoch [8/8], Batch [451/748], Loss: 0.2155
2024-06-23 01:21:26,940 Epoch [8/8], Batch [501/748], Loss: 0.2663
2024-06-23 01:22:18,776 Epoch [8/8], Batch [551/748], Loss: 0.1758
2024-06-23 01:23:10,270 Epoch [8/8], Batch [601/748], Loss: 0.4056
2024-06-23 01:24:01,766 Epoch [8/8], Batch [651/748], Loss: 0.3439
2024-06-23 01:24:53,173 Epoch [8/8], Batch [701/748], Loss: 0.2700
2024-06-23 01:25:41,344 Epoch 8/8, Train Loss: 0.2121, Train Accuracy: 0.9321
2024-06-23 01:27:05,526 Epoch 8/8, Val Loss: 1.0524, Val Accuracy: 0.6623
2024-06-23 01:27:05,529 Training finished!
2024-06-23 01:27:05,530 ==================================================
2024-06-23 01:27:07,254 ==================================================
2024-06-23 01:27:07,254 Training with Guassian Noise of 1000 length...
2024-06-23 01:27:08,325 Epoch [1/8], Batch [1/748], Loss: 1.6369
2024-06-23 01:27:59,711 Epoch [1/8], Batch [51/748], Loss: 1.5763
2024-06-23 01:28:50,861 Epoch [1/8], Batch [101/748], Loss: 1.3331
2024-06-23 01:29:42,066 Epoch [1/8], Batch [151/748], Loss: 1.3083
2024-06-23 01:30:33,531 Epoch [1/8], Batch [201/748], Loss: 1.2580
2024-06-23 01:31:25,086 Epoch [1/8], Batch [251/748], Loss: 1.0948
2024-06-23 01:32:16,502 Epoch [1/8], Batch [301/748], Loss: 1.0493
2024-06-23 01:33:08,158 Epoch [1/8], Batch [351/748], Loss: 0.9997
2024-06-23 01:33:59,681 Epoch [1/8], Batch [401/748], Loss: 0.9883
2024-06-23 01:34:50,913 Epoch [1/8], Batch [451/748], Loss: 1.0549
2024-06-23 01:35:42,456 Epoch [1/8], Batch [501/748], Loss: 1.0569
2024-06-23 01:36:33,859 Epoch [1/8], Batch [551/748], Loss: 1.4914
2024-06-23 01:37:25,440 Epoch [1/8], Batch [601/748], Loss: 0.9857
2024-06-23 01:38:16,977 Epoch [1/8], Batch [651/748], Loss: 0.9316
2024-06-23 01:39:08,446 Epoch [1/8], Batch [701/748], Loss: 0.9335
2024-06-23 01:39:56,578 Epoch 1/8, Train Loss: 1.1229, Train Accuracy: 0.4931
2024-06-23 01:41:20,009 Epoch 1/8, Val Loss: 0.9378, Val Accuracy: 0.5584
2024-06-23 01:41:21,016 Epoch [2/8], Batch [1/748], Loss: 0.9003
2024-06-23 01:42:12,214 Epoch [2/8], Batch [51/748], Loss: 0.9200
2024-06-23 01:43:03,543 Epoch [2/8], Batch [101/748], Loss: 0.8848
2024-06-23 01:43:55,249 Epoch [2/8], Batch [151/748], Loss: 0.8826
2024-06-23 01:44:46,620 Epoch [2/8], Batch [201/748], Loss: 0.8542
2024-06-23 01:45:38,145 Epoch [2/8], Batch [251/748], Loss: 0.9047
2024-06-23 01:46:29,635 Epoch [2/8], Batch [301/748], Loss: 0.7125
2024-06-23 01:47:21,013 Epoch [2/8], Batch [351/748], Loss: 1.0422
2024-06-23 01:48:12,230 Epoch [2/8], Batch [401/748], Loss: 0.8452
2024-06-23 01:49:03,356 Epoch [2/8], Batch [451/748], Loss: 0.6179
2024-06-23 01:49:54,727 Epoch [2/8], Batch [501/748], Loss: 0.7958
2024-06-23 01:50:45,991 Epoch [2/8], Batch [551/748], Loss: 0.7817
2024-06-23 01:51:37,214 Epoch [2/8], Batch [601/748], Loss: 0.9425
2024-06-23 01:52:28,423 Epoch [2/8], Batch [651/748], Loss: 0.6962
2024-06-23 01:53:19,327 Epoch [2/8], Batch [701/748], Loss: 0.7785
2024-06-23 01:54:06,761 Epoch 2/8, Train Loss: 0.8548, Train Accuracy: 0.6125
2024-06-23 01:55:28,483 Epoch 2/8, Val Loss: 0.9534, Val Accuracy: 0.5894
2024-06-23 01:55:29,488 Epoch [3/8], Batch [1/748], Loss: 0.7523
2024-06-23 01:56:20,262 Epoch [3/8], Batch [51/748], Loss: 0.7254
2024-06-23 01:57:11,121 Epoch [3/8], Batch [101/748], Loss: 0.8241
2024-06-23 01:58:01,691 Epoch [3/8], Batch [151/748], Loss: 0.8636
2024-06-23 01:58:52,279 Epoch [3/8], Batch [201/748], Loss: 0.8284
2024-06-23 01:59:42,741 Epoch [3/8], Batch [251/748], Loss: 0.6757
2024-06-23 02:00:33,436 Epoch [3/8], Batch [301/748], Loss: 0.5532
2024-06-23 02:01:24,090 Epoch [3/8], Batch [351/748], Loss: 0.7250
2024-06-23 02:02:14,798 Epoch [3/8], Batch [401/748], Loss: 0.4394
2024-06-23 02:03:05,467 Epoch [3/8], Batch [451/748], Loss: 0.7248
2024-06-23 02:03:56,281 Epoch [3/8], Batch [501/748], Loss: 0.7781
2024-06-23 02:04:46,928 Epoch [3/8], Batch [551/748], Loss: 0.6568
2024-06-23 02:05:37,926 Epoch [3/8], Batch [601/748], Loss: 0.7329
2024-06-23 02:06:29,080 Epoch [3/8], Batch [651/748], Loss: 0.7431
2024-06-23 02:07:20,067 Epoch [3/8], Batch [701/748], Loss: 0.6221
2024-06-23 02:08:07,527 Epoch 3/8, Train Loss: 0.7386, Train Accuracy: 0.6707
2024-06-23 02:09:30,484 Epoch 3/8, Val Loss: 0.8515, Val Accuracy: 0.6273
2024-06-23 02:09:31,493 Epoch [4/8], Batch [1/748], Loss: 0.8567
2024-06-23 02:10:22,312 Epoch [4/8], Batch [51/748], Loss: 0.6726
2024-06-23 02:11:13,195 Epoch [4/8], Batch [101/748], Loss: 0.5035
2024-06-23 02:12:03,879 Epoch [4/8], Batch [151/748], Loss: 0.6144
2024-06-23 02:12:54,620 Epoch [4/8], Batch [201/748], Loss: 0.7257
2024-06-23 02:13:45,585 Epoch [4/8], Batch [251/748], Loss: 0.6149
2024-06-23 02:14:36,275 Epoch [4/8], Batch [301/748], Loss: 0.7427
2024-06-23 02:15:26,889 Epoch [4/8], Batch [351/748], Loss: 0.4400
2024-06-23 02:16:17,777 Epoch [4/8], Batch [401/748], Loss: 0.8604
2024-06-23 02:17:08,436 Epoch [4/8], Batch [451/748], Loss: 0.5528
2024-06-23 02:17:59,178 Epoch [4/8], Batch [501/748], Loss: 0.4778
2024-06-23 02:18:49,817 Epoch [4/8], Batch [551/748], Loss: 0.6634
2024-06-23 02:19:40,440 Epoch [4/8], Batch [601/748], Loss: 0.5945
2024-06-23 02:20:31,037 Epoch [4/8], Batch [651/748], Loss: 0.6980
2024-06-23 02:21:21,560 Epoch [4/8], Batch [701/748], Loss: 0.6340
2024-06-23 02:22:08,776 Epoch 4/8, Train Loss: 0.6447, Train Accuracy: 0.7160
2024-06-23 02:23:29,694 Epoch 4/8, Val Loss: 0.8030, Val Accuracy: 0.6626
2024-06-23 02:23:30,713 Epoch [5/8], Batch [1/748], Loss: 0.4799
2024-06-23 02:24:21,396 Epoch [5/8], Batch [51/748], Loss: 0.5431
2024-06-23 02:25:12,165 Epoch [5/8], Batch [101/748], Loss: 0.5396
2024-06-23 02:26:02,632 Epoch [5/8], Batch [151/748], Loss: 0.4150
2024-06-23 02:26:53,129 Epoch [5/8], Batch [201/748], Loss: 0.5137
2024-06-23 02:27:43,664 Epoch [5/8], Batch [251/748], Loss: 0.4818
2024-06-23 02:28:34,278 Epoch [5/8], Batch [301/748], Loss: 0.3960
2024-06-23 02:29:24,926 Epoch [5/8], Batch [351/748], Loss: 0.5886
2024-06-23 02:30:15,691 Epoch [5/8], Batch [401/748], Loss: 0.3081
2024-06-23 02:31:05,762 Epoch [5/8], Batch [451/748], Loss: 0.5601
2024-06-23 02:31:55,914 Epoch [5/8], Batch [501/748], Loss: 0.5089
2024-06-23 02:32:46,148 Epoch [5/8], Batch [551/748], Loss: 0.4703
2024-06-23 02:33:36,481 Epoch [5/8], Batch [601/748], Loss: 0.6509
2024-06-23 02:34:26,628 Epoch [5/8], Batch [651/748], Loss: 0.5125
2024-06-23 02:35:16,786 Epoch [5/8], Batch [701/748], Loss: 0.5507
2024-06-23 02:36:03,550 Epoch 5/8, Train Loss: 0.5526, Train Accuracy: 0.7619
2024-06-23 02:37:22,674 Epoch 5/8, Val Loss: 0.8460, Val Accuracy: 0.6700
2024-06-23 02:37:23,693 Epoch [6/8], Batch [1/748], Loss: 0.4593
2024-06-23 02:38:13,676 Epoch [6/8], Batch [51/748], Loss: 0.4884
2024-06-23 02:39:03,752 Epoch [6/8], Batch [101/748], Loss: 0.4749
2024-06-23 02:39:53,977 Epoch [6/8], Batch [151/748], Loss: 0.5657
2024-06-23 02:40:44,103 Epoch [6/8], Batch [201/748], Loss: 0.5481
2024-06-23 02:41:34,396 Epoch [6/8], Batch [251/748], Loss: 0.5143
2024-06-23 02:42:24,550 Epoch [6/8], Batch [301/748], Loss: 0.3579
2024-06-23 02:43:14,819 Epoch [6/8], Batch [351/748], Loss: 0.6759
2024-06-23 02:44:04,992 Epoch [6/8], Batch [401/748], Loss: 0.3931
2024-06-23 02:44:55,196 Epoch [6/8], Batch [451/748], Loss: 0.3382
2024-06-23 02:45:45,376 Epoch [6/8], Batch [501/748], Loss: 0.4490
2024-06-23 02:46:35,468 Epoch [6/8], Batch [551/748], Loss: 0.3577
2024-06-23 02:47:25,829 Epoch [6/8], Batch [601/748], Loss: 0.6615
2024-06-23 02:48:16,026 Epoch [6/8], Batch [651/748], Loss: 0.4442
2024-06-23 02:49:06,231 Epoch [6/8], Batch [701/748], Loss: 0.5330
2024-06-23 02:49:52,939 Epoch 6/8, Train Loss: 0.4581, Train Accuracy: 0.8083
2024-06-23 02:51:12,104 Epoch 6/8, Val Loss: 0.9196, Val Accuracy: 0.6509
2024-06-23 02:51:13,102 Epoch [7/8], Batch [1/748], Loss: 0.5207
2024-06-23 02:52:03,229 Epoch [7/8], Batch [51/748], Loss: 0.5488
2024-06-23 02:52:53,438 Epoch [7/8], Batch [101/748], Loss: 0.4190
2024-06-23 02:53:43,738 Epoch [7/8], Batch [151/748], Loss: 0.4310
2024-06-23 02:54:33,845 Epoch [7/8], Batch [201/748], Loss: 0.3936
2024-06-23 02:55:23,984 Epoch [7/8], Batch [251/748], Loss: 0.3833
2024-06-23 02:56:14,133 Epoch [7/8], Batch [301/748], Loss: 0.2567
2024-06-23 02:57:04,277 Epoch [7/8], Batch [351/748], Loss: 0.3443
2024-06-23 02:57:54,355 Epoch [7/8], Batch [401/748], Loss: 0.4124
2024-06-23 02:58:44,568 Epoch [7/8], Batch [451/748], Loss: 0.1884
2024-06-23 02:59:34,711 Epoch [7/8], Batch [501/748], Loss: 0.2794
2024-06-23 03:00:25,044 Epoch [7/8], Batch [551/748], Loss: 0.4266
2024-06-23 03:01:15,351 Epoch [7/8], Batch [601/748], Loss: 0.3039
2024-06-23 03:02:05,547 Epoch [7/8], Batch [651/748], Loss: 0.5315
2024-06-23 03:02:55,773 Epoch [7/8], Batch [701/748], Loss: 0.3137
2024-06-23 03:03:42,738 Epoch 7/8, Train Loss: 0.3708, Train Accuracy: 0.8484
2024-06-23 03:05:01,913 Epoch 7/8, Val Loss: 0.9115, Val Accuracy: 0.6792
2024-06-23 03:05:02,948 Epoch [8/8], Batch [1/748], Loss: 0.4566
2024-06-23 03:05:53,100 Epoch [8/8], Batch [51/748], Loss: 0.2956
2024-06-23 03:06:43,183 Epoch [8/8], Batch [101/748], Loss: 0.1633
2024-06-23 03:07:33,312 Epoch [8/8], Batch [151/748], Loss: 0.1173
2024-06-23 03:08:23,412 Epoch [8/8], Batch [201/748], Loss: 0.2411
2024-06-23 03:09:13,570 Epoch [8/8], Batch [251/748], Loss: 0.3001
2024-06-23 03:10:03,788 Epoch [8/8], Batch [301/748], Loss: 0.2460
2024-06-23 03:10:54,006 Epoch [8/8], Batch [351/748], Loss: 0.3611
2024-06-23 03:11:44,257 Epoch [8/8], Batch [401/748], Loss: 0.5937
2024-06-23 03:12:34,491 Epoch [8/8], Batch [451/748], Loss: 0.1871
2024-06-23 03:13:24,904 Epoch [8/8], Batch [501/748], Loss: 0.3182
2024-06-23 03:14:14,925 Epoch [8/8], Batch [551/748], Loss: 0.4223
2024-06-23 03:15:05,150 Epoch [8/8], Batch [601/748], Loss: 0.3044
2024-06-23 03:15:55,210 Epoch [8/8], Batch [651/748], Loss: 0.2413
2024-06-23 03:16:45,394 Epoch [8/8], Batch [701/748], Loss: 0.5295
2024-06-23 03:17:32,447 Epoch 8/8, Train Loss: 0.2992, Train Accuracy: 0.8841
2024-06-23 03:18:51,648 Epoch 8/8, Val Loss: 1.1200, Val Accuracy: 0.6487
2024-06-23 03:18:51,650 Training finished!
2024-06-23 03:18:51,650 ==================================================
2024-06-23 03:18:52,370 ==================================================
2024-06-23 03:18:52,370 Training with Guassian Noise of 256 length...
2024-06-23 03:18:53,372 Epoch [1/8], Batch [1/748], Loss: 1.6325
2024-06-23 03:19:43,604 Epoch [1/8], Batch [51/748], Loss: 1.4157
2024-06-23 03:20:33,864 Epoch [1/8], Batch [101/748], Loss: 1.2330
2024-06-23 03:21:24,110 Epoch [1/8], Batch [151/748], Loss: 1.3265
2024-06-23 03:22:14,183 Epoch [1/8], Batch [201/748], Loss: 1.0429
2024-06-23 03:23:04,520 Epoch [1/8], Batch [251/748], Loss: 1.1284
2024-06-23 03:23:54,824 Epoch [1/8], Batch [301/748], Loss: 1.0170
2024-06-23 03:24:45,055 Epoch [1/8], Batch [351/748], Loss: 0.9337
2024-06-23 03:25:35,362 Epoch [1/8], Batch [401/748], Loss: 0.9941
2024-06-23 03:26:25,721 Epoch [1/8], Batch [451/748], Loss: 0.8021
2024-06-23 03:27:15,988 Epoch [1/8], Batch [501/748], Loss: 1.0384
2024-06-23 03:28:06,110 Epoch [1/8], Batch [551/748], Loss: 0.8721
2024-06-23 03:28:56,302 Epoch [1/8], Batch [601/748], Loss: 1.1262
2024-06-23 03:29:46,530 Epoch [1/8], Batch [651/748], Loss: 0.8941
2024-06-23 03:30:36,487 Epoch [1/8], Batch [701/748], Loss: 1.0804
2024-06-23 03:31:23,389 Epoch 1/8, Train Loss: 1.0941, Train Accuracy: 0.5047
2024-06-23 03:32:42,109 Epoch 1/8, Val Loss: 0.9366, Val Accuracy: 0.5777
2024-06-23 03:32:43,107 Epoch [2/8], Batch [1/748], Loss: 0.8087
2024-06-23 03:33:33,308 Epoch [2/8], Batch [51/748], Loss: 0.6876
2024-06-23 03:34:23,460 Epoch [2/8], Batch [101/748], Loss: 0.8742
2024-06-23 03:35:13,788 Epoch [2/8], Batch [151/748], Loss: 0.7925
2024-06-23 03:36:04,036 Epoch [2/8], Batch [201/748], Loss: 0.8691
2024-06-23 03:36:54,406 Epoch [2/8], Batch [251/748], Loss: 0.9424
2024-06-23 03:37:44,669 Epoch [2/8], Batch [301/748], Loss: 0.6085
2024-06-23 03:38:34,710 Epoch [2/8], Batch [351/748], Loss: 0.9409
2024-06-23 03:39:24,943 Epoch [2/8], Batch [401/748], Loss: 0.9410
2024-06-23 03:40:15,155 Epoch [2/8], Batch [451/748], Loss: 0.7084
2024-06-23 03:41:05,386 Epoch [2/8], Batch [501/748], Loss: 0.8462
2024-06-23 03:41:55,535 Epoch [2/8], Batch [551/748], Loss: 0.8567
2024-06-23 03:42:45,915 Epoch [2/8], Batch [601/748], Loss: 0.7406
2024-06-23 03:43:36,558 Epoch [2/8], Batch [651/748], Loss: 0.8662
2024-06-23 03:44:26,771 Epoch [2/8], Batch [701/748], Loss: 0.9056
2024-06-23 03:45:13,648 Epoch 2/8, Train Loss: 0.8425, Train Accuracy: 0.6221
2024-06-23 03:46:32,361 Epoch 2/8, Val Loss: 0.8564, Val Accuracy: 0.6074
2024-06-23 03:46:33,365 Epoch [3/8], Batch [1/748], Loss: 0.5991
2024-06-23 03:47:23,559 Epoch [3/8], Batch [51/748], Loss: 0.7735
2024-06-23 03:48:13,723 Epoch [3/8], Batch [101/748], Loss: 0.6559
2024-06-23 03:49:04,075 Epoch [3/8], Batch [151/748], Loss: 0.7371
2024-06-23 03:49:54,395 Epoch [3/8], Batch [201/748], Loss: 0.8101
2024-06-23 03:50:44,649 Epoch [3/8], Batch [251/748], Loss: 0.6928
2024-06-23 03:51:34,935 Epoch [3/8], Batch [301/748], Loss: 0.7269
2024-06-23 03:52:25,012 Epoch [3/8], Batch [351/748], Loss: 0.9275
2024-06-23 03:53:15,287 Epoch [3/8], Batch [401/748], Loss: 0.8155
2024-06-23 03:54:05,517 Epoch [3/8], Batch [451/748], Loss: 0.7117
2024-06-23 03:54:55,749 Epoch [3/8], Batch [501/748], Loss: 0.8659
2024-06-23 03:55:45,913 Epoch [3/8], Batch [551/748], Loss: 0.8661
2024-06-23 03:56:36,232 Epoch [3/8], Batch [601/748], Loss: 1.0262
2024-06-23 03:57:26,548 Epoch [3/8], Batch [651/748], Loss: 0.8929
2024-06-23 03:58:16,717 Epoch [3/8], Batch [701/748], Loss: 0.7939
2024-06-23 03:59:03,563 Epoch 3/8, Train Loss: 0.7411, Train Accuracy: 0.6727
2024-06-23 04:00:22,291 Epoch 3/8, Val Loss: 0.8059, Val Accuracy: 0.6454
2024-06-23 04:00:23,303 Epoch [4/8], Batch [1/748], Loss: 0.5082
2024-06-23 04:01:13,617 Epoch [4/8], Batch [51/748], Loss: 0.6751
2024-06-23 04:02:03,815 Epoch [4/8], Batch [101/748], Loss: 0.7042
2024-06-23 04:02:53,967 Epoch [4/8], Batch [151/748], Loss: 0.7032
2024-06-23 04:03:44,366 Epoch [4/8], Batch [201/748], Loss: 0.7630
2024-06-23 04:04:34,598 Epoch [4/8], Batch [251/748], Loss: 0.7006
2024-06-23 04:05:24,936 Epoch [4/8], Batch [301/748], Loss: 0.7746
2024-06-23 04:06:15,088 Epoch [4/8], Batch [351/748], Loss: 0.8909
2024-06-23 04:07:05,296 Epoch [4/8], Batch [401/748], Loss: 0.5099
2024-06-23 04:07:55,667 Epoch [4/8], Batch [451/748], Loss: 0.5361
2024-06-23 04:08:45,753 Epoch [4/8], Batch [501/748], Loss: 0.6351
2024-06-23 04:09:36,048 Epoch [4/8], Batch [551/748], Loss: 0.6684
2024-06-23 04:10:26,245 Epoch [4/8], Batch [601/748], Loss: 0.6052
2024-06-23 04:11:16,381 Epoch [4/8], Batch [651/748], Loss: 0.7673
2024-06-23 04:12:06,495 Epoch [4/8], Batch [701/748], Loss: 0.6361
2024-06-23 04:12:53,243 Epoch 4/8, Train Loss: 0.6458, Train Accuracy: 0.7136
2024-06-23 04:14:12,329 Epoch 4/8, Val Loss: 0.9764, Val Accuracy: 0.6051
2024-06-23 04:14:13,350 Epoch [5/8], Batch [1/748], Loss: 0.6499
2024-06-23 04:15:03,438 Epoch [5/8], Batch [51/748], Loss: 0.7312
2024-06-23 04:15:53,688 Epoch [5/8], Batch [101/748], Loss: 0.6037
2024-06-23 04:16:43,937 Epoch [5/8], Batch [151/748], Loss: 0.4393
2024-06-23 04:17:34,100 Epoch [5/8], Batch [201/748], Loss: 0.5345
2024-06-23 04:18:24,279 Epoch [5/8], Batch [251/748], Loss: 0.4167
2024-06-23 04:19:14,484 Epoch [5/8], Batch [301/748], Loss: 0.5263
2024-06-23 04:20:04,690 Epoch [5/8], Batch [351/748], Loss: 0.4770
2024-06-23 04:20:54,864 Epoch [5/8], Batch [401/748], Loss: 0.2689
2024-06-23 04:21:45,151 Epoch [5/8], Batch [451/748], Loss: 0.4160
2024-06-23 04:22:35,492 Epoch [5/8], Batch [501/748], Loss: 0.4347
2024-06-23 04:23:25,939 Epoch [5/8], Batch [551/748], Loss: 0.7585
2024-06-23 04:24:16,106 Epoch [5/8], Batch [601/748], Loss: 0.5625
2024-06-23 04:25:06,432 Epoch [5/8], Batch [651/748], Loss: 0.9286
2024-06-23 04:25:56,614 Epoch [5/8], Batch [701/748], Loss: 0.6021
2024-06-23 04:26:43,495 Epoch 5/8, Train Loss: 0.5559, Train Accuracy: 0.7579
2024-06-23 04:28:02,316 Epoch 5/8, Val Loss: 0.8561, Val Accuracy: 0.6574
2024-06-23 04:28:03,325 Epoch [6/8], Batch [1/748], Loss: 0.5030
2024-06-23 04:28:53,603 Epoch [6/8], Batch [51/748], Loss: 0.5007
2024-06-23 04:29:43,907 Epoch [6/8], Batch [101/748], Loss: 0.5813
2024-06-23 04:30:34,131 Epoch [6/8], Batch [151/748], Loss: 0.2650
2024-06-23 04:31:24,408 Epoch [6/8], Batch [201/748], Loss: 0.4278
2024-06-23 04:32:14,539 Epoch [6/8], Batch [251/748], Loss: 0.6351
2024-06-23 04:33:04,922 Epoch [6/8], Batch [301/748], Loss: 0.3988
2024-06-23 04:33:55,119 Epoch [6/8], Batch [351/748], Loss: 0.4163
2024-06-23 04:34:45,137 Epoch [6/8], Batch [401/748], Loss: 0.5112
2024-06-23 04:35:35,329 Epoch [6/8], Batch [451/748], Loss: 0.6397
2024-06-23 04:36:25,485 Epoch [6/8], Batch [501/748], Loss: 0.4202
2024-06-23 04:37:15,824 Epoch [6/8], Batch [551/748], Loss: 0.5333
2024-06-23 04:38:05,996 Epoch [6/8], Batch [601/748], Loss: 0.4490
2024-06-23 04:38:56,152 Epoch [6/8], Batch [651/748], Loss: 0.5875
2024-06-23 04:39:46,452 Epoch [6/8], Batch [701/748], Loss: 0.3692
2024-06-23 04:40:33,236 Epoch 6/8, Train Loss: 0.4665, Train Accuracy: 0.8056
2024-06-23 04:41:52,138 Epoch 6/8, Val Loss: 0.9537, Val Accuracy: 0.6557
2024-06-23 04:41:53,150 Epoch [7/8], Batch [1/748], Loss: 0.3061
2024-06-23 04:42:43,145 Epoch [7/8], Batch [51/748], Loss: 0.5275
2024-06-23 04:43:33,587 Epoch [7/8], Batch [101/748], Loss: 0.2725
2024-06-23 04:44:23,822 Epoch [7/8], Batch [151/748], Loss: 0.3424
2024-06-23 04:45:14,243 Epoch [7/8], Batch [201/748], Loss: 0.2534
2024-06-23 04:46:04,523 Epoch [7/8], Batch [251/748], Loss: 0.3640
2024-06-23 04:46:54,693 Epoch [7/8], Batch [301/748], Loss: 0.3500
2024-06-23 04:47:44,786 Epoch [7/8], Batch [351/748], Loss: 0.4528
2024-06-23 04:48:35,032 Epoch [7/8], Batch [401/748], Loss: 0.4224
2024-06-23 04:49:25,276 Epoch [7/8], Batch [451/748], Loss: 0.3408
2024-06-23 04:50:15,431 Epoch [7/8], Batch [501/748], Loss: 0.2644
2024-06-23 04:51:05,659 Epoch [7/8], Batch [551/748], Loss: 0.2456
2024-06-23 04:51:56,023 Epoch [7/8], Batch [601/748], Loss: 0.3997
2024-06-23 04:52:46,134 Epoch [7/8], Batch [651/748], Loss: 0.7627
2024-06-23 04:53:36,441 Epoch [7/8], Batch [701/748], Loss: 0.4515
2024-06-23 04:54:23,263 Epoch 7/8, Train Loss: 0.3853, Train Accuracy: 0.8430
2024-06-23 04:55:42,329 Epoch 7/8, Val Loss: 0.9223, Val Accuracy: 0.6815
2024-06-23 04:55:43,342 Epoch [8/8], Batch [1/748], Loss: 0.2252
2024-06-23 04:56:33,441 Epoch [8/8], Batch [51/748], Loss: 0.5594
2024-06-23 04:57:23,926 Epoch [8/8], Batch [101/748], Loss: 0.3666
2024-06-23 04:58:14,098 Epoch [8/8], Batch [151/748], Loss: 0.4611
2024-06-23 04:59:04,429 Epoch [8/8], Batch [201/748], Loss: 0.3910
2024-06-23 04:59:54,846 Epoch [8/8], Batch [251/748], Loss: 0.4364
2024-06-23 05:00:45,206 Epoch [8/8], Batch [301/748], Loss: 0.3007
2024-06-23 05:01:35,380 Epoch [8/8], Batch [351/748], Loss: 0.2971
2024-06-23 05:02:25,736 Epoch [8/8], Batch [401/748], Loss: 0.4226
2024-06-23 05:03:16,008 Epoch [8/8], Batch [451/748], Loss: 0.3179
2024-06-23 05:04:06,119 Epoch [8/8], Batch [501/748], Loss: 0.3282
2024-06-23 05:04:56,290 Epoch [8/8], Batch [551/748], Loss: 0.1548
2024-06-23 05:05:46,471 Epoch [8/8], Batch [601/748], Loss: 0.4998
2024-06-23 05:06:36,628 Epoch [8/8], Batch [651/748], Loss: 0.2504
2024-06-23 05:07:27,008 Epoch [8/8], Batch [701/748], Loss: 0.4389
2024-06-23 05:08:13,898 Epoch 8/8, Train Loss: 0.3170, Train Accuracy: 0.8761
2024-06-23 05:09:32,712 Epoch 8/8, Val Loss: 1.0501, Val Accuracy: 0.6710
2024-06-23 05:09:32,713 Training finished!
2024-06-23 05:09:32,714 ==================================================
2024-06-23 05:09:33,072 ==================================================
2024-06-23 05:09:33,072 Training with Guassian Noise of 64 length...
2024-06-23 05:09:34,073 Epoch [1/8], Batch [1/748], Loss: 1.6429
2024-06-23 05:10:24,057 Epoch [1/8], Batch [51/748], Loss: 1.4859
2024-06-23 05:11:14,297 Epoch [1/8], Batch [101/748], Loss: 1.1367
2024-06-23 05:12:04,453 Epoch [1/8], Batch [151/748], Loss: 1.2581
2024-06-23 05:12:54,677 Epoch [1/8], Batch [201/748], Loss: 1.2049
2024-06-23 05:13:44,954 Epoch [1/8], Batch [251/748], Loss: 1.0686
2024-06-23 05:14:35,120 Epoch [1/8], Batch [301/748], Loss: 1.0281
2024-06-23 05:15:25,259 Epoch [1/8], Batch [351/748], Loss: 0.8061
2024-06-23 05:16:15,576 Epoch [1/8], Batch [401/748], Loss: 0.9631
2024-06-23 05:17:05,838 Epoch [1/8], Batch [451/748], Loss: 0.8325
2024-06-23 05:17:55,944 Epoch [1/8], Batch [501/748], Loss: 0.8250
2024-06-23 05:18:45,945 Epoch [1/8], Batch [551/748], Loss: 0.8561
2024-06-23 05:19:36,082 Epoch [1/8], Batch [601/748], Loss: 1.0013
2024-06-23 05:20:26,154 Epoch [1/8], Batch [651/748], Loss: 0.8234
2024-06-23 05:21:16,351 Epoch [1/8], Batch [701/748], Loss: 0.8119
2024-06-23 05:22:03,153 Epoch 1/8, Train Loss: 1.0683, Train Accuracy: 0.5399
2024-06-23 05:23:22,389 Epoch 1/8, Val Loss: 0.8842, Val Accuracy: 0.6066
2024-06-23 05:23:23,393 Epoch [2/8], Batch [1/748], Loss: 0.8187
2024-06-23 05:24:13,484 Epoch [2/8], Batch [51/748], Loss: 0.9395
2024-06-23 05:25:03,783 Epoch [2/8], Batch [101/748], Loss: 1.0153
2024-06-23 05:25:54,012 Epoch [2/8], Batch [151/748], Loss: 0.7596
2024-06-23 05:26:44,194 Epoch [2/8], Batch [201/748], Loss: 0.7963
2024-06-23 05:27:34,309 Epoch [2/8], Batch [251/748], Loss: 0.8029
2024-06-23 05:28:24,468 Epoch [2/8], Batch [301/748], Loss: 0.9855
2024-06-23 05:29:14,666 Epoch [2/8], Batch [351/748], Loss: 0.6222
2024-06-23 05:30:04,805 Epoch [2/8], Batch [401/748], Loss: 0.6991
2024-06-23 05:30:54,946 Epoch [2/8], Batch [451/748], Loss: 0.7811
2024-06-23 05:31:45,080 Epoch [2/8], Batch [501/748], Loss: 0.8255
2024-06-23 05:32:35,280 Epoch [2/8], Batch [551/748], Loss: 0.5564
2024-06-23 05:33:25,506 Epoch [2/8], Batch [601/748], Loss: 0.8330
2024-06-23 05:34:15,528 Epoch [2/8], Batch [651/748], Loss: 0.7532
2024-06-23 05:35:05,619 Epoch [2/8], Batch [701/748], Loss: 0.8104
2024-06-23 05:35:52,401 Epoch 2/8, Train Loss: 0.8004, Train Accuracy: 0.6480
2024-06-23 05:37:11,666 Epoch 2/8, Val Loss: 0.8673, Val Accuracy: 0.6131
2024-06-23 05:37:12,671 Epoch [3/8], Batch [1/748], Loss: 0.7144
2024-06-23 05:38:02,615 Epoch [3/8], Batch [51/748], Loss: 0.5916
2024-06-23 05:38:52,748 Epoch [3/8], Batch [101/748], Loss: 0.9128
2024-06-23 05:39:42,847 Epoch [3/8], Batch [151/748], Loss: 0.7887
2024-06-23 05:40:32,974 Epoch [3/8], Batch [201/748], Loss: 0.7565
2024-06-23 05:41:23,125 Epoch [3/8], Batch [251/748], Loss: 0.6186
2024-06-23 05:42:13,301 Epoch [3/8], Batch [301/748], Loss: 0.8610
2024-06-23 05:43:03,640 Epoch [3/8], Batch [351/748], Loss: 0.9074
2024-06-23 05:43:53,893 Epoch [3/8], Batch [401/748], Loss: 0.8082
2024-06-23 05:44:44,093 Epoch [3/8], Batch [451/748], Loss: 0.4746
2024-06-23 05:45:34,287 Epoch [3/8], Batch [501/748], Loss: 0.6850
2024-06-23 05:46:24,470 Epoch [3/8], Batch [551/748], Loss: 0.6337
2024-06-23 05:47:14,597 Epoch [3/8], Batch [601/748], Loss: 0.6100
2024-06-23 05:48:04,650 Epoch [3/8], Batch [651/748], Loss: 0.5875
2024-06-23 05:48:54,756 Epoch [3/8], Batch [701/748], Loss: 0.3769
2024-06-23 05:49:41,430 Epoch 3/8, Train Loss: 0.6797, Train Accuracy: 0.6992
2024-06-23 05:51:00,452 Epoch 3/8, Val Loss: 0.8433, Val Accuracy: 0.6450
2024-06-23 05:51:01,469 Epoch [4/8], Batch [1/748], Loss: 0.3850
2024-06-23 05:51:51,484 Epoch [4/8], Batch [51/748], Loss: 0.5763
2024-06-23 05:52:41,579 Epoch [4/8], Batch [101/748], Loss: 0.5490
2024-06-23 05:53:31,848 Epoch [4/8], Batch [151/748], Loss: 0.6279
2024-06-23 05:54:22,058 Epoch [4/8], Batch [201/748], Loss: 0.5233
2024-06-23 05:55:12,164 Epoch [4/8], Batch [251/748], Loss: 0.4738
2024-06-23 05:56:02,220 Epoch [4/8], Batch [301/748], Loss: 0.7298
2024-06-23 05:56:52,294 Epoch [4/8], Batch [351/748], Loss: 0.6182
2024-06-23 05:57:42,531 Epoch [4/8], Batch [401/748], Loss: 0.5631
2024-06-23 05:58:32,489 Epoch [4/8], Batch [451/748], Loss: 0.5589
2024-06-23 05:59:22,504 Epoch [4/8], Batch [501/748], Loss: 0.5951
2024-06-23 06:00:12,520 Epoch [4/8], Batch [551/748], Loss: 0.5347
2024-06-23 06:01:02,779 Epoch [4/8], Batch [601/748], Loss: 0.5873
2024-06-23 06:01:52,944 Epoch [4/8], Batch [651/748], Loss: 0.3928
2024-06-23 06:02:42,973 Epoch [4/8], Batch [701/748], Loss: 0.8307
2024-06-23 06:03:29,753 Epoch 4/8, Train Loss: 0.5700, Train Accuracy: 0.7515
2024-06-23 06:04:48,569 Epoch 4/8, Val Loss: 0.8227, Val Accuracy: 0.6643
2024-06-23 06:04:49,543 Epoch [5/8], Batch [1/748], Loss: 0.5312
2024-06-23 06:05:39,545 Epoch [5/8], Batch [51/748], Loss: 0.4336
2024-06-23 06:06:29,549 Epoch [5/8], Batch [101/748], Loss: 0.6337
2024-06-23 06:07:19,658 Epoch [5/8], Batch [151/748], Loss: 0.4555
2024-06-23 06:08:09,700 Epoch [5/8], Batch [201/748], Loss: 0.5429
2024-06-23 06:08:59,781 Epoch [5/8], Batch [251/748], Loss: 0.7281
2024-06-23 06:09:50,029 Epoch [5/8], Batch [301/748], Loss: 0.4605
2024-06-23 06:10:40,118 Epoch [5/8], Batch [351/748], Loss: 0.3680
2024-06-23 06:11:30,257 Epoch [5/8], Batch [401/748], Loss: 0.5390
2024-06-23 06:12:20,302 Epoch [5/8], Batch [451/748], Loss: 0.8799
2024-06-23 06:13:10,508 Epoch [5/8], Batch [501/748], Loss: 0.2992
2024-06-23 06:14:00,588 Epoch [5/8], Batch [551/748], Loss: 0.3481
2024-06-23 06:14:50,730 Epoch [5/8], Batch [601/748], Loss: 0.4115
2024-06-23 06:15:40,873 Epoch [5/8], Batch [651/748], Loss: 0.4769
2024-06-23 06:16:30,861 Epoch [5/8], Batch [701/748], Loss: 0.4772
2024-06-23 06:17:17,573 Epoch 5/8, Train Loss: 0.4627, Train Accuracy: 0.8019
2024-06-23 06:18:36,438 Epoch 5/8, Val Loss: 0.9191, Val Accuracy: 0.6579
2024-06-23 06:18:37,436 Epoch [6/8], Batch [1/748], Loss: 0.5350
2024-06-23 06:19:27,368 Epoch [6/8], Batch [51/748], Loss: 0.3801
2024-06-23 06:20:17,317 Epoch [6/8], Batch [101/748], Loss: 0.6218
2024-06-23 06:21:07,435 Epoch [6/8], Batch [151/748], Loss: 0.3243
2024-06-23 06:21:57,530 Epoch [6/8], Batch [201/748], Loss: 0.5437
2024-06-23 06:22:47,539 Epoch [6/8], Batch [251/748], Loss: 0.3738
2024-06-23 06:23:37,663 Epoch [6/8], Batch [301/748], Loss: 0.2785
2024-06-23 06:24:27,684 Epoch [6/8], Batch [351/748], Loss: 0.3866
2024-06-23 06:25:17,902 Epoch [6/8], Batch [401/748], Loss: 0.3092
2024-06-23 06:26:08,064 Epoch [6/8], Batch [451/748], Loss: 0.7104
2024-06-23 06:26:58,195 Epoch [6/8], Batch [501/748], Loss: 0.3558
2024-06-23 06:27:48,375 Epoch [6/8], Batch [551/748], Loss: 0.2083
2024-06-23 06:28:38,571 Epoch [6/8], Batch [601/748], Loss: 0.4935
2024-06-23 06:29:28,753 Epoch [6/8], Batch [651/748], Loss: 0.2472
2024-06-23 06:30:18,972 Epoch [6/8], Batch [701/748], Loss: 0.3681
2024-06-23 06:31:05,664 Epoch 6/8, Train Loss: 0.3826, Train Accuracy: 0.8385
2024-06-23 06:32:24,636 Epoch 6/8, Val Loss: 0.9193, Val Accuracy: 0.6780
2024-06-23 06:32:25,641 Epoch [7/8], Batch [1/748], Loss: 0.1383
2024-06-23 06:33:15,931 Epoch [7/8], Batch [51/748], Loss: 0.2706
2024-06-23 06:34:06,092 Epoch [7/8], Batch [101/748], Loss: 0.3140
2024-06-23 06:34:56,190 Epoch [7/8], Batch [151/748], Loss: 0.3178
2024-06-23 06:35:46,685 Epoch [7/8], Batch [201/748], Loss: 0.5048
2024-06-23 06:36:36,805 Epoch [7/8], Batch [251/748], Loss: 0.3957
2024-06-23 06:37:26,967 Epoch [7/8], Batch [301/748], Loss: 0.2033
2024-06-23 06:38:17,045 Epoch [7/8], Batch [351/748], Loss: 0.3300
2024-06-23 06:39:07,163 Epoch [7/8], Batch [401/748], Loss: 0.2443
2024-06-23 06:39:57,257 Epoch [7/8], Batch [451/748], Loss: 0.2614
2024-06-23 06:40:47,369 Epoch [7/8], Batch [501/748], Loss: 0.3098
2024-06-23 06:41:37,428 Epoch [7/8], Batch [551/748], Loss: 0.2330
2024-06-23 06:42:27,517 Epoch [7/8], Batch [601/748], Loss: 0.2865
2024-06-23 06:43:17,776 Epoch [7/8], Batch [651/748], Loss: 0.2090
2024-06-23 06:44:07,891 Epoch [7/8], Batch [701/748], Loss: 0.1913
2024-06-23 06:44:54,635 Epoch 7/8, Train Loss: 0.3084, Train Accuracy: 0.8750
2024-06-23 06:46:13,731 Epoch 7/8, Val Loss: 1.0859, Val Accuracy: 0.6593
2024-06-23 06:46:14,733 Epoch [8/8], Batch [1/748], Loss: 0.3433
2024-06-23 06:47:04,796 Epoch [8/8], Batch [51/748], Loss: 0.1551
2024-06-23 06:47:54,867 Epoch [8/8], Batch [101/748], Loss: 0.2542
2024-06-23 06:48:44,931 Epoch [8/8], Batch [151/748], Loss: 0.1970
2024-06-23 06:49:35,185 Epoch [8/8], Batch [201/748], Loss: 0.1412
2024-06-23 06:50:25,309 Epoch [8/8], Batch [251/748], Loss: 0.3198
2024-06-23 06:51:15,506 Epoch [8/8], Batch [301/748], Loss: 0.1964
2024-06-23 06:52:05,819 Epoch [8/8], Batch [351/748], Loss: 0.1178
2024-06-23 06:52:56,044 Epoch [8/8], Batch [401/748], Loss: 0.1405
2024-06-23 06:53:46,386 Epoch [8/8], Batch [451/748], Loss: 0.3555
2024-06-23 06:54:36,550 Epoch [8/8], Batch [501/748], Loss: 0.1799
2024-06-23 06:55:26,679 Epoch [8/8], Batch [551/748], Loss: 0.2045
2024-06-23 06:56:16,780 Epoch [8/8], Batch [601/748], Loss: 0.0997
2024-06-23 06:57:06,869 Epoch [8/8], Batch [651/748], Loss: 0.2888
2024-06-23 06:57:56,986 Epoch [8/8], Batch [701/748], Loss: 0.4799
2024-06-23 06:58:43,732 Epoch 8/8, Train Loss: 0.2521, Train Accuracy: 0.8988
2024-06-23 07:00:02,870 Epoch 8/8, Val Loss: 1.1312, Val Accuracy: 0.6710
2024-06-23 07:00:02,872 Training finished!
2024-06-23 07:00:02,872 ==================================================
2024-06-23 07:00:03,164 ==================================================
2024-06-23 07:00:03,165 Training with Guassian Noise of 8 length...
2024-06-23 07:00:04,149 Epoch [1/8], Batch [1/748], Loss: 1.6605
2024-06-23 07:00:54,091 Epoch [1/8], Batch [51/748], Loss: 1.5577
2024-06-23 07:01:44,295 Epoch [1/8], Batch [101/748], Loss: 1.3776
2024-06-23 07:02:34,434 Epoch [1/8], Batch [151/748], Loss: 1.1032
2024-06-23 07:03:24,832 Epoch [1/8], Batch [201/748], Loss: 1.2079
2024-06-23 07:04:15,098 Epoch [1/8], Batch [251/748], Loss: 0.8712
2024-06-23 07:05:05,312 Epoch [1/8], Batch [301/748], Loss: 0.9394
2024-06-23 07:05:55,336 Epoch [1/8], Batch [351/748], Loss: 0.9345
2024-06-23 07:06:45,444 Epoch [1/8], Batch [401/748], Loss: 1.0139
2024-06-23 07:07:35,745 Epoch [1/8], Batch [451/748], Loss: 1.3234
2024-06-23 07:08:25,961 Epoch [1/8], Batch [501/748], Loss: 0.9405
2024-06-23 07:09:16,113 Epoch [1/8], Batch [551/748], Loss: 0.8766
2024-06-23 07:10:06,125 Epoch [1/8], Batch [601/748], Loss: 1.0200
2024-06-23 07:10:56,135 Epoch [1/8], Batch [651/748], Loss: 1.0125
2024-06-23 07:11:46,286 Epoch [1/8], Batch [701/748], Loss: 0.8954
2024-06-23 07:12:33,001 Epoch 1/8, Train Loss: 1.0731, Train Accuracy: 0.5409
2024-06-23 07:13:51,964 Epoch 1/8, Val Loss: 0.8822, Val Accuracy: 0.6086
2024-06-23 07:13:52,976 Epoch [2/8], Batch [1/748], Loss: 0.8131
2024-06-23 07:14:42,994 Epoch [2/8], Batch [51/748], Loss: 0.7780
2024-06-23 07:15:33,011 Epoch [2/8], Batch [101/748], Loss: 0.6700
2024-06-23 07:16:23,053 Epoch [2/8], Batch [151/748], Loss: 0.9932
2024-06-23 07:17:13,265 Epoch [2/8], Batch [201/748], Loss: 0.6118
2024-06-23 07:18:03,383 Epoch [2/8], Batch [251/748], Loss: 0.8757
2024-06-23 07:18:53,477 Epoch [2/8], Batch [301/748], Loss: 1.0728
2024-06-23 07:19:43,773 Epoch [2/8], Batch [351/748], Loss: 0.7445
2024-06-23 07:20:33,890 Epoch [2/8], Batch [401/748], Loss: 0.5544
2024-06-23 07:21:24,013 Epoch [2/8], Batch [451/748], Loss: 0.7409
2024-06-23 07:22:14,069 Epoch [2/8], Batch [501/748], Loss: 0.8536
2024-06-23 07:23:04,235 Epoch [2/8], Batch [551/748], Loss: 0.7107
2024-06-23 07:23:54,440 Epoch [2/8], Batch [601/748], Loss: 0.7375
2024-06-23 07:24:44,529 Epoch [2/8], Batch [651/748], Loss: 0.7354
2024-06-23 07:25:34,795 Epoch [2/8], Batch [701/748], Loss: 0.7448
2024-06-23 07:26:21,679 Epoch 2/8, Train Loss: 0.8091, Train Accuracy: 0.6449
2024-06-23 07:27:40,646 Epoch 2/8, Val Loss: 0.8160, Val Accuracy: 0.6506
2024-06-23 07:27:41,650 Epoch [3/8], Batch [1/748], Loss: 0.7474
2024-06-23 07:28:31,563 Epoch [3/8], Batch [51/748], Loss: 0.6101
2024-06-23 07:29:21,824 Epoch [3/8], Batch [101/748], Loss: 0.6603
2024-06-23 07:30:11,996 Epoch [3/8], Batch [151/748], Loss: 0.5903
2024-06-23 07:31:02,125 Epoch [3/8], Batch [201/748], Loss: 0.7946
2024-06-23 07:31:52,303 Epoch [3/8], Batch [251/748], Loss: 0.6238
2024-06-23 07:32:42,462 Epoch [3/8], Batch [301/748], Loss: 0.6766
2024-06-23 07:33:32,600 Epoch [3/8], Batch [351/748], Loss: 0.6199
2024-06-23 07:34:22,681 Epoch [3/8], Batch [401/748], Loss: 0.6836
2024-06-23 07:35:13,047 Epoch [3/8], Batch [451/748], Loss: 0.5857
2024-06-23 07:36:03,158 Epoch [3/8], Batch [501/748], Loss: 1.0870
2024-06-23 07:36:53,244 Epoch [3/8], Batch [551/748], Loss: 0.7757
2024-06-23 07:37:43,534 Epoch [3/8], Batch [601/748], Loss: 0.7446
2024-06-23 07:38:33,651 Epoch [3/8], Batch [651/748], Loss: 0.5757
2024-06-23 07:39:23,762 Epoch [3/8], Batch [701/748], Loss: 0.7146
2024-06-23 07:40:10,578 Epoch 3/8, Train Loss: 0.6963, Train Accuracy: 0.7010
2024-06-23 07:41:29,650 Epoch 3/8, Val Loss: 0.8096, Val Accuracy: 0.6649
2024-06-23 07:41:30,646 Epoch [4/8], Batch [1/748], Loss: 0.6589
2024-06-23 07:42:20,638 Epoch [4/8], Batch [51/748], Loss: 0.5735
2024-06-23 07:43:10,987 Epoch [4/8], Batch [101/748], Loss: 0.6292
2024-06-23 07:44:01,176 Epoch [4/8], Batch [151/748], Loss: 0.3950
2024-06-23 07:44:51,208 Epoch [4/8], Batch [201/748], Loss: 0.4845
2024-06-23 07:45:41,390 Epoch [4/8], Batch [251/748], Loss: 0.5270
2024-06-23 07:46:31,453 Epoch [4/8], Batch [301/748], Loss: 0.7880
2024-06-23 07:47:21,684 Epoch [4/8], Batch [351/748], Loss: 0.6194
2024-06-23 07:48:11,811 Epoch [4/8], Batch [401/748], Loss: 0.5523
2024-06-23 07:49:01,813 Epoch [4/8], Batch [451/748], Loss: 0.6453
2024-06-23 07:49:52,040 Epoch [4/8], Batch [501/748], Loss: 0.6102
2024-06-23 07:50:42,154 Epoch [4/8], Batch [551/748], Loss: 0.5899
2024-06-23 07:51:32,270 Epoch [4/8], Batch [601/748], Loss: 0.4761
2024-06-23 07:52:22,392 Epoch [4/8], Batch [651/748], Loss: 0.6492
2024-06-23 07:53:12,665 Epoch [4/8], Batch [701/748], Loss: 0.6341
2024-06-23 07:53:59,434 Epoch 4/8, Train Loss: 0.5896, Train Accuracy: 0.7515
2024-06-23 07:55:18,403 Epoch 4/8, Val Loss: 0.8384, Val Accuracy: 0.6740
2024-06-23 07:55:19,396 Epoch [5/8], Batch [1/748], Loss: 0.5064
2024-06-23 07:56:09,307 Epoch [5/8], Batch [51/748], Loss: 0.5204
2024-06-23 07:56:59,653 Epoch [5/8], Batch [101/748], Loss: 0.5786
2024-06-23 07:57:50,046 Epoch [5/8], Batch [151/748], Loss: 0.3221
2024-06-23 07:58:40,060 Epoch [5/8], Batch [201/748], Loss: 0.2055
2024-06-23 07:59:30,504 Epoch [5/8], Batch [251/748], Loss: 0.5859
2024-06-23 08:00:20,560 Epoch [5/8], Batch [301/748], Loss: 0.5028
2024-06-23 08:01:10,695 Epoch [5/8], Batch [351/748], Loss: 0.7861
2024-06-23 08:02:00,738 Epoch [5/8], Batch [401/748], Loss: 0.2757
2024-06-23 08:02:50,901 Epoch [5/8], Batch [451/748], Loss: 0.4125
2024-06-23 08:03:41,053 Epoch [5/8], Batch [501/748], Loss: 0.3770
2024-06-23 08:04:31,163 Epoch [5/8], Batch [551/748], Loss: 0.5058
2024-06-23 08:05:21,255 Epoch [5/8], Batch [601/748], Loss: 0.5622
2024-06-23 08:06:11,422 Epoch [5/8], Batch [651/748], Loss: 0.3059
2024-06-23 08:07:01,696 Epoch [5/8], Batch [701/748], Loss: 0.3035
2024-06-23 08:07:48,450 Epoch 5/8, Train Loss: 0.4813, Train Accuracy: 0.8001
2024-06-23 08:09:07,285 Epoch 5/8, Val Loss: 0.8488, Val Accuracy: 0.6843
2024-06-23 08:09:08,281 Epoch [6/8], Batch [1/748], Loss: 0.5756
2024-06-23 08:09:58,355 Epoch [6/8], Batch [51/748], Loss: 0.3064
2024-06-23 08:10:48,473 Epoch [6/8], Batch [101/748], Loss: 0.5050
2024-06-23 08:11:38,587 Epoch [6/8], Batch [151/748], Loss: 0.3965
2024-06-23 08:12:28,622 Epoch [6/8], Batch [201/748], Loss: 0.4934
2024-06-23 08:13:18,914 Epoch [6/8], Batch [251/748], Loss: 0.4652
2024-06-23 08:14:08,983 Epoch [6/8], Batch [301/748], Loss: 0.4094
2024-06-23 08:14:58,996 Epoch [6/8], Batch [351/748], Loss: 0.6819
2024-06-23 08:15:49,059 Epoch [6/8], Batch [401/748], Loss: 0.5347
2024-06-23 08:16:39,109 Epoch [6/8], Batch [451/748], Loss: 0.3703
2024-06-23 08:17:29,240 Epoch [6/8], Batch [501/748], Loss: 0.4994
2024-06-23 08:18:19,333 Epoch [6/8], Batch [551/748], Loss: 0.3187
2024-06-23 08:19:09,496 Epoch [6/8], Batch [601/748], Loss: 0.4455
2024-06-23 08:19:59,647 Epoch [6/8], Batch [651/748], Loss: 0.3265
2024-06-23 08:20:49,894 Epoch [6/8], Batch [701/748], Loss: 0.4336
2024-06-23 08:21:36,760 Epoch 6/8, Train Loss: 0.3916, Train Accuracy: 0.8427
2024-06-23 08:22:55,476 Epoch 6/8, Val Loss: 0.9628, Val Accuracy: 0.6807
2024-06-23 08:22:56,475 Epoch [7/8], Batch [1/748], Loss: 0.2218
2024-06-23 08:23:46,474 Epoch [7/8], Batch [51/748], Loss: 0.1855
2024-06-23 08:24:36,574 Epoch [7/8], Batch [101/748], Loss: 0.5432
2024-06-23 08:25:26,654 Epoch [7/8], Batch [151/748], Loss: 0.3356
2024-06-23 08:26:16,846 Epoch [7/8], Batch [201/748], Loss: 0.4243
2024-06-23 08:27:07,080 Epoch [7/8], Batch [251/748], Loss: 0.3455
2024-06-23 08:27:57,278 Epoch [7/8], Batch [301/748], Loss: 0.3088
2024-06-23 08:28:47,393 Epoch [7/8], Batch [351/748], Loss: 0.3068
2024-06-23 08:29:37,564 Epoch [7/8], Batch [401/748], Loss: 0.3046
2024-06-23 08:30:27,540 Epoch [7/8], Batch [451/748], Loss: 0.1611
2024-06-23 08:31:17,999 Epoch [7/8], Batch [501/748], Loss: 0.2963
2024-06-23 08:32:08,062 Epoch [7/8], Batch [551/748], Loss: 0.4154
2024-06-23 08:32:58,034 Epoch [7/8], Batch [601/748], Loss: 0.3116
2024-06-23 08:33:48,149 Epoch [7/8], Batch [651/748], Loss: 0.2402
2024-06-23 08:34:38,362 Epoch [7/8], Batch [701/748], Loss: 0.2676
2024-06-23 08:35:25,252 Epoch 7/8, Train Loss: 0.3028, Train Accuracy: 0.8831
2024-06-23 08:36:43,973 Epoch 7/8, Val Loss: 1.0283, Val Accuracy: 0.6733
2024-06-23 08:36:44,961 Epoch [8/8], Batch [1/748], Loss: 0.2372
2024-06-23 08:37:34,920 Epoch [8/8], Batch [51/748], Loss: 0.1437
2024-06-23 08:38:25,091 Epoch [8/8], Batch [101/748], Loss: 0.1696
2024-06-23 08:39:15,123 Epoch [8/8], Batch [151/748], Loss: 0.4029
2024-06-23 08:40:05,333 Epoch [8/8], Batch [201/748], Loss: 0.2052
2024-06-23 08:40:55,453 Epoch [8/8], Batch [251/748], Loss: 0.2035
2024-06-23 08:41:45,728 Epoch [8/8], Batch [301/748], Loss: 0.1853
2024-06-23 08:42:35,852 Epoch [8/8], Batch [351/748], Loss: 0.1325
2024-06-23 08:43:26,045 Epoch [8/8], Batch [401/748], Loss: 0.1638
2024-06-23 08:44:16,105 Epoch [8/8], Batch [451/748], Loss: 0.1516
2024-06-23 08:45:06,358 Epoch [8/8], Batch [501/748], Loss: 0.3403
2024-06-23 08:45:56,437 Epoch [8/8], Batch [551/748], Loss: 0.2474
2024-06-23 08:46:46,515 Epoch [8/8], Batch [601/748], Loss: 0.0890
2024-06-23 08:47:36,789 Epoch [8/8], Batch [651/748], Loss: 0.3419
2024-06-23 08:48:26,794 Epoch [8/8], Batch [701/748], Loss: 0.1887
2024-06-23 08:49:13,569 Epoch 8/8, Train Loss: 0.2338, Train Accuracy: 0.9130
2024-06-23 08:50:32,359 Epoch 8/8, Val Loss: 1.1194, Val Accuracy: 0.6751
2024-06-23 08:50:32,361 Training finished!
2024-06-23 08:50:32,361 ==================================================
2024-06-23 08:50:32,672 ==================================================
2024-06-23 08:50:32,673 Training with Guassian Noise of 1 length...
2024-06-23 08:50:33,694 Epoch [1/8], Batch [1/748], Loss: 1.6169
2024-06-23 08:51:23,732 Epoch [1/8], Batch [51/748], Loss: 1.4887
2024-06-23 08:52:13,869 Epoch [1/8], Batch [101/748], Loss: 1.4180
2024-06-23 08:53:04,086 Epoch [1/8], Batch [151/748], Loss: 1.1629
2024-06-23 08:53:54,283 Epoch [1/8], Batch [201/748], Loss: 1.0930
2024-06-23 08:54:44,355 Epoch [1/8], Batch [251/748], Loss: 1.0690
2024-06-23 08:55:34,560 Epoch [1/8], Batch [301/748], Loss: 1.0062
2024-06-23 08:56:24,827 Epoch [1/8], Batch [351/748], Loss: 0.8746
2024-06-23 08:57:14,951 Epoch [1/8], Batch [401/748], Loss: 1.0181
2024-06-23 08:58:05,054 Epoch [1/8], Batch [451/748], Loss: 1.0415
2024-06-23 08:58:55,194 Epoch [1/8], Batch [501/748], Loss: 1.0036
2024-06-23 08:59:45,299 Epoch [1/8], Batch [551/748], Loss: 1.1129
2024-06-23 09:00:35,316 Epoch [1/8], Batch [601/748], Loss: 1.1186
2024-06-23 09:01:25,551 Epoch [1/8], Batch [651/748], Loss: 0.9503
2024-06-23 09:02:15,477 Epoch [1/8], Batch [701/748], Loss: 0.8169
2024-06-23 09:03:02,292 Epoch 1/8, Train Loss: 1.0726, Train Accuracy: 0.5345
2024-06-23 09:04:21,518 Epoch 1/8, Val Loss: 0.8903, Val Accuracy: 0.6153
2024-06-23 09:04:22,495 Epoch [2/8], Batch [1/748], Loss: 1.0495
2024-06-23 09:05:12,507 Epoch [2/8], Batch [51/748], Loss: 0.9344
2024-06-23 09:06:02,398 Epoch [2/8], Batch [101/748], Loss: 0.7493
2024-06-23 09:06:52,607 Epoch [2/8], Batch [151/748], Loss: 0.8965
2024-06-23 09:07:42,784 Epoch [2/8], Batch [201/748], Loss: 0.8252
2024-06-23 09:08:32,837 Epoch [2/8], Batch [251/748], Loss: 0.7144
2024-06-23 09:09:23,023 Epoch [2/8], Batch [301/748], Loss: 0.8125
2024-06-23 09:10:13,154 Epoch [2/8], Batch [351/748], Loss: 0.6388
2024-06-23 09:11:03,477 Epoch [2/8], Batch [401/748], Loss: 0.7360
2024-06-23 09:11:53,679 Epoch [2/8], Batch [451/748], Loss: 0.6883
2024-06-23 09:12:43,867 Epoch [2/8], Batch [501/748], Loss: 0.7973
2024-06-23 09:13:33,941 Epoch [2/8], Batch [551/748], Loss: 0.9433
2024-06-23 09:14:24,115 Epoch [2/8], Batch [601/748], Loss: 0.8878
2024-06-23 09:15:14,538 Epoch [2/8], Batch [651/748], Loss: 0.7110
2024-06-23 09:16:05,183 Epoch [2/8], Batch [701/748], Loss: 1.0559
2024-06-23 09:16:52,753 Epoch 2/8, Train Loss: 0.8206, Train Accuracy: 0.6332
2024-06-23 09:18:14,064 Epoch 2/8, Val Loss: 0.8418, Val Accuracy: 0.6313
2024-06-23 09:18:15,062 Epoch [3/8], Batch [1/748], Loss: 0.9333
2024-06-23 09:19:05,227 Epoch [3/8], Batch [51/748], Loss: 0.8589
2024-06-23 09:19:55,368 Epoch [3/8], Batch [101/748], Loss: 0.7930
2024-06-23 09:20:46,304 Epoch [3/8], Batch [151/748], Loss: 0.7724
2024-06-23 09:21:37,067 Epoch [3/8], Batch [201/748], Loss: 0.7342
2024-06-23 09:22:27,252 Epoch [3/8], Batch [251/748], Loss: 0.6270
2024-06-23 09:23:17,706 Epoch [3/8], Batch [301/748], Loss: 0.5504
2024-06-23 09:24:07,961 Epoch [3/8], Batch [351/748], Loss: 0.7840
2024-06-23 09:24:58,107 Epoch [3/8], Batch [401/748], Loss: 0.8899
2024-06-23 09:25:48,931 Epoch [3/8], Batch [451/748], Loss: 0.7275
2024-06-23 09:26:39,206 Epoch [3/8], Batch [501/748], Loss: 0.6045
2024-06-23 09:27:29,518 Epoch [3/8], Batch [551/748], Loss: 0.8486
2024-06-23 09:28:19,889 Epoch [3/8], Batch [601/748], Loss: 0.5775
2024-06-23 09:29:10,124 Epoch [3/8], Batch [651/748], Loss: 0.3146
2024-06-23 09:30:00,195 Epoch [3/8], Batch [701/748], Loss: 0.8859
2024-06-23 09:30:46,901 Epoch 3/8, Train Loss: 0.7089, Train Accuracy: 0.6879
2024-06-23 09:32:06,218 Epoch 3/8, Val Loss: 0.7902, Val Accuracy: 0.6593
2024-06-23 09:32:07,239 Epoch [4/8], Batch [1/748], Loss: 0.6560
2024-06-23 09:32:57,480 Epoch [4/8], Batch [51/748], Loss: 0.8092
2024-06-23 09:33:47,653 Epoch [4/8], Batch [101/748], Loss: 0.7705
2024-06-23 09:34:37,857 Epoch [4/8], Batch [151/748], Loss: 0.3909
2024-06-23 09:35:28,251 Epoch [4/8], Batch [201/748], Loss: 0.5086
2024-06-23 09:36:18,519 Epoch [4/8], Batch [251/748], Loss: 0.4463
2024-06-23 09:37:08,774 Epoch [4/8], Batch [301/748], Loss: 0.4791
2024-06-23 09:37:59,101 Epoch [4/8], Batch [351/748], Loss: 0.6384
2024-06-23 09:38:49,197 Epoch [4/8], Batch [401/748], Loss: 0.6073
2024-06-23 09:39:39,440 Epoch [4/8], Batch [451/748], Loss: 0.5111
2024-06-23 09:40:29,484 Epoch [4/8], Batch [501/748], Loss: 0.7588
2024-06-23 09:41:19,628 Epoch [4/8], Batch [551/748], Loss: 0.5370
2024-06-23 09:42:09,834 Epoch [4/8], Batch [601/748], Loss: 0.5893
2024-06-23 09:42:59,978 Epoch [4/8], Batch [651/748], Loss: 0.5025
2024-06-23 09:43:50,162 Epoch [4/8], Batch [701/748], Loss: 0.4797
2024-06-23 09:44:37,027 Epoch 4/8, Train Loss: 0.6077, Train Accuracy: 0.7369
2024-06-23 09:45:56,246 Epoch 4/8, Val Loss: 0.9679, Val Accuracy: 0.6200
2024-06-23 09:45:57,250 Epoch [5/8], Batch [1/748], Loss: 0.3235
2024-06-23 09:46:47,215 Epoch [5/8], Batch [51/748], Loss: 0.4712
2024-06-23 09:47:37,334 Epoch [5/8], Batch [101/748], Loss: 0.6362
2024-06-23 09:48:27,434 Epoch [5/8], Batch [151/748], Loss: 0.6965
2024-06-23 09:49:17,675 Epoch [5/8], Batch [201/748], Loss: 0.5427
2024-06-23 09:50:07,896 Epoch [5/8], Batch [251/748], Loss: 0.4373
2024-06-23 09:50:57,945 Epoch [5/8], Batch [301/748], Loss: 0.5334
2024-06-23 09:51:48,190 Epoch [5/8], Batch [351/748], Loss: 0.6898
2024-06-23 09:52:38,303 Epoch [5/8], Batch [401/748], Loss: 0.7226
2024-06-23 09:53:28,809 Epoch [5/8], Batch [451/748], Loss: 0.5885
2024-06-23 09:54:19,125 Epoch [5/8], Batch [501/748], Loss: 0.3152
2024-06-23 09:55:09,263 Epoch [5/8], Batch [551/748], Loss: 0.7299
2024-06-23 09:55:59,555 Epoch [5/8], Batch [601/748], Loss: 0.3938
2024-06-23 09:56:50,180 Epoch [5/8], Batch [651/748], Loss: 0.3504
2024-06-23 09:57:40,521 Epoch [5/8], Batch [701/748], Loss: 0.5116
2024-06-23 09:58:27,338 Epoch 5/8, Train Loss: 0.5095, Train Accuracy: 0.7843
2024-06-23 09:59:47,150 Epoch 5/8, Val Loss: 0.8255, Val Accuracy: 0.6805
2024-06-23 09:59:48,149 Epoch [6/8], Batch [1/748], Loss: 0.4412
2024-06-23 10:00:38,154 Epoch [6/8], Batch [51/748], Loss: 0.3081
2024-06-23 10:01:28,537 Epoch [6/8], Batch [101/748], Loss: 0.5318
2024-06-23 10:02:18,779 Epoch [6/8], Batch [151/748], Loss: 0.3886
2024-06-23 10:03:09,151 Epoch [6/8], Batch [201/748], Loss: 0.6372
2024-06-23 10:03:59,395 Epoch [6/8], Batch [251/748], Loss: 0.4273
2024-06-23 10:04:49,547 Epoch [6/8], Batch [301/748], Loss: 0.6291
2024-06-23 10:05:39,932 Epoch [6/8], Batch [351/748], Loss: 0.5216
2024-06-23 10:06:30,082 Epoch [6/8], Batch [401/748], Loss: 0.4357
2024-06-23 10:07:20,360 Epoch [6/8], Batch [451/748], Loss: 0.3815
2024-06-23 10:08:10,482 Epoch [6/8], Batch [501/748], Loss: 0.6077
2024-06-23 10:09:00,666 Epoch [6/8], Batch [551/748], Loss: 0.3213
2024-06-23 10:09:50,947 Epoch [6/8], Batch [601/748], Loss: 0.5204
2024-06-23 10:10:40,991 Epoch [6/8], Batch [651/748], Loss: 0.3789
2024-06-23 10:11:31,229 Epoch [6/8], Batch [701/748], Loss: 0.2629
2024-06-23 10:12:18,228 Epoch 6/8, Train Loss: 0.4137, Train Accuracy: 0.8262
2024-06-23 10:13:37,659 Epoch 6/8, Val Loss: 0.9739, Val Accuracy: 0.6583
2024-06-23 10:13:38,658 Epoch [7/8], Batch [1/748], Loss: 0.1616
2024-06-23 10:14:28,723 Epoch [7/8], Batch [51/748], Loss: 0.2197
2024-06-23 10:15:18,972 Epoch [7/8], Batch [101/748], Loss: 0.3155
2024-06-23 10:16:09,090 Epoch [7/8], Batch [151/748], Loss: 0.5865
2024-06-23 10:16:59,279 Epoch [7/8], Batch [201/748], Loss: 0.2120
2024-06-23 10:17:49,528 Epoch [7/8], Batch [251/748], Loss: 0.2473
2024-06-23 10:18:39,651 Epoch [7/8], Batch [301/748], Loss: 0.4255
2024-06-23 10:19:29,949 Epoch [7/8], Batch [351/748], Loss: 0.3278
2024-06-23 10:20:20,113 Epoch [7/8], Batch [401/748], Loss: 0.3279
2024-06-23 10:21:10,281 Epoch [7/8], Batch [451/748], Loss: 0.2408
2024-06-23 10:22:00,332 Epoch [7/8], Batch [501/748], Loss: 0.4270
2024-06-23 10:22:50,543 Epoch [7/8], Batch [551/748], Loss: 0.3341
2024-06-23 10:23:40,772 Epoch [7/8], Batch [601/748], Loss: 0.2131
2024-06-23 10:24:30,984 Epoch [7/8], Batch [651/748], Loss: 0.2790
2024-06-23 10:25:21,105 Epoch [7/8], Batch [701/748], Loss: 0.2676
2024-06-23 10:26:07,868 Epoch 7/8, Train Loss: 0.3292, Train Accuracy: 0.8678
2024-06-23 10:27:27,185 Epoch 7/8, Val Loss: 1.0530, Val Accuracy: 0.6654
2024-06-23 10:27:28,182 Epoch [8/8], Batch [1/748], Loss: 0.1791
2024-06-23 10:28:18,379 Epoch [8/8], Batch [51/748], Loss: 0.1141
2024-06-23 10:29:08,612 Epoch [8/8], Batch [101/748], Loss: 0.1642
2024-06-23 10:29:58,856 Epoch [8/8], Batch [151/748], Loss: 0.2106
2024-06-23 10:30:48,977 Epoch [8/8], Batch [201/748], Loss: 0.1955
2024-06-23 10:31:39,467 Epoch [8/8], Batch [251/748], Loss: 0.1800
2024-06-23 10:32:29,607 Epoch [8/8], Batch [301/748], Loss: 0.2426
2024-06-23 10:33:19,977 Epoch [8/8], Batch [351/748], Loss: 0.2497
2024-06-23 10:34:10,126 Epoch [8/8], Batch [401/748], Loss: 0.2041
2024-06-23 10:35:00,167 Epoch [8/8], Batch [451/748], Loss: 0.4086
2024-06-23 10:35:50,397 Epoch [8/8], Batch [501/748], Loss: 0.5331
2024-06-23 10:36:40,428 Epoch [8/8], Batch [551/748], Loss: 0.3796
2024-06-23 10:37:30,607 Epoch [8/8], Batch [601/748], Loss: 0.2487
2024-06-23 10:38:20,700 Epoch [8/8], Batch [651/748], Loss: 0.2791
2024-06-23 10:39:10,833 Epoch [8/8], Batch [701/748], Loss: 0.3504
2024-06-23 10:39:57,544 Epoch 8/8, Train Loss: 0.2633, Train Accuracy: 0.8992
2024-06-23 10:41:16,769 Epoch 8/8, Val Loss: 1.2570, Val Accuracy: 0.6459
2024-06-23 10:41:16,771 Training finished!
2024-06-23 10:41:16,771 ==================================================
