2024-06-23 20:07:23,715 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d5000,n5,w2,s0.001,t4>', 'datetime': '2024-06-23T20:07:23.713604', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-23 20:07:23,715 collecting all words and their counts
2024-06-23 20:07:23,715 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-23 20:07:23,951 PROGRESS: at example #10000, processed 1168609 words (4944448 words/s), 72028 word types, 0 tags
2024-06-23 20:07:24,199 PROGRESS: at example #20000, processed 2388715 words (4931178 words/s), 103898 word types, 0 tags
2024-06-23 20:07:24,420 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-23 20:07:24,420 Creating a fresh vocabulary
2024-06-23 20:07:24,845 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-23T20:07:24.845470', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 20:07:24,845 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-23T20:07:24.845722', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 20:07:25,561 deleting the raw counts dictionary of 133984 items
2024-06-23 20:07:25,563 sample=0.001 downsamples 6 most-common words
2024-06-23 20:07:25,563 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-23T20:07:25.563518', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 20:07:26,763 estimated required memory for 133984 words and 5000 dimensions: 5426453000 bytes
2024-06-23 20:07:26,763 resetting layer weights
2024-06-23 20:07:30,502 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 5000 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-23T20:07:30.502803', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-23 20:07:31,565 EPOCH 0 - PROGRESS: at 0.31% examples, 9504 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:32,808 EPOCH 0 - PROGRESS: at 2.72% examples, 39193 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:33,818 EPOCH 0 - PROGRESS: at 5.00% examples, 51418 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:35,271 EPOCH 0 - PROGRESS: at 7.91% examples, 56688 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:36,547 EPOCH 0 - PROGRESS: at 9.99% examples, 56262 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:37,684 EPOCH 0 - PROGRESS: at 12.63% examples, 58520 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:38,713 EPOCH 0 - PROGRESS: at 14.66% examples, 60902 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:40,032 EPOCH 0 - PROGRESS: at 17.46% examples, 62977 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:41,045 EPOCH 0 - PROGRESS: at 20.19% examples, 66388 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:42,063 EPOCH 0 - PROGRESS: at 22.39% examples, 67455 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:43,201 EPOCH 0 - PROGRESS: at 24.89% examples, 68459 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:44,297 EPOCH 0 - PROGRESS: at 27.71% examples, 70257 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:45,333 EPOCH 0 - PROGRESS: at 30.22% examples, 71419 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:46,388 EPOCH 0 - PROGRESS: at 32.69% examples, 72337 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:47,514 EPOCH 0 - PROGRESS: at 35.20% examples, 72844 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:48,562 EPOCH 0 - PROGRESS: at 37.71% examples, 73595 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:49,808 EPOCH 0 - PROGRESS: at 40.45% examples, 74018 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:50,940 EPOCH 0 - PROGRESS: at 43.13% examples, 74325 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:52,153 EPOCH 0 - PROGRESS: at 46.14% examples, 75247 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:53,202 EPOCH 0 - PROGRESS: at 49.27% examples, 76170 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:54,247 EPOCH 0 - PROGRESS: at 52.05% examples, 77019 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:55,450 EPOCH 0 - PROGRESS: at 54.40% examples, 76911 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:56,566 EPOCH 0 - PROGRESS: at 57.34% examples, 77830 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:57,708 EPOCH 0 - PROGRESS: at 59.67% examples, 77861 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:07:58,732 EPOCH 0 - PROGRESS: at 62.01% examples, 78222 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:07:59,906 EPOCH 0 - PROGRESS: at 64.76% examples, 78817 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:00,965 EPOCH 0 - PROGRESS: at 66.99% examples, 79031 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:02,021 EPOCH 0 - PROGRESS: at 69.83% examples, 79876 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:03,171 EPOCH 0 - PROGRESS: at 72.07% examples, 79798 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:04,187 EPOCH 0 - PROGRESS: at 74.79% examples, 80637 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:05,383 EPOCH 0 - PROGRESS: at 77.00% examples, 80436 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:06,681 EPOCH 0 - PROGRESS: at 79.99% examples, 80853 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:08,013 EPOCH 0 - PROGRESS: at 84.17% examples, 81166 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:09,296 EPOCH 0 - PROGRESS: at 88.09% examples, 81578 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:10,594 EPOCH 0 - PROGRESS: at 92.40% examples, 81932 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:11,617 EPOCH 0 - PROGRESS: at 95.89% examples, 82572 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:12,716 EPOCH 0 - PROGRESS: at 98.82% examples, 82559 words/s, in_qsize 4, out_qsize 0
2024-06-23 20:08:12,909 EPOCH 0: training on 3499793 raw words (3519625 effective words) took 42.4s, 83009 effective words/s
2024-06-23 20:08:14,129 EPOCH 1 - PROGRESS: at 2.72% examples, 74089 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:15,411 EPOCH 1 - PROGRESS: at 6.10% examples, 84082 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:16,746 EPOCH 1 - PROGRESS: at 9.76% examples, 86039 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:17,761 EPOCH 1 - PROGRESS: at 13.18% examples, 90725 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:18,902 EPOCH 1 - PROGRESS: at 15.43% examples, 88432 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:20,138 EPOCH 1 - PROGRESS: at 18.73% examples, 89897 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:21,166 EPOCH 1 - PROGRESS: at 21.84% examples, 92006 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:22,273 EPOCH 1 - PROGRESS: at 24.32% examples, 90689 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:23,321 EPOCH 1 - PROGRESS: at 26.86% examples, 90195 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:24,458 EPOCH 1 - PROGRESS: at 29.93% examples, 90838 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:25,473 EPOCH 1 - PROGRESS: at 32.42% examples, 90649 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:26,530 EPOCH 1 - PROGRESS: at 35.20% examples, 90966 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:27,652 EPOCH 1 - PROGRESS: at 37.98% examples, 90813 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:28,690 EPOCH 1 - PROGRESS: at 40.45% examples, 90538 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:29,709 EPOCH 1 - PROGRESS: at 43.38% examples, 91006 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:30,833 EPOCH 1 - PROGRESS: at 46.14% examples, 90884 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:31,858 EPOCH 1 - PROGRESS: at 49.56% examples, 91761 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:32,924 EPOCH 1 - PROGRESS: at 52.05% examples, 91365 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:34,185 EPOCH 1 - PROGRESS: at 55.11% examples, 91585 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:35,457 EPOCH 1 - PROGRESS: at 58.32% examples, 91726 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:36,740 EPOCH 1 - PROGRESS: at 61.50% examples, 91815 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:38,021 EPOCH 1 - PROGRESS: at 64.54% examples, 91886 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:39,041 EPOCH 1 - PROGRESS: at 66.99% examples, 92119 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:40,152 EPOCH 1 - PROGRESS: at 69.58% examples, 92034 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:41,161 EPOCH 1 - PROGRESS: at 72.34% examples, 92617 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:42,248 EPOCH 1 - PROGRESS: at 74.54% examples, 92232 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:43,281 EPOCH 1 - PROGRESS: at 77.24% examples, 92697 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:44,425 EPOCH 1 - PROGRESS: at 79.49% examples, 92177 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:45,429 EPOCH 1 - PROGRESS: at 82.68% examples, 92381 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:46,683 EPOCH 1 - PROGRESS: at 86.02% examples, 91915 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:47,977 EPOCH 1 - PROGRESS: at 90.25% examples, 91947 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:49,287 EPOCH 1 - PROGRESS: at 94.31% examples, 91942 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:50,556 EPOCH 1 - PROGRESS: at 98.15% examples, 92035 words/s, in_qsize 6, out_qsize 0
2024-06-23 20:08:50,947 EPOCH 1: training on 3499793 raw words (3519523 effective words) took 38.0s, 92535 effective words/s
2024-06-23 20:08:52,176 EPOCH 2 - PROGRESS: at 2.72% examples, 73626 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:53,406 EPOCH 2 - PROGRESS: at 6.10% examples, 85614 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:08:54,725 EPOCH 2 - PROGRESS: at 9.76% examples, 87441 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:56,050 EPOCH 2 - PROGRESS: at 13.41% examples, 88244 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:57,350 EPOCH 2 - PROGRESS: at 16.52% examples, 89055 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:58,597 EPOCH 2 - PROGRESS: at 19.92% examples, 90201 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:08:59,904 EPOCH 2 - PROGRESS: at 23.22% examples, 90383 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:00,973 EPOCH 2 - PROGRESS: at 26.31% examples, 91702 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:02,100 EPOCH 2 - PROGRESS: at 28.83% examples, 90489 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:03,204 EPOCH 2 - PROGRESS: at 31.32% examples, 89683 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:04,276 EPOCH 2 - PROGRESS: at 34.10% examples, 89975 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:05,536 EPOCH 2 - PROGRESS: at 36.87% examples, 89052 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:06,815 EPOCH 2 - PROGRESS: at 40.22% examples, 89423 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:07,832 EPOCH 2 - PROGRESS: at 43.38% examples, 90560 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:08,965 EPOCH 2 - PROGRESS: at 45.89% examples, 89862 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:10,227 EPOCH 2 - PROGRESS: at 49.56% examples, 90279 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:11,252 EPOCH 2 - PROGRESS: at 52.39% examples, 90556 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:12,386 EPOCH 2 - PROGRESS: at 54.87% examples, 90429 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:13,412 EPOCH 2 - PROGRESS: at 57.58% examples, 90737 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:14,516 EPOCH 2 - PROGRESS: at 60.24% examples, 90720 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:15,542 EPOCH 2 - PROGRESS: at 62.75% examples, 90997 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:16,699 EPOCH 2 - PROGRESS: at 65.28% examples, 90769 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:17,736 EPOCH 2 - PROGRESS: at 67.81% examples, 90990 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:18,816 EPOCH 2 - PROGRESS: at 70.38% examples, 91054 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:19,831 EPOCH 2 - PROGRESS: at 72.80% examples, 91280 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:20,838 EPOCH 2 - PROGRESS: at 75.23% examples, 91535 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:21,905 EPOCH 2 - PROGRESS: at 77.75% examples, 91596 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:22,934 EPOCH 2 - PROGRESS: at 80.52% examples, 92046 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:23,962 EPOCH 2 - PROGRESS: at 83.87% examples, 91916 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:24,989 EPOCH 2 - PROGRESS: at 86.74% examples, 91786 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:26,142 EPOCH 2 - PROGRESS: at 90.59% examples, 91904 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:27,149 EPOCH 2 - PROGRESS: at 93.65% examples, 91840 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:28,156 EPOCH 2 - PROGRESS: at 96.87% examples, 92047 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:29,131 EPOCH 2: training on 3499793 raw words (3519656 effective words) took 38.2s, 92189 effective words/s
2024-06-23 20:09:30,363 EPOCH 3 - PROGRESS: at 2.72% examples, 73351 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:31,616 EPOCH 3 - PROGRESS: at 6.10% examples, 84654 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:32,619 EPOCH 3 - PROGRESS: at 9.50% examples, 91806 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:33,741 EPOCH 3 - PROGRESS: at 12.38% examples, 88978 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:34,747 EPOCH 3 - PROGRESS: at 15.14% examples, 92584 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:35,890 EPOCH 3 - PROGRESS: at 17.73% examples, 90257 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:36,911 EPOCH 3 - PROGRESS: at 20.74% examples, 92514 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:38,079 EPOCH 3 - PROGRESS: at 23.21% examples, 90453 words/s, in_qsize 7, out_qsize 1
2024-06-23 20:09:39,131 EPOCH 3 - PROGRESS: at 26.31% examples, 91917 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:40,180 EPOCH 3 - PROGRESS: at 28.83% examples, 91321 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:41,224 EPOCH 3 - PROGRESS: at 31.59% examples, 91701 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:42,291 EPOCH 3 - PROGRESS: at 34.10% examples, 91109 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:43,318 EPOCH 3 - PROGRESS: at 36.87% examples, 91556 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:44,502 EPOCH 3 - PROGRESS: at 39.67% examples, 91007 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:45,595 EPOCH 3 - PROGRESS: at 42.85% examples, 91639 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:46,714 EPOCH 3 - PROGRESS: at 45.24% examples, 90928 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:47,777 EPOCH 3 - PROGRESS: at 48.24% examples, 91111 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:48,835 EPOCH 3 - PROGRESS: at 50.80% examples, 90773 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:49,873 EPOCH 3 - PROGRESS: at 53.71% examples, 91049 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:50,878 EPOCH 3 - PROGRESS: at 55.91% examples, 90970 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:51,887 EPOCH 3 - PROGRESS: at 58.64% examples, 91322 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:52,912 EPOCH 3 - PROGRESS: at 61.28% examples, 91587 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:53,931 EPOCH 3 - PROGRESS: at 63.49% examples, 91427 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:54,950 EPOCH 3 - PROGRESS: at 66.30% examples, 92075 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:56,050 EPOCH 3 - PROGRESS: at 68.53% examples, 91652 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:57,286 EPOCH 3 - PROGRESS: at 71.63% examples, 91882 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:09:58,312 EPOCH 3 - PROGRESS: at 74.01% examples, 92045 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:09:59,438 EPOCH 3 - PROGRESS: at 76.50% examples, 91920 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:00,539 EPOCH 3 - PROGRESS: at 79.02% examples, 91860 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:01,600 EPOCH 3 - PROGRESS: at 82.03% examples, 91907 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:02,673 EPOCH 3 - PROGRESS: at 85.46% examples, 91955 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:03,683 EPOCH 3 - PROGRESS: at 88.52% examples, 91873 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:04,773 EPOCH 3 - PROGRESS: at 92.40% examples, 92155 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:05,841 EPOCH 3 - PROGRESS: at 95.24% examples, 91927 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:06,867 EPOCH 3 - PROGRESS: at 98.82% examples, 92349 words/s, in_qsize 4, out_qsize 0
2024-06-23 20:10:07,164 EPOCH 3: training on 3499793 raw words (3519499 effective words) took 38.0s, 92547 effective words/s
2024-06-23 20:10:08,396 EPOCH 4 - PROGRESS: at 2.72% examples, 73453 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:09,626 EPOCH 4 - PROGRESS: at 6.10% examples, 85483 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:10,872 EPOCH 4 - PROGRESS: at 9.76% examples, 89067 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:12,140 EPOCH 4 - PROGRESS: at 13.41% examples, 90484 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:13,185 EPOCH 4 - PROGRESS: at 15.74% examples, 89720 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:14,205 EPOCH 4 - PROGRESS: at 18.23% examples, 89488 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:15,416 EPOCH 4 - PROGRESS: at 21.02% examples, 88464 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:16,436 EPOCH 4 - PROGRESS: at 23.77% examples, 89472 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:17,630 EPOCH 4 - PROGRESS: at 26.58% examples, 88793 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:18,653 EPOCH 4 - PROGRESS: at 29.65% examples, 90452 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:19,795 EPOCH 4 - PROGRESS: at 32.15% examples, 89397 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:20,858 EPOCH 4 - PROGRESS: at 34.95% examples, 89764 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:21,928 EPOCH 4 - PROGRESS: at 37.71% examples, 90024 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:23,004 EPOCH 4 - PROGRESS: at 40.22% examples, 89579 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:24,044 EPOCH 4 - PROGRESS: at 43.38% examples, 90581 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:25,164 EPOCH 4 - PROGRESS: at 45.89% examples, 89952 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:26,414 EPOCH 4 - PROGRESS: at 49.56% examples, 90336 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:27,659 EPOCH 4 - PROGRESS: at 52.90% examples, 90696 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:28,932 EPOCH 4 - PROGRESS: at 55.91% examples, 90894 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:29,963 EPOCH 4 - PROGRESS: at 58.84% examples, 91597 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:31,066 EPOCH 4 - PROGRESS: at 61.28% examples, 91134 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:32,081 EPOCH 4 - PROGRESS: at 63.77% examples, 91411 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:33,217 EPOCH 4 - PROGRESS: at 66.30% examples, 91252 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:34,244 EPOCH 4 - PROGRESS: at 68.86% examples, 91483 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:35,262 EPOCH 4 - PROGRESS: at 71.14% examples, 91362 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:36,366 EPOCH 4 - PROGRESS: at 73.76% examples, 91642 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:37,379 EPOCH 4 - PROGRESS: at 75.99% examples, 91543 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:38,468 EPOCH 4 - PROGRESS: at 78.74% examples, 91850 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:39,468 EPOCH 4 - PROGRESS: at 81.29% examples, 91761 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:40,536 EPOCH 4 - PROGRESS: at 85.19% examples, 92130 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:41,552 EPOCH 4 - PROGRESS: at 88.09% examples, 92027 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:42,651 EPOCH 4 - PROGRESS: at 92.05% examples, 92278 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:43,765 EPOCH 4 - PROGRESS: at 95.24% examples, 92206 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:44,824 EPOCH 4 - PROGRESS: at 98.48% examples, 92272 words/s, in_qsize 5, out_qsize 0
2024-06-23 20:10:45,246 EPOCH 4: training on 3499793 raw words (3519604 effective words) took 38.1s, 92434 effective words/s
2024-06-23 20:10:46,502 EPOCH 5 - PROGRESS: at 2.72% examples, 71991 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:47,781 EPOCH 5 - PROGRESS: at 6.18% examples, 83018 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:49,022 EPOCH 5 - PROGRESS: at 9.72% examples, 87453 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:50,382 EPOCH 5 - PROGRESS: at 13.41% examples, 87670 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:51,383 EPOCH 5 - PROGRESS: at 15.74% examples, 88002 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:52,685 EPOCH 5 - PROGRESS: at 18.73% examples, 87365 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:53,704 EPOCH 5 - PROGRESS: at 21.00% examples, 86282 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:54,709 EPOCH 5 - PROGRESS: at 23.77% examples, 87659 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:56,020 EPOCH 5 - PROGRESS: at 26.58% examples, 86245 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:57,062 EPOCH 5 - PROGRESS: at 29.37% examples, 87096 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:10:58,312 EPOCH 5 - PROGRESS: at 32.15% examples, 86416 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:10:59,334 EPOCH 5 - PROGRESS: at 34.95% examples, 87253 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:00,494 EPOCH 5 - PROGRESS: at 37.71% examples, 87159 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:01,547 EPOCH 5 - PROGRESS: at 40.45% examples, 87658 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:02,600 EPOCH 5 - PROGRESS: at 43.13% examples, 87528 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:03,671 EPOCH 5 - PROGRESS: at 45.65% examples, 87331 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:04,861 EPOCH 5 - PROGRESS: at 48.24% examples, 86619 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:05,869 EPOCH 5 - PROGRESS: at 51.03% examples, 87214 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:07,114 EPOCH 5 - PROGRESS: at 53.93% examples, 86823 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:08,202 EPOCH 5 - PROGRESS: at 56.64% examples, 87487 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:09,260 EPOCH 5 - PROGRESS: at 59.11% examples, 87376 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:10,263 EPOCH 5 - PROGRESS: at 61.75% examples, 87865 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:11,317 EPOCH 5 - PROGRESS: at 64.05% examples, 87750 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:12,353 EPOCH 5 - PROGRESS: at 66.25% examples, 87706 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:13,521 EPOCH 5 - PROGRESS: at 68.86% examples, 87620 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:14,533 EPOCH 5 - PROGRESS: at 71.38% examples, 87996 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:15,695 EPOCH 5 - PROGRESS: at 73.76% examples, 87892 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:16,722 EPOCH 5 - PROGRESS: at 76.25% examples, 88194 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:17,881 EPOCH 5 - PROGRESS: at 78.74% examples, 88103 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:18,885 EPOCH 5 - PROGRESS: at 82.03% examples, 88717 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:20,013 EPOCH 5 - PROGRESS: at 85.19% examples, 88434 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:21,290 EPOCH 5 - PROGRESS: at 89.42% examples, 88632 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:22,627 EPOCH 5 - PROGRESS: at 93.38% examples, 88679 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:23,965 EPOCH 5 - PROGRESS: at 97.16% examples, 88715 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:24,768 EPOCH 5: training on 3499793 raw words (3519671 effective words) took 39.5s, 89066 effective words/s
2024-06-23 20:11:25,999 EPOCH 6 - PROGRESS: at 2.72% examples, 73423 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:27,248 EPOCH 6 - PROGRESS: at 6.10% examples, 84852 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:28,501 EPOCH 6 - PROGRESS: at 9.76% examples, 88464 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:29,522 EPOCH 6 - PROGRESS: at 13.18% examples, 92602 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:30,656 EPOCH 6 - PROGRESS: at 15.43% examples, 90026 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:31,806 EPOCH 6 - PROGRESS: at 18.49% examples, 90932 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:32,823 EPOCH 6 - PROGRESS: at 21.00% examples, 90605 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:34,072 EPOCH 6 - PROGRESS: at 24.05% examples, 90218 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:35,096 EPOCH 6 - PROGRESS: at 27.13% examples, 91909 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:36,204 EPOCH 6 - PROGRESS: at 29.65% examples, 90865 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:37,219 EPOCH 6 - PROGRESS: at 32.69% examples, 92286 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:38,321 EPOCH 6 - PROGRESS: at 35.20% examples, 91432 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:39,391 EPOCH 6 - PROGRESS: at 38.26% examples, 92250 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:40,453 EPOCH 6 - PROGRESS: at 40.69% examples, 91736 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:41,460 EPOCH 6 - PROGRESS: at 43.38% examples, 91598 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:42,560 EPOCH 6 - PROGRESS: at 46.48% examples, 92130 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:43,615 EPOCH 6 - PROGRESS: at 49.27% examples, 91736 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:44,659 EPOCH 6 - PROGRESS: at 52.39% examples, 92440 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:45,776 EPOCH 6 - PROGRESS: at 54.62% examples, 91809 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:47,039 EPOCH 6 - PROGRESS: at 57.81% examples, 91974 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:48,039 EPOCH 6 - PROGRESS: at 60.45% examples, 92310 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:49,169 EPOCH 6 - PROGRESS: at 63.02% examples, 92115 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:50,182 EPOCH 6 - PROGRESS: at 65.80% examples, 92759 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:51,260 EPOCH 6 - PROGRESS: at 68.06% examples, 92382 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:52,287 EPOCH 6 - PROGRESS: at 70.90% examples, 92920 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:53,353 EPOCH 6 - PROGRESS: at 73.03% examples, 92579 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:54,458 EPOCH 6 - PROGRESS: at 75.73% examples, 92824 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:55,507 EPOCH 6 - PROGRESS: at 78.25% examples, 92890 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:11:56,546 EPOCH 6 - PROGRESS: at 80.82% examples, 92963 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:57,565 EPOCH 6 - PROGRESS: at 84.29% examples, 92832 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:11:58,754 EPOCH 6 - PROGRESS: at 87.67% examples, 92818 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:00,024 EPOCH 6 - PROGRESS: at 92.05% examples, 92881 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:01,343 EPOCH 6 - PROGRESS: at 95.89% examples, 92817 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:02,425 EPOCH 6 - PROGRESS: at 99.66% examples, 93209 words/s, in_qsize 1, out_qsize 1
2024-06-23 20:12:02,576 EPOCH 6: training on 3499793 raw words (3519619 effective words) took 37.8s, 93102 effective words/s
2024-06-23 20:12:03,796 EPOCH 7 - PROGRESS: at 2.72% examples, 74138 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:05,002 EPOCH 7 - PROGRESS: at 6.10% examples, 86729 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:06,213 EPOCH 7 - PROGRESS: at 9.76% examples, 90804 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:07,592 EPOCH 7 - PROGRESS: at 13.41% examples, 89743 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:08,593 EPOCH 7 - PROGRESS: at 15.41% examples, 88091 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:09,916 EPOCH 7 - PROGRESS: at 18.78% examples, 88549 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:11,157 EPOCH 7 - PROGRESS: at 22.12% examples, 89720 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:12,187 EPOCH 7 - PROGRESS: at 25.18% examples, 91481 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:13,376 EPOCH 7 - PROGRESS: at 27.71% examples, 89733 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:14,459 EPOCH 7 - PROGRESS: at 30.78% examples, 90815 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:15,512 EPOCH 7 - PROGRESS: at 33.26% examples, 90372 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:16,724 EPOCH 7 - PROGRESS: at 36.33% examples, 90417 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:17,766 EPOCH 7 - PROGRESS: at 39.11% examples, 90776 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:18,854 EPOCH 7 - PROGRESS: at 41.93% examples, 90849 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:19,858 EPOCH 7 - PROGRESS: at 45.01% examples, 91946 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:20,979 EPOCH 7 - PROGRESS: at 47.61% examples, 91241 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:22,044 EPOCH 7 - PROGRESS: at 50.50% examples, 91370 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:23,116 EPOCH 7 - PROGRESS: at 53.46% examples, 91467 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:24,187 EPOCH 7 - PROGRESS: at 55.63% examples, 91090 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:25,252 EPOCH 7 - PROGRESS: at 58.64% examples, 91651 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:26,284 EPOCH 7 - PROGRESS: at 61.03% examples, 91454 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:27,294 EPOCH 7 - PROGRESS: at 63.77% examples, 92143 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:28,384 EPOCH 7 - PROGRESS: at 66.02% examples, 91729 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:29,639 EPOCH 7 - PROGRESS: at 69.11% examples, 91910 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:30,892 EPOCH 7 - PROGRESS: at 72.10% examples, 92066 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:31,902 EPOCH 7 - PROGRESS: at 74.79% examples, 92616 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:33,126 EPOCH 7 - PROGRESS: at 77.00% examples, 91833 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:34,362 EPOCH 7 - PROGRESS: at 79.97% examples, 91993 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:35,677 EPOCH 7 - PROGRESS: at 84.29% examples, 91974 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:36,950 EPOCH 7 - PROGRESS: at 88.09% examples, 92060 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:38,214 EPOCH 7 - PROGRESS: at 92.40% examples, 92165 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:39,448 EPOCH 7 - PROGRESS: at 96.14% examples, 92338 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:40,459 EPOCH 7 - PROGRESS: at 100.00% examples, 92913 words/s, in_qsize 0, out_qsize 1
2024-06-23 20:12:40,460 EPOCH 7: training on 3499793 raw words (3519426 effective words) took 37.9s, 92912 effective words/s
2024-06-23 20:12:41,663 EPOCH 8 - PROGRESS: at 2.72% examples, 75233 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:42,877 EPOCH 8 - PROGRESS: at 6.10% examples, 87108 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:44,100 EPOCH 8 - PROGRESS: at 9.76% examples, 90763 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:45,104 EPOCH 8 - PROGRESS: at 13.18% examples, 94826 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:46,290 EPOCH 8 - PROGRESS: at 15.43% examples, 90935 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:47,368 EPOCH 8 - PROGRESS: at 18.49% examples, 92659 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:48,474 EPOCH 8 - PROGRESS: at 21.00% examples, 91089 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:49,539 EPOCH 8 - PROGRESS: at 24.05% examples, 92466 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:50,637 EPOCH 8 - PROGRESS: at 26.58% examples, 91311 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:51,831 EPOCH 8 - PROGRESS: at 29.65% examples, 91399 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:52,856 EPOCH 8 - PROGRESS: at 32.15% examples, 91096 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:54,054 EPOCH 8 - PROGRESS: at 35.20% examples, 91162 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:55,066 EPOCH 8 - PROGRESS: at 37.98% examples, 91683 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:56,151 EPOCH 8 - PROGRESS: at 40.69% examples, 91705 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:12:57,393 EPOCH 8 - PROGRESS: at 44.32% examples, 92077 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:58,396 EPOCH 8 - PROGRESS: at 47.34% examples, 93060 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:12:59,595 EPOCH 8 - PROGRESS: at 50.02% examples, 91918 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:00,892 EPOCH 8 - PROGRESS: at 53.46% examples, 91956 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:01,946 EPOCH 8 - PROGRESS: at 55.91% examples, 92088 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:03,175 EPOCH 8 - PROGRESS: at 58.64% examples, 91494 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:04,222 EPOCH 8 - PROGRESS: at 61.28% examples, 91670 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:05,296 EPOCH 8 - PROGRESS: at 63.53% examples, 91304 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:06,365 EPOCH 8 - PROGRESS: at 65.80% examples, 91000 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:07,510 EPOCH 8 - PROGRESS: at 68.32% examples, 90849 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:08,622 EPOCH 8 - PROGRESS: at 70.90% examples, 90803 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:09,732 EPOCH 8 - PROGRESS: at 73.28% examples, 90749 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:10,809 EPOCH 8 - PROGRESS: at 75.73% examples, 90811 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:11,858 EPOCH 8 - PROGRESS: at 77.75% examples, 90309 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:12,934 EPOCH 8 - PROGRESS: at 79.99% examples, 90077 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:13,936 EPOCH 8 - PROGRESS: at 82.68% examples, 89746 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:14,943 EPOCH 8 - PROGRESS: at 85.46% examples, 89452 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:16,058 EPOCH 8 - PROGRESS: at 88.52% examples, 89180 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:17,108 EPOCH 8 - PROGRESS: at 91.70% examples, 89080 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:18,214 EPOCH 8 - PROGRESS: at 94.87% examples, 89124 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:19,277 EPOCH 8 - PROGRESS: at 97.87% examples, 89005 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:19,810 EPOCH 8: training on 3499793 raw words (3519567 effective words) took 39.3s, 89454 effective words/s
2024-06-23 20:13:21,148 EPOCH 9 - PROGRESS: at 2.76% examples, 67702 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:22,526 EPOCH 9 - PROGRESS: at 6.18% examples, 77487 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:23,648 EPOCH 9 - PROGRESS: at 9.50% examples, 83476 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:24,811 EPOCH 9 - PROGRESS: at 12.22% examples, 82052 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:25,817 EPOCH 9 - PROGRESS: at 14.66% examples, 83266 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:26,835 EPOCH 9 - PROGRESS: at 17.20% examples, 84012 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:28,058 EPOCH 9 - PROGRESS: at 19.92% examples, 83667 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:29,092 EPOCH 9 - PROGRESS: at 22.39% examples, 84026 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:30,136 EPOCH 9 - PROGRESS: at 25.18% examples, 85161 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:31,233 EPOCH 9 - PROGRESS: at 27.71% examples, 84852 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:32,286 EPOCH 9 - PROGRESS: at 30.22% examples, 84899 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:33,445 EPOCH 9 - PROGRESS: at 33.26% examples, 85752 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:34,635 EPOCH 9 - PROGRESS: at 35.75% examples, 84946 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:35,768 EPOCH 9 - PROGRESS: at 38.83% examples, 85787 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:36,871 EPOCH 9 - PROGRESS: at 41.24% examples, 85513 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:38,038 EPOCH 9 - PROGRESS: at 44.54% examples, 86083 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:39,195 EPOCH 9 - PROGRESS: at 47.08% examples, 85588 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:40,317 EPOCH 9 - PROGRESS: at 50.26% examples, 86256 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:41,405 EPOCH 9 - PROGRESS: at 52.90% examples, 86075 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:42,501 EPOCH 9 - PROGRESS: at 55.63% examples, 86757 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:43,535 EPOCH 9 - PROGRESS: at 58.06% examples, 86758 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:44,549 EPOCH 9 - PROGRESS: at 60.75% examples, 87240 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:45,718 EPOCH 9 - PROGRESS: at 63.24% examples, 87137 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:46,745 EPOCH 9 - PROGRESS: at 65.54% examples, 87149 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:47,923 EPOCH 9 - PROGRESS: at 68.06% examples, 87053 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:49,000 EPOCH 9 - PROGRESS: at 70.38% examples, 86928 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:50,032 EPOCH 9 - PROGRESS: at 72.80% examples, 87234 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:51,128 EPOCH 9 - PROGRESS: at 75.02% examples, 87046 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:52,279 EPOCH 9 - PROGRESS: at 77.47% examples, 87019 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:53,346 EPOCH 9 - PROGRESS: at 79.99% examples, 87222 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:54,521 EPOCH 9 - PROGRESS: at 83.53% examples, 87132 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:55,590 EPOCH 9 - PROGRESS: at 86.74% examples, 87324 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:13:56,700 EPOCH 9 - PROGRESS: at 90.25% examples, 87407 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:57,742 EPOCH 9 - PROGRESS: at 93.65% examples, 87649 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:58,902 EPOCH 9 - PROGRESS: at 96.87% examples, 87611 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:13:59,808 EPOCH 9: training on 3499793 raw words (3519477 effective words) took 40.0s, 88003 effective words/s
2024-06-23 20:13:59,809 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195667 effective words) took 389.3s, 90406 effective words/s', 'datetime': '2024-06-23T20:13:59.809536', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-23 20:28:44,724 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d4096,n5,w2,s0.001,t4>', 'datetime': '2024-06-23T20:28:44.715791', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-23 20:28:44,725 collecting all words and their counts
2024-06-23 20:28:44,725 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-23 20:28:45,431 PROGRESS: at example #10000, processed 1168609 words (1656991 words/s), 72028 word types, 0 tags
2024-06-23 20:28:46,425 PROGRESS: at example #20000, processed 2388715 words (1228086 words/s), 103898 word types, 0 tags
2024-06-23 20:28:46,942 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-23 20:28:46,943 Creating a fresh vocabulary
2024-06-23 20:28:48,053 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-23T20:28:48.053522', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 20:28:48,053 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-23T20:28:48.053785', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 20:28:49,941 deleting the raw counts dictionary of 133984 items
2024-06-23 20:28:49,948 sample=0.001 downsamples 6 most-common words
2024-06-23 20:28:49,948 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-23T20:28:49.948414', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 20:28:53,283 estimated required memory for 133984 words and 4096 dimensions: 4457462632 bytes
2024-06-23 20:28:53,283 resetting layer weights
2024-06-23 20:28:56,253 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 4096 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-23T20:28:56.253230', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-23 20:28:57,678 EPOCH 0 - PROGRESS: at 1.47% examples, 35316 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:28:58,791 EPOCH 0 - PROGRESS: at 4.53% examples, 59286 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:28:59,998 EPOCH 0 - PROGRESS: at 6.71% examples, 61486 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:01,006 EPOCH 0 - PROGRESS: at 7.91% examples, 56844 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:02,310 EPOCH 0 - PROGRESS: at 8.67% examples, 47895 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:03,744 EPOCH 0 - PROGRESS: at 9.72% examples, 44047 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:05,114 EPOCH 0 - PROGRESS: at 11.16% examples, 41758 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:06,232 EPOCH 0 - PROGRESS: at 11.97% examples, 40086 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:07,334 EPOCH 0 - PROGRESS: at 13.16% examples, 39707 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:08,802 EPOCH 0 - PROGRESS: at 14.43% examples, 39042 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:09,924 EPOCH 0 - PROGRESS: at 15.46% examples, 38760 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:10,961 EPOCH 0 - PROGRESS: at 16.52% examples, 38745 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:12,157 EPOCH 0 - PROGRESS: at 19.37% examples, 42111 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:13,197 EPOCH 0 - PROGRESS: at 22.39% examples, 46013 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:14,305 EPOCH 0 - PROGRESS: at 25.46% examples, 49250 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:15,320 EPOCH 0 - PROGRESS: at 28.56% examples, 52392 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:16,355 EPOCH 0 - PROGRESS: at 31.05% examples, 54173 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:17,366 EPOCH 0 - PROGRESS: at 33.82% examples, 56318 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:18,485 EPOCH 0 - PROGRESS: at 36.60% examples, 57979 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:19,685 EPOCH 0 - PROGRESS: at 39.94% examples, 60125 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:20,834 EPOCH 0 - PROGRESS: at 43.38% examples, 62196 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:21,943 EPOCH 0 - PROGRESS: at 46.74% examples, 64188 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:22,946 EPOCH 0 - PROGRESS: at 50.02% examples, 65883 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:23,974 EPOCH 0 - PROGRESS: at 52.90% examples, 67046 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:25,135 EPOCH 0 - PROGRESS: at 55.91% examples, 68498 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:26,303 EPOCH 0 - PROGRESS: at 59.11% examples, 69822 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:27,418 EPOCH 0 - PROGRESS: at 62.25% examples, 71170 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:28,541 EPOCH 0 - PROGRESS: at 65.28% examples, 72389 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:29,650 EPOCH 0 - PROGRESS: at 68.32% examples, 73580 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:30,746 EPOCH 0 - PROGRESS: at 71.38% examples, 74711 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:31,840 EPOCH 0 - PROGRESS: at 74.25% examples, 75759 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:32,840 EPOCH 0 - PROGRESS: at 77.00% examples, 76681 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:33,915 EPOCH 0 - PROGRESS: at 79.49% examples, 77136 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:35,106 EPOCH 0 - PROGRESS: at 83.53% examples, 77842 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:36,254 EPOCH 0 - PROGRESS: at 87.38% examples, 78609 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:37,373 EPOCH 0 - PROGRESS: at 91.70% examples, 79390 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:38,481 EPOCH 0 - PROGRESS: at 95.56% examples, 80155 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:39,487 EPOCH 0 - PROGRESS: at 99.40% examples, 80953 words/s, in_qsize 2, out_qsize 1
2024-06-23 20:29:39,580 EPOCH 0: training on 3499793 raw words (3519628 effective words) took 43.3s, 81242 effective words/s
2024-06-23 20:29:40,607 EPOCH 1 - PROGRESS: at 2.72% examples, 88078 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:41,680 EPOCH 1 - PROGRESS: at 6.10% examples, 100222 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:42,784 EPOCH 1 - PROGRESS: at 9.72% examples, 103078 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:43,902 EPOCH 1 - PROGRESS: at 13.41% examples, 104193 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:44,950 EPOCH 1 - PROGRESS: at 16.25% examples, 104317 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:46,085 EPOCH 1 - PROGRESS: at 19.08% examples, 101459 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:47,213 EPOCH 1 - PROGRESS: at 22.39% examples, 102165 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:48,312 EPOCH 1 - PROGRESS: at 25.74% examples, 102994 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:49,413 EPOCH 1 - PROGRESS: at 29.10% examples, 103649 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:50,540 EPOCH 1 - PROGRESS: at 32.42% examples, 103928 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:51,665 EPOCH 1 - PROGRESS: at 35.75% examples, 104199 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:52,765 EPOCH 1 - PROGRESS: at 39.11% examples, 104585 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:29:53,820 EPOCH 1 - PROGRESS: at 42.56% examples, 105263 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:54,902 EPOCH 1 - PROGRESS: at 45.89% examples, 105667 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:55,979 EPOCH 1 - PROGRESS: at 49.47% examples, 106033 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:57,033 EPOCH 1 - PROGRESS: at 52.90% examples, 106503 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:58,080 EPOCH 1 - PROGRESS: at 55.91% examples, 106949 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:29:59,142 EPOCH 1 - PROGRESS: at 59.11% examples, 107263 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:00,170 EPOCH 1 - PROGRESS: at 62.25% examples, 107726 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:01,261 EPOCH 1 - PROGRESS: at 65.28% examples, 107809 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:02,345 EPOCH 1 - PROGRESS: at 68.32% examples, 107948 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:03,381 EPOCH 1 - PROGRESS: at 71.38% examples, 108278 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:04,399 EPOCH 1 - PROGRESS: at 74.25% examples, 108630 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:05,428 EPOCH 1 - PROGRESS: at 77.24% examples, 108926 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:06,458 EPOCH 1 - PROGRESS: at 80.24% examples, 109168 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:07,487 EPOCH 1 - PROGRESS: at 84.29% examples, 109097 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:08,513 EPOCH 1 - PROGRESS: at 87.67% examples, 109030 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:09,542 EPOCH 1 - PROGRESS: at 91.70% examples, 108957 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:10,636 EPOCH 1 - PROGRESS: at 95.56% examples, 108990 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:11,695 EPOCH 1 - PROGRESS: at 99.66% examples, 109294 words/s, in_qsize 1, out_qsize 1
2024-06-23 20:30:11,748 EPOCH 1: training on 3499793 raw words (3519483 effective words) took 32.2s, 109426 effective words/s
2024-06-23 20:30:12,789 EPOCH 2 - PROGRESS: at 2.72% examples, 86934 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:13,838 EPOCH 2 - PROGRESS: at 6.10% examples, 100710 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:14,897 EPOCH 2 - PROGRESS: at 9.76% examples, 104901 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:15,930 EPOCH 2 - PROGRESS: at 13.18% examples, 105281 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:16,934 EPOCH 2 - PROGRESS: at 15.74% examples, 104157 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:17,945 EPOCH 2 - PROGRESS: at 18.49% examples, 103278 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:19,001 EPOCH 2 - PROGRESS: at 21.56% examples, 103373 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:20,033 EPOCH 2 - PROGRESS: at 24.61% examples, 103711 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:21,209 EPOCH 2 - PROGRESS: at 27.99% examples, 103489 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:22,389 EPOCH 2 - PROGRESS: at 31.32% examples, 103288 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:23,581 EPOCH 2 - PROGRESS: at 34.67% examples, 103027 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:24,788 EPOCH 2 - PROGRESS: at 37.98% examples, 102681 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:25,948 EPOCH 2 - PROGRESS: at 41.24% examples, 102729 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:27,028 EPOCH 2 - PROGRESS: at 44.76% examples, 103339 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:28,072 EPOCH 2 - PROGRESS: at 48.24% examples, 104079 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:29,112 EPOCH 2 - PROGRESS: at 51.83% examples, 104740 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:30,150 EPOCH 2 - PROGRESS: at 54.87% examples, 105346 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:31,171 EPOCH 2 - PROGRESS: at 57.81% examples, 105457 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:32,220 EPOCH 2 - PROGRESS: at 61.01% examples, 105905 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:33,269 EPOCH 2 - PROGRESS: at 63.77% examples, 105826 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:34,403 EPOCH 2 - PROGRESS: at 66.75% examples, 105819 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:35,523 EPOCH 2 - PROGRESS: at 69.83% examples, 105882 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:36,603 EPOCH 2 - PROGRESS: at 72.80% examples, 106067 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:37,670 EPOCH 2 - PROGRESS: at 75.73% examples, 106312 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:38,758 EPOCH 2 - PROGRESS: at 78.74% examples, 106448 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:39,779 EPOCH 2 - PROGRESS: at 82.27% examples, 106813 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:40,844 EPOCH 2 - PROGRESS: at 86.41% examples, 107036 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:41,898 EPOCH 2 - PROGRESS: at 90.59% examples, 107276 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:42,959 EPOCH 2 - PROGRESS: at 94.61% examples, 107482 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:44,032 EPOCH 2 - PROGRESS: at 98.48% examples, 107633 words/s, in_qsize 5, out_qsize 0
2024-06-23 20:30:44,370 EPOCH 2: training on 3499793 raw words (3519432 effective words) took 32.6s, 107899 effective words/s
2024-06-23 20:30:45,409 EPOCH 3 - PROGRESS: at 2.72% examples, 87125 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:46,469 EPOCH 3 - PROGRESS: at 6.10% examples, 100290 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:47,577 EPOCH 3 - PROGRESS: at 9.76% examples, 103001 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:48,710 EPOCH 3 - PROGRESS: at 13.41% examples, 103754 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:49,710 EPOCH 3 - PROGRESS: at 16.25% examples, 104893 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:50,774 EPOCH 3 - PROGRESS: at 19.01% examples, 103068 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:51,877 EPOCH 3 - PROGRESS: at 22.39% examples, 103890 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:53,070 EPOCH 3 - PROGRESS: at 25.74% examples, 103364 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:54,238 EPOCH 3 - PROGRESS: at 29.10% examples, 103286 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:55,491 EPOCH 3 - PROGRESS: at 32.42% examples, 102429 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:30:56,670 EPOCH 3 - PROGRESS: at 35.75% examples, 102383 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:57,756 EPOCH 3 - PROGRESS: at 39.11% examples, 103015 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:30:58,859 EPOCH 3 - PROGRESS: at 42.56% examples, 103454 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:00,003 EPOCH 3 - PROGRESS: at 45.89% examples, 103564 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:01,127 EPOCH 3 - PROGRESS: at 49.56% examples, 103773 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:02,193 EPOCH 3 - PROGRESS: at 52.65% examples, 103724 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:03,240 EPOCH 3 - PROGRESS: at 55.11% examples, 103267 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:04,356 EPOCH 3 - PROGRESS: at 58.38% examples, 103488 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:05,528 EPOCH 3 - PROGRESS: at 61.50% examples, 103418 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:06,642 EPOCH 3 - PROGRESS: at 64.54% examples, 103607 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:07,779 EPOCH 3 - PROGRESS: at 67.55% examples, 103695 words/s, in_qsize 8, out_qsize 1
2024-06-23 20:31:08,881 EPOCH 3 - PROGRESS: at 70.63% examples, 103925 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:09,961 EPOCH 3 - PROGRESS: at 73.50% examples, 104184 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:11,038 EPOCH 3 - PROGRESS: at 76.50% examples, 104469 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:12,097 EPOCH 3 - PROGRESS: at 79.49% examples, 104779 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:13,239 EPOCH 3 - PROGRESS: at 83.53% examples, 104765 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:14,392 EPOCH 3 - PROGRESS: at 87.38% examples, 104742 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:15,492 EPOCH 3 - PROGRESS: at 91.76% examples, 104895 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:16,593 EPOCH 3 - PROGRESS: at 95.56% examples, 105042 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:17,642 EPOCH 3 - PROGRESS: at 99.66% examples, 105495 words/s, in_qsize 1, out_qsize 1
2024-06-23 20:31:17,646 EPOCH 3: training on 3499793 raw words (3519485 effective words) took 33.3s, 105780 effective words/s
2024-06-23 20:31:18,696 EPOCH 4 - PROGRESS: at 2.76% examples, 86396 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:19,839 EPOCH 4 - PROGRESS: at 6.10% examples, 96019 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:20,946 EPOCH 4 - PROGRESS: at 9.76% examples, 100127 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:22,198 EPOCH 4 - PROGRESS: at 13.41% examples, 98962 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:23,338 EPOCH 4 - PROGRESS: at 16.54% examples, 100188 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:24,373 EPOCH 4 - PROGRESS: at 19.92% examples, 102610 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:25,516 EPOCH 4 - PROGRESS: at 23.22% examples, 102891 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:26,622 EPOCH 4 - PROGRESS: at 26.58% examples, 103554 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:27,726 EPOCH 4 - PROGRESS: at 29.93% examples, 104104 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:28,788 EPOCH 4 - PROGRESS: at 33.26% examples, 104945 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:29,810 EPOCH 4 - PROGRESS: at 36.33% examples, 105182 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:30,931 EPOCH 4 - PROGRESS: at 39.67% examples, 105328 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:32,050 EPOCH 4 - PROGRESS: at 43.13% examples, 105472 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:33,118 EPOCH 4 - PROGRESS: at 46.48% examples, 105957 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:34,168 EPOCH 4 - PROGRESS: at 50.02% examples, 106461 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:35,222 EPOCH 4 - PROGRESS: at 53.46% examples, 106906 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:36,277 EPOCH 4 - PROGRESS: at 56.41% examples, 107273 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:37,320 EPOCH 4 - PROGRESS: at 59.67% examples, 107668 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:38,365 EPOCH 4 - PROGRESS: at 62.75% examples, 108022 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:39,375 EPOCH 4 - PROGRESS: at 65.28% examples, 107574 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:40,393 EPOCH 4 - PROGRESS: at 68.06% examples, 107600 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:41,437 EPOCH 4 - PROGRESS: at 71.14% examples, 107905 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:42,471 EPOCH 4 - PROGRESS: at 74.01% examples, 108203 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:43,516 EPOCH 4 - PROGRESS: at 77.00% examples, 108453 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:44,536 EPOCH 4 - PROGRESS: at 80.24% examples, 109121 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:45,584 EPOCH 4 - PROGRESS: at 84.29% examples, 108981 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:46,669 EPOCH 4 - PROGRESS: at 88.09% examples, 109041 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:47,698 EPOCH 4 - PROGRESS: at 92.40% examples, 109302 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:48,731 EPOCH 4 - PROGRESS: at 96.14% examples, 109536 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:49,601 EPOCH 4: training on 3499793 raw words (3519504 effective words) took 31.9s, 110159 effective words/s
2024-06-23 20:31:50,635 EPOCH 5 - PROGRESS: at 2.72% examples, 87488 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:51,672 EPOCH 5 - PROGRESS: at 6.10% examples, 101654 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:52,745 EPOCH 5 - PROGRESS: at 9.76% examples, 105049 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:53,819 EPOCH 5 - PROGRESS: at 13.41% examples, 106738 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:54,875 EPOCH 5 - PROGRESS: at 16.52% examples, 108102 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:55,942 EPOCH 5 - PROGRESS: at 19.92% examples, 108815 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:57,047 EPOCH 5 - PROGRESS: at 23.22% examples, 108721 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:31:58,146 EPOCH 5 - PROGRESS: at 26.58% examples, 108757 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:31:59,237 EPOCH 5 - PROGRESS: at 29.93% examples, 108891 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:00,316 EPOCH 5 - PROGRESS: at 33.26% examples, 109116 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:01,367 EPOCH 5 - PROGRESS: at 36.60% examples, 109568 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:02,399 EPOCH 5 - PROGRESS: at 39.94% examples, 110102 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:03,438 EPOCH 5 - PROGRESS: at 43.13% examples, 109786 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:04,477 EPOCH 5 - PROGRESS: at 46.48% examples, 110196 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:05,515 EPOCH 5 - PROGRESS: at 50.02% examples, 110528 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:06,549 EPOCH 5 - PROGRESS: at 53.46% examples, 110867 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:07,578 EPOCH 5 - PROGRESS: at 56.41% examples, 111176 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:08,634 EPOCH 5 - PROGRESS: at 59.67% examples, 111299 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:09,656 EPOCH 5 - PROGRESS: at 62.48% examples, 111104 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:10,693 EPOCH 5 - PROGRESS: at 65.28% examples, 110824 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:11,781 EPOCH 5 - PROGRESS: at 68.32% examples, 110799 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:12,792 EPOCH 5 - PROGRESS: at 71.14% examples, 110697 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:13,814 EPOCH 5 - PROGRESS: at 73.76% examples, 110527 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:14,906 EPOCH 5 - PROGRESS: at 76.79% examples, 110497 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:15,960 EPOCH 5 - PROGRESS: at 79.72% examples, 110597 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:17,039 EPOCH 5 - PROGRESS: at 83.87% examples, 110598 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:18,102 EPOCH 5 - PROGRESS: at 87.67% examples, 110686 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:19,164 EPOCH 5 - PROGRESS: at 92.05% examples, 110774 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:20,299 EPOCH 5 - PROGRESS: at 95.89% examples, 110592 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:21,322 EPOCH 5 - PROGRESS: at 100.00% examples, 110975 words/s, in_qsize 0, out_qsize 1
2024-06-23 20:32:21,322 EPOCH 5: training on 3499793 raw words (3519679 effective words) took 31.7s, 110974 effective words/s
2024-06-23 20:32:22,350 EPOCH 6 - PROGRESS: at 2.72% examples, 88035 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:23,378 EPOCH 6 - PROGRESS: at 6.10% examples, 102380 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:24,406 EPOCH 6 - PROGRESS: at 9.76% examples, 107110 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:25,472 EPOCH 6 - PROGRESS: at 13.41% examples, 108525 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:26,547 EPOCH 6 - PROGRESS: at 16.52% examples, 109138 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:27,608 EPOCH 6 - PROGRESS: at 19.92% examples, 109775 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:28,713 EPOCH 6 - PROGRESS: at 23.22% examples, 109544 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:29,844 EPOCH 6 - PROGRESS: at 26.58% examples, 109054 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:30,918 EPOCH 6 - PROGRESS: at 29.93% examples, 109347 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:32,069 EPOCH 6 - PROGRESS: at 33.26% examples, 108799 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:33,255 EPOCH 6 - PROGRESS: at 36.60% examples, 108039 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:34,394 EPOCH 6 - PROGRESS: at 39.94% examples, 107792 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:35,516 EPOCH 6 - PROGRESS: at 43.42% examples, 107722 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:36,580 EPOCH 6 - PROGRESS: at 46.74% examples, 108088 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:37,615 EPOCH 6 - PROGRESS: at 50.26% examples, 108560 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:38,708 EPOCH 6 - PROGRESS: at 53.71% examples, 108638 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:39,756 EPOCH 6 - PROGRESS: at 56.64% examples, 108949 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:40,761 EPOCH 6 - PROGRESS: at 59.67% examples, 108966 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:41,794 EPOCH 6 - PROGRESS: at 62.48% examples, 108832 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:42,898 EPOCH 6 - PROGRESS: at 65.54% examples, 108800 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:43,964 EPOCH 6 - PROGRESS: at 68.53% examples, 108974 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:44,992 EPOCH 6 - PROGRESS: at 71.40% examples, 108875 words/s, in_qsize 6, out_qsize 1
2024-06-23 20:32:46,018 EPOCH 6 - PROGRESS: at 74.25% examples, 109171 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:47,089 EPOCH 6 - PROGRESS: at 77.24% examples, 109268 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:48,133 EPOCH 6 - PROGRESS: at 80.24% examples, 109440 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:49,182 EPOCH 6 - PROGRESS: at 84.64% examples, 109642 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:50,198 EPOCH 6 - PROGRESS: at 87.67% examples, 109246 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:51,276 EPOCH 6 - PROGRESS: at 91.70% examples, 108987 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:52,406 EPOCH 6 - PROGRESS: at 95.57% examples, 108889 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:53,486 EPOCH 6 - PROGRESS: at 99.66% examples, 109128 words/s, in_qsize 1, out_qsize 1
2024-06-23 20:32:53,497 EPOCH 6: training on 3499793 raw words (3519488 effective words) took 32.2s, 109400 effective words/s
2024-06-23 20:32:54,522 EPOCH 7 - PROGRESS: at 2.76% examples, 88446 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:55,559 EPOCH 7 - PROGRESS: at 6.10% examples, 102140 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:56,632 EPOCH 7 - PROGRESS: at 9.76% examples, 105398 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:32:57,701 EPOCH 7 - PROGRESS: at 13.41% examples, 107151 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:58,780 EPOCH 7 - PROGRESS: at 16.52% examples, 107950 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:32:59,858 EPOCH 7 - PROGRESS: at 19.92% examples, 108495 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:00,949 EPOCH 7 - PROGRESS: at 23.22% examples, 108649 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:02,009 EPOCH 7 - PROGRESS: at 26.01% examples, 106845 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:03,133 EPOCH 7 - PROGRESS: at 29.10% examples, 105787 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:04,164 EPOCH 7 - PROGRESS: at 31.61% examples, 104004 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:05,213 EPOCH 7 - PROGRESS: at 34.67% examples, 104082 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:06,289 EPOCH 7 - PROGRESS: at 37.71% examples, 103907 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:07,384 EPOCH 7 - PROGRESS: at 40.69% examples, 103630 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:08,461 EPOCH 7 - PROGRESS: at 43.67% examples, 102862 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:09,479 EPOCH 7 - PROGRESS: at 46.74% examples, 103203 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:10,628 EPOCH 7 - PROGRESS: at 50.02% examples, 102683 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:11,793 EPOCH 7 - PROGRESS: at 53.46% examples, 102701 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:12,855 EPOCH 7 - PROGRESS: at 56.41% examples, 103244 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:13,915 EPOCH 7 - PROGRESS: at 59.72% examples, 103751 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:14,943 EPOCH 7 - PROGRESS: at 62.75% examples, 104360 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:15,951 EPOCH 7 - PROGRESS: at 65.54% examples, 104548 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:17,006 EPOCH 7 - PROGRESS: at 68.53% examples, 104963 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:18,067 EPOCH 7 - PROGRESS: at 71.38% examples, 104895 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:19,162 EPOCH 7 - PROGRESS: at 74.25% examples, 105055 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:20,169 EPOCH 7 - PROGRESS: at 77.00% examples, 105196 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:21,223 EPOCH 7 - PROGRESS: at 79.72% examples, 105146 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:22,307 EPOCH 7 - PROGRESS: at 83.87% examples, 105333 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:23,378 EPOCH 7 - PROGRESS: at 87.67% examples, 105575 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:24,437 EPOCH 7 - PROGRESS: at 92.05% examples, 105842 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:25,471 EPOCH 7 - PROGRESS: at 95.89% examples, 106176 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:26,468 EPOCH 7: training on 3499793 raw words (3519570 effective words) took 33.0s, 106765 effective words/s
2024-06-23 20:33:27,481 EPOCH 8 - PROGRESS: at 2.72% examples, 89429 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:28,512 EPOCH 8 - PROGRESS: at 6.10% examples, 103023 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:29,629 EPOCH 8 - PROGRESS: at 9.76% examples, 104520 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:30,762 EPOCH 8 - PROGRESS: at 13.41% examples, 104873 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:31,845 EPOCH 8 - PROGRESS: at 16.52% examples, 106059 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:32,886 EPOCH 8 - PROGRESS: at 19.92% examples, 107525 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:33,973 EPOCH 8 - PROGRESS: at 23.22% examples, 107881 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:35,119 EPOCH 8 - PROGRESS: at 26.58% examples, 107426 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:36,233 EPOCH 8 - PROGRESS: at 29.93% examples, 107456 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:37,363 EPOCH 8 - PROGRESS: at 33.26% examples, 107325 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:38,384 EPOCH 8 - PROGRESS: at 36.33% examples, 107368 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:39,530 EPOCH 8 - PROGRESS: at 39.67% examples, 107124 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:40,589 EPOCH 8 - PROGRESS: at 43.13% examples, 107578 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:41,679 EPOCH 8 - PROGRESS: at 46.48% examples, 107774 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:42,742 EPOCH 8 - PROGRESS: at 50.02% examples, 108083 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:43,807 EPOCH 8 - PROGRESS: at 53.46% examples, 108362 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:44,869 EPOCH 8 - PROGRESS: at 56.41% examples, 108614 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:45,914 EPOCH 8 - PROGRESS: at 59.67% examples, 108929 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:46,942 EPOCH 8 - PROGRESS: at 62.48% examples, 108828 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:47,952 EPOCH 8 - PROGRESS: at 65.28% examples, 108801 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:48,994 EPOCH 8 - PROGRESS: at 68.06% examples, 108654 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:50,049 EPOCH 8 - PROGRESS: at 71.14% examples, 108871 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:51,101 EPOCH 8 - PROGRESS: at 74.01% examples, 109050 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:52,145 EPOCH 8 - PROGRESS: at 77.00% examples, 109274 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:53,169 EPOCH 8 - PROGRESS: at 79.97% examples, 109525 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:54,220 EPOCH 8 - PROGRESS: at 84.29% examples, 109712 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:33:55,260 EPOCH 8 - PROGRESS: at 88.09% examples, 109917 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:56,341 EPOCH 8 - PROGRESS: at 92.40% examples, 109960 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:57,367 EPOCH 8 - PROGRESS: at 95.89% examples, 109873 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:33:58,417 EPOCH 8 - PROGRESS: at 100.00% examples, 110180 words/s, in_qsize 0, out_qsize 1
2024-06-23 20:33:58,417 EPOCH 8: training on 3499793 raw words (3519669 effective words) took 31.9s, 110180 effective words/s
2024-06-23 20:33:59,444 EPOCH 9 - PROGRESS: at 2.72% examples, 88066 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:00,474 EPOCH 9 - PROGRESS: at 6.10% examples, 102299 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:01,529 EPOCH 9 - PROGRESS: at 9.76% examples, 106133 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:02,630 EPOCH 9 - PROGRESS: at 13.41% examples, 106852 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:03,832 EPOCH 9 - PROGRESS: at 16.52% examples, 105272 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:04,943 EPOCH 9 - PROGRESS: at 19.92% examples, 105717 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:06,025 EPOCH 9 - PROGRESS: at 23.22% examples, 106382 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:07,204 EPOCH 9 - PROGRESS: at 26.58% examples, 105737 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:08,354 EPOCH 9 - PROGRESS: at 29.93% examples, 105569 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:09,475 EPOCH 9 - PROGRESS: at 33.26% examples, 105716 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:10,603 EPOCH 9 - PROGRESS: at 36.60% examples, 105779 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:11,641 EPOCH 9 - PROGRESS: at 39.94% examples, 106545 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:12,691 EPOCH 9 - PROGRESS: at 43.38% examples, 107114 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:13,747 EPOCH 9 - PROGRESS: at 46.74% examples, 107574 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:14,861 EPOCH 9 - PROGRESS: at 50.26% examples, 107560 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:15,935 EPOCH 9 - PROGRESS: at 53.71% examples, 107812 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:17,025 EPOCH 9 - PROGRESS: at 56.64% examples, 107922 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:18,077 EPOCH 9 - PROGRESS: at 59.94% examples, 108240 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:19,122 EPOCH 9 - PROGRESS: at 62.75% examples, 108079 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:20,219 EPOCH 9 - PROGRESS: at 65.80% examples, 108115 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:21,294 EPOCH 9 - PROGRESS: at 68.86% examples, 108286 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:22,337 EPOCH 9 - PROGRESS: at 71.84% examples, 108568 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:23,364 EPOCH 9 - PROGRESS: at 74.79% examples, 108866 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:24,401 EPOCH 9 - PROGRESS: at 77.75% examples, 109117 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:25,428 EPOCH 9 - PROGRESS: at 80.82% examples, 109360 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:26,447 EPOCH 9 - PROGRESS: at 85.19% examples, 109680 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:27,518 EPOCH 9 - PROGRESS: at 89.42% examples, 109769 words/s, in_qsize 7, out_qsize 0
2024-06-23 20:34:28,577 EPOCH 9 - PROGRESS: at 93.38% examples, 109902 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:29,646 EPOCH 9 - PROGRESS: at 97.27% examples, 109983 words/s, in_qsize 8, out_qsize 0
2024-06-23 20:34:30,334 EPOCH 9: training on 3499793 raw words (3519427 effective words) took 31.9s, 110282 effective words/s
2024-06-23 20:34:30,334 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195365 effective words) took 334.1s, 105350 effective words/s', 'datetime': '2024-06-23T20:34:30.334718', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-23 20:44:51,847 ==================================================
2024-06-23 20:44:51,847 Training BERT + Doc2Vec features with Dimension-4096...
2024-06-23 20:44:53,448 Epoch [1/8], Batch [1/748], Loss: 1.6128
2024-06-23 20:45:42,150 Epoch [1/8], Batch [51/748], Loss: 1.5513
2024-06-23 20:46:31,971 Epoch [1/8], Batch [101/748], Loss: 1.3975
2024-06-23 20:47:25,719 Epoch [1/8], Batch [151/748], Loss: 1.3034
2024-06-23 20:48:16,089 Epoch [1/8], Batch [201/748], Loss: 1.0545
2024-06-23 20:49:10,638 Epoch [1/8], Batch [251/748], Loss: 1.0812
2024-06-23 20:50:05,855 Epoch [1/8], Batch [301/748], Loss: 1.0219
2024-06-23 20:50:57,543 Epoch [1/8], Batch [351/748], Loss: 0.9126
2024-06-23 20:51:50,898 Epoch [1/8], Batch [401/748], Loss: 1.0072
2024-06-23 20:52:42,300 Epoch [1/8], Batch [451/748], Loss: 1.0709
2024-06-23 20:53:33,351 Epoch [1/8], Batch [501/748], Loss: 1.0563
2024-06-23 20:54:24,061 Epoch [1/8], Batch [551/748], Loss: 1.1231
2024-06-23 20:55:14,546 Epoch [1/8], Batch [601/748], Loss: 0.8173
2024-06-23 20:56:04,673 Epoch [1/8], Batch [651/748], Loss: 0.9391
2024-06-23 20:56:55,012 Epoch [1/8], Batch [701/748], Loss: 0.9544
2024-06-23 20:57:41,903 Epoch 1/8, Train Loss: 1.0843, Train Accuracy: 0.5312
2024-06-23 20:59:00,798 Epoch 1/8, Val Loss: 0.9257, Val Accuracy: 0.5924
2024-06-23 20:59:01,813 Epoch [2/8], Batch [1/748], Loss: 0.8189
2024-06-23 20:59:51,833 Epoch [2/8], Batch [51/748], Loss: 0.8168
2024-06-23 21:00:42,209 Epoch [2/8], Batch [101/748], Loss: 0.8079
2024-06-23 21:01:32,590 Epoch [2/8], Batch [151/748], Loss: 0.8833
2024-06-23 21:02:22,950 Epoch [2/8], Batch [201/748], Loss: 0.7204
2024-06-23 21:03:13,267 Epoch [2/8], Batch [251/748], Loss: 0.7503
2024-06-23 21:04:03,573 Epoch [2/8], Batch [301/748], Loss: 0.6202
2024-06-23 21:04:53,949 Epoch [2/8], Batch [351/748], Loss: 0.9359
2024-06-23 21:05:44,254 Epoch [2/8], Batch [401/748], Loss: 0.6691
2024-06-23 21:06:34,759 Epoch [2/8], Batch [451/748], Loss: 0.6812
2024-06-23 21:07:25,043 Epoch [2/8], Batch [501/748], Loss: 0.8644
2024-06-23 21:08:15,301 Epoch [2/8], Batch [551/748], Loss: 0.8076
2024-06-23 21:09:05,468 Epoch [2/8], Batch [601/748], Loss: 0.6200
2024-06-23 21:09:55,632 Epoch [2/8], Batch [651/748], Loss: 0.6733
2024-06-23 21:10:45,809 Epoch [2/8], Batch [701/748], Loss: 0.6954
2024-06-23 21:11:32,636 Epoch 2/8, Train Loss: 0.8205, Train Accuracy: 0.6342
2024-06-23 21:12:51,460 Epoch 2/8, Val Loss: 0.8784, Val Accuracy: 0.6143
2024-06-23 21:12:52,468 Epoch [3/8], Batch [1/748], Loss: 0.6398
2024-06-23 21:13:42,595 Epoch [3/8], Batch [51/748], Loss: 0.7456
2024-06-23 21:14:33,024 Epoch [3/8], Batch [101/748], Loss: 0.6909
2024-06-23 21:15:23,425 Epoch [3/8], Batch [151/748], Loss: 0.9307
2024-06-23 21:16:13,727 Epoch [3/8], Batch [201/748], Loss: 0.6420
2024-06-23 21:17:04,124 Epoch [3/8], Batch [251/748], Loss: 0.5405
2024-06-23 21:17:54,600 Epoch [3/8], Batch [301/748], Loss: 0.8109
2024-06-23 21:18:44,958 Epoch [3/8], Batch [351/748], Loss: 0.7198
2024-06-23 21:19:35,193 Epoch [3/8], Batch [401/748], Loss: 0.8622
2024-06-23 21:20:25,370 Epoch [3/8], Batch [451/748], Loss: 0.8666
2024-06-23 21:21:15,573 Epoch [3/8], Batch [501/748], Loss: 0.7377
2024-06-23 21:22:05,774 Epoch [3/8], Batch [551/748], Loss: 0.6760
2024-06-23 21:22:56,014 Epoch [3/8], Batch [601/748], Loss: 0.4976
2024-06-23 21:23:46,222 Epoch [3/8], Batch [651/748], Loss: 0.7408
2024-06-23 21:24:36,416 Epoch [3/8], Batch [701/748], Loss: 0.5257
2024-06-23 21:25:23,228 Epoch 3/8, Train Loss: 0.7140, Train Accuracy: 0.6821
2024-06-23 21:26:42,307 Epoch 3/8, Val Loss: 0.8299, Val Accuracy: 0.6362
2024-06-23 21:26:43,317 Epoch [4/8], Batch [1/748], Loss: 0.9454
2024-06-23 21:27:33,444 Epoch [4/8], Batch [51/748], Loss: 0.5540
2024-06-23 21:28:23,627 Epoch [4/8], Batch [101/748], Loss: 0.5368
2024-06-23 21:29:13,964 Epoch [4/8], Batch [151/748], Loss: 0.7198
2024-06-23 21:30:04,295 Epoch [4/8], Batch [201/748], Loss: 0.4641
2024-06-23 21:30:54,524 Epoch [4/8], Batch [251/748], Loss: 0.5620
2024-06-23 21:31:44,951 Epoch [4/8], Batch [301/748], Loss: 0.4228
2024-06-23 21:32:35,064 Epoch [4/8], Batch [351/748], Loss: 0.5366
2024-06-23 21:33:25,338 Epoch [4/8], Batch [401/748], Loss: 0.4884
2024-06-23 21:34:15,681 Epoch [4/8], Batch [451/748], Loss: 0.6292
2024-06-23 21:35:06,009 Epoch [4/8], Batch [501/748], Loss: 0.5419
2024-06-23 21:35:56,416 Epoch [4/8], Batch [551/748], Loss: 0.7706
2024-06-23 21:36:46,560 Epoch [4/8], Batch [601/748], Loss: 0.9371
2024-06-23 21:37:36,768 Epoch [4/8], Batch [651/748], Loss: 0.5831
2024-06-23 21:38:27,118 Epoch [4/8], Batch [701/748], Loss: 0.6194
2024-06-23 21:39:14,034 Epoch 4/8, Train Loss: 0.6215, Train Accuracy: 0.7280
2024-06-23 21:40:32,852 Epoch 4/8, Val Loss: 0.8667, Val Accuracy: 0.6343
2024-06-23 21:40:33,859 Epoch [5/8], Batch [1/748], Loss: 0.5066
2024-06-23 21:41:24,012 Epoch [5/8], Batch [51/748], Loss: 0.5277
2024-06-23 21:42:14,240 Epoch [5/8], Batch [101/748], Loss: 0.5295
2024-06-23 21:43:04,544 Epoch [5/8], Batch [151/748], Loss: 0.4452
2024-06-23 21:43:54,775 Epoch [5/8], Batch [201/748], Loss: 0.4832
2024-06-23 21:44:45,129 Epoch [5/8], Batch [251/748], Loss: 0.3987
2024-06-23 21:45:35,374 Epoch [5/8], Batch [301/748], Loss: 0.5582
2024-06-23 21:46:25,687 Epoch [5/8], Batch [351/748], Loss: 0.4758
2024-06-23 21:47:15,854 Epoch [5/8], Batch [401/748], Loss: 0.5885
2024-06-23 21:48:06,097 Epoch [5/8], Batch [451/748], Loss: 0.6083
2024-06-23 21:48:56,378 Epoch [5/8], Batch [501/748], Loss: 0.6214
2024-06-23 21:49:46,596 Epoch [5/8], Batch [551/748], Loss: 0.4740
2024-06-23 21:50:36,816 Epoch [5/8], Batch [601/748], Loss: 0.7698
2024-06-23 21:51:26,995 Epoch [5/8], Batch [651/748], Loss: 0.4066
2024-06-23 21:52:17,238 Epoch [5/8], Batch [701/748], Loss: 0.5002
2024-06-23 21:53:04,185 Epoch 5/8, Train Loss: 0.5268, Train Accuracy: 0.7729
2024-06-23 21:54:23,248 Epoch 5/8, Val Loss: 0.9220, Val Accuracy: 0.6415
2024-06-23 21:54:24,259 Epoch [6/8], Batch [1/748], Loss: 0.4850
2024-06-23 21:55:14,437 Epoch [6/8], Batch [51/748], Loss: 0.4942
2024-06-23 21:56:04,645 Epoch [6/8], Batch [101/748], Loss: 0.6374
2024-06-23 21:56:55,079 Epoch [6/8], Batch [151/748], Loss: 0.4175
2024-06-23 21:57:45,316 Epoch [6/8], Batch [201/748], Loss: 0.4608
2024-06-23 21:58:35,646 Epoch [6/8], Batch [251/748], Loss: 0.4034
2024-06-23 21:59:26,034 Epoch [6/8], Batch [301/748], Loss: 0.3545
2024-06-23 22:00:16,382 Epoch [6/8], Batch [351/748], Loss: 0.4956
2024-06-23 22:01:06,735 Epoch [6/8], Batch [401/748], Loss: 0.5043
2024-06-23 22:01:57,126 Epoch [6/8], Batch [451/748], Loss: 0.4355
2024-06-23 22:02:47,732 Epoch [6/8], Batch [501/748], Loss: 0.2980
2024-06-23 22:03:38,229 Epoch [6/8], Batch [551/748], Loss: 0.5716
2024-06-23 22:04:28,705 Epoch [6/8], Batch [601/748], Loss: 0.4194
2024-06-23 22:05:19,147 Epoch [6/8], Batch [651/748], Loss: 0.4254
2024-06-23 22:06:09,574 Epoch [6/8], Batch [701/748], Loss: 0.4406
2024-06-23 22:06:56,445 Epoch 6/8, Train Loss: 0.4326, Train Accuracy: 0.8198
2024-06-23 22:08:15,537 Epoch 6/8, Val Loss: 0.9500, Val Accuracy: 0.6649
2024-06-23 22:08:16,520 Epoch [7/8], Batch [1/748], Loss: 0.4727
2024-06-23 22:09:06,693 Epoch [7/8], Batch [51/748], Loss: 0.2363
2024-06-23 22:09:56,843 Epoch [7/8], Batch [101/748], Loss: 0.4873
2024-06-23 22:10:47,063 Epoch [7/8], Batch [151/748], Loss: 0.2413
2024-06-23 22:11:37,377 Epoch [7/8], Batch [201/748], Loss: 0.3224
2024-06-23 22:12:27,720 Epoch [7/8], Batch [251/748], Loss: 0.2973
2024-06-23 22:13:18,064 Epoch [7/8], Batch [301/748], Loss: 0.2523
2024-06-23 22:14:08,388 Epoch [7/8], Batch [351/748], Loss: 0.2141
2024-06-23 22:14:58,695 Epoch [7/8], Batch [401/748], Loss: 0.3345
2024-06-23 22:15:48,917 Epoch [7/8], Batch [451/748], Loss: 0.1794
2024-06-23 22:16:39,165 Epoch [7/8], Batch [501/748], Loss: 0.3554
2024-06-23 22:17:29,303 Epoch [7/8], Batch [551/748], Loss: 0.5551
2024-06-23 22:18:19,709 Epoch [7/8], Batch [601/748], Loss: 0.4318
2024-06-23 22:19:09,933 Epoch [7/8], Batch [651/748], Loss: 0.2418
2024-06-23 22:20:00,162 Epoch [7/8], Batch [701/748], Loss: 0.2363
2024-06-23 22:20:46,921 Epoch 7/8, Train Loss: 0.3582, Train Accuracy: 0.8550
2024-06-23 22:22:05,812 Epoch 7/8, Val Loss: 0.9913, Val Accuracy: 0.6631
2024-06-23 22:22:06,820 Epoch [8/8], Batch [1/748], Loss: 0.2478
2024-06-23 22:22:56,905 Epoch [8/8], Batch [51/748], Loss: 0.2192
2024-06-23 22:23:47,166 Epoch [8/8], Batch [101/748], Loss: 0.2106
2024-06-23 22:24:37,397 Epoch [8/8], Batch [151/748], Loss: 0.3784
2024-06-23 22:25:27,850 Epoch [8/8], Batch [201/748], Loss: 0.3579
2024-06-23 22:26:18,117 Epoch [8/8], Batch [251/748], Loss: 0.3085
2024-06-23 22:27:08,391 Epoch [8/8], Batch [301/748], Loss: 0.1907
2024-06-23 22:27:59,034 Epoch [8/8], Batch [351/748], Loss: 0.1914
2024-06-23 22:28:49,693 Epoch [8/8], Batch [401/748], Loss: 0.1989
2024-06-23 22:29:40,132 Epoch [8/8], Batch [451/748], Loss: 0.5005
2024-06-23 22:30:30,329 Epoch [8/8], Batch [501/748], Loss: 0.4084
2024-06-23 22:31:20,702 Epoch [8/8], Batch [551/748], Loss: 0.3399
2024-06-23 22:32:11,065 Epoch [8/8], Batch [601/748], Loss: 0.2808
2024-06-23 22:33:01,263 Epoch [8/8], Batch [651/748], Loss: 0.3515
2024-06-23 22:33:51,647 Epoch [8/8], Batch [701/748], Loss: 0.2387
2024-06-23 22:34:38,512 Epoch 8/8, Train Loss: 0.2938, Train Accuracy: 0.8853
2024-06-23 22:35:57,568 Epoch 8/8, Val Loss: 0.9820, Val Accuracy: 0.6838
2024-06-23 22:35:57,569 Training finished!
2024-06-23 22:35:57,570 ==================================================
2024-06-23 22:36:21,125 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d2048,n5,w2,s0.001,t4>', 'datetime': '2024-06-23T22:36:21.125828', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-23 22:36:21,126 collecting all words and their counts
2024-06-23 22:36:21,126 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-23 22:36:21,346 PROGRESS: at example #10000, processed 1168609 words (5305102 words/s), 72028 word types, 0 tags
2024-06-23 22:36:21,592 PROGRESS: at example #20000, processed 2388715 words (4966453 words/s), 103898 word types, 0 tags
2024-06-23 22:36:21,814 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-23 22:36:21,814 Creating a fresh vocabulary
2024-06-23 22:36:22,234 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-23T22:36:22.234850', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 22:36:22,235 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-23T22:36:22.235075', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 22:36:22,938 deleting the raw counts dictionary of 133984 items
2024-06-23 22:36:22,940 sample=0.001 downsamples 6 most-common words
2024-06-23 22:36:22,940 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-23T22:36:22.940810', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-23 22:36:24,079 estimated required memory for 133984 words and 2048 dimensions: 2262227816 bytes
2024-06-23 22:36:24,079 resetting layer weights
2024-06-23 22:36:25,498 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 2048 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-23T22:36:25.498863', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-23 22:36:26,516 EPOCH 0 - PROGRESS: at 3.09% examples, 98879 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:27,571 EPOCH 0 - PROGRESS: at 7.91% examples, 130558 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:28,599 EPOCH 0 - PROGRESS: at 13.64% examples, 148469 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:29,633 EPOCH 0 - PROGRESS: at 18.49% examples, 154844 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:30,644 EPOCH 0 - PROGRESS: at 23.77% examples, 161247 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:31,664 EPOCH 0 - PROGRESS: at 28.83% examples, 163697 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:32,709 EPOCH 0 - PROGRESS: at 34.10% examples, 166325 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:33,773 EPOCH 0 - PROGRESS: at 39.39% examples, 167892 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:34,795 EPOCH 0 - PROGRESS: at 44.54% examples, 168801 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:35,803 EPOCH 0 - PROGRESS: at 49.27% examples, 167815 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:36,816 EPOCH 0 - PROGRESS: at 54.40% examples, 169559 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:37,817 EPOCH 0 - PROGRESS: at 59.11% examples, 170355 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:38,845 EPOCH 0 - PROGRESS: at 63.77% examples, 170671 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:39,847 EPOCH 0 - PROGRESS: at 68.06% examples, 170591 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:40,860 EPOCH 0 - PROGRESS: at 72.54% examples, 170999 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:41,881 EPOCH 0 - PROGRESS: at 77.00% examples, 171271 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:43,023 EPOCH 0 - PROGRESS: at 82.68% examples, 171453 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:44,077 EPOCH 0 - PROGRESS: at 89.75% examples, 172505 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:45,133 EPOCH 0 - PROGRESS: at 95.24% examples, 171896 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:45,818 EPOCH 0: training on 3499793 raw words (3519613 effective words) took 20.3s, 173251 effective words/s
2024-06-23 22:36:46,884 EPOCH 1 - PROGRESS: at 5.45% examples, 179424 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:47,942 EPOCH 1 - PROGRESS: at 11.72% examples, 184094 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:48,957 EPOCH 1 - PROGRESS: at 17.20% examples, 188253 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:50,101 EPOCH 1 - PROGRESS: at 23.22% examples, 189185 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:51,157 EPOCH 1 - PROGRESS: at 28.83% examples, 189149 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:52,177 EPOCH 1 - PROGRESS: at 34.67% examples, 191846 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:53,254 EPOCH 1 - PROGRESS: at 40.22% examples, 190915 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:54,324 EPOCH 1 - PROGRESS: at 45.89% examples, 190432 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:55,373 EPOCH 1 - PROGRESS: at 51.83% examples, 190420 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:56,426 EPOCH 1 - PROGRESS: at 56.41% examples, 188463 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:57,431 EPOCH 1 - PROGRESS: at 61.50% examples, 188486 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:36:58,459 EPOCH 1 - PROGRESS: at 66.53% examples, 188919 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:36:59,463 EPOCH 1 - PROGRESS: at 71.63% examples, 189647 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:00,498 EPOCH 1 - PROGRESS: at 75.73% examples, 187781 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:01,526 EPOCH 1 - PROGRESS: at 80.82% examples, 188110 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:02,527 EPOCH 1 - PROGRESS: at 87.10% examples, 187636 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:03,598 EPOCH 1 - PROGRESS: at 93.76% examples, 187037 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:04,551 EPOCH 1: training on 3499793 raw words (3519567 effective words) took 18.7s, 187938 effective words/s
2024-06-23 22:37:05,557 EPOCH 2 - PROGRESS: at 5.22% examples, 179888 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:06,610 EPOCH 2 - PROGRESS: at 11.44% examples, 184878 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:07,610 EPOCH 2 - PROGRESS: at 16.52% examples, 186491 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:08,716 EPOCH 2 - PROGRESS: at 22.39% examples, 187336 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:09,760 EPOCH 2 - PROGRESS: at 27.99% examples, 188072 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:10,768 EPOCH 2 - PROGRESS: at 33.54% examples, 189741 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:11,798 EPOCH 2 - PROGRESS: at 38.83% examples, 188954 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:12,807 EPOCH 2 - PROGRESS: at 43.96% examples, 187674 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:13,819 EPOCH 2 - PROGRESS: at 49.56% examples, 187675 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:14,821 EPOCH 2 - PROGRESS: at 54.40% examples, 186870 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:15,827 EPOCH 2 - PROGRESS: at 59.11% examples, 186128 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:16,869 EPOCH 2 - PROGRESS: at 64.05% examples, 185759 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:17,874 EPOCH 2 - PROGRESS: at 69.11% examples, 186740 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:18,929 EPOCH 2 - PROGRESS: at 74.01% examples, 186854 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:20,033 EPOCH 2 - PROGRESS: at 78.54% examples, 185105 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:21,154 EPOCH 2 - PROGRESS: at 84.91% examples, 184613 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:22,227 EPOCH 2 - PROGRESS: at 92.05% examples, 185292 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:23,278 EPOCH 2 - PROGRESS: at 98.48% examples, 185580 words/s, in_qsize 5, out_qsize 0
2024-06-23 22:37:23,458 EPOCH 2: training on 3499793 raw words (3519707 effective words) took 18.9s, 186207 effective words/s
2024-06-23 22:37:24,494 EPOCH 3 - PROGRESS: at 5.22% examples, 174652 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:25,563 EPOCH 3 - PROGRESS: at 11.44% examples, 180845 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:26,601 EPOCH 3 - PROGRESS: at 16.80% examples, 184728 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:27,665 EPOCH 3 - PROGRESS: at 22.67% examples, 187859 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:28,712 EPOCH 3 - PROGRESS: at 28.28% examples, 188370 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:29,761 EPOCH 3 - PROGRESS: at 33.82% examples, 188751 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:30,874 EPOCH 3 - PROGRESS: at 39.67% examples, 188739 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:31,952 EPOCH 3 - PROGRESS: at 45.24% examples, 188312 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:32,976 EPOCH 3 - PROGRESS: at 50.80% examples, 187998 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:33,990 EPOCH 3 - PROGRESS: at 56.18% examples, 188862 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:35,025 EPOCH 3 - PROGRESS: at 61.50% examples, 189231 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:36,030 EPOCH 3 - PROGRESS: at 66.02% examples, 188357 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:37,122 EPOCH 3 - PROGRESS: at 71.14% examples, 187911 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:38,147 EPOCH 3 - PROGRESS: at 75.99% examples, 188348 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:39,181 EPOCH 3 - PROGRESS: at 81.68% examples, 189206 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:40,258 EPOCH 3 - PROGRESS: at 89.10% examples, 189600 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:41,289 EPOCH 3 - PROGRESS: at 95.89% examples, 190429 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:41,890 EPOCH 3: training on 3499793 raw words (3519756 effective words) took 18.4s, 191011 effective words/s
2024-06-23 22:37:42,900 EPOCH 4 - PROGRESS: at 5.59% examples, 188877 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:43,903 EPOCH 4 - PROGRESS: at 11.44% examples, 188986 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:44,926 EPOCH 4 - PROGRESS: at 16.80% examples, 191141 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:45,974 EPOCH 4 - PROGRESS: at 22.67% examples, 193395 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:46,975 EPOCH 4 - PROGRESS: at 28.28% examples, 194562 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:48,002 EPOCH 4 - PROGRESS: at 34.10% examples, 196236 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:49,010 EPOCH 4 - PROGRESS: at 39.39% examples, 195105 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:50,054 EPOCH 4 - PROGRESS: at 45.01% examples, 194647 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:51,071 EPOCH 4 - PROGRESS: at 50.80% examples, 194854 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:52,118 EPOCH 4 - PROGRESS: at 56.18% examples, 194445 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:53,119 EPOCH 4 - PROGRESS: at 61.28% examples, 193992 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:54,207 EPOCH 4 - PROGRESS: at 66.30% examples, 193024 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:55,244 EPOCH 4 - PROGRESS: at 71.38% examples, 192991 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:37:56,247 EPOCH 4 - PROGRESS: at 76.25% examples, 193364 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:57,324 EPOCH 4 - PROGRESS: at 81.68% examples, 192725 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:58,348 EPOCH 4 - PROGRESS: at 88.52% examples, 192894 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:37:59,366 EPOCH 4 - PROGRESS: at 95.24% examples, 193115 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:00,110 EPOCH 4: training on 3499793 raw words (3519549 effective words) took 18.2s, 193198 effective words/s
2024-06-23 22:38:01,115 EPOCH 5 - PROGRESS: at 5.45% examples, 189973 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:02,171 EPOCH 5 - PROGRESS: at 10.84% examples, 179773 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:03,204 EPOCH 5 - PROGRESS: at 16.52% examples, 184405 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:04,218 EPOCH 5 - PROGRESS: at 22.39% examples, 189948 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:05,234 EPOCH 5 - PROGRESS: at 27.13% examples, 185336 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:06,279 EPOCH 5 - PROGRESS: at 32.69% examples, 186333 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:07,358 EPOCH 5 - PROGRESS: at 38.54% examples, 187573 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:08,475 EPOCH 5 - PROGRESS: at 44.21% examples, 186425 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:09,538 EPOCH 5 - PROGRESS: at 50.02% examples, 186597 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:10,549 EPOCH 5 - PROGRESS: at 55.40% examples, 187659 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:11,664 EPOCH 5 - PROGRESS: at 61.03% examples, 187698 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:12,711 EPOCH 5 - PROGRESS: at 66.02% examples, 187910 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:13,734 EPOCH 5 - PROGRESS: at 71.14% examples, 188464 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:14,768 EPOCH 5 - PROGRESS: at 76.25% examples, 189419 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:15,771 EPOCH 5 - PROGRESS: at 81.68% examples, 189952 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:16,791 EPOCH 5 - PROGRESS: at 88.09% examples, 189749 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:17,802 EPOCH 5 - PROGRESS: at 94.61% examples, 189652 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:18,651 EPOCH 5: training on 3499793 raw words (3519556 effective words) took 18.5s, 189877 effective words/s
2024-06-23 22:38:19,669 EPOCH 6 - PROGRESS: at 5.59% examples, 187527 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:20,687 EPOCH 6 - PROGRESS: at 11.97% examples, 196843 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:21,699 EPOCH 6 - PROGRESS: at 16.52% examples, 187216 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:22,755 EPOCH 6 - PROGRESS: at 22.12% examples, 187714 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:23,810 EPOCH 6 - PROGRESS: at 27.99% examples, 189883 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:24,810 EPOCH 6 - PROGRESS: at 32.97% examples, 188262 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:25,829 EPOCH 6 - PROGRESS: at 38.26% examples, 187999 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:26,842 EPOCH 6 - PROGRESS: at 44.32% examples, 190382 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:27,964 EPOCH 6 - PROGRESS: at 50.26% examples, 189986 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:28,975 EPOCH 6 - PROGRESS: at 55.91% examples, 191686 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:30,022 EPOCH 6 - PROGRESS: at 61.03% examples, 190725 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:31,032 EPOCH 6 - PROGRESS: at 66.02% examples, 191247 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:32,163 EPOCH 6 - PROGRESS: at 71.38% examples, 190766 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:33,164 EPOCH 6 - PROGRESS: at 76.25% examples, 191312 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:34,202 EPOCH 6 - PROGRESS: at 82.27% examples, 192574 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:35,207 EPOCH 6 - PROGRESS: at 89.42% examples, 192986 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:36,253 EPOCH 6 - PROGRESS: at 95.89% examples, 192889 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:36,856 EPOCH 6: training on 3499793 raw words (3519612 effective words) took 18.2s, 193377 effective words/s
2024-06-23 22:38:38,026 EPOCH 7 - PROGRESS: at 6.10% examples, 180386 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:39,078 EPOCH 7 - PROGRESS: at 12.63% examples, 189444 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:40,087 EPOCH 7 - PROGRESS: at 17.96% examples, 192115 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:41,134 EPOCH 7 - PROGRESS: at 24.05% examples, 196364 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:42,136 EPOCH 7 - PROGRESS: at 29.65% examples, 196913 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:43,140 EPOCH 7 - PROGRESS: at 35.20% examples, 197301 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:44,165 EPOCH 7 - PROGRESS: at 40.22% examples, 194227 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:45,184 EPOCH 7 - PROGRESS: at 45.89% examples, 194495 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:46,190 EPOCH 7 - PROGRESS: at 51.83% examples, 194932 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:47,265 EPOCH 7 - PROGRESS: at 56.18% examples, 191097 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:48,273 EPOCH 7 - PROGRESS: at 61.50% examples, 191711 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:49,355 EPOCH 7 - PROGRESS: at 66.75% examples, 191852 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:50,356 EPOCH 7 - PROGRESS: at 71.84% examples, 192426 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:51,366 EPOCH 7 - PROGRESS: at 77.00% examples, 193398 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:52,370 EPOCH 7 - PROGRESS: at 83.53% examples, 194995 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:53,403 EPOCH 7 - PROGRESS: at 89.75% examples, 193711 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:54,408 EPOCH 7 - PROGRESS: at 95.89% examples, 193455 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:55,049 EPOCH 7: training on 3499793 raw words (3519675 effective words) took 18.2s, 193518 effective words/s
2024-06-23 22:38:56,071 EPOCH 8 - PROGRESS: at 5.59% examples, 186840 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:38:57,074 EPOCH 8 - PROGRESS: at 11.97% examples, 197954 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:58,089 EPOCH 8 - PROGRESS: at 16.80% examples, 190999 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:38:59,137 EPOCH 8 - PROGRESS: at 22.11% examples, 188410 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:00,150 EPOCH 8 - PROGRESS: at 27.71% examples, 190080 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:01,192 EPOCH 8 - PROGRESS: at 33.54% examples, 192046 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:02,199 EPOCH 8 - PROGRESS: at 38.83% examples, 191541 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:03,213 EPOCH 8 - PROGRESS: at 44.32% examples, 191027 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:04,224 EPOCH 8 - PROGRESS: at 49.56% examples, 189584 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:05,225 EPOCH 8 - PROGRESS: at 54.40% examples, 188596 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:06,234 EPOCH 8 - PROGRESS: at 59.32% examples, 188522 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:07,241 EPOCH 8 - PROGRESS: at 64.76% examples, 190119 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:08,278 EPOCH 8 - PROGRESS: at 69.83% examples, 190334 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:09,348 EPOCH 8 - PROGRESS: at 75.23% examples, 191378 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:10,381 EPOCH 8 - PROGRESS: at 80.24% examples, 191411 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:11,430 EPOCH 8 - PROGRESS: at 87.10% examples, 191375 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:12,436 EPOCH 8 - PROGRESS: at 94.03% examples, 191830 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:13,357 EPOCH 8: training on 3499793 raw words (3519659 effective words) took 18.3s, 192290 effective words/s
2024-06-23 22:39:14,519 EPOCH 9 - PROGRESS: at 6.10% examples, 181358 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:15,533 EPOCH 9 - PROGRESS: at 12.63% examples, 193316 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:16,537 EPOCH 9 - PROGRESS: at 18.23% examples, 198192 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:17,590 EPOCH 9 - PROGRESS: at 23.77% examples, 196036 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:18,652 EPOCH 9 - PROGRESS: at 29.38% examples, 194417 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:19,673 EPOCH 9 - PROGRESS: at 34.95% examples, 194669 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:20,676 EPOCH 9 - PROGRESS: at 40.45% examples, 195260 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:21,686 EPOCH 9 - PROGRESS: at 46.14% examples, 195640 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:22,690 EPOCH 9 - PROGRESS: at 52.05% examples, 195980 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:23,691 EPOCH 9 - PROGRESS: at 57.58% examples, 197290 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:24,784 EPOCH 9 - PROGRESS: at 63.02% examples, 196729 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:25,887 EPOCH 9 - PROGRESS: at 68.06% examples, 195353 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:26,944 EPOCH 9 - PROGRESS: at 73.03% examples, 194793 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:28,028 EPOCH 9 - PROGRESS: at 78.25% examples, 194645 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:29,044 EPOCH 9 - PROGRESS: at 84.64% examples, 194739 words/s, in_qsize 7, out_qsize 0
2024-06-23 22:39:30,078 EPOCH 9 - PROGRESS: at 91.25% examples, 194655 words/s, in_qsize 8, out_qsize 0
2024-06-23 22:39:31,127 EPOCH 9 - PROGRESS: at 98.15% examples, 195003 words/s, in_qsize 6, out_qsize 0
2024-06-23 22:39:31,337 EPOCH 9: training on 3499793 raw words (3519546 effective words) took 18.0s, 195787 effective words/s
2024-06-23 22:39:31,338 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35196240 effective words) took 185.8s, 189391 effective words/s', 'datetime': '2024-06-23T22:39:31.338300', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-23 22:45:29,455 ==================================================
2024-06-23 22:45:29,456 Training BERT + Doc2Vec features with Dimension-2048...
2024-06-23 22:45:30,430 Epoch [1/8], Batch [1/748], Loss: 1.6111
2024-06-23 22:46:19,129 Epoch [1/8], Batch [51/748], Loss: 1.4476
2024-06-23 22:47:08,983 Epoch [1/8], Batch [101/748], Loss: 1.2919
2024-06-23 22:47:59,224 Epoch [1/8], Batch [151/748], Loss: 1.3237
2024-06-23 22:48:49,627 Epoch [1/8], Batch [201/748], Loss: 0.9872
2024-06-23 22:49:39,859 Epoch [1/8], Batch [251/748], Loss: 0.9386
2024-06-23 22:50:30,445 Epoch [1/8], Batch [301/748], Loss: 1.1402
2024-06-23 22:51:21,140 Epoch [1/8], Batch [351/748], Loss: 1.0000
2024-06-23 22:52:11,758 Epoch [1/8], Batch [401/748], Loss: 0.9563
2024-06-23 22:53:02,158 Epoch [1/8], Batch [451/748], Loss: 0.9074
2024-06-23 22:53:52,682 Epoch [1/8], Batch [501/748], Loss: 0.9028
2024-06-23 22:54:43,035 Epoch [1/8], Batch [551/748], Loss: 1.0987
2024-06-23 22:55:33,315 Epoch [1/8], Batch [601/748], Loss: 0.7624
2024-06-23 22:56:23,565 Epoch [1/8], Batch [651/748], Loss: 0.9529
2024-06-23 22:57:14,150 Epoch [1/8], Batch [701/748], Loss: 1.0975
2024-06-23 22:58:01,254 Epoch 1/8, Train Loss: 1.0758, Train Accuracy: 0.5229
2024-06-23 22:59:21,602 Epoch 1/8, Val Loss: 0.9261, Val Accuracy: 0.5725
2024-06-23 22:59:22,602 Epoch [2/8], Batch [1/748], Loss: 1.1677
2024-06-23 23:00:12,738 Epoch [2/8], Batch [51/748], Loss: 0.9405
2024-06-23 23:01:03,411 Epoch [2/8], Batch [101/748], Loss: 0.8314
2024-06-23 23:01:53,951 Epoch [2/8], Batch [151/748], Loss: 0.9868
2024-06-23 23:02:44,579 Epoch [2/8], Batch [201/748], Loss: 1.0709
2024-06-23 23:03:35,252 Epoch [2/8], Batch [251/748], Loss: 1.1313
2024-06-23 23:04:25,722 Epoch [2/8], Batch [301/748], Loss: 0.7867
2024-06-23 23:05:16,235 Epoch [2/8], Batch [351/748], Loss: 0.9897
2024-06-23 23:06:06,752 Epoch [2/8], Batch [401/748], Loss: 1.0373
2024-06-23 23:06:57,002 Epoch [2/8], Batch [451/748], Loss: 0.7769
2024-06-23 23:07:47,545 Epoch [2/8], Batch [501/748], Loss: 0.7247
2024-06-23 23:08:37,972 Epoch [2/8], Batch [551/748], Loss: 0.6975
2024-06-23 23:09:28,469 Epoch [2/8], Batch [601/748], Loss: 0.8187
2024-06-23 23:10:18,911 Epoch [2/8], Batch [651/748], Loss: 0.5279
2024-06-23 23:11:09,282 Epoch [2/8], Batch [701/748], Loss: 0.7550
2024-06-23 23:11:56,347 Epoch 2/8, Train Loss: 0.8504, Train Accuracy: 0.6112
2024-06-23 23:13:16,131 Epoch 2/8, Val Loss: 0.9117, Val Accuracy: 0.6083
2024-06-23 23:13:17,139 Epoch [3/8], Batch [1/748], Loss: 0.5941
2024-06-23 23:14:07,386 Epoch [3/8], Batch [51/748], Loss: 0.6120
2024-06-23 23:14:57,806 Epoch [3/8], Batch [101/748], Loss: 0.9669
2024-06-23 23:15:48,102 Epoch [3/8], Batch [151/748], Loss: 0.8130
2024-06-23 23:16:38,420 Epoch [3/8], Batch [201/748], Loss: 0.7031
2024-06-23 23:17:28,759 Epoch [3/8], Batch [251/748], Loss: 0.8540
2024-06-23 23:18:19,129 Epoch [3/8], Batch [301/748], Loss: 1.2246
2024-06-23 23:19:09,594 Epoch [3/8], Batch [351/748], Loss: 0.6245
2024-06-23 23:20:00,423 Epoch [3/8], Batch [401/748], Loss: 0.7162
2024-06-23 23:20:51,364 Epoch [3/8], Batch [451/748], Loss: 0.7928
2024-06-23 23:21:42,085 Epoch [3/8], Batch [501/748], Loss: 0.6866
2024-06-23 23:22:32,549 Epoch [3/8], Batch [551/748], Loss: 0.6982
2024-06-23 23:23:22,988 Epoch [3/8], Batch [601/748], Loss: 0.6600
2024-06-23 23:24:13,297 Epoch [3/8], Batch [651/748], Loss: 0.6183
2024-06-23 23:25:03,571 Epoch [3/8], Batch [701/748], Loss: 0.8953
2024-06-23 23:25:50,537 Epoch 3/8, Train Loss: 0.7436, Train Accuracy: 0.6682
2024-06-23 23:27:10,020 Epoch 3/8, Val Loss: 0.8506, Val Accuracy: 0.6245
2024-06-23 23:27:11,042 Epoch [4/8], Batch [1/748], Loss: 0.6432
2024-06-23 23:28:01,263 Epoch [4/8], Batch [51/748], Loss: 0.7885
2024-06-23 23:28:51,609 Epoch [4/8], Batch [101/748], Loss: 0.5790
2024-06-23 23:29:41,918 Epoch [4/8], Batch [151/748], Loss: 0.6724
2024-06-23 23:30:32,312 Epoch [4/8], Batch [201/748], Loss: 0.3895
2024-06-23 23:31:22,859 Epoch [4/8], Batch [251/748], Loss: 0.6785
2024-06-23 23:32:13,181 Epoch [4/8], Batch [301/748], Loss: 0.8527
2024-06-23 23:33:03,729 Epoch [4/8], Batch [351/748], Loss: 0.5198
2024-06-23 23:33:54,172 Epoch [4/8], Batch [401/748], Loss: 0.6843
2024-06-23 23:34:44,494 Epoch [4/8], Batch [451/748], Loss: 0.7386
2024-06-23 23:35:34,957 Epoch [4/8], Batch [501/748], Loss: 0.7011
2024-06-23 23:36:25,310 Epoch [4/8], Batch [551/748], Loss: 0.7672
2024-06-23 23:37:15,698 Epoch [4/8], Batch [601/748], Loss: 0.6114
2024-06-23 23:38:06,050 Epoch [4/8], Batch [651/748], Loss: 0.6731
2024-06-23 23:38:56,331 Epoch [4/8], Batch [701/748], Loss: 0.7156
2024-06-23 23:39:43,183 Epoch 4/8, Train Loss: 0.6526, Train Accuracy: 0.7136
2024-06-23 23:41:02,546 Epoch 4/8, Val Loss: 0.8440, Val Accuracy: 0.6527
2024-06-23 23:41:03,591 Epoch [5/8], Batch [1/748], Loss: 0.4171
2024-06-23 23:41:53,877 Epoch [5/8], Batch [51/748], Loss: 0.7400
2024-06-23 23:42:44,135 Epoch [5/8], Batch [101/748], Loss: 0.4904
2024-06-23 23:43:34,629 Epoch [5/8], Batch [151/748], Loss: 0.5670
2024-06-23 23:44:24,909 Epoch [5/8], Batch [201/748], Loss: 0.4793
2024-06-23 23:45:15,299 Epoch [5/8], Batch [251/748], Loss: 0.5668
2024-06-23 23:46:05,526 Epoch [5/8], Batch [301/748], Loss: 0.6889
2024-06-23 23:46:55,693 Epoch [5/8], Batch [351/748], Loss: 0.6591
2024-06-23 23:47:46,045 Epoch [5/8], Batch [401/748], Loss: 0.8091
2024-06-23 23:48:36,477 Epoch [5/8], Batch [451/748], Loss: 0.3650
2024-06-23 23:49:26,795 Epoch [5/8], Batch [501/748], Loss: 0.3079
2024-06-23 23:50:17,399 Epoch [5/8], Batch [551/748], Loss: 0.2781
2024-06-23 23:51:07,789 Epoch [5/8], Batch [601/748], Loss: 0.5154
2024-06-23 23:51:58,098 Epoch [5/8], Batch [651/748], Loss: 0.5469
2024-06-23 23:52:48,396 Epoch [5/8], Batch [701/748], Loss: 0.4461
2024-06-23 23:53:35,390 Epoch 5/8, Train Loss: 0.5657, Train Accuracy: 0.7586
2024-06-23 23:54:54,601 Epoch 5/8, Val Loss: 0.8791, Val Accuracy: 0.6601
2024-06-23 23:54:55,609 Epoch [6/8], Batch [1/748], Loss: 0.4557
2024-06-23 23:55:45,972 Epoch [6/8], Batch [51/748], Loss: 0.3427
2024-06-23 23:56:36,228 Epoch [6/8], Batch [101/748], Loss: 0.4509
2024-06-23 23:57:26,595 Epoch [6/8], Batch [151/748], Loss: 0.2945
2024-06-23 23:58:16,764 Epoch [6/8], Batch [201/748], Loss: 0.5313
2024-06-23 23:59:07,174 Epoch [6/8], Batch [251/748], Loss: 0.4528
2024-06-23 23:59:57,573 Epoch [6/8], Batch [301/748], Loss: 0.5039
2024-06-24 00:00:47,844 Epoch [6/8], Batch [351/748], Loss: 0.5270
2024-06-24 00:01:38,474 Epoch [6/8], Batch [401/748], Loss: 0.3160
2024-06-24 00:02:28,779 Epoch [6/8], Batch [451/748], Loss: 0.3628
2024-06-24 00:03:19,175 Epoch [6/8], Batch [501/748], Loss: 0.4195
2024-06-24 00:04:09,443 Epoch [6/8], Batch [551/748], Loss: 0.5729
2024-06-24 00:04:59,780 Epoch [6/8], Batch [601/748], Loss: 0.2795
2024-06-24 00:05:50,176 Epoch [6/8], Batch [651/748], Loss: 0.4718
2024-06-24 00:06:40,261 Epoch [6/8], Batch [701/748], Loss: 0.4621
2024-06-24 00:07:27,254 Epoch 6/8, Train Loss: 0.4723, Train Accuracy: 0.8057
2024-06-24 00:08:46,567 Epoch 6/8, Val Loss: 0.9008, Val Accuracy: 0.6653
2024-06-24 00:08:47,564 Epoch [7/8], Batch [1/748], Loss: 0.3448
2024-06-24 00:09:37,897 Epoch [7/8], Batch [51/748], Loss: 0.4284
2024-06-24 00:10:28,941 Epoch [7/8], Batch [101/748], Loss: 0.4450
2024-06-24 00:11:19,713 Epoch [7/8], Batch [151/748], Loss: 0.3802
2024-06-24 00:12:10,232 Epoch [7/8], Batch [201/748], Loss: 0.2583
2024-06-24 00:13:00,670 Epoch [7/8], Batch [251/748], Loss: 0.4167
2024-06-24 00:13:51,176 Epoch [7/8], Batch [301/748], Loss: 0.2438
2024-06-24 00:14:41,618 Epoch [7/8], Batch [351/748], Loss: 0.5085
2024-06-24 00:15:32,032 Epoch [7/8], Batch [401/748], Loss: 0.3830
2024-06-24 00:16:22,372 Epoch [7/8], Batch [451/748], Loss: 0.1531
2024-06-24 00:17:12,773 Epoch [7/8], Batch [501/748], Loss: 0.5892
2024-06-24 00:18:03,277 Epoch [7/8], Batch [551/748], Loss: 0.5774
2024-06-24 00:18:53,773 Epoch [7/8], Batch [601/748], Loss: 0.4509
2024-06-24 00:19:44,180 Epoch [7/8], Batch [651/748], Loss: 0.3361
2024-06-24 00:20:34,679 Epoch [7/8], Batch [701/748], Loss: 0.3925
2024-06-24 00:21:21,856 Epoch 7/8, Train Loss: 0.3915, Train Accuracy: 0.8436
2024-06-24 00:22:41,287 Epoch 7/8, Val Loss: 0.9406, Val Accuracy: 0.6703
2024-06-24 00:22:42,288 Epoch [8/8], Batch [1/748], Loss: 0.4079
2024-06-24 00:23:32,739 Epoch [8/8], Batch [51/748], Loss: 0.3955
2024-06-24 00:24:23,155 Epoch [8/8], Batch [101/748], Loss: 0.3497
2024-06-24 00:25:13,698 Epoch [8/8], Batch [151/748], Loss: 0.1877
2024-06-24 00:26:04,132 Epoch [8/8], Batch [201/748], Loss: 0.3907
2024-06-24 00:26:54,648 Epoch [8/8], Batch [251/748], Loss: 0.4323
2024-06-24 00:27:45,219 Epoch [8/8], Batch [301/748], Loss: 0.2967
2024-06-24 00:28:35,489 Epoch [8/8], Batch [351/748], Loss: 0.3739
2024-06-24 00:29:25,849 Epoch [8/8], Batch [401/748], Loss: 0.3165
2024-06-24 00:30:16,239 Epoch [8/8], Batch [451/748], Loss: 0.2847
2024-06-24 00:31:06,622 Epoch [8/8], Batch [501/748], Loss: 0.3859
2024-06-24 00:31:56,915 Epoch [8/8], Batch [551/748], Loss: 0.2495
2024-06-24 00:32:47,158 Epoch [8/8], Batch [601/748], Loss: 0.2939
2024-06-24 00:33:37,456 Epoch [8/8], Batch [651/748], Loss: 0.4607
2024-06-24 00:34:27,794 Epoch [8/8], Batch [701/748], Loss: 0.2390
2024-06-24 00:35:14,758 Epoch 8/8, Train Loss: 0.3123, Train Accuracy: 0.8779
2024-06-24 00:36:34,337 Epoch 8/8, Val Loss: 0.9661, Val Accuracy: 0.6848
2024-06-24 00:36:34,339 Training finished!
2024-06-24 00:36:34,339 ==================================================
2024-06-24 00:36:58,470 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d1024,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T00:36:58.470313', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 00:36:58,470 collecting all words and their counts
2024-06-24 00:36:58,470 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 00:36:58,699 PROGRESS: at example #10000, processed 1168609 words (5101214 words/s), 72028 word types, 0 tags
2024-06-24 00:36:58,949 PROGRESS: at example #20000, processed 2388715 words (4893859 words/s), 103898 word types, 0 tags
2024-06-24 00:36:59,185 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 00:36:59,185 Creating a fresh vocabulary
2024-06-24 00:36:59,657 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T00:36:59.657832', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 00:36:59,658 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T00:36:59.658052', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 00:37:00,454 deleting the raw counts dictionary of 133984 items
2024-06-24 00:37:00,456 sample=0.001 downsamples 6 most-common words
2024-06-24 00:37:00,456 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T00:37:00.456837', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 00:37:01,758 estimated required memory for 133984 words and 1024 dimensions: 1164610408 bytes
2024-06-24 00:37:01,758 resetting layer weights
2024-06-24 00:37:02,552 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 1024 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T00:37:02.552651', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 00:37:03,594 EPOCH 0 - PROGRESS: at 6.10% examples, 202395 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:04,606 EPOCH 0 - PROGRESS: at 15.43% examples, 258381 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:05,608 EPOCH 0 - PROGRESS: at 23.77% examples, 271623 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:06,626 EPOCH 0 - PROGRESS: at 32.69% examples, 282253 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:07,686 EPOCH 0 - PROGRESS: at 41.70% examples, 286245 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:08,690 EPOCH 0 - PROGRESS: at 51.03% examples, 293156 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:09,693 EPOCH 0 - PROGRESS: at 59.67% examples, 296738 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:10,712 EPOCH 0 - PROGRESS: at 68.06% examples, 300003 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:11,739 EPOCH 0 - PROGRESS: at 75.74% examples, 300080 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:12,739 EPOCH 0 - PROGRESS: at 85.19% examples, 301887 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:13,812 EPOCH 0 - PROGRESS: at 96.14% examples, 302460 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:14,118 EPOCH 0: training on 3499793 raw words (3519588 effective words) took 11.6s, 304408 effective words/s
2024-06-24 00:37:15,166 EPOCH 1 - PROGRESS: at 9.50% examples, 306348 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:16,211 EPOCH 1 - PROGRESS: at 19.01% examples, 315784 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:17,249 EPOCH 1 - PROGRESS: at 28.56% examples, 319437 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:18,253 EPOCH 1 - PROGRESS: at 36.87% examples, 314419 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:19,298 EPOCH 1 - PROGRESS: at 45.48% examples, 310808 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:20,378 EPOCH 1 - PROGRESS: at 54.62% examples, 308224 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:21,418 EPOCH 1 - PROGRESS: at 62.52% examples, 305332 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:22,440 EPOCH 1 - PROGRESS: at 70.63% examples, 306198 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:23,456 EPOCH 1 - PROGRESS: at 78.25% examples, 305854 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:24,518 EPOCH 1 - PROGRESS: at 88.67% examples, 305329 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:25,552 EPOCH 1 - PROGRESS: at 99.29% examples, 305724 words/s, in_qsize 3, out_qsize 1
2024-06-24 00:37:25,598 EPOCH 1: training on 3499793 raw words (3519598 effective words) took 11.5s, 306696 effective words/s
2024-06-24 00:37:26,602 EPOCH 2 - PROGRESS: at 9.50% examples, 319544 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:27,602 EPOCH 2 - PROGRESS: at 18.23% examples, 314574 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:28,696 EPOCH 2 - PROGRESS: at 27.99% examples, 316262 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:29,710 EPOCH 2 - PROGRESS: at 36.87% examples, 316090 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:30,726 EPOCH 2 - PROGRESS: at 45.48% examples, 313878 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:31,790 EPOCH 2 - PROGRESS: at 55.11% examples, 314774 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:32,815 EPOCH 2 - PROGRESS: at 63.77% examples, 315685 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:33,848 EPOCH 2 - PROGRESS: at 71.84% examples, 314846 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:34,864 EPOCH 2 - PROGRESS: at 80.24% examples, 316727 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:35,883 EPOCH 2 - PROGRESS: at 91.33% examples, 316487 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:36,674 EPOCH 2: training on 3499793 raw words (3519515 effective words) took 11.1s, 317837 effective words/s
2024-06-24 00:37:37,736 EPOCH 3 - PROGRESS: at 9.50% examples, 302530 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:38,749 EPOCH 3 - PROGRESS: at 18.49% examples, 308835 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:39,792 EPOCH 3 - PROGRESS: at 27.71% examples, 311072 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:40,829 EPOCH 3 - PROGRESS: at 37.16% examples, 315234 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:41,838 EPOCH 3 - PROGRESS: at 45.89% examples, 313703 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:42,880 EPOCH 3 - PROGRESS: at 54.87% examples, 312518 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:43,953 EPOCH 3 - PROGRESS: at 63.02% examples, 308893 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:44,969 EPOCH 3 - PROGRESS: at 70.90% examples, 308386 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:45,999 EPOCH 3 - PROGRESS: at 78.54% examples, 307375 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:47,022 EPOCH 3 - PROGRESS: at 87.67% examples, 304946 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:48,071 EPOCH 3 - PROGRESS: at 97.56% examples, 302343 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:48,298 EPOCH 3: training on 3499793 raw words (3519664 effective words) took 11.6s, 302905 effective words/s
2024-06-24 00:37:49,321 EPOCH 4 - PROGRESS: at 8.48% examples, 284452 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:50,370 EPOCH 4 - PROGRESS: at 17.73% examples, 294883 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:51,460 EPOCH 4 - PROGRESS: at 26.86% examples, 297268 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:52,482 EPOCH 4 - PROGRESS: at 35.75% examples, 301156 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:53,511 EPOCH 4 - PROGRESS: at 44.57% examples, 301130 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:54,553 EPOCH 4 - PROGRESS: at 53.93% examples, 303675 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:55,564 EPOCH 4 - PROGRESS: at 61.98% examples, 304006 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:56,569 EPOCH 4 - PROGRESS: at 69.58% examples, 303256 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:37:57,591 EPOCH 4 - PROGRESS: at 77.47% examples, 304138 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:58,624 EPOCH 4 - PROGRESS: at 87.67% examples, 305570 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:37:59,650 EPOCH 4 - PROGRESS: at 98.50% examples, 306189 words/s, in_qsize 5, out_qsize 0
2024-06-24 00:37:59,757 EPOCH 4: training on 3499793 raw words (3519675 effective words) took 11.5s, 307252 effective words/s
2024-06-24 00:38:00,762 EPOCH 5 - PROGRESS: at 8.95% examples, 299824 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:01,763 EPOCH 5 - PROGRESS: at 17.20% examples, 294694 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:02,769 EPOCH 5 - PROGRESS: at 25.74% examples, 298917 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:03,770 EPOCH 5 - PROGRESS: at 34.10% examples, 299096 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:04,770 EPOCH 5 - PROGRESS: at 42.56% examples, 299175 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:05,804 EPOCH 5 - PROGRESS: at 51.58% examples, 299255 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:06,816 EPOCH 5 - PROGRESS: at 59.67% examples, 300187 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:07,824 EPOCH 5 - PROGRESS: at 67.29% examples, 299798 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:08,837 EPOCH 5 - PROGRESS: at 74.79% examples, 299227 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:09,847 EPOCH 5 - PROGRESS: at 83.87% examples, 300825 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:10,868 EPOCH 5 - PROGRESS: at 94.87% examples, 302902 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:11,340 EPOCH 5: training on 3499793 raw words (3519493 effective words) took 11.6s, 303974 effective words/s
2024-06-24 00:38:12,407 EPOCH 6 - PROGRESS: at 9.20% examples, 291133 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:13,477 EPOCH 6 - PROGRESS: at 18.23% examples, 294939 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:14,479 EPOCH 6 - PROGRESS: at 26.86% examples, 299329 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:15,483 EPOCH 6 - PROGRESS: at 36.33% examples, 308857 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:16,510 EPOCH 6 - PROGRESS: at 45.24% examples, 309328 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:17,515 EPOCH 6 - PROGRESS: at 54.15% examples, 309149 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:18,570 EPOCH 6 - PROGRESS: at 63.24% examples, 312316 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:19,587 EPOCH 6 - PROGRESS: at 71.63% examples, 313722 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:20,639 EPOCH 6 - PROGRESS: at 79.49% examples, 312455 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:21,685 EPOCH 6 - PROGRESS: at 90.59% examples, 312686 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:22,581 EPOCH 6: training on 3499793 raw words (3519500 effective words) took 11.2s, 313165 effective words/s
2024-06-24 00:38:23,632 EPOCH 7 - PROGRESS: at 9.20% examples, 295633 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:24,675 EPOCH 7 - PROGRESS: at 18.73% examples, 310606 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:25,696 EPOCH 7 - PROGRESS: at 27.43% examples, 308104 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:26,716 EPOCH 7 - PROGRESS: at 36.87% examples, 314298 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:27,766 EPOCH 7 - PROGRESS: at 45.65% examples, 310440 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:28,777 EPOCH 7 - PROGRESS: at 55.11% examples, 314601 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:29,797 EPOCH 7 - PROGRESS: at 63.53% examples, 314336 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:30,850 EPOCH 7 - PROGRESS: at 72.10% examples, 315365 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:31,866 EPOCH 7 - PROGRESS: at 80.24% examples, 316093 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:32,886 EPOCH 7 - PROGRESS: at 91.03% examples, 314905 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:33,772 EPOCH 7: training on 3499793 raw words (3519570 effective words) took 11.2s, 314585 effective words/s
2024-06-24 00:38:34,781 EPOCH 8 - PROGRESS: at 8.95% examples, 298386 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:35,795 EPOCH 8 - PROGRESS: at 18.23% examples, 311767 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:36,806 EPOCH 8 - PROGRESS: at 27.43% examples, 316442 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:37,811 EPOCH 8 - PROGRESS: at 36.87% examples, 321860 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:38,845 EPOCH 8 - PROGRESS: at 45.65% examples, 317362 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:39,866 EPOCH 8 - PROGRESS: at 54.41% examples, 314974 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:40,866 EPOCH 8 - PROGRESS: at 63.02% examples, 316952 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:41,888 EPOCH 8 - PROGRESS: at 71.14% examples, 316396 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:42,899 EPOCH 8 - PROGRESS: at 79.25% examples, 317296 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:43,924 EPOCH 8 - PROGRESS: at 90.59% examples, 318698 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:44,820 EPOCH 8: training on 3499793 raw words (3519598 effective words) took 11.0s, 318698 effective words/s
2024-06-24 00:38:45,838 EPOCH 9 - PROGRESS: at 9.25% examples, 305570 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:46,841 EPOCH 9 - PROGRESS: at 18.49% examples, 317202 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:47,868 EPOCH 9 - PROGRESS: at 27.13% examples, 311695 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:48,883 EPOCH 9 - PROGRESS: at 36.33% examples, 315073 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:49,901 EPOCH 9 - PROGRESS: at 45.24% examples, 314864 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:50,923 EPOCH 9 - PROGRESS: at 54.40% examples, 314516 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:51,963 EPOCH 9 - PROGRESS: at 62.25% examples, 310634 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:53,021 EPOCH 9 - PROGRESS: at 69.86% examples, 307069 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:54,073 EPOCH 9 - PROGRESS: at 77.23% examples, 304391 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:55,086 EPOCH 9 - PROGRESS: at 86.77% examples, 304443 words/s, in_qsize 7, out_qsize 0
2024-06-24 00:38:56,112 EPOCH 9 - PROGRESS: at 97.56% examples, 305152 words/s, in_qsize 8, out_qsize 0
2024-06-24 00:38:56,306 EPOCH 9: training on 3499793 raw words (3519572 effective words) took 11.5s, 306535 effective words/s
2024-06-24 00:38:56,306 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195773 effective words) took 113.8s, 309403 effective words/s', 'datetime': '2024-06-24T00:38:56.306656', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 00:42:27,569 ==================================================
2024-06-24 00:42:27,570 Training BERT + Doc2Vec features with Dimension-1024...
2024-06-24 00:42:28,546 Epoch [1/8], Batch [1/748], Loss: 1.5906
2024-06-24 00:43:17,531 Epoch [1/8], Batch [51/748], Loss: 1.4319
2024-06-24 00:44:07,482 Epoch [1/8], Batch [101/748], Loss: 1.2732
2024-06-24 00:44:57,652 Epoch [1/8], Batch [151/748], Loss: 1.2915
2024-06-24 00:45:48,123 Epoch [1/8], Batch [201/748], Loss: 1.1767
2024-06-24 00:46:38,620 Epoch [1/8], Batch [251/748], Loss: 0.9114
2024-06-24 00:47:29,163 Epoch [1/8], Batch [301/748], Loss: 1.0638
2024-06-24 00:48:19,591 Epoch [1/8], Batch [351/748], Loss: 1.0969
2024-06-24 00:49:09,984 Epoch [1/8], Batch [401/748], Loss: 0.9847
2024-06-24 00:50:00,451 Epoch [1/8], Batch [451/748], Loss: 0.8921
2024-06-24 00:50:50,702 Epoch [1/8], Batch [501/748], Loss: 1.0032
2024-06-24 00:51:41,280 Epoch [1/8], Batch [551/748], Loss: 0.9043
2024-06-24 00:52:31,684 Epoch [1/8], Batch [601/748], Loss: 1.1380
2024-06-24 00:53:22,317 Epoch [1/8], Batch [651/748], Loss: 0.8338
2024-06-24 00:54:12,736 Epoch [1/8], Batch [701/748], Loss: 0.8743
2024-06-24 00:54:59,745 Epoch 1/8, Train Loss: 1.0670, Train Accuracy: 0.5422
2024-06-24 00:56:19,444 Epoch 1/8, Val Loss: 0.9112, Val Accuracy: 0.6069
2024-06-24 00:56:20,468 Epoch [2/8], Batch [1/748], Loss: 0.9070
2024-06-24 00:57:10,856 Epoch [2/8], Batch [51/748], Loss: 0.8134
2024-06-24 00:58:01,189 Epoch [2/8], Batch [101/748], Loss: 0.7517
2024-06-24 00:58:51,614 Epoch [2/8], Batch [151/748], Loss: 0.8084
2024-06-24 00:59:42,113 Epoch [2/8], Batch [201/748], Loss: 0.7612
2024-06-24 01:00:32,381 Epoch [2/8], Batch [251/748], Loss: 0.9558
2024-06-24 01:01:22,702 Epoch [2/8], Batch [301/748], Loss: 0.7394
2024-06-24 01:02:13,052 Epoch [2/8], Batch [351/748], Loss: 0.9288
2024-06-24 01:03:03,361 Epoch [2/8], Batch [401/748], Loss: 0.6789
2024-06-24 01:03:53,897 Epoch [2/8], Batch [451/748], Loss: 0.8114
2024-06-24 01:04:44,289 Epoch [2/8], Batch [501/748], Loss: 1.0759
2024-06-24 01:05:34,782 Epoch [2/8], Batch [551/748], Loss: 0.8356
2024-06-24 01:06:25,039 Epoch [2/8], Batch [601/748], Loss: 0.7337
2024-06-24 01:07:15,499 Epoch [2/8], Batch [651/748], Loss: 0.6477
2024-06-24 01:08:05,805 Epoch [2/8], Batch [701/748], Loss: 0.6969
2024-06-24 01:08:52,816 Epoch 2/8, Train Loss: 0.8030, Train Accuracy: 0.6460
2024-06-24 01:10:12,286 Epoch 2/8, Val Loss: 0.8386, Val Accuracy: 0.6385
2024-06-24 01:10:13,270 Epoch [3/8], Batch [1/748], Loss: 0.9012
2024-06-24 01:11:03,584 Epoch [3/8], Batch [51/748], Loss: 0.7003
2024-06-24 01:11:54,034 Epoch [3/8], Batch [101/748], Loss: 0.6884
2024-06-24 01:12:44,489 Epoch [3/8], Batch [151/748], Loss: 0.7485
2024-06-24 01:13:35,034 Epoch [3/8], Batch [201/748], Loss: 0.4864
2024-06-24 01:14:25,550 Epoch [3/8], Batch [251/748], Loss: 0.7399
2024-06-24 01:15:16,031 Epoch [3/8], Batch [301/748], Loss: 0.6427
2024-06-24 01:16:06,415 Epoch [3/8], Batch [351/748], Loss: 0.5662
2024-06-24 01:16:56,943 Epoch [3/8], Batch [401/748], Loss: 0.6414
2024-06-24 01:17:47,416 Epoch [3/8], Batch [451/748], Loss: 0.8148
2024-06-24 01:18:37,825 Epoch [3/8], Batch [501/748], Loss: 0.5635
2024-06-24 01:19:28,290 Epoch [3/8], Batch [551/748], Loss: 0.6687
2024-06-24 01:20:18,677 Epoch [3/8], Batch [601/748], Loss: 0.7246
2024-06-24 01:21:09,082 Epoch [3/8], Batch [651/748], Loss: 0.7488
2024-06-24 01:21:59,359 Epoch [3/8], Batch [701/748], Loss: 0.7251
2024-06-24 01:22:46,378 Epoch 3/8, Train Loss: 0.6870, Train Accuracy: 0.7006
2024-06-24 01:24:06,204 Epoch 3/8, Val Loss: 0.7695, Val Accuracy: 0.6639
2024-06-24 01:24:07,186 Epoch [4/8], Batch [1/748], Loss: 0.4811
2024-06-24 01:24:57,378 Epoch [4/8], Batch [51/748], Loss: 0.4700
2024-06-24 01:25:47,882 Epoch [4/8], Batch [101/748], Loss: 0.5674
2024-06-24 01:26:38,202 Epoch [4/8], Batch [151/748], Loss: 0.6235
2024-06-24 01:27:28,563 Epoch [4/8], Batch [201/748], Loss: 0.6831
2024-06-24 01:28:19,036 Epoch [4/8], Batch [251/748], Loss: 0.6812
2024-06-24 01:29:09,599 Epoch [4/8], Batch [301/748], Loss: 0.5734
2024-06-24 01:29:59,964 Epoch [4/8], Batch [351/748], Loss: 0.3451
2024-06-24 01:30:50,221 Epoch [4/8], Batch [401/748], Loss: 0.6045
2024-06-24 01:31:40,705 Epoch [4/8], Batch [451/748], Loss: 0.5377
2024-06-24 01:32:30,953 Epoch [4/8], Batch [501/748], Loss: 0.4596
2024-06-24 01:33:21,429 Epoch [4/8], Batch [551/748], Loss: 0.6780
2024-06-24 01:34:11,787 Epoch [4/8], Batch [601/748], Loss: 0.4862
2024-06-24 01:35:02,100 Epoch [4/8], Batch [651/748], Loss: 0.5979
2024-06-24 01:35:52,502 Epoch [4/8], Batch [701/748], Loss: 0.6536
2024-06-24 01:36:39,376 Epoch 4/8, Train Loss: 0.5890, Train Accuracy: 0.7488
2024-06-24 01:37:58,762 Epoch 4/8, Val Loss: 0.7718, Val Accuracy: 0.6793
2024-06-24 01:37:59,772 Epoch [5/8], Batch [1/748], Loss: 0.5909
2024-06-24 01:38:50,033 Epoch [5/8], Batch [51/748], Loss: 0.5063
2024-06-24 01:39:40,413 Epoch [5/8], Batch [101/748], Loss: 0.4589
2024-06-24 01:40:30,846 Epoch [5/8], Batch [151/748], Loss: 0.5486
2024-06-24 01:41:21,399 Epoch [5/8], Batch [201/748], Loss: 0.5809
2024-06-24 01:42:11,747 Epoch [5/8], Batch [251/748], Loss: 0.4850
2024-06-24 01:43:02,170 Epoch [5/8], Batch [301/748], Loss: 0.4586
2024-06-24 01:43:52,934 Epoch [5/8], Batch [351/748], Loss: 0.4920
2024-06-24 01:44:43,958 Epoch [5/8], Batch [401/748], Loss: 0.6869
2024-06-24 01:45:34,574 Epoch [5/8], Batch [451/748], Loss: 0.6168
2024-06-24 01:46:24,958 Epoch [5/8], Batch [501/748], Loss: 0.5254
2024-06-24 01:47:15,471 Epoch [5/8], Batch [551/748], Loss: 0.6000
2024-06-24 01:48:05,790 Epoch [5/8], Batch [601/748], Loss: 0.5767
2024-06-24 01:48:56,193 Epoch [5/8], Batch [651/748], Loss: 0.4261
2024-06-24 01:49:46,596 Epoch [5/8], Batch [701/748], Loss: 0.4980
2024-06-24 01:50:33,537 Epoch 5/8, Train Loss: 0.4877, Train Accuracy: 0.7999
2024-06-24 01:51:53,356 Epoch 5/8, Val Loss: 0.8526, Val Accuracy: 0.6715
2024-06-24 01:51:54,352 Epoch [6/8], Batch [1/748], Loss: 0.2736
2024-06-24 01:52:44,685 Epoch [6/8], Batch [51/748], Loss: 0.3821
2024-06-24 01:53:35,402 Epoch [6/8], Batch [101/748], Loss: 0.2781
2024-06-24 01:54:25,930 Epoch [6/8], Batch [151/748], Loss: 0.2736
2024-06-24 01:55:16,269 Epoch [6/8], Batch [201/748], Loss: 0.3869
2024-06-24 01:56:06,741 Epoch [6/8], Batch [251/748], Loss: 0.6254
2024-06-24 01:56:57,068 Epoch [6/8], Batch [301/748], Loss: 0.2364
2024-06-24 01:57:47,543 Epoch [6/8], Batch [351/748], Loss: 0.3895
2024-06-24 01:58:37,847 Epoch [6/8], Batch [401/748], Loss: 0.2832
2024-06-24 01:59:28,281 Epoch [6/8], Batch [451/748], Loss: 0.3421
2024-06-24 02:00:18,712 Epoch [6/8], Batch [501/748], Loss: 0.4745
2024-06-24 02:01:09,156 Epoch [6/8], Batch [551/748], Loss: 0.3810
2024-06-24 02:01:59,629 Epoch [6/8], Batch [601/748], Loss: 0.2843
2024-06-24 02:02:50,018 Epoch [6/8], Batch [651/748], Loss: 0.2265
2024-06-24 02:03:40,398 Epoch [6/8], Batch [701/748], Loss: 0.6471
2024-06-24 02:04:27,259 Epoch 6/8, Train Loss: 0.3917, Train Accuracy: 0.8425
2024-06-24 02:05:46,978 Epoch 6/8, Val Loss: 0.9429, Val Accuracy: 0.6669
2024-06-24 02:05:47,994 Epoch [7/8], Batch [1/748], Loss: 0.2801
2024-06-24 02:06:38,425 Epoch [7/8], Batch [51/748], Loss: 0.5635
2024-06-24 02:07:28,758 Epoch [7/8], Batch [101/748], Loss: 0.3585
2024-06-24 02:08:19,158 Epoch [7/8], Batch [151/748], Loss: 0.3769
2024-06-24 02:09:09,572 Epoch [7/8], Batch [201/748], Loss: 0.2923
2024-06-24 02:09:59,939 Epoch [7/8], Batch [251/748], Loss: 0.5116
2024-06-24 02:10:50,116 Epoch [7/8], Batch [301/748], Loss: 0.4085
2024-06-24 02:11:40,615 Epoch [7/8], Batch [351/748], Loss: 0.5532
2024-06-24 02:12:31,137 Epoch [7/8], Batch [401/748], Loss: 0.1802
2024-06-24 02:13:21,540 Epoch [7/8], Batch [451/748], Loss: 0.2974
2024-06-24 02:14:11,949 Epoch [7/8], Batch [501/748], Loss: 0.2387
2024-06-24 02:15:02,403 Epoch [7/8], Batch [551/748], Loss: 0.3505
2024-06-24 02:15:52,704 Epoch [7/8], Batch [601/748], Loss: 0.4832
2024-06-24 02:16:43,022 Epoch [7/8], Batch [651/748], Loss: 0.2777
2024-06-24 02:17:33,515 Epoch [7/8], Batch [701/748], Loss: 0.4268
2024-06-24 02:18:20,587 Epoch 7/8, Train Loss: 0.3212, Train Accuracy: 0.8775
2024-06-24 02:19:40,300 Epoch 7/8, Val Loss: 1.0323, Val Accuracy: 0.6577
2024-06-24 02:19:41,323 Epoch [8/8], Batch [1/748], Loss: 0.1564
2024-06-24 02:20:31,631 Epoch [8/8], Batch [51/748], Loss: 0.2759
2024-06-24 02:21:22,090 Epoch [8/8], Batch [101/748], Loss: 0.2293
2024-06-24 02:22:12,511 Epoch [8/8], Batch [151/748], Loss: 0.1785
2024-06-24 02:23:02,941 Epoch [8/8], Batch [201/748], Loss: 0.2010
2024-06-24 02:23:53,398 Epoch [8/8], Batch [251/748], Loss: 0.3194
2024-06-24 02:24:43,819 Epoch [8/8], Batch [301/748], Loss: 0.0865
2024-06-24 02:25:34,289 Epoch [8/8], Batch [351/748], Loss: 0.4040
2024-06-24 02:26:24,587 Epoch [8/8], Batch [401/748], Loss: 0.3104
2024-06-24 02:27:14,993 Epoch [8/8], Batch [451/748], Loss: 0.4283
2024-06-24 02:28:05,295 Epoch [8/8], Batch [501/748], Loss: 0.4047
2024-06-24 02:28:55,557 Epoch [8/8], Batch [551/748], Loss: 0.3357
2024-06-24 02:29:45,835 Epoch [8/8], Batch [601/748], Loss: 0.4238
2024-06-24 02:30:36,045 Epoch [8/8], Batch [651/748], Loss: 0.2847
2024-06-24 02:31:26,476 Epoch [8/8], Batch [701/748], Loss: 0.5084
2024-06-24 02:32:13,351 Epoch 8/8, Train Loss: 0.2466, Train Accuracy: 0.9090
2024-06-24 02:33:32,923 Epoch 8/8, Val Loss: 1.1835, Val Accuracy: 0.6360
2024-06-24 02:33:32,925 Training finished!
2024-06-24 02:33:32,925 ==================================================
2024-06-24 02:33:56,455 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d512,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T02:33:56.455224', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 02:33:56,455 collecting all words and their counts
2024-06-24 02:33:56,455 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 02:33:56,687 PROGRESS: at example #10000, processed 1168609 words (5037504 words/s), 72028 word types, 0 tags
2024-06-24 02:33:56,941 PROGRESS: at example #20000, processed 2388715 words (4814440 words/s), 103898 word types, 0 tags
2024-06-24 02:33:57,170 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 02:33:57,170 Creating a fresh vocabulary
2024-06-24 02:33:57,612 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T02:33:57.612433', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 02:33:57,612 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T02:33:57.612632', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 02:33:58,343 deleting the raw counts dictionary of 133984 items
2024-06-24 02:33:58,345 sample=0.001 downsamples 6 most-common words
2024-06-24 02:33:58,345 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T02:33:58.345908', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 02:33:59,509 estimated required memory for 133984 words and 512 dimensions: 615801704 bytes
2024-06-24 02:33:59,509 resetting layer weights
2024-06-24 02:33:59,863 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 512 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T02:33:59.863741', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 02:34:00,921 EPOCH 0 - PROGRESS: at 11.10% examples, 360679 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:01,923 EPOCH 0 - PROGRESS: at 24.05% examples, 408288 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:02,934 EPOCH 0 - PROGRESS: at 36.87% examples, 423565 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:03,945 EPOCH 0 - PROGRESS: at 50.02% examples, 431270 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:04,949 EPOCH 0 - PROGRESS: at 62.75% examples, 440370 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:05,963 EPOCH 0 - PROGRESS: at 73.76% examples, 438996 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:06,974 EPOCH 0 - PROGRESS: at 86.41% examples, 438194 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:07,897 EPOCH 0: training on 3499793 raw words (3519609 effective words) took 8.0s, 438375 effective words/s
2024-06-24 02:34:08,908 EPOCH 1 - PROGRESS: at 13.18% examples, 436485 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:09,919 EPOCH 1 - PROGRESS: at 25.74% examples, 445211 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:10,941 EPOCH 1 - PROGRESS: at 38.26% examples, 443548 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:11,942 EPOCH 1 - PROGRESS: at 51.03% examples, 444864 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:12,950 EPOCH 1 - PROGRESS: at 63.02% examples, 445041 words/s, in_qsize 8, out_qsize 1
2024-06-24 02:34:13,959 EPOCH 1 - PROGRESS: at 74.25% examples, 444872 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:14,975 EPOCH 1 - PROGRESS: at 87.38% examples, 444406 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:15,775 EPOCH 1: training on 3499793 raw words (3519387 effective words) took 7.9s, 446925 effective words/s
2024-06-24 02:34:16,806 EPOCH 2 - PROGRESS: at 14.19% examples, 466648 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:17,808 EPOCH 2 - PROGRESS: at 27.99% examples, 482203 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:18,809 EPOCH 2 - PROGRESS: at 40.77% examples, 474580 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:19,812 EPOCH 2 - PROGRESS: at 53.46% examples, 465624 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:20,818 EPOCH 2 - PROGRESS: at 65.28% examples, 463672 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:21,822 EPOCH 2 - PROGRESS: at 76.25% examples, 459219 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:22,844 EPOCH 2 - PROGRESS: at 90.59% examples, 457674 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:23,461 EPOCH 2: training on 3499793 raw words (3519439 effective words) took 7.7s, 458063 effective words/s
2024-06-24 02:34:24,495 EPOCH 3 - PROGRESS: at 14.19% examples, 465785 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:25,502 EPOCH 3 - PROGRESS: at 26.86% examples, 460829 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:26,534 EPOCH 3 - PROGRESS: at 39.11% examples, 449135 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:27,543 EPOCH 3 - PROGRESS: at 52.05% examples, 448333 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:28,546 EPOCH 3 - PROGRESS: at 64.05% examples, 450202 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:29,562 EPOCH 3 - PROGRESS: at 75.47% examples, 450341 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:30,569 EPOCH 3 - PROGRESS: at 89.42% examples, 449641 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:31,237 EPOCH 3: training on 3499793 raw words (3519518 effective words) took 7.8s, 452834 effective words/s
2024-06-24 02:34:32,254 EPOCH 4 - PROGRESS: at 14.19% examples, 473781 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:33,265 EPOCH 4 - PROGRESS: at 26.86% examples, 463987 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:34,307 EPOCH 4 - PROGRESS: at 39.39% examples, 452947 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:35,329 EPOCH 4 - PROGRESS: at 52.39% examples, 449740 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:36,341 EPOCH 4 - PROGRESS: at 63.53% examples, 444573 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:37,360 EPOCH 4 - PROGRESS: at 75.02% examples, 445452 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:38,367 EPOCH 4 - PROGRESS: at 88.09% examples, 444042 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:39,163 EPOCH 4: training on 3499793 raw words (3519524 effective words) took 7.9s, 444298 effective words/s
2024-06-24 02:34:40,173 EPOCH 5 - PROGRESS: at 14.15% examples, 476536 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:41,191 EPOCH 5 - PROGRESS: at 27.43% examples, 473401 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:42,216 EPOCH 5 - PROGRESS: at 40.69% examples, 471616 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:43,220 EPOCH 5 - PROGRESS: at 53.71% examples, 465781 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:44,228 EPOCH 5 - PROGRESS: at 65.01% examples, 459658 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:45,266 EPOCH 5 - PROGRESS: at 76.25% examples, 454960 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:46,271 EPOCH 5 - PROGRESS: at 90.01% examples, 452368 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:46,966 EPOCH 5: training on 3499793 raw words (3519557 effective words) took 7.8s, 451197 effective words/s
2024-06-24 02:34:47,976 EPOCH 6 - PROGRESS: at 14.19% examples, 477253 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:48,987 EPOCH 6 - PROGRESS: at 26.86% examples, 465478 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:50,025 EPOCH 6 - PROGRESS: at 39.39% examples, 454577 words/s, in_qsize 8, out_qsize 1
2024-06-24 02:34:51,028 EPOCH 6 - PROGRESS: at 52.90% examples, 458020 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:52,033 EPOCH 6 - PROGRESS: at 65.28% examples, 461574 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:53,070 EPOCH 6 - PROGRESS: at 76.79% examples, 458340 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:54,074 EPOCH 6 - PROGRESS: at 90.25% examples, 453891 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:54,706 EPOCH 6: training on 3499793 raw words (3519641 effective words) took 7.7s, 454954 effective words/s
2024-06-24 02:34:55,715 EPOCH 7 - PROGRESS: at 13.41% examples, 447769 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:34:56,747 EPOCH 7 - PROGRESS: at 25.76% examples, 441344 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:57,758 EPOCH 7 - PROGRESS: at 38.27% examples, 442628 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:58,760 EPOCH 7 - PROGRESS: at 51.83% examples, 449090 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:34:59,760 EPOCH 7 - PROGRESS: at 63.02% examples, 445094 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:00,775 EPOCH 7 - PROGRESS: at 74.79% examples, 447806 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:01,815 EPOCH 7 - PROGRESS: at 89.10% examples, 448221 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:02,505 EPOCH 7: training on 3499793 raw words (3519664 effective words) took 7.8s, 451552 effective words/s
2024-06-24 02:35:03,512 EPOCH 8 - PROGRESS: at 13.90% examples, 468864 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:35:04,523 EPOCH 8 - PROGRESS: at 26.87% examples, 466238 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:35:05,530 EPOCH 8 - PROGRESS: at 39.11% examples, 456427 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:06,542 EPOCH 8 - PROGRESS: at 52.65% examples, 458373 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:07,575 EPOCH 8 - PROGRESS: at 64.52% examples, 455454 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:08,586 EPOCH 8 - PROGRESS: at 75.47% examples, 451824 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:35:09,592 EPOCH 8 - PROGRESS: at 89.10% examples, 449552 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:35:10,315 EPOCH 8: training on 3499793 raw words (3519526 effective words) took 7.8s, 450897 effective words/s
2024-06-24 02:35:11,324 EPOCH 9 - PROGRESS: at 13.90% examples, 467616 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:12,332 EPOCH 9 - PROGRESS: at 26.58% examples, 461370 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:13,340 EPOCH 9 - PROGRESS: at 39.39% examples, 459523 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:35:14,390 EPOCH 9 - PROGRESS: at 53.22% examples, 458909 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:15,392 EPOCH 9 - PROGRESS: at 65.28% examples, 460615 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:16,394 EPOCH 9 - PROGRESS: at 77.00% examples, 461728 words/s, in_qsize 8, out_qsize 0
2024-06-24 02:35:17,417 EPOCH 9 - PROGRESS: at 91.70% examples, 459883 words/s, in_qsize 7, out_qsize 0
2024-06-24 02:35:17,955 EPOCH 9: training on 3499793 raw words (3519605 effective words) took 7.6s, 460907 effective words/s
2024-06-24 02:35:17,956 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195470 effective words) took 78.1s, 450693 effective words/s', 'datetime': '2024-06-24T02:35:17.955966', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 02:37:42,268 ==================================================
2024-06-24 02:37:42,268 Training BERT + Doc2Vec features with Dimension-512...
2024-06-24 02:37:43,236 Epoch [1/8], Batch [1/748], Loss: 1.5754
2024-06-24 02:38:32,076 Epoch [1/8], Batch [51/748], Loss: 1.4707
2024-06-24 02:39:21,842 Epoch [1/8], Batch [101/748], Loss: 1.2386
2024-06-24 02:40:11,974 Epoch [1/8], Batch [151/748], Loss: 1.3058
2024-06-24 02:41:02,384 Epoch [1/8], Batch [201/748], Loss: 1.1842
2024-06-24 02:41:52,781 Epoch [1/8], Batch [251/748], Loss: 0.9431
2024-06-24 02:42:43,144 Epoch [1/8], Batch [301/748], Loss: 0.9505
2024-06-24 02:43:33,736 Epoch [1/8], Batch [351/748], Loss: 1.1163
2024-06-24 02:44:24,102 Epoch [1/8], Batch [401/748], Loss: 0.9450
2024-06-24 02:45:14,515 Epoch [1/8], Batch [451/748], Loss: 1.0187
2024-06-24 02:46:04,851 Epoch [1/8], Batch [501/748], Loss: 0.9960
2024-06-24 02:46:55,087 Epoch [1/8], Batch [551/748], Loss: 1.1374
2024-06-24 02:47:45,432 Epoch [1/8], Batch [601/748], Loss: 0.9340
2024-06-24 02:48:35,717 Epoch [1/8], Batch [651/748], Loss: 1.0216
2024-06-24 02:49:26,028 Epoch [1/8], Batch [701/748], Loss: 0.7380
2024-06-24 02:50:12,939 Epoch 1/8, Train Loss: 1.0858, Train Accuracy: 0.5258
2024-06-24 02:51:32,102 Epoch 1/8, Val Loss: 0.9085, Val Accuracy: 0.5957
2024-06-24 02:51:33,108 Epoch [2/8], Batch [1/748], Loss: 0.7846
2024-06-24 02:52:23,327 Epoch [2/8], Batch [51/748], Loss: 0.8823
2024-06-24 02:53:13,648 Epoch [2/8], Batch [101/748], Loss: 0.6559
2024-06-24 02:54:04,105 Epoch [2/8], Batch [151/748], Loss: 0.8099
2024-06-24 02:54:54,528 Epoch [2/8], Batch [201/748], Loss: 0.6544
2024-06-24 02:55:44,823 Epoch [2/8], Batch [251/748], Loss: 0.9324
2024-06-24 02:56:35,217 Epoch [2/8], Batch [301/748], Loss: 0.7266
2024-06-24 02:57:25,536 Epoch [2/8], Batch [351/748], Loss: 0.7829
2024-06-24 02:58:15,692 Epoch [2/8], Batch [401/748], Loss: 0.9175
2024-06-24 02:59:06,052 Epoch [2/8], Batch [451/748], Loss: 0.9575
2024-06-24 02:59:56,094 Epoch [2/8], Batch [501/748], Loss: 0.7065
2024-06-24 03:00:46,197 Epoch [2/8], Batch [551/748], Loss: 0.9081
2024-06-24 03:01:36,611 Epoch [2/8], Batch [601/748], Loss: 0.7609
2024-06-24 03:02:26,843 Epoch [2/8], Batch [651/748], Loss: 0.8264
2024-06-24 03:03:17,213 Epoch [2/8], Batch [701/748], Loss: 0.6484
2024-06-24 03:04:04,090 Epoch 2/8, Train Loss: 0.8388, Train Accuracy: 0.6272
2024-06-24 03:05:23,348 Epoch 2/8, Val Loss: 0.8076, Val Accuracy: 0.6425
2024-06-24 03:05:24,369 Epoch [3/8], Batch [1/748], Loss: 0.9052
2024-06-24 03:06:14,643 Epoch [3/8], Batch [51/748], Loss: 0.8084
2024-06-24 03:07:04,803 Epoch [3/8], Batch [101/748], Loss: 0.8852
2024-06-24 03:07:55,171 Epoch [3/8], Batch [151/748], Loss: 1.0153
2024-06-24 03:08:45,616 Epoch [3/8], Batch [201/748], Loss: 0.6266
2024-06-24 03:09:35,879 Epoch [3/8], Batch [251/748], Loss: 1.2328
2024-06-24 03:10:26,327 Epoch [3/8], Batch [301/748], Loss: 0.6766
2024-06-24 03:11:16,585 Epoch [3/8], Batch [351/748], Loss: 0.6496
2024-06-24 03:12:06,821 Epoch [3/8], Batch [401/748], Loss: 0.6522
2024-06-24 03:12:57,239 Epoch [3/8], Batch [451/748], Loss: 0.5313
2024-06-24 03:13:47,702 Epoch [3/8], Batch [501/748], Loss: 0.9819
2024-06-24 03:14:37,989 Epoch [3/8], Batch [551/748], Loss: 0.6056
2024-06-24 03:15:28,259 Epoch [3/8], Batch [601/748], Loss: 0.6153
2024-06-24 03:16:18,646 Epoch [3/8], Batch [651/748], Loss: 0.6992
2024-06-24 03:17:08,896 Epoch [3/8], Batch [701/748], Loss: 0.7841
2024-06-24 03:17:55,808 Epoch 3/8, Train Loss: 0.7331, Train Accuracy: 0.6747
2024-06-24 03:19:14,873 Epoch 3/8, Val Loss: 0.7909, Val Accuracy: 0.6638
2024-06-24 03:19:15,862 Epoch [4/8], Batch [1/748], Loss: 0.7210
2024-06-24 03:20:05,801 Epoch [4/8], Batch [51/748], Loss: 0.9169
2024-06-24 03:20:56,200 Epoch [4/8], Batch [101/748], Loss: 0.5217
2024-06-24 03:21:46,709 Epoch [4/8], Batch [151/748], Loss: 0.5036
2024-06-24 03:22:37,134 Epoch [4/8], Batch [201/748], Loss: 0.3907
2024-06-24 03:23:27,556 Epoch [4/8], Batch [251/748], Loss: 0.7056
2024-06-24 03:24:17,753 Epoch [4/8], Batch [301/748], Loss: 0.5459
2024-06-24 03:25:08,039 Epoch [4/8], Batch [351/748], Loss: 0.5328
2024-06-24 03:25:58,272 Epoch [4/8], Batch [401/748], Loss: 0.8057
2024-06-24 03:26:48,561 Epoch [4/8], Batch [451/748], Loss: 0.8763
2024-06-24 03:27:38,923 Epoch [4/8], Batch [501/748], Loss: 0.6472
2024-06-24 03:28:29,141 Epoch [4/8], Batch [551/748], Loss: 0.4725
2024-06-24 03:29:19,374 Epoch [4/8], Batch [601/748], Loss: 0.5664
2024-06-24 03:30:09,640 Epoch [4/8], Batch [651/748], Loss: 0.5565
2024-06-24 03:30:59,833 Epoch [4/8], Batch [701/748], Loss: 0.5652
2024-06-24 03:31:46,695 Epoch 4/8, Train Loss: 0.6352, Train Accuracy: 0.7247
2024-06-24 03:33:05,916 Epoch 4/8, Val Loss: 0.8303, Val Accuracy: 0.6541
2024-06-24 03:33:06,925 Epoch [5/8], Batch [1/748], Loss: 0.6806
2024-06-24 03:33:56,951 Epoch [5/8], Batch [51/748], Loss: 0.6356
2024-06-24 03:34:47,110 Epoch [5/8], Batch [101/748], Loss: 0.6570
2024-06-24 03:35:37,548 Epoch [5/8], Batch [151/748], Loss: 0.8038
2024-06-24 03:36:27,848 Epoch [5/8], Batch [201/748], Loss: 0.5697
2024-06-24 03:37:18,126 Epoch [5/8], Batch [251/748], Loss: 0.5165
2024-06-24 03:38:08,565 Epoch [5/8], Batch [301/748], Loss: 0.5144
2024-06-24 03:38:58,912 Epoch [5/8], Batch [351/748], Loss: 0.4154
2024-06-24 03:39:49,150 Epoch [5/8], Batch [401/748], Loss: 0.4020
2024-06-24 03:40:39,274 Epoch [5/8], Batch [451/748], Loss: 0.4582
2024-06-24 03:41:29,560 Epoch [5/8], Batch [501/748], Loss: 0.8207
2024-06-24 03:42:19,682 Epoch [5/8], Batch [551/748], Loss: 0.9993
2024-06-24 03:43:10,183 Epoch [5/8], Batch [601/748], Loss: 0.5391
2024-06-24 03:44:00,493 Epoch [5/8], Batch [651/748], Loss: 0.4128
2024-06-24 03:44:50,922 Epoch [5/8], Batch [701/748], Loss: 0.3797
2024-06-24 03:45:37,808 Epoch 5/8, Train Loss: 0.5343, Train Accuracy: 0.7748
2024-06-24 03:46:56,842 Epoch 5/8, Val Loss: 0.8356, Val Accuracy: 0.6731
2024-06-24 03:46:57,828 Epoch [6/8], Batch [1/748], Loss: 0.4839
2024-06-24 03:47:48,044 Epoch [6/8], Batch [51/748], Loss: 0.3791
2024-06-24 03:48:38,236 Epoch [6/8], Batch [101/748], Loss: 0.2695
2024-06-24 03:49:28,665 Epoch [6/8], Batch [151/748], Loss: 0.2517
2024-06-24 03:50:18,902 Epoch [6/8], Batch [201/748], Loss: 0.4188
2024-06-24 03:51:09,170 Epoch [6/8], Batch [251/748], Loss: 0.4990
2024-06-24 03:51:59,447 Epoch [6/8], Batch [301/748], Loss: 0.2890
2024-06-24 03:52:49,758 Epoch [6/8], Batch [351/748], Loss: 0.5658
2024-06-24 03:53:40,357 Epoch [6/8], Batch [401/748], Loss: 0.5037
2024-06-24 03:54:30,598 Epoch [6/8], Batch [451/748], Loss: 0.4341
2024-06-24 03:55:21,078 Epoch [6/8], Batch [501/748], Loss: 0.2865
2024-06-24 03:56:11,212 Epoch [6/8], Batch [551/748], Loss: 0.4574
2024-06-24 03:57:01,410 Epoch [6/8], Batch [601/748], Loss: 0.6458
2024-06-24 03:57:51,705 Epoch [6/8], Batch [651/748], Loss: 0.5668
2024-06-24 03:58:41,842 Epoch [6/8], Batch [701/748], Loss: 0.4163
2024-06-24 03:59:28,737 Epoch 6/8, Train Loss: 0.4452, Train Accuracy: 0.8157
2024-06-24 04:00:47,744 Epoch 6/8, Val Loss: 0.9613, Val Accuracy: 0.6593
2024-06-24 04:00:48,747 Epoch [7/8], Batch [1/748], Loss: 0.3742
2024-06-24 04:01:38,920 Epoch [7/8], Batch [51/748], Loss: 0.3079
2024-06-24 04:02:29,201 Epoch [7/8], Batch [101/748], Loss: 0.4874
2024-06-24 04:03:19,521 Epoch [7/8], Batch [151/748], Loss: 0.2427
2024-06-24 04:04:09,851 Epoch [7/8], Batch [201/748], Loss: 0.3153
2024-06-24 04:05:00,062 Epoch [7/8], Batch [251/748], Loss: 0.3438
2024-06-24 04:05:50,266 Epoch [7/8], Batch [301/748], Loss: 0.2781
2024-06-24 04:06:40,594 Epoch [7/8], Batch [351/748], Loss: 0.2871
2024-06-24 04:07:30,850 Epoch [7/8], Batch [401/748], Loss: 0.5053
2024-06-24 04:08:21,098 Epoch [7/8], Batch [451/748], Loss: 0.2581
2024-06-24 04:09:11,356 Epoch [7/8], Batch [501/748], Loss: 0.3599
2024-06-24 04:10:01,645 Epoch [7/8], Batch [551/748], Loss: 0.3909
2024-06-24 04:10:51,760 Epoch [7/8], Batch [601/748], Loss: 0.3496
2024-06-24 04:11:42,093 Epoch [7/8], Batch [651/748], Loss: 0.3187
2024-06-24 04:12:32,282 Epoch [7/8], Batch [701/748], Loss: 0.2482
2024-06-24 04:13:19,282 Epoch 7/8, Train Loss: 0.3598, Train Accuracy: 0.8551
2024-06-24 04:14:38,356 Epoch 7/8, Val Loss: 1.0918, Val Accuracy: 0.6447
2024-06-24 04:14:39,375 Epoch [8/8], Batch [1/748], Loss: 0.2020
2024-06-24 04:15:29,649 Epoch [8/8], Batch [51/748], Loss: 0.3885
2024-06-24 04:16:20,025 Epoch [8/8], Batch [101/748], Loss: 0.3296
2024-06-24 04:17:10,297 Epoch [8/8], Batch [151/748], Loss: 0.3775
2024-06-24 04:18:00,700 Epoch [8/8], Batch [201/748], Loss: 0.4827
2024-06-24 04:18:50,980 Epoch [8/8], Batch [251/748], Loss: 0.3672
2024-06-24 04:19:41,283 Epoch [8/8], Batch [301/748], Loss: 0.3452
2024-06-24 04:20:31,555 Epoch [8/8], Batch [351/748], Loss: 0.4182
2024-06-24 04:21:22,045 Epoch [8/8], Batch [401/748], Loss: 0.2036
2024-06-24 04:22:12,150 Epoch [8/8], Batch [451/748], Loss: 0.3618
2024-06-24 04:23:02,400 Epoch [8/8], Batch [501/748], Loss: 0.4523
2024-06-24 04:23:52,780 Epoch [8/8], Batch [551/748], Loss: 0.3841
2024-06-24 04:24:43,203 Epoch [8/8], Batch [601/748], Loss: 0.2376
2024-06-24 04:25:33,662 Epoch [8/8], Batch [651/748], Loss: 0.6273
2024-06-24 04:26:23,897 Epoch [8/8], Batch [701/748], Loss: 0.2296
2024-06-24 04:27:10,907 Epoch 8/8, Train Loss: 0.2986, Train Accuracy: 0.8842
2024-06-24 04:28:29,984 Epoch 8/8, Val Loss: 1.0604, Val Accuracy: 0.6596
2024-06-24 04:28:29,986 Training finished!
2024-06-24 04:28:29,986 ==================================================
2024-06-24 04:28:53,528 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d256,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T04:28:53.528413', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 04:28:53,528 collecting all words and their counts
2024-06-24 04:28:53,528 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 04:28:53,761 PROGRESS: at example #10000, processed 1168609 words (5023730 words/s), 72028 word types, 0 tags
2024-06-24 04:28:54,011 PROGRESS: at example #20000, processed 2388715 words (4886164 words/s), 103898 word types, 0 tags
2024-06-24 04:28:54,236 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 04:28:54,236 Creating a fresh vocabulary
2024-06-24 04:28:54,657 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T04:28:54.657226', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 04:28:54,657 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T04:28:54.657433', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 04:28:55,385 deleting the raw counts dictionary of 133984 items
2024-06-24 04:28:55,386 sample=0.001 downsamples 6 most-common words
2024-06-24 04:28:55,386 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T04:28:55.386969', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 04:28:56,540 estimated required memory for 133984 words and 256 dimensions: 341397352 bytes
2024-06-24 04:28:56,540 resetting layer weights
2024-06-24 04:28:56,720 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T04:28:56.720774', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 04:28:57,727 EPOCH 0 - PROGRESS: at 16.25% examples, 558009 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:28:58,749 EPOCH 0 - PROGRESS: at 33.82% examples, 587048 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:28:59,761 EPOCH 0 - PROGRESS: at 51.03% examples, 592184 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:00,761 EPOCH 0 - PROGRESS: at 66.53% examples, 591293 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:01,790 EPOCH 0 - PROGRESS: at 81.68% examples, 587083 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:02,772 EPOCH 0: training on 3499793 raw words (3519717 effective words) took 6.0s, 581916 effective words/s
2024-06-24 04:29:03,783 EPOCH 1 - PROGRESS: at 19.01% examples, 654942 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:04,794 EPOCH 1 - PROGRESS: at 37.71% examples, 658336 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:05,798 EPOCH 1 - PROGRESS: at 55.40% examples, 647869 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:06,799 EPOCH 1 - PROGRESS: at 71.63% examples, 642845 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:07,806 EPOCH 1 - PROGRESS: at 89.98% examples, 638904 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:08,301 EPOCH 1: training on 3499793 raw words (3519637 effective words) took 5.5s, 637001 effective words/s
2024-06-24 04:29:09,304 EPOCH 2 - PROGRESS: at 18.73% examples, 649399 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:10,309 EPOCH 2 - PROGRESS: at 36.33% examples, 637911 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:11,324 EPOCH 2 - PROGRESS: at 53.22% examples, 618705 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:12,343 EPOCH 2 - PROGRESS: at 69.58% examples, 620736 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:13,347 EPOCH 2 - PROGRESS: at 86.02% examples, 615475 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:14,061 EPOCH 2: training on 3499793 raw words (3519486 effective words) took 5.8s, 611301 effective words/s
2024-06-24 04:29:15,101 EPOCH 3 - PROGRESS: at 19.08% examples, 636741 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:16,115 EPOCH 3 - PROGRESS: at 36.87% examples, 633478 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:17,122 EPOCH 3 - PROGRESS: at 53.71% examples, 617619 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:18,124 EPOCH 3 - PROGRESS: at 68.86% examples, 610267 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:19,156 EPOCH 3 - PROGRESS: at 85.46% examples, 605761 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:19,869 EPOCH 3: training on 3499793 raw words (3519644 effective words) took 5.8s, 606350 effective words/s
2024-06-24 04:29:20,876 EPOCH 4 - PROGRESS: at 19.37% examples, 666743 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:21,889 EPOCH 4 - PROGRESS: at 37.71% examples, 658758 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:22,904 EPOCH 4 - PROGRESS: at 55.91% examples, 652522 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:23,918 EPOCH 4 - PROGRESS: at 72.34% examples, 646766 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:24,920 EPOCH 4 - PROGRESS: at 91.41% examples, 644689 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:25,329 EPOCH 4: training on 3499793 raw words (3519614 effective words) took 5.5s, 645037 effective words/s
2024-06-24 04:29:26,338 EPOCH 5 - PROGRESS: at 18.23% examples, 625619 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:27,345 EPOCH 5 - PROGRESS: at 36.87% examples, 644826 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:28,357 EPOCH 5 - PROGRESS: at 54.62% examples, 637401 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:29,369 EPOCH 5 - PROGRESS: at 71.14% examples, 635644 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:30,396 EPOCH 5 - PROGRESS: at 88.84% examples, 628752 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:30,904 EPOCH 5: training on 3499793 raw words (3519515 effective words) took 5.6s, 631622 effective words/s
2024-06-24 04:29:31,936 EPOCH 6 - PROGRESS: at 18.47% examples, 621332 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:32,939 EPOCH 6 - PROGRESS: at 37.16% examples, 643848 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:33,961 EPOCH 6 - PROGRESS: at 55.40% examples, 641056 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:34,968 EPOCH 6 - PROGRESS: at 72.10% examples, 641866 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:35,969 EPOCH 6 - PROGRESS: at 89.98% examples, 634916 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:36,475 EPOCH 6: training on 3499793 raw words (3519577 effective words) took 5.6s, 631989 effective words/s
2024-06-24 04:29:37,488 EPOCH 7 - PROGRESS: at 18.26% examples, 624087 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:38,526 EPOCH 7 - PROGRESS: at 35.20% examples, 605261 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:39,545 EPOCH 7 - PROGRESS: at 52.65% examples, 602861 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:40,558 EPOCH 7 - PROGRESS: at 68.86% examples, 607179 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:41,570 EPOCH 7 - PROGRESS: at 85.46% examples, 605702 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:42,265 EPOCH 7: training on 3499793 raw words (3519506 effective words) took 5.8s, 608315 effective words/s
2024-06-24 04:29:43,268 EPOCH 8 - PROGRESS: at 18.73% examples, 649498 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:44,271 EPOCH 8 - PROGRESS: at 37.16% examples, 653324 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:45,273 EPOCH 8 - PROGRESS: at 55.11% examples, 648415 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:46,300 EPOCH 8 - PROGRESS: at 71.58% examples, 641522 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:47,302 EPOCH 8 - PROGRESS: at 88.41% examples, 630540 words/s, in_qsize 8, out_qsize 0
2024-06-24 04:29:47,836 EPOCH 8: training on 3499793 raw words (3519469 effective words) took 5.6s, 632154 effective words/s
2024-06-24 04:29:48,867 EPOCH 9 - PROGRESS: at 18.49% examples, 622491 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:49,885 EPOCH 9 - PROGRESS: at 36.87% examples, 635112 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:50,890 EPOCH 9 - PROGRESS: at 54.40% examples, 628845 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:51,909 EPOCH 9 - PROGRESS: at 70.11% examples, 620911 words/s, in_qsize 8, out_qsize 1
2024-06-24 04:29:52,933 EPOCH 9 - PROGRESS: at 87.02% examples, 615340 words/s, in_qsize 7, out_qsize 0
2024-06-24 04:29:53,554 EPOCH 9: training on 3499793 raw words (3519486 effective words) took 5.7s, 615873 effective words/s
2024-06-24 04:29:53,555 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195651 effective words) took 56.8s, 619268 effective words/s', 'datetime': '2024-06-24T04:29:53.555321', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 04:31:35,757 ==================================================
2024-06-24 04:31:35,758 Training BERT + Doc2Vec features with Dimension-256...
2024-06-24 04:31:36,717 Epoch [1/8], Batch [1/748], Loss: 1.6272
2024-06-24 04:32:25,612 Epoch [1/8], Batch [51/748], Loss: 1.5075
2024-06-24 04:33:15,840 Epoch [1/8], Batch [101/748], Loss: 1.2602
2024-06-24 04:34:06,062 Epoch [1/8], Batch [151/748], Loss: 1.1223
2024-06-24 04:34:56,227 Epoch [1/8], Batch [201/748], Loss: 1.0228
2024-06-24 04:35:46,728 Epoch [1/8], Batch [251/748], Loss: 1.1873
2024-06-24 04:36:37,024 Epoch [1/8], Batch [301/748], Loss: 1.0507
2024-06-24 04:37:27,403 Epoch [1/8], Batch [351/748], Loss: 1.1723
2024-06-24 04:38:17,700 Epoch [1/8], Batch [401/748], Loss: 0.9819
2024-06-24 04:39:07,996 Epoch [1/8], Batch [451/748], Loss: 0.9230
2024-06-24 04:39:58,294 Epoch [1/8], Batch [501/748], Loss: 0.9056
2024-06-24 04:40:48,587 Epoch [1/8], Batch [551/748], Loss: 0.8903
2024-06-24 04:41:38,899 Epoch [1/8], Batch [601/748], Loss: 0.7872
2024-06-24 04:42:29,055 Epoch [1/8], Batch [651/748], Loss: 0.7081
2024-06-24 04:43:19,585 Epoch [1/8], Batch [701/748], Loss: 1.0328
2024-06-24 04:44:06,661 Epoch 1/8, Train Loss: 1.0321, Train Accuracy: 0.5607
2024-06-24 04:45:25,746 Epoch 1/8, Val Loss: 0.8772, Val Accuracy: 0.6141
2024-06-24 04:45:26,740 Epoch [2/8], Batch [1/748], Loss: 0.6688
2024-06-24 04:46:16,933 Epoch [2/8], Batch [51/748], Loss: 1.0255
2024-06-24 04:47:07,249 Epoch [2/8], Batch [101/748], Loss: 0.9808
2024-06-24 04:47:57,536 Epoch [2/8], Batch [151/748], Loss: 0.9515
2024-06-24 04:48:47,650 Epoch [2/8], Batch [201/748], Loss: 0.7996
2024-06-24 04:49:37,882 Epoch [2/8], Batch [251/748], Loss: 1.0407
2024-06-24 04:50:28,357 Epoch [2/8], Batch [301/748], Loss: 0.9274
2024-06-24 04:51:18,755 Epoch [2/8], Batch [351/748], Loss: 0.7360
2024-06-24 04:52:08,988 Epoch [2/8], Batch [401/748], Loss: 0.7655
2024-06-24 04:52:59,104 Epoch [2/8], Batch [451/748], Loss: 0.8689
2024-06-24 04:53:49,420 Epoch [2/8], Batch [501/748], Loss: 0.7726
2024-06-24 04:54:39,705 Epoch [2/8], Batch [551/748], Loss: 0.7105
2024-06-24 04:55:30,157 Epoch [2/8], Batch [601/748], Loss: 0.7177
2024-06-24 04:56:20,483 Epoch [2/8], Batch [651/748], Loss: 0.8108
2024-06-24 04:57:10,800 Epoch [2/8], Batch [701/748], Loss: 0.6888
2024-06-24 04:57:57,674 Epoch 2/8, Train Loss: 0.7817, Train Accuracy: 0.6523
2024-06-24 04:59:16,826 Epoch 2/8, Val Loss: 0.8437, Val Accuracy: 0.6200
2024-06-24 04:59:17,823 Epoch [3/8], Batch [1/748], Loss: 0.6038
2024-06-24 05:00:08,112 Epoch [3/8], Batch [51/748], Loss: 0.4915
2024-06-24 05:00:58,295 Epoch [3/8], Batch [101/748], Loss: 0.5277
2024-06-24 05:01:48,692 Epoch [3/8], Batch [151/748], Loss: 0.5708
2024-06-24 05:02:38,990 Epoch [3/8], Batch [201/748], Loss: 0.7627
2024-06-24 05:03:29,569 Epoch [3/8], Batch [251/748], Loss: 0.5454
2024-06-24 05:04:19,811 Epoch [3/8], Batch [301/748], Loss: 0.8587
2024-06-24 05:05:10,095 Epoch [3/8], Batch [351/748], Loss: 0.7050
2024-06-24 05:06:00,382 Epoch [3/8], Batch [401/748], Loss: 0.6547
2024-06-24 05:06:50,722 Epoch [3/8], Batch [451/748], Loss: 0.8402
2024-06-24 05:07:41,005 Epoch [3/8], Batch [501/748], Loss: 0.6846
2024-06-24 05:08:31,166 Epoch [3/8], Batch [551/748], Loss: 0.6629
2024-06-24 05:09:21,545 Epoch [3/8], Batch [601/748], Loss: 0.6029
2024-06-24 05:10:11,826 Epoch [3/8], Batch [651/748], Loss: 0.8336
2024-06-24 05:11:02,285 Epoch [3/8], Batch [701/748], Loss: 0.5188
2024-06-24 05:11:49,218 Epoch 3/8, Train Loss: 0.6706, Train Accuracy: 0.7057
2024-06-24 05:13:08,391 Epoch 3/8, Val Loss: 0.8160, Val Accuracy: 0.6571
2024-06-24 05:13:09,393 Epoch [4/8], Batch [1/748], Loss: 0.6831
2024-06-24 05:13:59,553 Epoch [4/8], Batch [51/748], Loss: 0.5322
2024-06-24 05:14:49,915 Epoch [4/8], Batch [101/748], Loss: 0.3535
2024-06-24 05:15:40,273 Epoch [4/8], Batch [151/748], Loss: 0.5474
2024-06-24 05:16:30,551 Epoch [4/8], Batch [201/748], Loss: 0.5104
2024-06-24 05:17:20,800 Epoch [4/8], Batch [251/748], Loss: 0.4349
2024-06-24 05:18:11,227 Epoch [4/8], Batch [301/748], Loss: 0.4150
2024-06-24 05:19:01,590 Epoch [4/8], Batch [351/748], Loss: 0.5370
2024-06-24 05:19:51,900 Epoch [4/8], Batch [401/748], Loss: 0.3938
2024-06-24 05:20:42,108 Epoch [4/8], Batch [451/748], Loss: 0.4890
2024-06-24 05:21:32,372 Epoch [4/8], Batch [501/748], Loss: 0.6283
2024-06-24 05:22:22,767 Epoch [4/8], Batch [551/748], Loss: 0.4797
2024-06-24 05:23:13,339 Epoch [4/8], Batch [601/748], Loss: 0.7319
2024-06-24 05:24:03,620 Epoch [4/8], Batch [651/748], Loss: 0.6546
2024-06-24 05:24:53,981 Epoch [4/8], Batch [701/748], Loss: 0.6087
2024-06-24 05:25:41,154 Epoch 4/8, Train Loss: 0.5558, Train Accuracy: 0.7631
2024-06-24 05:27:00,217 Epoch 4/8, Val Loss: 0.8040, Val Accuracy: 0.6790
2024-06-24 05:27:01,218 Epoch [5/8], Batch [1/748], Loss: 0.4370
2024-06-24 05:27:51,426 Epoch [5/8], Batch [51/748], Loss: 0.3917
2024-06-24 05:28:41,619 Epoch [5/8], Batch [101/748], Loss: 0.6091
2024-06-24 05:29:32,004 Epoch [5/8], Batch [151/748], Loss: 0.3685
2024-06-24 05:30:22,383 Epoch [5/8], Batch [201/748], Loss: 0.4744
2024-06-24 05:31:12,763 Epoch [5/8], Batch [251/748], Loss: 0.5217
2024-06-24 05:32:03,103 Epoch [5/8], Batch [301/748], Loss: 0.4142
2024-06-24 05:32:53,450 Epoch [5/8], Batch [351/748], Loss: 0.5574
2024-06-24 05:33:43,700 Epoch [5/8], Batch [401/748], Loss: 0.5419
2024-06-24 05:34:33,954 Epoch [5/8], Batch [451/748], Loss: 0.6255
2024-06-24 05:35:24,278 Epoch [5/8], Batch [501/748], Loss: 0.4866
2024-06-24 05:36:14,484 Epoch [5/8], Batch [551/748], Loss: 0.3997
2024-06-24 05:37:05,007 Epoch [5/8], Batch [601/748], Loss: 0.5844
2024-06-24 05:37:55,466 Epoch [5/8], Batch [651/748], Loss: 0.4169
2024-06-24 05:38:45,749 Epoch [5/8], Batch [701/748], Loss: 0.3078
2024-06-24 05:39:32,892 Epoch 5/8, Train Loss: 0.4574, Train Accuracy: 0.8099
2024-06-24 05:40:51,944 Epoch 5/8, Val Loss: 0.9239, Val Accuracy: 0.6499
2024-06-24 05:40:52,960 Epoch [6/8], Batch [1/748], Loss: 0.5317
2024-06-24 05:41:43,269 Epoch [6/8], Batch [51/748], Loss: 0.2391
2024-06-24 05:42:33,547 Epoch [6/8], Batch [101/748], Loss: 0.6139
2024-06-24 05:43:23,985 Epoch [6/8], Batch [151/748], Loss: 0.3360
2024-06-24 05:44:14,465 Epoch [6/8], Batch [201/748], Loss: 0.6120
2024-06-24 05:45:04,891 Epoch [6/8], Batch [251/748], Loss: 0.2633
2024-06-24 05:45:55,361 Epoch [6/8], Batch [301/748], Loss: 0.3059
2024-06-24 05:46:45,773 Epoch [6/8], Batch [351/748], Loss: 0.3243
2024-06-24 05:47:36,116 Epoch [6/8], Batch [401/748], Loss: 0.6195
2024-06-24 05:48:26,451 Epoch [6/8], Batch [451/748], Loss: 0.4276
2024-06-24 05:49:16,657 Epoch [6/8], Batch [501/748], Loss: 0.4735
2024-06-24 05:50:06,873 Epoch [6/8], Batch [551/748], Loss: 0.4578
2024-06-24 05:50:57,104 Epoch [6/8], Batch [601/748], Loss: 0.4102
2024-06-24 05:51:47,487 Epoch [6/8], Batch [651/748], Loss: 0.5033
2024-06-24 05:52:37,876 Epoch [6/8], Batch [701/748], Loss: 0.1809
2024-06-24 05:53:24,886 Epoch 6/8, Train Loss: 0.3621, Train Accuracy: 0.8560
2024-06-24 05:54:44,199 Epoch 6/8, Val Loss: 1.0025, Val Accuracy: 0.6497
2024-06-24 05:54:45,193 Epoch [7/8], Batch [1/748], Loss: 0.1252
2024-06-24 05:55:35,450 Epoch [7/8], Batch [51/748], Loss: 0.2850
2024-06-24 05:56:25,763 Epoch [7/8], Batch [101/748], Loss: 0.2522
2024-06-24 05:57:16,175 Epoch [7/8], Batch [151/748], Loss: 0.1881
2024-06-24 05:58:06,559 Epoch [7/8], Batch [201/748], Loss: 0.3614
2024-06-24 05:58:57,011 Epoch [7/8], Batch [251/748], Loss: 0.2110
2024-06-24 05:59:47,387 Epoch [7/8], Batch [301/748], Loss: 0.2008
2024-06-24 06:00:37,724 Epoch [7/8], Batch [351/748], Loss: 0.3540
2024-06-24 06:01:28,012 Epoch [7/8], Batch [401/748], Loss: 0.2277
2024-06-24 06:02:18,170 Epoch [7/8], Batch [451/748], Loss: 0.4606
2024-06-24 06:03:08,569 Epoch [7/8], Batch [501/748], Loss: 0.2452
2024-06-24 06:03:58,941 Epoch [7/8], Batch [551/748], Loss: 0.1117
2024-06-24 06:04:49,266 Epoch [7/8], Batch [601/748], Loss: 0.3404
2024-06-24 06:05:39,671 Epoch [7/8], Batch [651/748], Loss: 0.3257
2024-06-24 06:06:30,001 Epoch [7/8], Batch [701/748], Loss: 0.3682
2024-06-24 06:07:16,911 Epoch 7/8, Train Loss: 0.2851, Train Accuracy: 0.8899
2024-06-24 06:08:35,961 Epoch 7/8, Val Loss: 1.0708, Val Accuracy: 0.6499
2024-06-24 06:08:36,947 Epoch [8/8], Batch [1/748], Loss: 0.3641
2024-06-24 06:09:27,148 Epoch [8/8], Batch [51/748], Loss: 0.2434
2024-06-24 06:10:17,383 Epoch [8/8], Batch [101/748], Loss: 0.0802
2024-06-24 06:11:07,691 Epoch [8/8], Batch [151/748], Loss: 0.2196
2024-06-24 06:11:58,140 Epoch [8/8], Batch [201/748], Loss: 0.1028
2024-06-24 06:12:48,629 Epoch [8/8], Batch [251/748], Loss: 0.1811
2024-06-24 06:13:39,195 Epoch [8/8], Batch [301/748], Loss: 0.0853
2024-06-24 06:14:29,553 Epoch [8/8], Batch [351/748], Loss: 0.2738
2024-06-24 06:15:19,929 Epoch [8/8], Batch [401/748], Loss: 0.1399
2024-06-24 06:16:10,089 Epoch [8/8], Batch [451/748], Loss: 0.1346
2024-06-24 06:17:00,360 Epoch [8/8], Batch [501/748], Loss: 0.4698
2024-06-24 06:17:50,697 Epoch [8/8], Batch [551/748], Loss: 0.2371
2024-06-24 06:18:40,984 Epoch [8/8], Batch [601/748], Loss: 0.2422
2024-06-24 06:19:31,278 Epoch [8/8], Batch [651/748], Loss: 0.2707
2024-06-24 06:20:21,579 Epoch [8/8], Batch [701/748], Loss: 0.1540
2024-06-24 06:21:08,414 Epoch 8/8, Train Loss: 0.2187, Train Accuracy: 0.9204
2024-06-24 06:22:27,511 Epoch 8/8, Val Loss: 1.2398, Val Accuracy: 0.6430
2024-06-24 06:22:27,513 Training finished!
2024-06-24 06:22:27,513 ==================================================
2024-06-24 06:22:50,906 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d64,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T06:22:50.906823', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 06:22:50,907 collecting all words and their counts
2024-06-24 06:22:50,907 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 06:22:51,133 PROGRESS: at example #10000, processed 1168609 words (5157367 words/s), 72028 word types, 0 tags
2024-06-24 06:22:51,383 PROGRESS: at example #20000, processed 2388715 words (4882555 words/s), 103898 word types, 0 tags
2024-06-24 06:22:51,609 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 06:22:51,609 Creating a fresh vocabulary
2024-06-24 06:22:52,020 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T06:22:52.020211', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 06:22:52,020 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T06:22:52.020431', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 06:22:52,739 deleting the raw counts dictionary of 133984 items
2024-06-24 06:22:52,741 sample=0.001 downsamples 6 most-common words
2024-06-24 06:22:52,741 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T06:22:52.741738', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 06:22:53,897 estimated required memory for 133984 words and 64 dimensions: 135594088 bytes
2024-06-24 06:22:53,897 resetting layer weights
2024-06-24 06:22:53,943 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 64 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T06:22:53.943052', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 06:22:54,969 EPOCH 0 - PROGRESS: at 20.45% examples, 694434 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:22:55,972 EPOCH 0 - PROGRESS: at 41.00% examples, 715321 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:22:56,984 EPOCH 0 - PROGRESS: at 62.75% examples, 736738 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:22:58,015 EPOCH 0 - PROGRESS: at 82.68% examples, 738399 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:22:58,848 EPOCH 0: training on 3499793 raw words (3519484 effective words) took 4.9s, 718069 effective words/s
2024-06-24 06:22:59,873 EPOCH 1 - PROGRESS: at 19.01% examples, 646087 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:00,875 EPOCH 1 - PROGRESS: at 39.10% examples, 681320 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:01,886 EPOCH 1 - PROGRESS: at 58.32% examples, 681542 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:02,892 EPOCH 1 - PROGRESS: at 76.50% examples, 689415 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:03,892 EPOCH 1 - PROGRESS: at 93.92% examples, 661447 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:04,195 EPOCH 1: training on 3499793 raw words (3519389 effective words) took 5.3s, 658688 effective words/s
2024-06-24 06:23:05,208 EPOCH 2 - PROGRESS: at 17.46% examples, 593970 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:06,209 EPOCH 2 - PROGRESS: at 35.49% examples, 621115 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:07,211 EPOCH 2 - PROGRESS: at 55.40% examples, 649879 words/s, in_qsize 6, out_qsize 1
2024-06-24 06:23:08,225 EPOCH 2 - PROGRESS: at 73.03% examples, 657045 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:09,233 EPOCH 2 - PROGRESS: at 93.11% examples, 656317 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:09,536 EPOCH 2: training on 3499793 raw words (3519552 effective words) took 5.3s, 659352 effective words/s
2024-06-24 06:23:10,544 EPOCH 3 - PROGRESS: at 19.86% examples, 686437 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:11,547 EPOCH 3 - PROGRESS: at 41.65% examples, 731281 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:12,570 EPOCH 3 - PROGRESS: at 62.25% examples, 731817 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:13,588 EPOCH 3 - PROGRESS: at 82.27% examples, 739430 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:14,427 EPOCH 3: training on 3499793 raw words (3519433 effective words) took 4.9s, 720071 effective words/s
2024-06-24 06:23:15,440 EPOCH 4 - PROGRESS: at 19.37% examples, 663105 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:16,446 EPOCH 4 - PROGRESS: at 39.67% examples, 693707 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:17,465 EPOCH 4 - PROGRESS: at 58.32% examples, 681274 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:18,478 EPOCH 4 - PROGRESS: at 74.25% examples, 665944 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:19,499 EPOCH 4 - PROGRESS: at 94.03% examples, 657823 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:19,774 EPOCH 4: training on 3499793 raw words (3519594 effective words) took 5.3s, 658584 effective words/s
2024-06-24 06:23:20,780 EPOCH 5 - PROGRESS: at 20.74% examples, 717838 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:21,781 EPOCH 5 - PROGRESS: at 43.38% examples, 762962 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:22,783 EPOCH 5 - PROGRESS: at 63.24% examples, 751011 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:23,785 EPOCH 5 - PROGRESS: at 80.52% examples, 734636 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:24,683 EPOCH 5: training on 3499793 raw words (3519617 effective words) took 4.9s, 717517 effective words/s
2024-06-24 06:23:25,720 EPOCH 6 - PROGRESS: at 19.01% examples, 638437 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:26,722 EPOCH 6 - PROGRESS: at 38.54% examples, 667692 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:27,736 EPOCH 6 - PROGRESS: at 58.32% examples, 678070 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:28,755 EPOCH 6 - PROGRESS: at 75.99% examples, 679725 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:29,760 EPOCH 6 - PROGRESS: at 94.61% examples, 661199 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:29,997 EPOCH 6: training on 3499793 raw words (3519482 effective words) took 5.3s, 662818 effective words/s
2024-06-24 06:23:31,004 EPOCH 7 - PROGRESS: at 20.45% examples, 706848 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:32,021 EPOCH 7 - PROGRESS: at 42.56% examples, 741649 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:33,052 EPOCH 7 - PROGRESS: at 65.01% examples, 762354 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:34,070 EPOCH 7 - PROGRESS: at 85.46% examples, 757770 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:34,679 EPOCH 7: training on 3499793 raw words (3519524 effective words) took 4.7s, 752229 effective words/s
2024-06-24 06:23:35,685 EPOCH 8 - PROGRESS: at 18.73% examples, 647696 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:36,690 EPOCH 8 - PROGRESS: at 37.71% examples, 661654 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:37,715 EPOCH 8 - PROGRESS: at 57.12% examples, 668594 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:38,740 EPOCH 8 - PROGRESS: at 74.25% examples, 664359 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:39,746 EPOCH 8 - PROGRESS: at 96.87% examples, 676311 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:39,857 EPOCH 8: training on 3499793 raw words (3519505 effective words) took 5.2s, 680065 effective words/s
2024-06-24 06:23:40,864 EPOCH 9 - PROGRESS: at 19.01% examples, 658034 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:41,873 EPOCH 9 - PROGRESS: at 41.24% examples, 724874 words/s, in_qsize 8, out_qsize 0
2024-06-24 06:23:42,878 EPOCH 9 - PROGRESS: at 62.25% examples, 735120 words/s, in_qsize 7, out_qsize 1
2024-06-24 06:23:43,888 EPOCH 9 - PROGRESS: at 80.82% examples, 733552 words/s, in_qsize 7, out_qsize 0
2024-06-24 06:23:44,866 EPOCH 9: training on 3499793 raw words (3519544 effective words) took 5.0s, 703303 effective words/s
2024-06-24 06:23:44,866 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195124 effective words) took 50.9s, 691139 effective words/s', 'datetime': '2024-06-24T06:23:44.866656', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 06:24:55,288 ==================================================
2024-06-24 06:24:55,288 Training BERT + Doc2Vec features with Dimension-64...
2024-06-24 06:24:56,261 Epoch [1/8], Batch [1/748], Loss: 1.5395
2024-06-24 06:25:45,377 Epoch [1/8], Batch [51/748], Loss: 1.5820
2024-06-24 06:26:35,297 Epoch [1/8], Batch [101/748], Loss: 1.2143
2024-06-24 06:27:25,608 Epoch [1/8], Batch [151/748], Loss: 1.2006
2024-06-24 06:28:15,849 Epoch [1/8], Batch [201/748], Loss: 0.9366
2024-06-24 06:29:06,259 Epoch [1/8], Batch [251/748], Loss: 1.1262
2024-06-24 06:29:56,612 Epoch [1/8], Batch [301/748], Loss: 0.7699
2024-06-24 06:30:47,082 Epoch [1/8], Batch [351/748], Loss: 0.9457
2024-06-24 06:31:37,363 Epoch [1/8], Batch [401/748], Loss: 0.7543
2024-06-24 06:32:27,902 Epoch [1/8], Batch [451/748], Loss: 0.9632
2024-06-24 06:33:18,321 Epoch [1/8], Batch [501/748], Loss: 0.9748
2024-06-24 06:34:08,596 Epoch [1/8], Batch [551/748], Loss: 0.8060
2024-06-24 06:34:58,888 Epoch [1/8], Batch [601/748], Loss: 0.9552
2024-06-24 06:35:49,211 Epoch [1/8], Batch [651/748], Loss: 0.8615
2024-06-24 06:36:39,436 Epoch [1/8], Batch [701/748], Loss: 0.9256
2024-06-24 06:37:26,413 Epoch 1/8, Train Loss: 1.0458, Train Accuracy: 0.5507
2024-06-24 06:38:45,506 Epoch 1/8, Val Loss: 0.8562, Val Accuracy: 0.6188
2024-06-24 06:38:46,526 Epoch [2/8], Batch [1/748], Loss: 0.7732
2024-06-24 06:39:36,688 Epoch [2/8], Batch [51/748], Loss: 0.6762
2024-06-24 06:40:26,947 Epoch [2/8], Batch [101/748], Loss: 0.6446
2024-06-24 06:41:17,336 Epoch [2/8], Batch [151/748], Loss: 0.9003
2024-06-24 06:42:07,703 Epoch [2/8], Batch [201/748], Loss: 0.9777
2024-06-24 06:42:57,904 Epoch [2/8], Batch [251/748], Loss: 0.6434
2024-06-24 06:43:48,252 Epoch [2/8], Batch [301/748], Loss: 0.8005
2024-06-24 06:44:38,606 Epoch [2/8], Batch [351/748], Loss: 0.8446
2024-06-24 06:45:28,973 Epoch [2/8], Batch [401/748], Loss: 0.7068
2024-06-24 06:46:19,303 Epoch [2/8], Batch [451/748], Loss: 0.7727
2024-06-24 06:47:09,558 Epoch [2/8], Batch [501/748], Loss: 0.9816
2024-06-24 06:47:59,825 Epoch [2/8], Batch [551/748], Loss: 0.7986
2024-06-24 06:48:50,097 Epoch [2/8], Batch [601/748], Loss: 0.6491
2024-06-24 06:49:40,559 Epoch [2/8], Batch [651/748], Loss: 0.7206
2024-06-24 06:50:30,768 Epoch [2/8], Batch [701/748], Loss: 0.7097
2024-06-24 06:51:17,722 Epoch 2/8, Train Loss: 0.7923, Train Accuracy: 0.6480
2024-06-24 06:52:36,730 Epoch 2/8, Val Loss: 0.9112, Val Accuracy: 0.6022
2024-06-24 06:52:37,735 Epoch [3/8], Batch [1/748], Loss: 0.6943
2024-06-24 06:53:27,981 Epoch [3/8], Batch [51/748], Loss: 0.8143
2024-06-24 06:54:18,305 Epoch [3/8], Batch [101/748], Loss: 0.8103
2024-06-24 06:55:08,800 Epoch [3/8], Batch [151/748], Loss: 0.6240
2024-06-24 06:55:59,072 Epoch [3/8], Batch [201/748], Loss: 0.8976
2024-06-24 06:56:49,404 Epoch [3/8], Batch [251/748], Loss: 0.8068
2024-06-24 06:57:39,873 Epoch [3/8], Batch [301/748], Loss: 0.4279
2024-06-24 06:58:30,266 Epoch [3/8], Batch [351/748], Loss: 0.7357
2024-06-24 06:59:20,651 Epoch [3/8], Batch [401/748], Loss: 0.5604
2024-06-24 07:00:10,996 Epoch [3/8], Batch [451/748], Loss: 0.7803
2024-06-24 07:01:01,247 Epoch [3/8], Batch [501/748], Loss: 0.5723
2024-06-24 07:01:51,662 Epoch [3/8], Batch [551/748], Loss: 0.5924
2024-06-24 07:02:41,724 Epoch [3/8], Batch [601/748], Loss: 0.6361
2024-06-24 07:03:32,164 Epoch [3/8], Batch [651/748], Loss: 0.6307
2024-06-24 07:04:22,574 Epoch [3/8], Batch [701/748], Loss: 0.6820
2024-06-24 07:05:09,568 Epoch 3/8, Train Loss: 0.6918, Train Accuracy: 0.6919
2024-06-24 07:06:28,593 Epoch 3/8, Val Loss: 0.8085, Val Accuracy: 0.6472
2024-06-24 07:06:29,586 Epoch [4/8], Batch [1/748], Loss: 0.5955
2024-06-24 07:07:19,930 Epoch [4/8], Batch [51/748], Loss: 0.4927
2024-06-24 07:08:10,257 Epoch [4/8], Batch [101/748], Loss: 0.9205
2024-06-24 07:09:00,496 Epoch [4/8], Batch [151/748], Loss: 0.5383
2024-06-24 07:09:50,959 Epoch [4/8], Batch [201/748], Loss: 0.6428
2024-06-24 07:10:41,206 Epoch [4/8], Batch [251/748], Loss: 0.6543
2024-06-24 07:11:31,597 Epoch [4/8], Batch [301/748], Loss: 0.8918
2024-06-24 07:12:21,859 Epoch [4/8], Batch [351/748], Loss: 0.7927
2024-06-24 07:13:12,377 Epoch [4/8], Batch [401/748], Loss: 0.6632
2024-06-24 07:14:02,729 Epoch [4/8], Batch [451/748], Loss: 0.5028
2024-06-24 07:14:52,998 Epoch [4/8], Batch [501/748], Loss: 0.6900
2024-06-24 07:15:43,294 Epoch [4/8], Batch [551/748], Loss: 0.5969
2024-06-24 07:16:33,475 Epoch [4/8], Batch [601/748], Loss: 0.3706
2024-06-24 07:17:23,727 Epoch [4/8], Batch [651/748], Loss: 0.7909
2024-06-24 07:18:14,115 Epoch [4/8], Batch [701/748], Loss: 0.6118
2024-06-24 07:19:01,015 Epoch 4/8, Train Loss: 0.5945, Train Accuracy: 0.7334
2024-06-24 07:20:20,045 Epoch 4/8, Val Loss: 0.8641, Val Accuracy: 0.6404
2024-06-24 07:20:21,048 Epoch [5/8], Batch [1/748], Loss: 0.4853
2024-06-24 07:21:11,345 Epoch [5/8], Batch [51/748], Loss: 0.7063
2024-06-24 07:22:01,519 Epoch [5/8], Batch [101/748], Loss: 0.6000
2024-06-24 07:22:51,745 Epoch [5/8], Batch [151/748], Loss: 0.5495
2024-06-24 07:23:42,266 Epoch [5/8], Batch [201/748], Loss: 0.3870
2024-06-24 07:24:32,677 Epoch [5/8], Batch [251/748], Loss: 0.5970
2024-06-24 07:25:23,015 Epoch [5/8], Batch [301/748], Loss: 0.4558
2024-06-24 07:26:13,277 Epoch [5/8], Batch [351/748], Loss: 0.4069
2024-06-24 07:27:03,651 Epoch [5/8], Batch [401/748], Loss: 0.5231
2024-06-24 07:27:53,940 Epoch [5/8], Batch [451/748], Loss: 0.4960
2024-06-24 07:28:44,203 Epoch [5/8], Batch [501/748], Loss: 0.6134
2024-06-24 07:29:34,631 Epoch [5/8], Batch [551/748], Loss: 0.6562
2024-06-24 07:30:24,877 Epoch [5/8], Batch [601/748], Loss: 0.5229
2024-06-24 07:31:15,205 Epoch [5/8], Batch [651/748], Loss: 0.3769
2024-06-24 07:32:05,659 Epoch [5/8], Batch [701/748], Loss: 0.4559
2024-06-24 07:32:52,571 Epoch 5/8, Train Loss: 0.5028, Train Accuracy: 0.7798
2024-06-24 07:34:11,661 Epoch 5/8, Val Loss: 0.9340, Val Accuracy: 0.6450
2024-06-24 07:34:12,665 Epoch [6/8], Batch [1/748], Loss: 0.3181
2024-06-24 07:35:02,987 Epoch [6/8], Batch [51/748], Loss: 0.4472
2024-06-24 07:35:53,152 Epoch [6/8], Batch [101/748], Loss: 0.3764
2024-06-24 07:36:43,602 Epoch [6/8], Batch [151/748], Loss: 0.3908
2024-06-24 07:37:33,943 Epoch [6/8], Batch [201/748], Loss: 0.2478
2024-06-24 07:38:24,299 Epoch [6/8], Batch [251/748], Loss: 0.3212
2024-06-24 07:39:14,709 Epoch [6/8], Batch [301/748], Loss: 0.2145
2024-06-24 07:40:05,075 Epoch [6/8], Batch [351/748], Loss: 0.5980
2024-06-24 07:40:55,300 Epoch [6/8], Batch [401/748], Loss: 0.2587
2024-06-24 07:41:45,582 Epoch [6/8], Batch [451/748], Loss: 0.4290
2024-06-24 07:42:36,035 Epoch [6/8], Batch [501/748], Loss: 0.6172
2024-06-24 07:43:26,398 Epoch [6/8], Batch [551/748], Loss: 0.4139
2024-06-24 07:44:16,640 Epoch [6/8], Batch [601/748], Loss: 0.2942
2024-06-24 07:45:07,009 Epoch [6/8], Batch [651/748], Loss: 0.4747
2024-06-24 07:45:57,407 Epoch [6/8], Batch [701/748], Loss: 0.2782
2024-06-24 07:46:44,349 Epoch 6/8, Train Loss: 0.4246, Train Accuracy: 0.8137
2024-06-24 07:48:03,419 Epoch 6/8, Val Loss: 0.9030, Val Accuracy: 0.6785
2024-06-24 07:48:04,411 Epoch [7/8], Batch [1/748], Loss: 0.2663
2024-06-24 07:48:54,523 Epoch [7/8], Batch [51/748], Loss: 0.2297
2024-06-24 07:49:44,946 Epoch [7/8], Batch [101/748], Loss: 0.1271
2024-06-24 07:50:35,020 Epoch [7/8], Batch [151/748], Loss: 0.2814
2024-06-24 07:51:25,361 Epoch [7/8], Batch [201/748], Loss: 0.5584
2024-06-24 07:52:15,705 Epoch [7/8], Batch [251/748], Loss: 0.3369
2024-06-24 07:53:06,185 Epoch [7/8], Batch [301/748], Loss: 0.4025
2024-06-24 07:53:56,577 Epoch [7/8], Batch [351/748], Loss: 0.4312
2024-06-24 07:54:46,925 Epoch [7/8], Batch [401/748], Loss: 0.3015
2024-06-24 07:55:37,226 Epoch [7/8], Batch [451/748], Loss: 0.2331
2024-06-24 07:56:27,529 Epoch [7/8], Batch [501/748], Loss: 0.3374
2024-06-24 07:57:17,929 Epoch [7/8], Batch [551/748], Loss: 0.5616
2024-06-24 07:58:08,324 Epoch [7/8], Batch [601/748], Loss: 0.3490
2024-06-24 07:58:58,706 Epoch [7/8], Batch [651/748], Loss: 0.3181
2024-06-24 07:59:49,036 Epoch [7/8], Batch [701/748], Loss: 0.5442
2024-06-24 08:00:35,957 Epoch 7/8, Train Loss: 0.3649, Train Accuracy: 0.8453
2024-06-24 08:01:54,983 Epoch 7/8, Val Loss: 1.0213, Val Accuracy: 0.6623
2024-06-24 08:01:55,996 Epoch [8/8], Batch [1/748], Loss: 0.2984
2024-06-24 08:02:46,238 Epoch [8/8], Batch [51/748], Loss: 0.2163
2024-06-24 08:03:36,741 Epoch [8/8], Batch [101/748], Loss: 0.1940
2024-06-24 08:04:27,124 Epoch [8/8], Batch [151/748], Loss: 0.3228
2024-06-24 08:05:17,459 Epoch [8/8], Batch [201/748], Loss: 0.2107
2024-06-24 08:06:07,838 Epoch [8/8], Batch [251/748], Loss: 0.3182
2024-06-24 08:06:58,132 Epoch [8/8], Batch [301/748], Loss: 0.3921
2024-06-24 08:07:48,581 Epoch [8/8], Batch [351/748], Loss: 0.3713
2024-06-24 08:08:38,977 Epoch [8/8], Batch [401/748], Loss: 0.2831
2024-06-24 08:09:29,217 Epoch [8/8], Batch [451/748], Loss: 0.3050
2024-06-24 08:10:19,361 Epoch [8/8], Batch [501/748], Loss: 0.4940
2024-06-24 08:11:09,523 Epoch [8/8], Batch [551/748], Loss: 0.1784
2024-06-24 08:11:59,825 Epoch [8/8], Batch [601/748], Loss: 0.2960
2024-06-24 08:12:49,976 Epoch [8/8], Batch [651/748], Loss: 0.3868
2024-06-24 08:13:40,471 Epoch [8/8], Batch [701/748], Loss: 0.1573
2024-06-24 08:14:27,369 Epoch 8/8, Train Loss: 0.3033, Train Accuracy: 0.8765
2024-06-24 08:15:46,466 Epoch 8/8, Val Loss: 1.1182, Val Accuracy: 0.6504
2024-06-24 08:15:46,468 Training finished!
2024-06-24 08:15:46,468 ==================================================
2024-06-24 08:16:09,887 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d8,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T08:16:09.886984', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 08:16:09,887 collecting all words and their counts
2024-06-24 08:16:09,887 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 08:16:10,114 PROGRESS: at example #10000, processed 1168609 words (5140868 words/s), 72028 word types, 0 tags
2024-06-24 08:16:10,365 PROGRESS: at example #20000, processed 2388715 words (4875575 words/s), 103898 word types, 0 tags
2024-06-24 08:16:10,589 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 08:16:10,589 Creating a fresh vocabulary
2024-06-24 08:16:11,002 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T08:16:11.002028', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 08:16:11,002 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T08:16:11.002232', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 08:16:11,720 deleting the raw counts dictionary of 133984 items
2024-06-24 08:16:11,722 sample=0.001 downsamples 6 most-common words
2024-06-24 08:16:11,722 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T08:16:11.722403', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 08:16:12,869 estimated required memory for 133984 words and 8 dimensions: 75568136 bytes
2024-06-24 08:16:12,869 resetting layer weights
2024-06-24 08:16:12,875 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 8 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T08:16:12.875138', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 08:16:13,895 EPOCH 0 - PROGRESS: at 18.23% examples, 619992 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:14,920 EPOCH 0 - PROGRESS: at 35.20% examples, 606808 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:15,959 EPOCH 0 - PROGRESS: at 53.15% examples, 606624 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:16,968 EPOCH 0 - PROGRESS: at 68.86% examples, 605762 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:17,968 EPOCH 0 - PROGRESS: at 85.19% examples, 604054 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:18,800 EPOCH 0: training on 3499793 raw words (3519474 effective words) took 5.9s, 594420 effective words/s
2024-06-24 08:16:19,813 EPOCH 1 - PROGRESS: at 18.23% examples, 623956 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:20,842 EPOCH 1 - PROGRESS: at 37.71% examples, 651838 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:21,852 EPOCH 1 - PROGRESS: at 58.52% examples, 681771 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:22,865 EPOCH 1 - PROGRESS: at 78.45% examples, 705364 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:23,883 EPOCH 1 - PROGRESS: at 98.48% examples, 683986 words/s, in_qsize 5, out_qsize 0
2024-06-24 08:16:23,936 EPOCH 1: training on 3499793 raw words (3519416 effective words) took 5.1s, 685827 effective words/s
2024-06-24 08:16:24,943 EPOCH 2 - PROGRESS: at 18.49% examples, 637010 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:25,944 EPOCH 2 - PROGRESS: at 38.26% examples, 672490 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:26,949 EPOCH 2 - PROGRESS: at 57.81% examples, 680460 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:27,952 EPOCH 2 - PROGRESS: at 76.79% examples, 696551 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:28,960 EPOCH 2 - PROGRESS: at 96.87% examples, 682064 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:29,081 EPOCH 2: training on 3499793 raw words (3519574 effective words) took 5.1s, 684499 effective words/s
2024-06-24 08:16:30,119 EPOCH 3 - PROGRESS: at 19.01% examples, 637047 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:31,123 EPOCH 3 - PROGRESS: at 38.54% examples, 666338 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:32,125 EPOCH 3 - PROGRESS: at 58.64% examples, 683135 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:33,138 EPOCH 3 - PROGRESS: at 77.47% examples, 696835 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:34,175 EPOCH 3 - PROGRESS: at 96.46% examples, 670643 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:34,306 EPOCH 3: training on 3499793 raw words (3519663 effective words) took 5.2s, 674013 effective words/s
2024-06-24 08:16:35,316 EPOCH 4 - PROGRESS: at 17.46% examples, 595543 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:36,321 EPOCH 4 - PROGRESS: at 34.95% examples, 610511 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:37,339 EPOCH 4 - PROGRESS: at 55.40% examples, 646150 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:38,348 EPOCH 4 - PROGRESS: at 72.80% examples, 652655 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:39,365 EPOCH 4 - PROGRESS: at 90.96% examples, 641573 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:39,811 EPOCH 4: training on 3499793 raw words (3519552 effective words) took 5.5s, 639645 effective words/s
2024-06-24 08:16:40,824 EPOCH 5 - PROGRESS: at 18.00% examples, 613890 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:41,826 EPOCH 5 - PROGRESS: at 35.48% examples, 621116 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:42,826 EPOCH 5 - PROGRESS: at 54.18% examples, 633748 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:43,850 EPOCH 5 - PROGRESS: at 73.01% examples, 655644 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:44,879 EPOCH 5 - PROGRESS: at 92.40% examples, 648534 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:45,251 EPOCH 5: training on 3499793 raw words (3519653 effective words) took 5.4s, 647470 effective words/s
2024-06-24 08:16:46,266 EPOCH 6 - PROGRESS: at 18.00% examples, 612527 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:47,298 EPOCH 6 - PROGRESS: at 35.75% examples, 616012 words/s, in_qsize 6, out_qsize 1
2024-06-24 08:16:48,328 EPOCH 6 - PROGRESS: at 55.11% examples, 633741 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:49,355 EPOCH 6 - PROGRESS: at 73.03% examples, 645141 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:50,377 EPOCH 6 - PROGRESS: at 90.59% examples, 631240 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:50,871 EPOCH 6: training on 3499793 raw words (3519584 effective words) took 5.6s, 626550 effective words/s
2024-06-24 08:16:51,878 EPOCH 7 - PROGRESS: at 18.23% examples, 627317 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:52,894 EPOCH 7 - PROGRESS: at 38.82% examples, 677628 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:53,897 EPOCH 7 - PROGRESS: at 59.94% examples, 703850 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:54,902 EPOCH 7 - PROGRESS: at 78.01% examples, 706292 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:55,933 EPOCH 7 - PROGRESS: at 98.48% examples, 686912 words/s, in_qsize 5, out_qsize 0
2024-06-24 08:16:55,963 EPOCH 7: training on 3499793 raw words (3519577 effective words) took 5.1s, 691668 effective words/s
2024-06-24 08:16:56,967 EPOCH 8 - PROGRESS: at 19.62% examples, 679105 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:16:57,984 EPOCH 8 - PROGRESS: at 39.94% examples, 697954 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:16:59,007 EPOCH 8 - PROGRESS: at 59.45% examples, 693089 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:17:00,017 EPOCH 8 - PROGRESS: at 75.73% examples, 680246 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:17:01,031 EPOCH 8 - PROGRESS: at 91.70% examples, 644481 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:17:01,521 EPOCH 8: training on 3499793 raw words (3519551 effective words) took 5.6s, 633656 effective words/s
2024-06-24 08:17:02,533 EPOCH 9 - PROGRESS: at 16.80% examples, 574812 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:17:03,541 EPOCH 9 - PROGRESS: at 32.69% examples, 569757 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:17:04,555 EPOCH 9 - PROGRESS: at 50.26% examples, 583528 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:17:05,579 EPOCH 9 - PROGRESS: at 68.78% examples, 610905 words/s, in_qsize 7, out_qsize 0
2024-06-24 08:17:06,580 EPOCH 9 - PROGRESS: at 86.41% examples, 616032 words/s, in_qsize 8, out_qsize 0
2024-06-24 08:17:07,277 EPOCH 9: training on 3499793 raw words (3519675 effective words) took 5.8s, 611855 effective words/s
2024-06-24 08:17:07,277 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195719 effective words) took 54.4s, 646951 effective words/s', 'datetime': '2024-06-24T08:17:07.277826', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 08:18:03,556 ==================================================
2024-06-24 08:18:03,556 Training BERT + Doc2Vec features with Dimension-8...
2024-06-24 08:18:04,526 Epoch [1/8], Batch [1/748], Loss: 1.6040
2024-06-24 08:18:53,599 Epoch [1/8], Batch [51/748], Loss: 1.5805
2024-06-24 08:19:43,667 Epoch [1/8], Batch [101/748], Loss: 1.4645
2024-06-24 08:20:33,866 Epoch [1/8], Batch [151/748], Loss: 1.3439
2024-06-24 08:21:24,265 Epoch [1/8], Batch [201/748], Loss: 1.2280
2024-06-24 08:22:14,778 Epoch [1/8], Batch [251/748], Loss: 1.0744
2024-06-24 08:23:05,237 Epoch [1/8], Batch [301/748], Loss: 1.0379
2024-06-24 08:23:55,544 Epoch [1/8], Batch [351/748], Loss: 1.0630
2024-06-24 08:24:46,013 Epoch [1/8], Batch [401/748], Loss: 1.0333
2024-06-24 08:25:36,142 Epoch [1/8], Batch [451/748], Loss: 0.9927
2024-06-24 08:26:26,522 Epoch [1/8], Batch [501/748], Loss: 1.0870
2024-06-24 08:27:16,886 Epoch [1/8], Batch [551/748], Loss: 0.9136
2024-06-24 08:28:07,207 Epoch [1/8], Batch [601/748], Loss: 1.0993
2024-06-24 08:28:57,535 Epoch [1/8], Batch [651/748], Loss: 0.9431
2024-06-24 08:29:47,821 Epoch [1/8], Batch [701/748], Loss: 0.6433
2024-06-24 08:30:34,644 Epoch 1/8, Train Loss: 1.1015, Train Accuracy: 0.5258
2024-06-24 08:31:53,858 Epoch 1/8, Val Loss: 0.9309, Val Accuracy: 0.6024
2024-06-24 08:31:54,881 Epoch [2/8], Batch [1/748], Loss: 0.6561
2024-06-24 08:32:45,038 Epoch [2/8], Batch [51/748], Loss: 0.7643
2024-06-24 08:33:35,517 Epoch [2/8], Batch [101/748], Loss: 0.7313
2024-06-24 08:34:25,783 Epoch [2/8], Batch [151/748], Loss: 0.6545
2024-06-24 08:35:16,205 Epoch [2/8], Batch [201/748], Loss: 0.8537
2024-06-24 08:36:06,453 Epoch [2/8], Batch [251/748], Loss: 0.8657
2024-06-24 08:36:56,852 Epoch [2/8], Batch [301/748], Loss: 0.9966
2024-06-24 08:37:47,230 Epoch [2/8], Batch [351/748], Loss: 0.6982
2024-06-24 08:38:37,516 Epoch [2/8], Batch [401/748], Loss: 0.8028
2024-06-24 08:39:27,869 Epoch [2/8], Batch [451/748], Loss: 0.8656
2024-06-24 08:40:18,126 Epoch [2/8], Batch [501/748], Loss: 0.6698
2024-06-24 08:41:08,657 Epoch [2/8], Batch [551/748], Loss: 1.2602
2024-06-24 08:41:58,929 Epoch [2/8], Batch [601/748], Loss: 0.8942
2024-06-24 08:42:49,331 Epoch [2/8], Batch [651/748], Loss: 0.7609
2024-06-24 08:43:39,715 Epoch [2/8], Batch [701/748], Loss: 0.6503
2024-06-24 08:44:26,668 Epoch 2/8, Train Loss: 0.8182, Train Accuracy: 0.6450
2024-06-24 08:45:45,814 Epoch 2/8, Val Loss: 0.7909, Val Accuracy: 0.6653
2024-06-24 08:45:46,828 Epoch [3/8], Batch [1/748], Loss: 0.8212
2024-06-24 08:46:37,053 Epoch [3/8], Batch [51/748], Loss: 0.5579
2024-06-24 08:47:27,540 Epoch [3/8], Batch [101/748], Loss: 0.5876
2024-06-24 08:48:17,800 Epoch [3/8], Batch [151/748], Loss: 0.8735
2024-06-24 08:49:08,107 Epoch [3/8], Batch [201/748], Loss: 0.4811
2024-06-24 08:49:58,448 Epoch [3/8], Batch [251/748], Loss: 0.4946
2024-06-24 08:50:48,702 Epoch [3/8], Batch [301/748], Loss: 0.6358
2024-06-24 08:51:39,035 Epoch [3/8], Batch [351/748], Loss: 0.8744
2024-06-24 08:52:29,275 Epoch [3/8], Batch [401/748], Loss: 0.5487
2024-06-24 08:53:19,738 Epoch [3/8], Batch [451/748], Loss: 0.6159
2024-06-24 08:54:10,126 Epoch [3/8], Batch [501/748], Loss: 0.7711
2024-06-24 08:55:00,411 Epoch [3/8], Batch [551/748], Loss: 0.5147
2024-06-24 08:55:50,750 Epoch [3/8], Batch [601/748], Loss: 0.6871
2024-06-24 08:56:41,071 Epoch [3/8], Batch [651/748], Loss: 0.6332
2024-06-24 08:57:31,511 Epoch [3/8], Batch [701/748], Loss: 0.7825
2024-06-24 08:58:18,478 Epoch 3/8, Train Loss: 0.6928, Train Accuracy: 0.7044
2024-06-24 08:59:37,562 Epoch 3/8, Val Loss: 0.8410, Val Accuracy: 0.6629
2024-06-24 08:59:38,577 Epoch [4/8], Batch [1/748], Loss: 0.7186
2024-06-24 09:00:28,768 Epoch [4/8], Batch [51/748], Loss: 0.5966
2024-06-24 09:01:19,084 Epoch [4/8], Batch [101/748], Loss: 0.6360
2024-06-24 09:02:09,371 Epoch [4/8], Batch [151/748], Loss: 0.3498
2024-06-24 09:02:59,688 Epoch [4/8], Batch [201/748], Loss: 0.5494
2024-06-24 09:03:49,994 Epoch [4/8], Batch [251/748], Loss: 0.4601
2024-06-24 09:04:40,333 Epoch [4/8], Batch [301/748], Loss: 0.7179
2024-06-24 09:05:30,691 Epoch [4/8], Batch [351/748], Loss: 0.6348
2024-06-24 09:06:20,858 Epoch [4/8], Batch [401/748], Loss: 0.3730
2024-06-24 09:07:11,238 Epoch [4/8], Batch [451/748], Loss: 0.6885
2024-06-24 09:08:01,400 Epoch [4/8], Batch [501/748], Loss: 0.6517
2024-06-24 09:08:51,838 Epoch [4/8], Batch [551/748], Loss: 0.4227
2024-06-24 09:09:42,284 Epoch [4/8], Batch [601/748], Loss: 0.7287
2024-06-24 09:10:32,703 Epoch [4/8], Batch [651/748], Loss: 0.8122
2024-06-24 09:11:23,116 Epoch [4/8], Batch [701/748], Loss: 0.4466
2024-06-24 09:12:10,032 Epoch 4/8, Train Loss: 0.5781, Train Accuracy: 0.7619
2024-06-24 09:13:29,403 Epoch 4/8, Val Loss: 0.8185, Val Accuracy: 0.6788
2024-06-24 09:13:30,398 Epoch [5/8], Batch [1/748], Loss: 0.6150
2024-06-24 09:14:20,610 Epoch [5/8], Batch [51/748], Loss: 0.2573
2024-06-24 09:15:10,897 Epoch [5/8], Batch [101/748], Loss: 0.5053
2024-06-24 09:16:01,220 Epoch [5/8], Batch [151/748], Loss: 0.3649
2024-06-24 09:16:51,545 Epoch [5/8], Batch [201/748], Loss: 0.6381
2024-06-24 09:17:41,773 Epoch [5/8], Batch [251/748], Loss: 0.5172
2024-06-24 09:18:32,152 Epoch [5/8], Batch [301/748], Loss: 0.4544
2024-06-24 09:19:22,515 Epoch [5/8], Batch [351/748], Loss: 0.4693
2024-06-24 09:20:12,777 Epoch [5/8], Batch [401/748], Loss: 0.4440
2024-06-24 09:21:03,149 Epoch [5/8], Batch [451/748], Loss: 0.4610
2024-06-24 09:21:53,422 Epoch [5/8], Batch [501/748], Loss: 0.5625
2024-06-24 09:22:43,822 Epoch [5/8], Batch [551/748], Loss: 0.4810
2024-06-24 09:23:34,144 Epoch [5/8], Batch [601/748], Loss: 0.4006
2024-06-24 09:24:24,462 Epoch [5/8], Batch [651/748], Loss: 0.5766
2024-06-24 09:25:14,844 Epoch [5/8], Batch [701/748], Loss: 0.5197
2024-06-24 09:26:01,788 Epoch 5/8, Train Loss: 0.4656, Train Accuracy: 0.8099
2024-06-24 09:27:20,953 Epoch 5/8, Val Loss: 0.8836, Val Accuracy: 0.6713
2024-06-24 09:27:21,960 Epoch [6/8], Batch [1/748], Loss: 0.4342
2024-06-24 09:28:12,058 Epoch [6/8], Batch [51/748], Loss: 0.2055
2024-06-24 09:29:02,342 Epoch [6/8], Batch [101/748], Loss: 0.5205
2024-06-24 09:29:52,868 Epoch [6/8], Batch [151/748], Loss: 0.4722
2024-06-24 09:30:43,162 Epoch [6/8], Batch [201/748], Loss: 0.5565
2024-06-24 09:31:33,433 Epoch [6/8], Batch [251/748], Loss: 0.2915
2024-06-24 09:32:23,727 Epoch [6/8], Batch [301/748], Loss: 0.1863
2024-06-24 09:33:14,134 Epoch [6/8], Batch [351/748], Loss: 0.3184
2024-06-24 09:34:04,302 Epoch [6/8], Batch [401/748], Loss: 0.3403
2024-06-24 09:34:54,575 Epoch [6/8], Batch [451/748], Loss: 0.4164
2024-06-24 09:35:44,974 Epoch [6/8], Batch [501/748], Loss: 0.4714
2024-06-24 09:36:35,408 Epoch [6/8], Batch [551/748], Loss: 0.2999
2024-06-24 09:37:26,210 Epoch [6/8], Batch [601/748], Loss: 0.3871
2024-06-24 09:38:16,524 Epoch [6/8], Batch [651/748], Loss: 0.4286
2024-06-24 09:39:06,859 Epoch [6/8], Batch [701/748], Loss: 0.3573
2024-06-24 09:39:53,769 Epoch 6/8, Train Loss: 0.3724, Train Accuracy: 0.8529
2024-06-24 09:41:13,124 Epoch 6/8, Val Loss: 0.9619, Val Accuracy: 0.6710
2024-06-24 09:41:14,122 Epoch [7/8], Batch [1/748], Loss: 0.2359
2024-06-24 09:42:04,259 Epoch [7/8], Batch [51/748], Loss: 0.2600
2024-06-24 09:42:54,649 Epoch [7/8], Batch [101/748], Loss: 0.2051
2024-06-24 09:43:45,268 Epoch [7/8], Batch [151/748], Loss: 0.4059
2024-06-24 09:44:35,492 Epoch [7/8], Batch [201/748], Loss: 0.2566
2024-06-24 09:45:25,859 Epoch [7/8], Batch [251/748], Loss: 0.3602
2024-06-24 09:46:16,399 Epoch [7/8], Batch [301/748], Loss: 0.1645
2024-06-24 09:47:06,871 Epoch [7/8], Batch [351/748], Loss: 0.2782
2024-06-24 09:47:57,349 Epoch [7/8], Batch [401/748], Loss: 0.3036
2024-06-24 09:48:47,687 Epoch [7/8], Batch [451/748], Loss: 0.2260
2024-06-24 09:49:38,380 Epoch [7/8], Batch [501/748], Loss: 0.4165
2024-06-24 09:50:28,730 Epoch [7/8], Batch [551/748], Loss: 0.3470
2024-06-24 09:51:19,025 Epoch [7/8], Batch [601/748], Loss: 0.2737
2024-06-24 09:52:09,465 Epoch [7/8], Batch [651/748], Loss: 0.1926
2024-06-24 09:53:00,033 Epoch [7/8], Batch [701/748], Loss: 0.2148
2024-06-24 09:53:47,065 Epoch 7/8, Train Loss: 0.2969, Train Accuracy: 0.8852
2024-06-24 09:55:06,223 Epoch 7/8, Val Loss: 1.1381, Val Accuracy: 0.6492
2024-06-24 09:55:07,224 Epoch [8/8], Batch [1/748], Loss: 0.2352
2024-06-24 09:55:57,471 Epoch [8/8], Batch [51/748], Loss: 0.1495
2024-06-24 09:56:47,770 Epoch [8/8], Batch [101/748], Loss: 0.2164
2024-06-24 09:57:38,215 Epoch [8/8], Batch [151/748], Loss: 0.1892
2024-06-24 09:58:28,522 Epoch [8/8], Batch [201/748], Loss: 0.1196
2024-06-24 09:59:18,877 Epoch [8/8], Batch [251/748], Loss: 0.0501
2024-06-24 10:00:09,106 Epoch [8/8], Batch [301/748], Loss: 0.1617
2024-06-24 10:00:59,524 Epoch [8/8], Batch [351/748], Loss: 0.0829
2024-06-24 10:01:50,224 Epoch [8/8], Batch [401/748], Loss: 0.0799
2024-06-24 10:02:40,478 Epoch [8/8], Batch [451/748], Loss: 0.1704
2024-06-24 10:03:30,878 Epoch [8/8], Batch [501/748], Loss: 0.1473
2024-06-24 10:04:21,210 Epoch [8/8], Batch [551/748], Loss: 0.2111
2024-06-24 10:05:11,837 Epoch [8/8], Batch [601/748], Loss: 0.2430
2024-06-24 10:06:02,155 Epoch [8/8], Batch [651/748], Loss: 0.3006
2024-06-24 10:06:52,471 Epoch [8/8], Batch [701/748], Loss: 0.1323
2024-06-24 10:07:39,571 Epoch 8/8, Train Loss: 0.2384, Train Accuracy: 0.9137
2024-06-24 10:08:58,676 Epoch 8/8, Val Loss: 1.0421, Val Accuracy: 0.6942
2024-06-24 10:08:58,678 Training finished!
2024-06-24 10:08:58,679 ==================================================
2024-06-24 10:09:23,108 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d4096,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T10:09:23.107957', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 10:09:23,108 collecting all words and their counts
2024-06-24 10:09:23,108 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 10:09:23,335 PROGRESS: at example #10000, processed 1168609 words (5151310 words/s), 72028 word types, 0 tags
2024-06-24 10:09:23,583 PROGRESS: at example #20000, processed 2388715 words (4910180 words/s), 103898 word types, 0 tags
2024-06-24 10:09:23,833 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 10:09:23,834 Creating a fresh vocabulary
2024-06-24 10:09:24,253 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T10:09:24.253214', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 10:09:24,253 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T10:09:24.253418', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 10:09:24,956 deleting the raw counts dictionary of 133984 items
2024-06-24 10:09:24,958 sample=0.001 downsamples 6 most-common words
2024-06-24 10:09:24,958 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T10:09:24.958419', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 10:09:26,104 estimated required memory for 133984 words and 4096 dimensions: 4457462632 bytes
2024-06-24 10:09:26,104 resetting layer weights
2024-06-24 10:09:28,921 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 4096 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T10:09:28.921673', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 10:09:29,933 EPOCH 0 - PROGRESS: at 1.19% examples, 39900 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:31,056 EPOCH 0 - PROGRESS: at 3.42% examples, 51782 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:32,165 EPOCH 0 - PROGRESS: at 6.10% examples, 64868 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:33,175 EPOCH 0 - PROGRESS: at 8.95% examples, 70586 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:34,204 EPOCH 0 - PROGRESS: at 11.72% examples, 73865 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:35,436 EPOCH 0 - PROGRESS: at 14.66% examples, 76759 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:36,650 EPOCH 0 - PROGRESS: at 18.00% examples, 80241 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:37,745 EPOCH 0 - PROGRESS: at 21.28% examples, 83858 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:38,809 EPOCH 0 - PROGRESS: at 23.77% examples, 83882 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:39,863 EPOCH 0 - PROGRESS: at 26.86% examples, 85845 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:40,977 EPOCH 0 - PROGRESS: at 29.93% examples, 87033 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:42,018 EPOCH 0 - PROGRESS: at 32.69% examples, 87740 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:43,082 EPOCH 0 - PROGRESS: at 35.48% examples, 88223 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:44,254 EPOCH 0 - PROGRESS: at 38.26% examples, 87984 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:45,283 EPOCH 0 - PROGRESS: at 41.10% examples, 88557 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:46,415 EPOCH 0 - PROGRESS: at 44.32% examples, 89123 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:09:47,474 EPOCH 0 - PROGRESS: at 46.74% examples, 88891 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:09:48,700 EPOCH 0 - PROGRESS: at 50.26% examples, 89430 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:49,749 EPOCH 0 - PROGRESS: at 53.46% examples, 90206 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:09:50,923 EPOCH 0 - PROGRESS: at 56.18% examples, 90381 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:52,003 EPOCH 0 - PROGRESS: at 59.11% examples, 90907 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:53,074 EPOCH 0 - PROGRESS: at 61.75% examples, 91005 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:54,098 EPOCH 0 - PROGRESS: at 64.54% examples, 91653 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:09:55,150 EPOCH 0 - PROGRESS: at 66.75% examples, 91402 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:09:56,208 EPOCH 0 - PROGRESS: at 69.35% examples, 91524 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:57,212 EPOCH 0 - PROGRESS: at 72.10% examples, 92153 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:09:58,278 EPOCH 0 - PROGRESS: at 74.25% examples, 91838 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:09:59,497 EPOCH 0 - PROGRESS: at 77.23% examples, 92086 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:00,572 EPOCH 0 - PROGRESS: at 79.99% examples, 92416 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:01,593 EPOCH 0 - PROGRESS: at 83.53% examples, 92572 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:02,601 EPOCH 0 - PROGRESS: at 86.74% examples, 92770 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:03,606 EPOCH 0 - PROGRESS: at 90.25% examples, 92966 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:04,795 EPOCH 0 - PROGRESS: at 94.31% examples, 93236 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:06,014 EPOCH 0 - PROGRESS: at 98.15% examples, 93413 words/s, in_qsize 6, out_qsize 0
2024-06-24 10:10:06,418 EPOCH 0: training on 3499793 raw words (3519495 effective words) took 37.5s, 93874 effective words/s
2024-06-24 10:10:07,481 EPOCH 1 - PROGRESS: at 2.72% examples, 85183 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:08,586 EPOCH 1 - PROGRESS: at 6.18% examples, 97152 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:09,638 EPOCH 1 - PROGRESS: at 9.25% examples, 96419 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:10,805 EPOCH 1 - PROGRESS: at 12.93% examples, 98106 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:11,864 EPOCH 1 - PROGRESS: at 16.01% examples, 101046 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:12,968 EPOCH 1 - PROGRESS: at 18.84% examples, 99258 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:14,130 EPOCH 1 - PROGRESS: at 22.12% examples, 99848 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:15,167 EPOCH 1 - PROGRESS: at 24.61% examples, 98232 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:16,363 EPOCH 1 - PROGRESS: at 27.99% examples, 98470 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:17,459 EPOCH 1 - PROGRESS: at 30.78% examples, 97753 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:18,466 EPOCH 1 - PROGRESS: at 33.82% examples, 98717 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:19,613 EPOCH 1 - PROGRESS: at 36.60% examples, 97707 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:20,695 EPOCH 1 - PROGRESS: at 39.94% examples, 98700 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:21,752 EPOCH 1 - PROGRESS: at 43.38% examples, 99720 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:22,779 EPOCH 1 - PROGRESS: at 45.89% examples, 98962 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:23,963 EPOCH 1 - PROGRESS: at 48.87% examples, 97980 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:25,187 EPOCH 1 - PROGRESS: at 52.39% examples, 97973 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:26,223 EPOCH 1 - PROGRESS: at 55.11% examples, 98396 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:27,284 EPOCH 1 - PROGRESS: at 58.06% examples, 98653 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:28,365 EPOCH 1 - PROGRESS: at 60.72% examples, 98344 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:29,377 EPOCH 1 - PROGRESS: at 63.53% examples, 98770 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:30,507 EPOCH 1 - PROGRESS: at 66.53% examples, 99112 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:31,521 EPOCH 1 - PROGRESS: at 69.35% examples, 99489 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:32,548 EPOCH 1 - PROGRESS: at 71.84% examples, 99392 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:33,551 EPOCH 1 - PROGRESS: at 74.01% examples, 98999 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:34,711 EPOCH 1 - PROGRESS: at 77.00% examples, 99165 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:35,813 EPOCH 1 - PROGRESS: at 79.99% examples, 99510 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:36,845 EPOCH 1 - PROGRESS: at 83.53% examples, 99404 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:38,045 EPOCH 1 - PROGRESS: at 87.39% examples, 99429 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:39,129 EPOCH 1 - PROGRESS: at 91.41% examples, 99497 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:40,179 EPOCH 1 - PROGRESS: at 94.87% examples, 99667 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:41,215 EPOCH 1 - PROGRESS: at 98.48% examples, 99865 words/s, in_qsize 5, out_qsize 0
2024-06-24 10:10:41,594 EPOCH 1: training on 3499793 raw words (3519598 effective words) took 35.2s, 100073 effective words/s
2024-06-24 10:10:42,724 EPOCH 2 - PROGRESS: at 2.72% examples, 80091 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:43,822 EPOCH 2 - PROGRESS: at 5.82% examples, 89961 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:44,926 EPOCH 2 - PROGRESS: at 9.50% examples, 96122 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:46,043 EPOCH 2 - PROGRESS: at 12.88% examples, 96717 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:47,155 EPOCH 2 - PROGRESS: at 15.69% examples, 97131 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:48,184 EPOCH 2 - PROGRESS: at 18.73% examples, 98639 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:49,361 EPOCH 2 - PROGRESS: at 21.84% examples, 97839 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:50,446 EPOCH 2 - PROGRESS: at 25.18% examples, 99336 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:51,543 EPOCH 2 - PROGRESS: at 27.99% examples, 98419 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:52,602 EPOCH 2 - PROGRESS: at 31.05% examples, 98942 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:53,647 EPOCH 2 - PROGRESS: at 34.10% examples, 99496 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:54,772 EPOCH 2 - PROGRESS: at 37.16% examples, 99339 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:10:55,953 EPOCH 2 - PROGRESS: at 40.45% examples, 99521 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:56,977 EPOCH 2 - PROGRESS: at 43.67% examples, 100054 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:58,140 EPOCH 2 - PROGRESS: at 46.82% examples, 99677 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:10:59,254 EPOCH 2 - PROGRESS: at 50.26% examples, 100162 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:00,336 EPOCH 2 - PROGRESS: at 53.46% examples, 100247 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:01,338 EPOCH 2 - PROGRESS: at 55.95% examples, 100212 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:02,352 EPOCH 2 - PROGRESS: at 58.64% examples, 100124 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:03,498 EPOCH 2 - PROGRESS: at 61.50% examples, 99900 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:04,572 EPOCH 2 - PROGRESS: at 64.29% examples, 99997 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:05,687 EPOCH 2 - PROGRESS: at 66.99% examples, 99922 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:06,737 EPOCH 2 - PROGRESS: at 69.83% examples, 100127 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:07,809 EPOCH 2 - PROGRESS: at 72.54% examples, 100198 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:08,817 EPOCH 2 - PROGRESS: at 75.02% examples, 100140 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:09,885 EPOCH 2 - PROGRESS: at 77.23% examples, 99523 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:10,943 EPOCH 2 - PROGRESS: at 79.99% examples, 99666 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:12,056 EPOCH 2 - PROGRESS: at 83.53% examples, 99286 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:13,085 EPOCH 2 - PROGRESS: at 87.10% examples, 99537 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:14,152 EPOCH 2 - PROGRESS: at 90.25% examples, 99040 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:15,169 EPOCH 2 - PROGRESS: at 93.65% examples, 99025 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:16,184 EPOCH 2 - PROGRESS: at 96.87% examples, 99013 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:17,107 EPOCH 2: training on 3499793 raw words (3519568 effective words) took 35.5s, 99119 effective words/s
2024-06-24 10:11:18,270 EPOCH 3 - PROGRESS: at 2.72% examples, 77723 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:19,333 EPOCH 3 - PROGRESS: at 5.82% examples, 90059 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:20,430 EPOCH 3 - PROGRESS: at 8.95% examples, 90361 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:21,666 EPOCH 3 - PROGRESS: at 12.22% examples, 89971 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:22,708 EPOCH 3 - PROGRESS: at 14.89% examples, 91057 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:23,895 EPOCH 3 - PROGRESS: at 18.00% examples, 91346 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:24,913 EPOCH 3 - PROGRESS: at 20.45% examples, 90949 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:25,923 EPOCH 3 - PROGRESS: at 22.95% examples, 90693 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:27,058 EPOCH 3 - PROGRESS: at 26.04% examples, 91376 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:28,138 EPOCH 3 - PROGRESS: at 28.83% examples, 91474 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:29,206 EPOCH 3 - PROGRESS: at 31.59% examples, 91667 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:30,299 EPOCH 3 - PROGRESS: at 34.39% examples, 91648 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:31,494 EPOCH 3 - PROGRESS: at 37.44% examples, 91678 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:32,659 EPOCH 3 - PROGRESS: at 40.45% examples, 91873 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:33,837 EPOCH 3 - PROGRESS: at 43.67% examples, 91984 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:34,928 EPOCH 3 - PROGRESS: at 46.74% examples, 92537 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:35,947 EPOCH 3 - PROGRESS: at 50.02% examples, 93354 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:37,049 EPOCH 3 - PROGRESS: at 52.90% examples, 93203 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:38,145 EPOCH 3 - PROGRESS: at 55.63% examples, 93572 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:39,301 EPOCH 3 - PROGRESS: at 58.64% examples, 93639 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:40,344 EPOCH 3 - PROGRESS: at 61.50% examples, 94163 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:41,536 EPOCH 3 - PROGRESS: at 64.30% examples, 94047 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:42,627 EPOCH 3 - PROGRESS: at 67.29% examples, 94727 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:43,697 EPOCH 3 - PROGRESS: at 69.83% examples, 94676 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:44,791 EPOCH 3 - PROGRESS: at 72.80% examples, 95232 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:45,803 EPOCH 3 - PROGRESS: at 75.23% examples, 95344 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:47,070 EPOCH 3 - PROGRESS: at 78.25% examples, 95293 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:48,135 EPOCH 3 - PROGRESS: at 81.68% examples, 95858 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:49,178 EPOCH 3 - PROGRESS: at 85.19% examples, 95867 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:50,351 EPOCH 3 - PROGRESS: at 89.42% examples, 96095 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:51,353 EPOCH 3 - PROGRESS: at 93.11% examples, 96502 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:52,514 EPOCH 3 - PROGRESS: at 96.46% examples, 96443 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:53,367 EPOCH 3: training on 3499793 raw words (3519565 effective words) took 36.3s, 97074 effective words/s
2024-06-24 10:11:54,444 EPOCH 4 - PROGRESS: at 2.72% examples, 84091 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:55,466 EPOCH 4 - PROGRESS: at 5.82% examples, 95575 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:56,646 EPOCH 4 - PROGRESS: at 9.20% examples, 94661 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:57,774 EPOCH 4 - PROGRESS: at 12.93% examples, 97650 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:11:58,879 EPOCH 4 - PROGRESS: at 15.41% examples, 96176 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:11:59,969 EPOCH 4 - PROGRESS: at 18.73% examples, 98475 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:01,015 EPOCH 4 - PROGRESS: at 21.56% examples, 98070 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:02,171 EPOCH 4 - PROGRESS: at 24.89% examples, 98758 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:03,185 EPOCH 4 - PROGRESS: at 27.71% examples, 98725 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:04,192 EPOCH 4 - PROGRESS: at 30.78% examples, 99706 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:05,321 EPOCH 4 - PROGRESS: at 33.82% examples, 99485 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:06,360 EPOCH 4 - PROGRESS: at 36.87% examples, 99991 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:07,364 EPOCH 4 - PROGRESS: at 39.67% examples, 99960 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:08,411 EPOCH 4 - PROGRESS: at 42.56% examples, 99641 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:09,489 EPOCH 4 - PROGRESS: at 45.65% examples, 99811 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:10,580 EPOCH 4 - PROGRESS: at 48.87% examples, 99869 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:11,704 EPOCH 4 - PROGRESS: at 51.83% examples, 99188 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:12,785 EPOCH 4 - PROGRESS: at 54.87% examples, 99841 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:13,904 EPOCH 4 - PROGRESS: at 57.81% examples, 99742 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:15,114 EPOCH 4 - PROGRESS: at 61.03% examples, 99703 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:16,154 EPOCH 4 - PROGRESS: at 63.53% examples, 99515 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:17,154 EPOCH 4 - PROGRESS: at 65.80% examples, 99104 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:18,282 EPOCH 4 - PROGRESS: at 68.53% examples, 99029 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:19,411 EPOCH 4 - PROGRESS: at 71.14% examples, 98565 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:20,467 EPOCH 4 - PROGRESS: at 73.76% examples, 98751 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:21,518 EPOCH 4 - PROGRESS: at 76.50% examples, 98966 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:22,592 EPOCH 4 - PROGRESS: at 79.26% examples, 99065 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:23,659 EPOCH 4 - PROGRESS: at 83.12% examples, 99512 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:24,774 EPOCH 4 - PROGRESS: at 86.34% examples, 99164 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:25,806 EPOCH 4 - PROGRESS: at 90.25% examples, 99402 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:26,957 EPOCH 4 - PROGRESS: at 94.03% examples, 99278 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:28,069 EPOCH 4 - PROGRESS: at 97.58% examples, 99270 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:28,688 EPOCH 4: training on 3499793 raw words (3519514 effective words) took 35.3s, 99659 effective words/s
2024-06-24 10:12:29,792 EPOCH 5 - PROGRESS: at 2.72% examples, 81994 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:30,849 EPOCH 5 - PROGRESS: at 6.10% examples, 97396 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:31,905 EPOCH 5 - PROGRESS: at 9.50% examples, 99565 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:32,961 EPOCH 5 - PROGRESS: at 12.88% examples, 100694 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:34,030 EPOCH 5 - PROGRESS: at 16.01% examples, 102995 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:35,113 EPOCH 5 - PROGRESS: at 19.01% examples, 102720 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:36,201 EPOCH 5 - PROGRESS: at 22.11% examples, 102473 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:37,248 EPOCH 5 - PROGRESS: at 24.90% examples, 101552 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:38,335 EPOCH 5 - PROGRESS: at 27.99% examples, 101509 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:39,368 EPOCH 5 - PROGRESS: at 31.05% examples, 101985 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:40,571 EPOCH 5 - PROGRESS: at 34.10% examples, 100922 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:41,662 EPOCH 5 - PROGRESS: at 37.16% examples, 100914 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:42,814 EPOCH 5 - PROGRESS: at 40.45% examples, 101160 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:43,899 EPOCH 5 - PROGRESS: at 43.67% examples, 101190 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:44,969 EPOCH 5 - PROGRESS: at 46.48% examples, 100688 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:46,071 EPOCH 5 - PROGRESS: at 50.02% examples, 101192 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:47,187 EPOCH 5 - PROGRESS: at 53.15% examples, 101028 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:48,223 EPOCH 5 - PROGRESS: at 55.63% examples, 100778 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:49,335 EPOCH 5 - PROGRESS: at 58.84% examples, 101147 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:50,397 EPOCH 5 - PROGRESS: at 61.73% examples, 101262 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:51,459 EPOCH 5 - PROGRESS: at 64.52% examples, 101346 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:52,538 EPOCH 5 - PROGRESS: at 67.29% examples, 101369 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:53,610 EPOCH 5 - PROGRESS: at 70.38% examples, 101828 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:54,652 EPOCH 5 - PROGRESS: at 72.80% examples, 101551 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:55,653 EPOCH 5 - PROGRESS: at 75.47% examples, 101844 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:56,676 EPOCH 5 - PROGRESS: at 78.25% examples, 102028 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:12:57,812 EPOCH 5 - PROGRESS: at 81.16% examples, 101784 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:58,870 EPOCH 5 - PROGRESS: at 85.46% examples, 102205 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:12:59,949 EPOCH 5 - PROGRESS: at 88.84% examples, 101873 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:01,085 EPOCH 5 - PROGRESS: at 92.40% examples, 101394 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:02,274 EPOCH 5 - PROGRESS: at 96.14% examples, 101382 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:03,330 EPOCH 5 - PROGRESS: at 99.40% examples, 101039 words/s, in_qsize 2, out_qsize 1
2024-06-24 10:13:03,426 EPOCH 5: training on 3499793 raw words (3519753 effective words) took 34.7s, 101335 effective words/s
2024-06-24 10:13:04,534 EPOCH 6 - PROGRESS: at 2.72% examples, 81639 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:05,602 EPOCH 6 - PROGRESS: at 6.10% examples, 96706 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:06,685 EPOCH 6 - PROGRESS: at 9.76% examples, 101318 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:07,759 EPOCH 6 - PROGRESS: at 12.88% examples, 99296 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:08,770 EPOCH 6 - PROGRESS: at 15.14% examples, 97308 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:09,812 EPOCH 6 - PROGRESS: at 18.49% examples, 100211 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:10,882 EPOCH 6 - PROGRESS: at 21.84% examples, 101904 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:11,895 EPOCH 6 - PROGRESS: at 24.61% examples, 101462 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:13,018 EPOCH 6 - PROGRESS: at 27.99% examples, 102070 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:14,070 EPOCH 6 - PROGRESS: at 31.32% examples, 103255 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:15,084 EPOCH 6 - PROGRESS: at 34.10% examples, 102856 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:16,112 EPOCH 6 - PROGRESS: at 37.16% examples, 103190 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:17,310 EPOCH 6 - PROGRESS: at 40.45% examples, 102911 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:18,385 EPOCH 6 - PROGRESS: at 43.96% examples, 103546 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:19,423 EPOCH 6 - PROGRESS: at 46.74% examples, 103085 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:20,486 EPOCH 6 - PROGRESS: at 50.06% examples, 103098 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:21,494 EPOCH 6 - PROGRESS: at 53.22% examples, 103423 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:22,536 EPOCH 6 - PROGRESS: at 55.91% examples, 103528 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:23,567 EPOCH 6 - PROGRESS: at 58.64% examples, 103183 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:24,635 EPOCH 6 - PROGRESS: at 61.50% examples, 103163 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:25,837 EPOCH 6 - PROGRESS: at 64.30% examples, 102514 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:26,906 EPOCH 6 - PROGRESS: at 67.29% examples, 102954 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:27,966 EPOCH 6 - PROGRESS: at 69.85% examples, 102580 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:28,985 EPOCH 6 - PROGRESS: at 72.54% examples, 102761 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:29,990 EPOCH 6 - PROGRESS: at 75.23% examples, 102993 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:31,081 EPOCH 6 - PROGRESS: at 78.01% examples, 102881 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:32,176 EPOCH 6 - PROGRESS: at 81.29% examples, 103099 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:33,233 EPOCH 6 - PROGRESS: at 85.46% examples, 103479 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:34,317 EPOCH 6 - PROGRESS: at 88.85% examples, 103087 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:35,381 EPOCH 6 - PROGRESS: at 92.96% examples, 103415 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:36,431 EPOCH 6 - PROGRESS: at 96.46% examples, 103460 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:37,437 EPOCH 6 - PROGRESS: at 100.00% examples, 103494 words/s, in_qsize 0, out_qsize 1
2024-06-24 10:13:37,437 EPOCH 6: training on 3499793 raw words (3519452 effective words) took 34.0s, 103493 effective words/s
2024-06-24 10:13:38,476 EPOCH 7 - PROGRESS: at 2.72% examples, 87105 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:39,511 EPOCH 7 - PROGRESS: at 6.10% examples, 101524 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:40,554 EPOCH 7 - PROGRESS: at 9.50% examples, 102809 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:41,593 EPOCH 7 - PROGRESS: at 12.68% examples, 101148 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:42,640 EPOCH 7 - PROGRESS: at 15.74% examples, 103847 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:43,683 EPOCH 7 - PROGRESS: at 18.73% examples, 104085 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:44,746 EPOCH 7 - PROGRESS: at 21.84% examples, 103989 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:45,852 EPOCH 7 - PROGRESS: at 24.90% examples, 103321 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:46,856 EPOCH 7 - PROGRESS: at 27.99% examples, 103966 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:48,024 EPOCH 7 - PROGRESS: at 31.04% examples, 102896 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:49,087 EPOCH 7 - PROGRESS: at 34.10% examples, 102947 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:50,151 EPOCH 7 - PROGRESS: at 37.42% examples, 103762 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:51,168 EPOCH 7 - PROGRESS: at 40.22% examples, 103345 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:52,179 EPOCH 7 - PROGRESS: at 43.38% examples, 103726 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:53,289 EPOCH 7 - PROGRESS: at 46.74% examples, 104046 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:54,293 EPOCH 7 - PROGRESS: at 49.83% examples, 103766 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:55,414 EPOCH 7 - PROGRESS: at 53.22% examples, 103962 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:56,485 EPOCH 7 - PROGRESS: at 55.91% examples, 103878 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:57,556 EPOCH 7 - PROGRESS: at 58.59% examples, 103309 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:13:58,599 EPOCH 7 - PROGRESS: at 61.75% examples, 103875 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:13:59,642 EPOCH 7 - PROGRESS: at 64.54% examples, 103927 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:00,674 EPOCH 7 - PROGRESS: at 66.99% examples, 103611 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:01,712 EPOCH 7 - PROGRESS: at 70.11% examples, 104129 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:02,722 EPOCH 7 - PROGRESS: at 72.80% examples, 104279 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:03,732 EPOCH 7 - PROGRESS: at 75.47% examples, 104440 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:04,931 EPOCH 7 - PROGRESS: at 78.30% examples, 103856 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:05,943 EPOCH 7 - PROGRESS: at 81.22% examples, 103993 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:07,036 EPOCH 7 - PROGRESS: at 85.19% examples, 103880 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:08,098 EPOCH 7 - PROGRESS: at 89.10% examples, 103872 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:09,208 EPOCH 7 - PROGRESS: at 92.70% examples, 103706 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:10,255 EPOCH 7 - PROGRESS: at 96.46% examples, 104058 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:11,158 EPOCH 7: training on 3499793 raw words (3519677 effective words) took 33.7s, 104389 effective words/s
2024-06-24 10:14:12,175 EPOCH 8 - PROGRESS: at 2.72% examples, 89033 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:13,198 EPOCH 8 - PROGRESS: at 6.10% examples, 103213 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:14,227 EPOCH 8 - PROGRESS: at 9.50% examples, 104389 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:15,240 EPOCH 8 - PROGRESS: at 12.93% examples, 105432 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:16,299 EPOCH 8 - PROGRESS: at 15.69% examples, 105077 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:17,382 EPOCH 8 - PROGRESS: at 19.01% examples, 106060 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:18,460 EPOCH 8 - PROGRESS: at 22.39% examples, 106811 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:19,462 EPOCH 8 - PROGRESS: at 25.18% examples, 105904 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:20,604 EPOCH 8 - PROGRESS: at 28.56% examples, 105782 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:21,692 EPOCH 8 - PROGRESS: at 31.88% examples, 106251 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:22,708 EPOCH 8 - PROGRESS: at 34.67% examples, 105569 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:23,814 EPOCH 8 - PROGRESS: at 37.98% examples, 105809 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:24,855 EPOCH 8 - PROGRESS: at 41.24% examples, 106514 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:25,904 EPOCH 8 - PROGRESS: at 44.18% examples, 105728 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:26,988 EPOCH 8 - PROGRESS: at 47.61% examples, 106078 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:28,034 EPOCH 8 - PROGRESS: at 50.80% examples, 105999 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:29,106 EPOCH 8 - PROGRESS: at 53.93% examples, 105787 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:30,182 EPOCH 8 - PROGRESS: at 56.88% examples, 106099 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:31,212 EPOCH 8 - PROGRESS: at 59.94% examples, 106126 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:32,263 EPOCH 8 - PROGRESS: at 63.02% examples, 106504 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:33,316 EPOCH 8 - PROGRESS: at 65.80% examples, 106389 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:34,380 EPOCH 8 - PROGRESS: at 68.53% examples, 106253 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:35,493 EPOCH 8 - PROGRESS: at 71.58% examples, 106315 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:36,523 EPOCH 8 - PROGRESS: at 74.25% examples, 106290 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:37,628 EPOCH 8 - PROGRESS: at 76.71% examples, 105617 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:38,675 EPOCH 8 - PROGRESS: at 79.72% examples, 105939 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:39,717 EPOCH 8 - PROGRESS: at 83.53% examples, 105904 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:40,754 EPOCH 8 - PROGRESS: at 87.38% examples, 106250 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:41,792 EPOCH 8 - PROGRESS: at 90.96% examples, 105913 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:42,825 EPOCH 8 - PROGRESS: at 94.87% examples, 106254 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:43,858 EPOCH 8 - PROGRESS: at 98.19% examples, 105960 words/s, in_qsize 6, out_qsize 0
2024-06-24 10:14:44,242 EPOCH 8: training on 3499793 raw words (3519529 effective words) took 33.1s, 106395 effective words/s
2024-06-24 10:14:45,301 EPOCH 9 - PROGRESS: at 2.72% examples, 85484 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:46,360 EPOCH 9 - PROGRESS: at 6.10% examples, 99403 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:47,421 EPOCH 9 - PROGRESS: at 9.21% examples, 97623 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:48,470 EPOCH 9 - PROGRESS: at 12.93% examples, 101782 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:49,493 EPOCH 9 - PROGRESS: at 15.74% examples, 102873 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:50,532 EPOCH 9 - PROGRESS: at 18.73% examples, 103348 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:51,617 EPOCH 9 - PROGRESS: at 21.84% examples, 103036 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:52,792 EPOCH 9 - PROGRESS: at 25.18% examples, 102848 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:53,866 EPOCH 9 - PROGRESS: at 28.56% examples, 103820 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:54,927 EPOCH 9 - PROGRESS: at 31.32% examples, 102867 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:55,991 EPOCH 9 - PROGRESS: at 34.67% examples, 103768 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:57,053 EPOCH 9 - PROGRESS: at 37.71% examples, 103745 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:14:58,094 EPOCH 9 - PROGRESS: at 41.00% examples, 104596 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:14:59,170 EPOCH 9 - PROGRESS: at 43.89% examples, 103766 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:00,256 EPOCH 9 - PROGRESS: at 47.34% examples, 104228 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:01,324 EPOCH 9 - PROGRESS: at 50.27% examples, 103552 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:02,349 EPOCH 9 - PROGRESS: at 53.46% examples, 103756 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:03,410 EPOCH 9 - PROGRESS: at 56.14% examples, 103734 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:04,507 EPOCH 9 - PROGRESS: at 59.11% examples, 103540 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:05,569 EPOCH 9 - PROGRESS: at 61.75% examples, 103063 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:06,664 EPOCH 9 - PROGRESS: at 64.76% examples, 103352 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:07,723 EPOCH 9 - PROGRESS: at 67.81% examples, 103800 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:08,775 EPOCH 9 - PROGRESS: at 70.11% examples, 103019 words/s, in_qsize 8, out_qsize 1
2024-06-24 10:15:09,849 EPOCH 9 - PROGRESS: at 73.03% examples, 103340 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:10,863 EPOCH 9 - PROGRESS: at 75.73% examples, 103525 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:11,907 EPOCH 9 - PROGRESS: at 78.30% examples, 103205 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:12,995 EPOCH 9 - PROGRESS: at 81.63% examples, 103438 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:14,032 EPOCH 9 - PROGRESS: at 85.46% examples, 103539 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:15,065 EPOCH 9 - PROGRESS: at 89.42% examples, 103641 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:16,105 EPOCH 9 - PROGRESS: at 93.11% examples, 103719 words/s, in_qsize 8, out_qsize 0
2024-06-24 10:15:17,161 EPOCH 9 - PROGRESS: at 96.46% examples, 103733 words/s, in_qsize 7, out_qsize 0
2024-06-24 10:15:18,090 EPOCH 9: training on 3499793 raw words (3519507 effective words) took 33.8s, 103993 effective words/s
2024-06-24 10:15:18,091 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195658 effective words) took 349.2s, 100798 effective words/s', 'datetime': '2024-06-24T10:15:18.091052', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 10:26:03,171 ==================================================
2024-06-24 10:26:03,171 Training BERT + Doc2Vec features with Dimension-4096...
2024-06-24 10:26:04,145 Epoch [1/8], Batch [1/748], Loss: 1.6170
2024-06-24 10:26:52,990 Epoch [1/8], Batch [51/748], Loss: 1.4942
2024-06-24 10:27:42,695 Epoch [1/8], Batch [101/748], Loss: 1.3527
2024-06-24 10:28:32,906 Epoch [1/8], Batch [151/748], Loss: 1.2288
2024-06-24 10:29:23,298 Epoch [1/8], Batch [201/748], Loss: 1.1774
2024-06-24 10:30:13,682 Epoch [1/8], Batch [251/748], Loss: 1.1197
2024-06-24 10:31:04,204 Epoch [1/8], Batch [301/748], Loss: 1.1581
2024-06-24 10:31:54,642 Epoch [1/8], Batch [351/748], Loss: 1.0824
2024-06-24 10:32:45,034 Epoch [1/8], Batch [401/748], Loss: 1.0195
2024-06-24 10:33:35,361 Epoch [1/8], Batch [451/748], Loss: 0.9177
2024-06-24 10:34:25,711 Epoch [1/8], Batch [501/748], Loss: 0.9114
2024-06-24 10:35:16,002 Epoch [1/8], Batch [551/748], Loss: 1.1044
2024-06-24 10:36:06,571 Epoch [1/8], Batch [601/748], Loss: 1.1448
2024-06-24 10:36:57,017 Epoch [1/8], Batch [651/748], Loss: 0.9366
2024-06-24 10:37:47,480 Epoch [1/8], Batch [701/748], Loss: 0.8196
2024-06-24 10:38:34,365 Epoch 1/8, Train Loss: 1.0650, Train Accuracy: 0.5423
2024-06-24 10:39:53,852 Epoch 1/8, Val Loss: 0.9243, Val Accuracy: 0.6001
2024-06-24 10:39:54,861 Epoch [2/8], Batch [1/748], Loss: 0.7492
2024-06-24 10:40:45,034 Epoch [2/8], Batch [51/748], Loss: 0.7452
2024-06-24 10:41:35,397 Epoch [2/8], Batch [101/748], Loss: 1.1459
2024-06-24 10:42:25,761 Epoch [2/8], Batch [151/748], Loss: 0.8228
2024-06-24 10:43:16,379 Epoch [2/8], Batch [201/748], Loss: 0.7254
2024-06-24 10:44:06,610 Epoch [2/8], Batch [251/748], Loss: 1.0652
2024-06-24 10:44:57,009 Epoch [2/8], Batch [301/748], Loss: 0.9352
2024-06-24 10:45:47,383 Epoch [2/8], Batch [351/748], Loss: 0.8181
2024-06-24 10:46:37,722 Epoch [2/8], Batch [401/748], Loss: 0.8560
2024-06-24 10:47:28,281 Epoch [2/8], Batch [451/748], Loss: 0.8009
2024-06-24 10:48:18,665 Epoch [2/8], Batch [501/748], Loss: 0.8314
2024-06-24 10:49:08,963 Epoch [2/8], Batch [551/748], Loss: 0.6064
2024-06-24 10:49:59,326 Epoch [2/8], Batch [601/748], Loss: 0.9504
2024-06-24 10:50:49,623 Epoch [2/8], Batch [651/748], Loss: 0.8956
2024-06-24 10:51:40,003 Epoch [2/8], Batch [701/748], Loss: 0.5576
2024-06-24 10:52:27,102 Epoch 2/8, Train Loss: 0.8208, Train Accuracy: 0.6347
2024-06-24 10:53:47,050 Epoch 2/8, Val Loss: 0.9305, Val Accuracy: 0.5738
2024-06-24 10:53:48,048 Epoch [3/8], Batch [1/748], Loss: 0.7270
2024-06-24 10:54:38,524 Epoch [3/8], Batch [51/748], Loss: 0.5606
2024-06-24 10:55:29,103 Epoch [3/8], Batch [101/748], Loss: 0.6700
2024-06-24 10:56:19,820 Epoch [3/8], Batch [151/748], Loss: 0.7575
2024-06-24 10:57:10,211 Epoch [3/8], Batch [201/748], Loss: 0.6861
2024-06-24 10:58:00,508 Epoch [3/8], Batch [251/748], Loss: 0.9929
2024-06-24 10:58:50,836 Epoch [3/8], Batch [301/748], Loss: 0.8185
2024-06-24 10:59:41,209 Epoch [3/8], Batch [351/748], Loss: 0.5592
2024-06-24 11:00:31,599 Epoch [3/8], Batch [401/748], Loss: 0.7006
2024-06-24 11:01:22,087 Epoch [3/8], Batch [451/748], Loss: 0.6580
2024-06-24 11:02:12,404 Epoch [3/8], Batch [501/748], Loss: 0.9999
2024-06-24 11:03:02,633 Epoch [3/8], Batch [551/748], Loss: 0.5647
2024-06-24 11:03:53,103 Epoch [3/8], Batch [601/748], Loss: 0.7636
2024-06-24 11:04:43,495 Epoch [3/8], Batch [651/748], Loss: 0.5651
2024-06-24 11:05:33,919 Epoch [3/8], Batch [701/748], Loss: 0.5089
2024-06-24 11:06:21,003 Epoch 3/8, Train Loss: 0.7229, Train Accuracy: 0.6763
2024-06-24 11:07:40,339 Epoch 3/8, Val Loss: 0.8999, Val Accuracy: 0.5972
2024-06-24 11:07:41,344 Epoch [4/8], Batch [1/748], Loss: 0.6759
2024-06-24 11:08:31,537 Epoch [4/8], Batch [51/748], Loss: 0.6623
2024-06-24 11:09:21,965 Epoch [4/8], Batch [101/748], Loss: 0.6357
2024-06-24 11:10:12,278 Epoch [4/8], Batch [151/748], Loss: 0.5428
2024-06-24 11:11:02,757 Epoch [4/8], Batch [201/748], Loss: 0.7554
2024-06-24 11:11:53,148 Epoch [4/8], Batch [251/748], Loss: 0.4511
2024-06-24 11:12:43,591 Epoch [4/8], Batch [301/748], Loss: 0.5649
2024-06-24 11:13:34,085 Epoch [4/8], Batch [351/748], Loss: 0.6073
2024-06-24 11:14:24,362 Epoch [4/8], Batch [401/748], Loss: 0.5981
2024-06-24 11:15:14,846 Epoch [4/8], Batch [451/748], Loss: 0.6069
2024-06-24 11:16:05,328 Epoch [4/8], Batch [501/748], Loss: 0.7790
2024-06-24 11:16:55,714 Epoch [4/8], Batch [551/748], Loss: 0.6651
2024-06-24 11:17:46,177 Epoch [4/8], Batch [601/748], Loss: 0.5981
2024-06-24 11:18:36,500 Epoch [4/8], Batch [651/748], Loss: 0.4144
2024-06-24 11:19:26,983 Epoch [4/8], Batch [701/748], Loss: 0.4651
2024-06-24 11:20:13,791 Epoch 4/8, Train Loss: 0.6316, Train Accuracy: 0.7232
2024-06-24 11:21:33,151 Epoch 4/8, Val Loss: 0.8997, Val Accuracy: 0.6260
2024-06-24 11:21:34,150 Epoch [5/8], Batch [1/748], Loss: 0.5712
2024-06-24 11:22:24,473 Epoch [5/8], Batch [51/748], Loss: 0.4283
2024-06-24 11:23:14,830 Epoch [5/8], Batch [101/748], Loss: 0.5021
2024-06-24 11:24:05,186 Epoch [5/8], Batch [151/748], Loss: 0.3750
2024-06-24 11:24:55,518 Epoch [5/8], Batch [201/748], Loss: 0.4746
2024-06-24 11:25:45,975 Epoch [5/8], Batch [251/748], Loss: 0.5404
2024-06-24 11:26:36,397 Epoch [5/8], Batch [301/748], Loss: 0.5596
2024-06-24 11:27:27,223 Epoch [5/8], Batch [351/748], Loss: 0.8563
2024-06-24 11:28:18,010 Epoch [5/8], Batch [401/748], Loss: 0.6656
2024-06-24 11:29:08,746 Epoch [5/8], Batch [451/748], Loss: 0.6285
2024-06-24 11:29:59,166 Epoch [5/8], Batch [501/748], Loss: 0.6108
2024-06-24 11:30:49,672 Epoch [5/8], Batch [551/748], Loss: 0.6830
2024-06-24 11:31:40,265 Epoch [5/8], Batch [601/748], Loss: 0.2166
2024-06-24 11:32:30,781 Epoch [5/8], Batch [651/748], Loss: 0.3891
2024-06-24 11:33:21,585 Epoch [5/8], Batch [701/748], Loss: 0.4911
2024-06-24 11:34:08,755 Epoch 5/8, Train Loss: 0.5459, Train Accuracy: 0.7655
2024-06-24 11:35:28,284 Epoch 5/8, Val Loss: 0.9476, Val Accuracy: 0.6230
2024-06-24 11:35:29,273 Epoch [6/8], Batch [1/748], Loss: 0.6358
2024-06-24 11:36:19,612 Epoch [6/8], Batch [51/748], Loss: 0.5026
2024-06-24 11:37:10,083 Epoch [6/8], Batch [101/748], Loss: 0.3528
2024-06-24 11:38:00,694 Epoch [6/8], Batch [151/748], Loss: 0.3116
2024-06-24 11:38:51,257 Epoch [6/8], Batch [201/748], Loss: 0.3069
2024-06-24 11:39:41,840 Epoch [6/8], Batch [251/748], Loss: 0.4307
2024-06-24 11:40:32,275 Epoch [6/8], Batch [301/748], Loss: 0.5368
2024-06-24 11:41:22,847 Epoch [6/8], Batch [351/748], Loss: 0.4338
2024-06-24 11:42:13,347 Epoch [6/8], Batch [401/748], Loss: 0.2589
2024-06-24 11:43:03,986 Epoch [6/8], Batch [451/748], Loss: 0.3606
2024-06-24 11:43:54,596 Epoch [6/8], Batch [501/748], Loss: 0.4083
2024-06-24 11:44:44,805 Epoch [6/8], Batch [551/748], Loss: 0.8222
2024-06-24 11:45:35,223 Epoch [6/8], Batch [601/748], Loss: 0.4308
2024-06-24 11:46:25,774 Epoch [6/8], Batch [651/748], Loss: 0.4021
2024-06-24 11:47:16,179 Epoch [6/8], Batch [701/748], Loss: 0.6212
2024-06-24 11:48:03,188 Epoch 6/8, Train Loss: 0.4581, Train Accuracy: 0.8058
2024-06-24 11:49:23,390 Epoch 6/8, Val Loss: 0.9217, Val Accuracy: 0.6588
2024-06-24 11:49:24,391 Epoch [7/8], Batch [1/748], Loss: 0.4057
2024-06-24 11:50:14,569 Epoch [7/8], Batch [51/748], Loss: 0.1687
2024-06-24 11:51:04,977 Epoch [7/8], Batch [101/748], Loss: 0.4152
2024-06-24 11:51:55,466 Epoch [7/8], Batch [151/748], Loss: 0.2822
2024-06-24 11:52:45,867 Epoch [7/8], Batch [201/748], Loss: 0.3667
2024-06-24 11:53:36,397 Epoch [7/8], Batch [251/748], Loss: 0.4238
2024-06-24 11:54:26,796 Epoch [7/8], Batch [301/748], Loss: 0.3997
2024-06-24 11:55:17,262 Epoch [7/8], Batch [351/748], Loss: 0.4429
2024-06-24 11:56:07,977 Epoch [7/8], Batch [401/748], Loss: 0.3309
2024-06-24 11:56:58,379 Epoch [7/8], Batch [451/748], Loss: 0.3496
2024-06-24 11:57:48,745 Epoch [7/8], Batch [501/748], Loss: 0.4451
2024-06-24 11:58:39,187 Epoch [7/8], Batch [551/748], Loss: 0.3374
2024-06-24 11:59:29,620 Epoch [7/8], Batch [601/748], Loss: 0.3348
2024-06-24 12:00:20,042 Epoch [7/8], Batch [651/748], Loss: 0.3596
2024-06-24 12:01:10,418 Epoch [7/8], Batch [701/748], Loss: 0.3213
2024-06-24 12:01:57,369 Epoch 7/8, Train Loss: 0.3768, Train Accuracy: 0.8453
2024-06-24 12:03:16,835 Epoch 7/8, Val Loss: 0.9651, Val Accuracy: 0.6666
2024-06-24 12:03:17,846 Epoch [8/8], Batch [1/748], Loss: 0.4315
2024-06-24 12:04:07,967 Epoch [8/8], Batch [51/748], Loss: 0.3683
2024-06-24 12:04:58,293 Epoch [8/8], Batch [101/748], Loss: 0.4165
2024-06-24 12:05:48,796 Epoch [8/8], Batch [151/748], Loss: 0.4284
2024-06-24 12:06:39,008 Epoch [8/8], Batch [201/748], Loss: 0.3341
2024-06-24 12:07:29,466 Epoch [8/8], Batch [251/748], Loss: 0.2284
2024-06-24 12:08:19,988 Epoch [8/8], Batch [301/748], Loss: 0.2965
2024-06-24 12:09:10,408 Epoch [8/8], Batch [351/748], Loss: 0.2097
2024-06-24 12:10:00,871 Epoch [8/8], Batch [401/748], Loss: 0.3062
2024-06-24 12:10:51,460 Epoch [8/8], Batch [451/748], Loss: 0.3296
2024-06-24 12:11:41,926 Epoch [8/8], Batch [501/748], Loss: 0.1547
2024-06-24 12:12:32,518 Epoch [8/8], Batch [551/748], Loss: 0.4905
2024-06-24 12:13:23,046 Epoch [8/8], Batch [601/748], Loss: 0.2167
2024-06-24 12:14:13,369 Epoch [8/8], Batch [651/748], Loss: 0.2385
2024-06-24 12:15:03,802 Epoch [8/8], Batch [701/748], Loss: 0.4110
2024-06-24 12:15:50,681 Epoch 8/8, Train Loss: 0.3035, Train Accuracy: 0.8822
2024-06-24 12:17:09,992 Epoch 8/8, Val Loss: 1.1230, Val Accuracy: 0.6444
2024-06-24 12:17:09,993 Training finished!
2024-06-24 12:17:09,994 ==================================================
2024-06-24 12:17:33,399 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d2048,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T12:17:33.399515', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 12:17:33,399 collecting all words and their counts
2024-06-24 12:17:33,399 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 12:17:33,634 PROGRESS: at example #10000, processed 1168609 words (4989266 words/s), 72028 word types, 0 tags
2024-06-24 12:17:33,884 PROGRESS: at example #20000, processed 2388715 words (4875518 words/s), 103898 word types, 0 tags
2024-06-24 12:17:34,111 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 12:17:34,111 Creating a fresh vocabulary
2024-06-24 12:17:34,533 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T12:17:34.533036', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 12:17:34,533 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T12:17:34.533236', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 12:17:35,253 deleting the raw counts dictionary of 133984 items
2024-06-24 12:17:35,255 sample=0.001 downsamples 6 most-common words
2024-06-24 12:17:35,255 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T12:17:35.255304', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 12:17:36,476 estimated required memory for 133984 words and 2048 dimensions: 2262227816 bytes
2024-06-24 12:17:36,476 resetting layer weights
2024-06-24 12:17:47,339 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 2048 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T12:17:47.339295', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 12:17:48,345 EPOCH 0 - PROGRESS: at 3.09% examples, 99967 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:17:49,363 EPOCH 0 - PROGRESS: at 8.18% examples, 138603 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:17:50,366 EPOCH 0 - PROGRESS: at 14.66% examples, 165322 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:17:51,437 EPOCH 0 - PROGRESS: at 20.16% examples, 170870 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:17:52,462 EPOCH 0 - PROGRESS: at 26.01% examples, 177555 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:17:53,504 EPOCH 0 - PROGRESS: at 31.88% examples, 181586 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:17:54,511 EPOCH 0 - PROGRESS: at 37.42% examples, 183965 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:17:55,618 EPOCH 0 - PROGRESS: at 43.38% examples, 184732 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:17:56,619 EPOCH 0 - PROGRESS: at 48.87% examples, 185254 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:17:57,759 EPOCH 0 - PROGRESS: at 54.87% examples, 186084 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:17:58,769 EPOCH 0 - PROGRESS: at 60.15% examples, 187088 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:17:59,795 EPOCH 0 - PROGRESS: at 64.79% examples, 186073 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:00,802 EPOCH 0 - PROGRESS: at 69.58% examples, 186266 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:01,805 EPOCH 0 - PROGRESS: at 74.01% examples, 185705 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:02,865 EPOCH 0 - PROGRESS: at 79.02% examples, 185851 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:03,939 EPOCH 0 - PROGRESS: at 85.46% examples, 185832 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:05,031 EPOCH 0 - PROGRESS: at 92.70% examples, 186242 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:06,065 EPOCH 0 - PROGRESS: at 99.29% examples, 186653 words/s, in_qsize 3, out_qsize 1
2024-06-24 12:18:06,124 EPOCH 0: training on 3499793 raw words (3519579 effective words) took 18.8s, 187406 effective words/s
2024-06-24 12:18:07,185 EPOCH 1 - PROGRESS: at 5.82% examples, 189294 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:08,211 EPOCH 1 - PROGRESS: at 11.97% examples, 192016 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:09,330 EPOCH 1 - PROGRESS: at 18.23% examples, 196655 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:10,375 EPOCH 1 - PROGRESS: at 24.61% examples, 202265 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:11,449 EPOCH 1 - PROGRESS: at 30.22% examples, 198984 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:12,474 EPOCH 1 - PROGRESS: at 35.48% examples, 196798 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:13,521 EPOCH 1 - PROGRESS: at 41.10% examples, 195924 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:14,543 EPOCH 1 - PROGRESS: at 46.48% examples, 194740 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:15,571 EPOCH 1 - PROGRESS: at 52.05% examples, 193619 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:16,585 EPOCH 1 - PROGRESS: at 56.88% examples, 192973 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:17,619 EPOCH 1 - PROGRESS: at 62.48% examples, 193862 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:18,712 EPOCH 1 - PROGRESS: at 67.29% examples, 192074 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:19,747 EPOCH 1 - PROGRESS: at 72.54% examples, 192833 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:20,851 EPOCH 1 - PROGRESS: at 77.47% examples, 191886 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:21,891 EPOCH 1 - PROGRESS: at 82.68% examples, 190563 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:22,913 EPOCH 1 - PROGRESS: at 89.10% examples, 189710 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:23,954 EPOCH 1 - PROGRESS: at 95.19% examples, 189297 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:24,657 EPOCH 1: training on 3499793 raw words (3519571 effective words) took 18.5s, 189950 effective words/s
2024-06-24 12:18:25,718 EPOCH 2 - PROGRESS: at 5.82% examples, 189171 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:26,731 EPOCH 2 - PROGRESS: at 11.97% examples, 193128 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:27,738 EPOCH 2 - PROGRESS: at 17.33% examples, 194819 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:28,842 EPOCH 2 - PROGRESS: at 22.95% examples, 191137 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:29,868 EPOCH 2 - PROGRESS: at 28.54% examples, 191772 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:30,995 EPOCH 2 - PROGRESS: at 34.10% examples, 189249 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:32,141 EPOCH 2 - PROGRESS: at 40.18% examples, 189628 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:33,165 EPOCH 2 - PROGRESS: at 45.89% examples, 190318 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:34,175 EPOCH 2 - PROGRESS: at 51.58% examples, 190061 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:35,284 EPOCH 2 - PROGRESS: at 56.64% examples, 189010 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:36,309 EPOCH 2 - PROGRESS: at 61.98% examples, 189518 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:37,350 EPOCH 2 - PROGRESS: at 66.53% examples, 188106 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:38,387 EPOCH 2 - PROGRESS: at 71.38% examples, 187707 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:39,406 EPOCH 2 - PROGRESS: at 76.25% examples, 188231 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:40,408 EPOCH 2 - PROGRESS: at 81.22% examples, 188217 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:41,513 EPOCH 2 - PROGRESS: at 88.67% examples, 188353 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:42,575 EPOCH 2 - PROGRESS: at 95.56% examples, 188918 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:43,259 EPOCH 2: training on 3499793 raw words (3519651 effective words) took 18.6s, 189239 effective words/s
2024-06-24 12:18:44,268 EPOCH 3 - PROGRESS: at 5.00% examples, 169393 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:45,279 EPOCH 3 - PROGRESS: at 10.56% examples, 178435 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:46,351 EPOCH 3 - PROGRESS: at 16.52% examples, 184465 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:47,396 EPOCH 3 - PROGRESS: at 22.12% examples, 186167 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:48,428 EPOCH 3 - PROGRESS: at 27.41% examples, 185636 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:49,446 EPOCH 3 - PROGRESS: at 32.69% examples, 185774 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:50,472 EPOCH 3 - PROGRESS: at 38.26% examples, 187088 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:51,516 EPOCH 3 - PROGRESS: at 43.67% examples, 186425 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:52,526 EPOCH 3 - PROGRESS: at 48.91% examples, 185521 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:53,529 EPOCH 3 - PROGRESS: at 53.93% examples, 184910 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:54,538 EPOCH 3 - PROGRESS: at 59.45% examples, 186937 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:55,577 EPOCH 3 - PROGRESS: at 64.29% examples, 186563 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:56,646 EPOCH 3 - PROGRESS: at 69.35% examples, 186586 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:18:57,784 EPOCH 3 - PROGRESS: at 74.79% examples, 187026 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:58,840 EPOCH 3 - PROGRESS: at 80.24% examples, 188350 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:18:59,858 EPOCH 3 - PROGRESS: at 86.74% examples, 188254 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:00,872 EPOCH 3 - PROGRESS: at 93.11% examples, 187654 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:01,894 EPOCH 3 - PROGRESS: at 98.82% examples, 187036 words/s, in_qsize 4, out_qsize 0
2024-06-24 12:19:01,977 EPOCH 3: training on 3499793 raw words (3519677 effective words) took 18.7s, 188078 effective words/s
2024-06-24 12:19:03,001 EPOCH 4 - PROGRESS: at 5.45% examples, 186204 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:04,011 EPOCH 4 - PROGRESS: at 10.84% examples, 182035 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:05,055 EPOCH 4 - PROGRESS: at 16.25% examples, 182018 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:06,086 EPOCH 4 - PROGRESS: at 21.56% examples, 182525 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:07,103 EPOCH 4 - PROGRESS: at 26.86% examples, 183263 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:08,128 EPOCH 4 - PROGRESS: at 32.15% examples, 183623 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:09,132 EPOCH 4 - PROGRESS: at 37.42% examples, 184384 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:10,135 EPOCH 4 - PROGRESS: at 43.13% examples, 186231 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:11,207 EPOCH 4 - PROGRESS: at 48.87% examples, 186284 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:12,207 EPOCH 4 - PROGRESS: at 54.40% examples, 187580 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:13,276 EPOCH 4 - PROGRESS: at 59.67% examples, 187493 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:14,321 EPOCH 4 - PROGRESS: at 64.52% examples, 186964 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:15,378 EPOCH 4 - PROGRESS: at 69.83% examples, 187883 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:16,406 EPOCH 4 - PROGRESS: at 74.54% examples, 187585 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:17,421 EPOCH 4 - PROGRESS: at 79.25% examples, 187494 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:18,488 EPOCH 4 - PROGRESS: at 85.46% examples, 186839 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:19,568 EPOCH 4 - PROGRESS: at 92.40% examples, 186750 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:20,647 EPOCH 4 - PROGRESS: at 99.40% examples, 187492 words/s, in_qsize 2, out_qsize 1
2024-06-24 12:19:20,749 EPOCH 4: training on 3499793 raw words (3519840 effective words) took 18.8s, 187532 effective words/s
2024-06-24 12:19:21,755 EPOCH 5 - PROGRESS: at 5.45% examples, 189970 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:22,808 EPOCH 5 - PROGRESS: at 11.97% examples, 194713 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:23,872 EPOCH 5 - PROGRESS: at 17.47% examples, 192371 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:25,012 EPOCH 5 - PROGRESS: at 23.49% examples, 192383 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:26,019 EPOCH 5 - PROGRESS: at 28.83% examples, 191602 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:27,030 EPOCH 5 - PROGRESS: at 34.10% examples, 191015 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:28,089 EPOCH 5 - PROGRESS: at 39.94% examples, 192044 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:29,134 EPOCH 5 - PROGRESS: at 45.24% examples, 190769 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:30,152 EPOCH 5 - PROGRESS: at 50.80% examples, 190298 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:31,171 EPOCH 5 - PROGRESS: at 56.18% examples, 190866 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:32,193 EPOCH 5 - PROGRESS: at 61.28% examples, 190389 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:33,198 EPOCH 5 - PROGRESS: at 65.82% examples, 189417 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:34,321 EPOCH 5 - PROGRESS: at 71.14% examples, 189180 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:35,348 EPOCH 5 - PROGRESS: at 76.25% examples, 190192 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:36,372 EPOCH 5 - PROGRESS: at 81.68% examples, 190416 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:37,404 EPOCH 5 - PROGRESS: at 89.10% examples, 191254 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:38,426 EPOCH 5 - PROGRESS: at 95.24% examples, 190942 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:39,098 EPOCH 5: training on 3499793 raw words (3519599 effective words) took 18.3s, 191866 effective words/s
2024-06-24 12:19:40,165 EPOCH 6 - PROGRESS: at 5.82% examples, 188245 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:41,173 EPOCH 6 - PROGRESS: at 12.63% examples, 202797 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:42,276 EPOCH 6 - PROGRESS: at 18.00% examples, 195221 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:43,285 EPOCH 6 - PROGRESS: at 23.77% examples, 198201 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:44,396 EPOCH 6 - PROGRESS: at 29.65% examples, 196229 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:45,477 EPOCH 6 - PROGRESS: at 35.75% examples, 197480 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:46,486 EPOCH 6 - PROGRESS: at 41.41% examples, 197512 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:47,487 EPOCH 6 - PROGRESS: at 46.39% examples, 195418 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:48,491 EPOCH 6 - PROGRESS: at 52.05% examples, 194735 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:49,504 EPOCH 6 - PROGRESS: at 56.65% examples, 193038 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:50,523 EPOCH 6 - PROGRESS: at 61.75% examples, 192422 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:51,565 EPOCH 6 - PROGRESS: at 66.99% examples, 193124 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:52,657 EPOCH 6 - PROGRESS: at 72.10% examples, 192302 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:53,692 EPOCH 6 - PROGRESS: at 77.00% examples, 192275 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:54,773 EPOCH 6 - PROGRESS: at 82.68% examples, 191688 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:55,820 EPOCH 6 - PROGRESS: at 89.98% examples, 192253 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:19:56,826 EPOCH 6 - PROGRESS: at 96.14% examples, 192083 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:57,434 EPOCH 6: training on 3499793 raw words (3519618 effective words) took 18.3s, 191990 effective words/s
2024-06-24 12:19:58,445 EPOCH 7 - PROGRESS: at 5.00% examples, 168988 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:19:59,459 EPOCH 7 - PROGRESS: at 10.84% examples, 182934 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:00,482 EPOCH 7 - PROGRESS: at 16.52% examples, 187125 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:01,544 EPOCH 7 - PROGRESS: at 22.39% examples, 189801 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:02,550 EPOCH 7 - PROGRESS: at 27.99% examples, 191448 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:03,605 EPOCH 7 - PROGRESS: at 33.26% examples, 189503 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:04,690 EPOCH 7 - PROGRESS: at 39.11% examples, 190088 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:05,756 EPOCH 7 - PROGRESS: at 45.01% examples, 190962 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:06,785 EPOCH 7 - PROGRESS: at 50.56% examples, 190247 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:07,788 EPOCH 7 - PROGRESS: at 55.91% examples, 191124 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:08,796 EPOCH 7 - PROGRESS: at 60.75% examples, 189971 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:09,882 EPOCH 7 - PROGRESS: at 66.02% examples, 190205 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:10,943 EPOCH 7 - PROGRESS: at 71.14% examples, 190051 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:11,978 EPOCH 7 - PROGRESS: at 75.73% examples, 189512 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:12,982 EPOCH 7 - PROGRESS: at 80.82% examples, 190020 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:13,983 EPOCH 7 - PROGRESS: at 87.67% examples, 190635 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:15,065 EPOCH 7 - PROGRESS: at 94.31% examples, 189716 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:15,965 EPOCH 7: training on 3499793 raw words (3519516 effective words) took 18.5s, 189961 effective words/s
2024-06-24 12:20:16,983 EPOCH 8 - PROGRESS: at 5.45% examples, 187516 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:18,054 EPOCH 8 - PROGRESS: at 11.97% examples, 191861 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:19,074 EPOCH 8 - PROGRESS: at 17.46% examples, 193250 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:20,078 EPOCH 8 - PROGRESS: at 23.21% examples, 196957 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:21,166 EPOCH 8 - PROGRESS: at 29.10% examples, 196041 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:22,268 EPOCH 8 - PROGRESS: at 35.48% examples, 198257 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:23,288 EPOCH 8 - PROGRESS: at 41.70% examples, 200651 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:24,366 EPOCH 8 - PROGRESS: at 48.01% examples, 201106 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:25,431 EPOCH 8 - PROGRESS: at 54.40% examples, 202748 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:26,466 EPOCH 8 - PROGRESS: at 59.67% examples, 201755 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:27,487 EPOCH 8 - PROGRESS: at 65.28% examples, 202907 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:28,500 EPOCH 8 - PROGRESS: at 70.63% examples, 203252 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:29,530 EPOCH 8 - PROGRESS: at 75.73% examples, 203196 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:30,639 EPOCH 8 - PROGRESS: at 82.03% examples, 203400 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:31,747 EPOCH 8 - PROGRESS: at 90.01% examples, 203718 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:32,752 EPOCH 8 - PROGRESS: at 97.27% examples, 204637 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:33,123 EPOCH 8: training on 3499793 raw words (3519477 effective words) took 17.2s, 205179 effective words/s
2024-06-24 12:20:34,136 EPOCH 9 - PROGRESS: at 5.82% examples, 198272 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:35,180 EPOCH 9 - PROGRESS: at 11.97% examples, 194760 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:36,196 EPOCH 9 - PROGRESS: at 18.23% examples, 205162 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:37,206 EPOCH 9 - PROGRESS: at 23.77% examples, 203259 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:38,216 EPOCH 9 - PROGRESS: at 29.37% examples, 202161 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:39,281 EPOCH 9 - PROGRESS: at 35.23% examples, 201307 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:40,336 EPOCH 9 - PROGRESS: at 41.10% examples, 200923 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:41,371 EPOCH 9 - PROGRESS: at 47.35% examples, 202419 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:42,406 EPOCH 9 - PROGRESS: at 53.46% examples, 202428 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:43,427 EPOCH 9 - PROGRESS: at 59.11% examples, 203670 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:44,448 EPOCH 9 - PROGRESS: at 64.30% examples, 202906 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:45,500 EPOCH 9 - PROGRESS: at 69.58% examples, 202616 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:46,514 EPOCH 9 - PROGRESS: at 74.54% examples, 202104 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:47,535 EPOCH 9 - PROGRESS: at 79.49% examples, 201605 words/s, in_qsize 7, out_qsize 0
2024-06-24 12:20:48,537 EPOCH 9 - PROGRESS: at 85.73% examples, 200781 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:49,616 EPOCH 9 - PROGRESS: at 92.05% examples, 198561 words/s, in_qsize 8, out_qsize 0
2024-06-24 12:20:50,658 EPOCH 9 - PROGRESS: at 98.48% examples, 198184 words/s, in_qsize 5, out_qsize 0
2024-06-24 12:20:50,825 EPOCH 9: training on 3499793 raw words (3519508 effective words) took 17.7s, 198861 effective words/s
2024-06-24 12:20:50,826 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35196036 effective words) took 183.5s, 191818 effective words/s', 'datetime': '2024-06-24T12:20:50.826249', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 12:27:30,986 ==================================================
2024-06-24 12:27:30,988 Training BERT + Doc2Vec features with Dimension-2048...
2024-06-24 12:27:31,951 Epoch [1/8], Batch [1/748], Loss: 1.6222
2024-06-24 12:28:20,745 Epoch [1/8], Batch [51/748], Loss: 1.5129
2024-06-24 12:29:10,638 Epoch [1/8], Batch [101/748], Loss: 1.3790
2024-06-24 12:30:00,918 Epoch [1/8], Batch [151/748], Loss: 1.1721
2024-06-24 12:30:51,301 Epoch [1/8], Batch [201/748], Loss: 1.1252
2024-06-24 12:31:41,717 Epoch [1/8], Batch [251/748], Loss: 0.9026
2024-06-24 12:32:32,140 Epoch [1/8], Batch [301/748], Loss: 1.1373
2024-06-24 12:33:22,756 Epoch [1/8], Batch [351/748], Loss: 0.8949
2024-06-24 12:34:13,182 Epoch [1/8], Batch [401/748], Loss: 0.8472
2024-06-24 12:35:03,536 Epoch [1/8], Batch [451/748], Loss: 1.0034
2024-06-24 12:35:53,877 Epoch [1/8], Batch [501/748], Loss: 0.8905
2024-06-24 12:36:44,335 Epoch [1/8], Batch [551/748], Loss: 0.8780
2024-06-24 12:37:34,791 Epoch [1/8], Batch [601/748], Loss: 0.7678
2024-06-24 12:38:25,054 Epoch [1/8], Batch [651/748], Loss: 0.8755
2024-06-24 12:39:15,669 Epoch [1/8], Batch [701/748], Loss: 0.9131
2024-06-24 12:40:02,562 Epoch 1/8, Train Loss: 1.0556, Train Accuracy: 0.5554
2024-06-24 12:41:21,876 Epoch 1/8, Val Loss: 0.8833, Val Accuracy: 0.6096
2024-06-24 12:41:22,902 Epoch [2/8], Batch [1/748], Loss: 0.7718
2024-06-24 12:42:13,166 Epoch [2/8], Batch [51/748], Loss: 0.8092
2024-06-24 12:43:03,624 Epoch [2/8], Batch [101/748], Loss: 0.9326
2024-06-24 12:43:53,997 Epoch [2/8], Batch [151/748], Loss: 0.8642
2024-06-24 12:44:44,324 Epoch [2/8], Batch [201/748], Loss: 0.7739
2024-06-24 12:45:34,742 Epoch [2/8], Batch [251/748], Loss: 0.7314
2024-06-24 12:46:25,158 Epoch [2/8], Batch [301/748], Loss: 0.9242
2024-06-24 12:47:15,514 Epoch [2/8], Batch [351/748], Loss: 0.7212
2024-06-24 12:48:05,915 Epoch [2/8], Batch [401/748], Loss: 0.7350
2024-06-24 12:48:56,215 Epoch [2/8], Batch [451/748], Loss: 0.6922
2024-06-24 12:49:46,697 Epoch [2/8], Batch [501/748], Loss: 0.8019
2024-06-24 12:50:37,115 Epoch [2/8], Batch [551/748], Loss: 0.7104
2024-06-24 12:51:27,426 Epoch [2/8], Batch [601/748], Loss: 0.5730
2024-06-24 12:52:17,812 Epoch [2/8], Batch [651/748], Loss: 0.5974
2024-06-24 12:53:08,273 Epoch [2/8], Batch [701/748], Loss: 0.8720
2024-06-24 12:53:55,233 Epoch 2/8, Train Loss: 0.7990, Train Accuracy: 0.6439
2024-06-24 12:55:14,765 Epoch 2/8, Val Loss: 0.8434, Val Accuracy: 0.6221
2024-06-24 12:55:15,764 Epoch [3/8], Batch [1/748], Loss: 0.6463
2024-06-24 12:56:05,890 Epoch [3/8], Batch [51/748], Loss: 0.5882
2024-06-24 12:56:56,316 Epoch [3/8], Batch [101/748], Loss: 0.8338
2024-06-24 12:57:46,817 Epoch [3/8], Batch [151/748], Loss: 0.6088
2024-06-24 12:58:37,162 Epoch [3/8], Batch [201/748], Loss: 0.6829
2024-06-24 12:59:27,651 Epoch [3/8], Batch [251/748], Loss: 0.9186
2024-06-24 13:00:18,048 Epoch [3/8], Batch [301/748], Loss: 0.6308
2024-06-24 13:01:08,989 Epoch [3/8], Batch [351/748], Loss: 0.8999
2024-06-24 13:02:00,001 Epoch [3/8], Batch [401/748], Loss: 0.7024
2024-06-24 13:02:51,234 Epoch [3/8], Batch [451/748], Loss: 0.6504
2024-06-24 13:03:42,481 Epoch [3/8], Batch [501/748], Loss: 0.7017
2024-06-24 13:04:33,205 Epoch [3/8], Batch [551/748], Loss: 0.8240
2024-06-24 13:05:23,912 Epoch [3/8], Batch [601/748], Loss: 0.5512
2024-06-24 13:06:14,491 Epoch [3/8], Batch [651/748], Loss: 0.7253
2024-06-24 13:07:05,167 Epoch [3/8], Batch [701/748], Loss: 0.5055
2024-06-24 13:07:52,298 Epoch 3/8, Train Loss: 0.6971, Train Accuracy: 0.6875
2024-06-24 13:09:12,118 Epoch 3/8, Val Loss: 0.8416, Val Accuracy: 0.6315
2024-06-24 13:09:13,125 Epoch [4/8], Batch [1/748], Loss: 0.7580
2024-06-24 13:10:03,499 Epoch [4/8], Batch [51/748], Loss: 0.5940
2024-06-24 13:10:53,950 Epoch [4/8], Batch [101/748], Loss: 0.7730
2024-06-24 13:11:44,484 Epoch [4/8], Batch [151/748], Loss: 0.5189
2024-06-24 13:12:34,964 Epoch [4/8], Batch [201/748], Loss: 0.6231
2024-06-24 13:13:25,570 Epoch [4/8], Batch [251/748], Loss: 0.5634
2024-06-24 13:14:16,173 Epoch [4/8], Batch [301/748], Loss: 0.5196
2024-06-24 13:15:06,665 Epoch [4/8], Batch [351/748], Loss: 0.5173
2024-06-24 13:15:57,112 Epoch [4/8], Batch [401/748], Loss: 0.5323
2024-06-24 13:16:47,579 Epoch [4/8], Batch [451/748], Loss: 0.7993
2024-06-24 13:17:38,085 Epoch [4/8], Batch [501/748], Loss: 0.5571
2024-06-24 13:18:28,721 Epoch [4/8], Batch [551/748], Loss: 0.6405
2024-06-24 13:19:19,144 Epoch [4/8], Batch [601/748], Loss: 0.5552
2024-06-24 13:20:09,573 Epoch [4/8], Batch [651/748], Loss: 0.5546
2024-06-24 13:20:59,986 Epoch [4/8], Batch [701/748], Loss: 0.4216
2024-06-24 13:21:47,416 Epoch 4/8, Train Loss: 0.6016, Train Accuracy: 0.7297
2024-06-24 13:23:08,184 Epoch 4/8, Val Loss: 0.9196, Val Accuracy: 0.6267
2024-06-24 13:23:09,199 Epoch [5/8], Batch [1/748], Loss: 0.5994
2024-06-24 13:23:59,836 Epoch [5/8], Batch [51/748], Loss: 0.4082
2024-06-24 13:24:50,462 Epoch [5/8], Batch [101/748], Loss: 0.4255
2024-06-24 13:25:41,372 Epoch [5/8], Batch [151/748], Loss: 0.7532
2024-06-24 13:26:32,051 Epoch [5/8], Batch [201/748], Loss: 0.5449
2024-06-24 13:27:22,685 Epoch [5/8], Batch [251/748], Loss: 0.3069
2024-06-24 13:28:13,265 Epoch [5/8], Batch [301/748], Loss: 0.4202
2024-06-24 13:29:04,016 Epoch [5/8], Batch [351/748], Loss: 0.6484
2024-06-24 13:29:54,681 Epoch [5/8], Batch [401/748], Loss: 0.3296
2024-06-24 13:30:45,353 Epoch [5/8], Batch [451/748], Loss: 0.7743
2024-06-24 13:31:35,963 Epoch [5/8], Batch [501/748], Loss: 0.5529
2024-06-24 13:32:26,687 Epoch [5/8], Batch [551/748], Loss: 0.5316
2024-06-24 13:33:17,689 Epoch [5/8], Batch [601/748], Loss: 0.3239
2024-06-24 13:34:08,212 Epoch [5/8], Batch [651/748], Loss: 0.4125
2024-06-24 13:34:59,138 Epoch [5/8], Batch [701/748], Loss: 0.3547
2024-06-24 13:35:46,787 Epoch 5/8, Train Loss: 0.5207, Train Accuracy: 0.7660
2024-06-24 13:37:08,065 Epoch 5/8, Val Loss: 0.9329, Val Accuracy: 0.6353
2024-06-24 13:37:09,101 Epoch [6/8], Batch [1/748], Loss: 0.5992
2024-06-24 13:37:59,805 Epoch [6/8], Batch [51/748], Loss: 0.4964
2024-06-24 13:38:50,809 Epoch [6/8], Batch [101/748], Loss: 0.4314
2024-06-24 13:39:42,453 Epoch [6/8], Batch [151/748], Loss: 0.2347
2024-06-24 13:40:33,582 Epoch [6/8], Batch [201/748], Loss: 0.3450
2024-06-24 13:41:25,372 Epoch [6/8], Batch [251/748], Loss: 0.4594
2024-06-24 13:42:16,696 Epoch [6/8], Batch [301/748], Loss: 0.3317
2024-06-24 13:43:07,996 Epoch [6/8], Batch [351/748], Loss: 0.5127
2024-06-24 13:43:58,741 Epoch [6/8], Batch [401/748], Loss: 0.6040
2024-06-24 13:44:49,515 Epoch [6/8], Batch [451/748], Loss: 0.5443
2024-06-24 13:45:40,493 Epoch [6/8], Batch [501/748], Loss: 0.4200
2024-06-24 13:46:31,384 Epoch [6/8], Batch [551/748], Loss: 0.5304
2024-06-24 13:47:22,233 Epoch [6/8], Batch [601/748], Loss: 0.3442
2024-06-24 13:48:12,993 Epoch [6/8], Batch [651/748], Loss: 0.4111
2024-06-24 13:49:03,880 Epoch [6/8], Batch [701/748], Loss: 0.3753
2024-06-24 13:49:51,302 Epoch 6/8, Train Loss: 0.4462, Train Accuracy: 0.7981
2024-06-24 13:51:11,849 Epoch 6/8, Val Loss: 0.9411, Val Accuracy: 0.6571
2024-06-24 13:51:12,849 Epoch [7/8], Batch [1/748], Loss: 0.5381
2024-06-24 13:52:03,772 Epoch [7/8], Batch [51/748], Loss: 0.3718
2024-06-24 13:52:54,881 Epoch [7/8], Batch [101/748], Loss: 0.3352
2024-06-24 13:53:46,028 Epoch [7/8], Batch [151/748], Loss: 0.3648
2024-06-24 13:54:36,968 Epoch [7/8], Batch [201/748], Loss: 0.3441
2024-06-24 13:55:28,038 Epoch [7/8], Batch [251/748], Loss: 0.4159
2024-06-24 13:56:19,041 Epoch [7/8], Batch [301/748], Loss: 0.2618
2024-06-24 13:57:09,799 Epoch [7/8], Batch [351/748], Loss: 0.3308
2024-06-24 13:58:00,452 Epoch [7/8], Batch [401/748], Loss: 0.3186
2024-06-24 13:58:50,996 Epoch [7/8], Batch [451/748], Loss: 0.4919
2024-06-24 13:59:41,846 Epoch [7/8], Batch [501/748], Loss: 0.2336
2024-06-24 14:00:32,387 Epoch [7/8], Batch [551/748], Loss: 0.5465
2024-06-24 14:01:23,420 Epoch [7/8], Batch [601/748], Loss: 0.5918
2024-06-24 14:02:14,135 Epoch [7/8], Batch [651/748], Loss: 0.5078
2024-06-24 14:03:05,385 Epoch [7/8], Batch [701/748], Loss: 0.2252
2024-06-24 14:03:53,224 Epoch 7/8, Train Loss: 0.3822, Train Accuracy: 0.8318
2024-06-24 14:05:14,962 Epoch 7/8, Val Loss: 1.0800, Val Accuracy: 0.6486
2024-06-24 14:05:15,957 Epoch [8/8], Batch [1/748], Loss: 0.3041
2024-06-24 14:06:06,744 Epoch [8/8], Batch [51/748], Loss: 0.2709
2024-06-24 14:06:57,726 Epoch [8/8], Batch [101/748], Loss: 0.2118
2024-06-24 14:07:48,863 Epoch [8/8], Batch [151/748], Loss: 0.4266
2024-06-24 14:08:40,028 Epoch [8/8], Batch [201/748], Loss: 0.3413
2024-06-24 14:09:31,112 Epoch [8/8], Batch [251/748], Loss: 0.4061
2024-06-24 14:10:21,911 Epoch [8/8], Batch [301/748], Loss: 0.1882
2024-06-24 14:11:12,993 Epoch [8/8], Batch [351/748], Loss: 0.2765
2024-06-24 14:12:04,094 Epoch [8/8], Batch [401/748], Loss: 0.2198
2024-06-24 14:12:54,927 Epoch [8/8], Batch [451/748], Loss: 0.2160
2024-06-24 14:13:46,190 Epoch [8/8], Batch [501/748], Loss: 0.4003
2024-06-24 14:14:37,361 Epoch [8/8], Batch [551/748], Loss: 0.3103
2024-06-24 14:15:28,363 Epoch [8/8], Batch [601/748], Loss: 0.1887
2024-06-24 14:16:18,997 Epoch [8/8], Batch [651/748], Loss: 0.3624
2024-06-24 14:17:09,640 Epoch [8/8], Batch [701/748], Loss: 0.2135
2024-06-24 14:17:56,949 Epoch 8/8, Train Loss: 0.3240, Train Accuracy: 0.8634
2024-06-24 14:19:17,463 Epoch 8/8, Val Loss: 1.0107, Val Accuracy: 0.6698
2024-06-24 14:19:17,465 Training finished!
2024-06-24 14:19:17,465 ==================================================
2024-06-24 14:19:42,145 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d1024,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T14:19:42.145418', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 14:19:42,145 collecting all words and their counts
2024-06-24 14:19:42,145 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 14:19:42,403 PROGRESS: at example #10000, processed 1168609 words (4534019 words/s), 72028 word types, 0 tags
2024-06-24 14:19:42,676 PROGRESS: at example #20000, processed 2388715 words (4476260 words/s), 103898 word types, 0 tags
2024-06-24 14:19:42,905 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 14:19:42,905 Creating a fresh vocabulary
2024-06-24 14:19:43,329 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T14:19:43.329040', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 14:19:43,329 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T14:19:43.329245', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 14:19:44,051 deleting the raw counts dictionary of 133984 items
2024-06-24 14:19:44,053 sample=0.001 downsamples 6 most-common words
2024-06-24 14:19:44,053 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T14:19:44.053659', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 14:19:45,234 estimated required memory for 133984 words and 1024 dimensions: 1164610408 bytes
2024-06-24 14:19:45,234 resetting layer weights
2024-06-24 14:19:46,764 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 1024 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T14:19:46.764044', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 14:19:47,770 EPOCH 0 - PROGRESS: at 6.10% examples, 209583 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:48,777 EPOCH 0 - PROGRESS: at 15.74% examples, 268651 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:19:49,794 EPOCH 0 - PROGRESS: at 24.89% examples, 287148 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:50,824 EPOCH 0 - PROGRESS: at 33.54% examples, 290625 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:19:51,843 EPOCH 0 - PROGRESS: at 41.65% examples, 289381 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:52,897 EPOCH 0 - PROGRESS: at 50.26% examples, 288510 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:53,953 EPOCH 0 - PROGRESS: at 58.64% examples, 289202 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:19:55,001 EPOCH 0 - PROGRESS: at 66.53% examples, 289935 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:56,032 EPOCH 0 - PROGRESS: at 74.25% examples, 290976 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:57,106 EPOCH 0 - PROGRESS: at 82.68% examples, 290551 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:58,160 EPOCH 0 - PROGRESS: at 93.39% examples, 290923 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:19:58,813 EPOCH 0: training on 3499793 raw words (3519546 effective words) took 12.0s, 292204 effective words/s
2024-06-24 14:19:59,833 EPOCH 1 - PROGRESS: at 8.44% examples, 285367 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:00,898 EPOCH 1 - PROGRESS: at 17.46% examples, 288201 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:01,917 EPOCH 1 - PROGRESS: at 26.31% examples, 296402 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:02,953 EPOCH 1 - PROGRESS: at 34.67% examples, 294619 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:04,020 EPOCH 1 - PROGRESS: at 43.38% examples, 293767 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:05,046 EPOCH 1 - PROGRESS: at 52.39% examples, 295087 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:06,058 EPOCH 1 - PROGRESS: at 60.24% examples, 295210 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:07,072 EPOCH 1 - PROGRESS: at 67.81% examples, 295188 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:08,085 EPOCH 1 - PROGRESS: at 75.02% examples, 294094 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:09,113 EPOCH 1 - PROGRESS: at 83.53% examples, 293707 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:10,156 EPOCH 1 - PROGRESS: at 94.31% examples, 294929 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:10,676 EPOCH 1: training on 3499793 raw words (3519633 effective words) took 11.9s, 296779 effective words/s
2024-06-24 14:20:11,688 EPOCH 2 - PROGRESS: at 9.25% examples, 307391 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:12,704 EPOCH 2 - PROGRESS: at 18.49% examples, 316046 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:13,713 EPOCH 2 - PROGRESS: at 27.43% examples, 316145 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:14,751 EPOCH 2 - PROGRESS: at 36.60% examples, 316563 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:15,769 EPOCH 2 - PROGRESS: at 45.24% examples, 314109 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:16,790 EPOCH 2 - PROGRESS: at 53.96% examples, 310682 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:17,836 EPOCH 2 - PROGRESS: at 61.75% examples, 307097 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:18,852 EPOCH 2 - PROGRESS: at 69.11% examples, 304311 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:19,928 EPOCH 2 - PROGRESS: at 76.24% examples, 300130 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:20,932 EPOCH 2 - PROGRESS: at 84.94% examples, 298884 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:21,934 EPOCH 2 - PROGRESS: at 94.31% examples, 297165 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:22,539 EPOCH 2: training on 3499793 raw words (3519483 effective words) took 11.9s, 296784 effective words/s
2024-06-24 14:20:23,561 EPOCH 3 - PROGRESS: at 8.95% examples, 294434 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:24,589 EPOCH 3 - PROGRESS: at 17.47% examples, 292986 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:25,623 EPOCH 3 - PROGRESS: at 25.46% examples, 288556 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:26,642 EPOCH 3 - PROGRESS: at 33.26% examples, 285082 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:27,700 EPOCH 3 - PROGRESS: at 41.41% examples, 282765 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:28,702 EPOCH 3 - PROGRESS: at 49.27% examples, 280626 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:29,730 EPOCH 3 - PROGRESS: at 56.64% examples, 279368 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:30,816 EPOCH 3 - PROGRESS: at 64.05% examples, 276436 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:31,868 EPOCH 3 - PROGRESS: at 71.38% examples, 276283 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:32,882 EPOCH 3 - PROGRESS: at 77.98% examples, 275170 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:33,916 EPOCH 3 - PROGRESS: at 87.10% examples, 275564 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:34,941 EPOCH 3 - PROGRESS: at 97.27% examples, 276998 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:35,195 EPOCH 3: training on 3499793 raw words (3519524 effective words) took 12.7s, 278154 effective words/s
2024-06-24 14:20:36,210 EPOCH 4 - PROGRESS: at 8.44% examples, 286645 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:37,211 EPOCH 4 - PROGRESS: at 16.80% examples, 288057 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:38,239 EPOCH 4 - PROGRESS: at 25.18% examples, 289054 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:39,279 EPOCH 4 - PROGRESS: at 33.54% examples, 288915 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:40,304 EPOCH 4 - PROGRESS: at 41.41% examples, 285671 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:41,339 EPOCH 4 - PROGRESS: at 50.02% examples, 286389 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:42,345 EPOCH 4 - PROGRESS: at 58.64% examples, 290755 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:43,351 EPOCH 4 - PROGRESS: at 66.99% examples, 295248 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:44,379 EPOCH 4 - PROGRESS: at 74.79% examples, 295826 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:45,396 EPOCH 4 - PROGRESS: at 84.29% examples, 298529 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:46,444 EPOCH 4 - PROGRESS: at 94.87% examples, 299165 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:46,977 EPOCH 4: training on 3499793 raw words (3519547 effective words) took 11.8s, 298828 effective words/s
2024-06-24 14:20:47,980 EPOCH 5 - PROGRESS: at 8.18% examples, 279829 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:48,988 EPOCH 5 - PROGRESS: at 17.20% examples, 293632 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:50,016 EPOCH 5 - PROGRESS: at 25.46% examples, 292693 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:51,028 EPOCH 5 - PROGRESS: at 33.82% examples, 293620 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:52,060 EPOCH 5 - PROGRESS: at 42.18% examples, 293013 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:53,086 EPOCH 5 - PROGRESS: at 50.80% examples, 292840 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:54,130 EPOCH 5 - PROGRESS: at 59.11% examples, 293377 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:55,151 EPOCH 5 - PROGRESS: at 66.99% examples, 294550 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:20:56,163 EPOCH 5 - PROGRESS: at 74.79% examples, 295710 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:57,183 EPOCH 5 - PROGRESS: at 82.68% examples, 294405 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:58,256 EPOCH 5 - PROGRESS: at 93.38% examples, 293916 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:20:58,897 EPOCH 5: training on 3499793 raw words (3519471 effective words) took 11.9s, 295328 effective words/s
2024-06-24 14:20:59,904 EPOCH 6 - PROGRESS: at 8.75% examples, 299245 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:00,933 EPOCH 6 - PROGRESS: at 18.00% examples, 305007 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:01,990 EPOCH 6 - PROGRESS: at 26.86% examples, 303947 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:02,997 EPOCH 6 - PROGRESS: at 35.20% examples, 302431 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:04,059 EPOCH 6 - PROGRESS: at 43.10% examples, 294412 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:05,076 EPOCH 6 - PROGRESS: at 52.05% examples, 296103 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:06,113 EPOCH 6 - PROGRESS: at 60.24% examples, 296405 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:07,121 EPOCH 6 - PROGRESS: at 67.81% examples, 296476 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:08,127 EPOCH 6 - PROGRESS: at 74.54% examples, 293263 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:09,191 EPOCH 6 - PROGRESS: at 82.68% examples, 291922 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:10,205 EPOCH 6 - PROGRESS: at 92.70% examples, 291426 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:10,969 EPOCH 6: training on 3499793 raw words (3519541 effective words) took 12.1s, 291653 effective words/s
2024-06-24 14:21:11,974 EPOCH 7 - PROGRESS: at 9.25% examples, 309633 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:12,993 EPOCH 7 - PROGRESS: at 17.73% examples, 301739 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:13,999 EPOCH 7 - PROGRESS: at 26.58% examples, 306917 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:15,022 EPOCH 7 - PROGRESS: at 36.05% examples, 313398 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:16,076 EPOCH 7 - PROGRESS: at 45.65% examples, 315232 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:17,080 EPOCH 7 - PROGRESS: at 54.87% examples, 317359 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:18,092 EPOCH 7 - PROGRESS: at 63.24% examples, 317052 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:19,124 EPOCH 7 - PROGRESS: at 70.63% examples, 312464 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:20,135 EPOCH 7 - PROGRESS: at 77.75% examples, 309424 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:21,149 EPOCH 7 - PROGRESS: at 86.02% examples, 305021 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:22,154 EPOCH 7 - PROGRESS: at 94.87% examples, 300881 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:22,739 EPOCH 7: training on 3499793 raw words (3519490 effective words) took 11.8s, 299134 effective words/s
2024-06-24 14:21:23,753 EPOCH 8 - PROGRESS: at 8.44% examples, 286932 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:24,755 EPOCH 8 - PROGRESS: at 17.73% examples, 303054 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:25,780 EPOCH 8 - PROGRESS: at 26.31% examples, 302524 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:26,785 EPOCH 8 - PROGRESS: at 34.67% examples, 301533 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:27,832 EPOCH 8 - PROGRESS: at 43.10% examples, 298364 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:28,857 EPOCH 8 - PROGRESS: at 51.58% examples, 295754 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:29,911 EPOCH 8 - PROGRESS: at 59.67% examples, 295436 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:30,921 EPOCH 8 - PROGRESS: at 67.29% examples, 295542 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:31,976 EPOCH 8 - PROGRESS: at 74.50% examples, 293020 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:32,986 EPOCH 8 - PROGRESS: at 82.68% examples, 293251 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:33,992 EPOCH 8 - PROGRESS: at 92.96% examples, 293739 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:34,655 EPOCH 8: training on 3499793 raw words (3519549 effective words) took 11.9s, 295450 effective words/s
2024-06-24 14:21:35,662 EPOCH 9 - PROGRESS: at 8.75% examples, 299096 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:36,668 EPOCH 9 - PROGRESS: at 18.49% examples, 318284 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:37,681 EPOCH 9 - PROGRESS: at 27.43% examples, 317260 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:38,702 EPOCH 9 - PROGRESS: at 35.20% examples, 306395 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:39,728 EPOCH 9 - PROGRESS: at 43.67% examples, 303537 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:40,763 EPOCH 9 - PROGRESS: at 52.90% examples, 304448 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:41,769 EPOCH 9 - PROGRESS: at 61.28% examples, 306295 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:42,802 EPOCH 9 - PROGRESS: at 69.35% examples, 306642 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:43,809 EPOCH 9 - PROGRESS: at 77.24% examples, 307660 words/s, in_qsize 7, out_qsize 0
2024-06-24 14:21:44,815 EPOCH 9 - PROGRESS: at 87.10% examples, 308591 words/s, in_qsize 8, out_qsize 0
2024-06-24 14:21:45,824 EPOCH 9 - PROGRESS: at 98.15% examples, 310289 words/s, in_qsize 6, out_qsize 0
2024-06-24 14:21:45,949 EPOCH 9: training on 3499793 raw words (3519457 effective words) took 11.3s, 311720 effective words/s
2024-06-24 14:21:45,950 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195241 effective words) took 119.2s, 295297 effective words/s', 'datetime': '2024-06-24T14:21:45.950236', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 14:25:37,627 ==================================================
2024-06-24 14:25:37,627 Training BERT + Doc2Vec features with Dimension-1024...
2024-06-24 14:25:38,614 Epoch [1/8], Batch [1/748], Loss: 1.5997
2024-06-24 14:26:27,754 Epoch [1/8], Batch [51/748], Loss: 1.5483
2024-06-24 14:27:18,560 Epoch [1/8], Batch [101/748], Loss: 1.3779
2024-06-24 14:28:09,658 Epoch [1/8], Batch [151/748], Loss: 1.2899
2024-06-24 14:29:00,547 Epoch [1/8], Batch [201/748], Loss: 1.0747
2024-06-24 14:29:51,875 Epoch [1/8], Batch [251/748], Loss: 1.0843
2024-06-24 14:30:43,027 Epoch [1/8], Batch [301/748], Loss: 0.9810
2024-06-24 14:31:34,174 Epoch [1/8], Batch [351/748], Loss: 1.1237
2024-06-24 14:32:25,338 Epoch [1/8], Batch [401/748], Loss: 0.9895
2024-06-24 14:33:16,770 Epoch [1/8], Batch [451/748], Loss: 0.7654
2024-06-24 14:34:07,920 Epoch [1/8], Batch [501/748], Loss: 1.0610
2024-06-24 14:34:59,078 Epoch [1/8], Batch [551/748], Loss: 0.7782
2024-06-24 14:35:50,282 Epoch [1/8], Batch [601/748], Loss: 0.8934
2024-06-24 14:36:41,448 Epoch [1/8], Batch [651/748], Loss: 0.8972
2024-06-24 14:37:32,671 Epoch [1/8], Batch [701/748], Loss: 0.6695
2024-06-24 14:38:20,683 Epoch 1/8, Train Loss: 1.0764, Train Accuracy: 0.5401
2024-06-24 14:39:43,442 Epoch 1/8, Val Loss: 0.9222, Val Accuracy: 0.6058
2024-06-24 14:39:44,514 Epoch [2/8], Batch [1/748], Loss: 0.8818
2024-06-24 14:40:35,858 Epoch [2/8], Batch [51/748], Loss: 0.8940
2024-06-24 14:41:27,253 Epoch [2/8], Batch [101/748], Loss: 0.8819
2024-06-24 14:42:18,293 Epoch [2/8], Batch [151/748], Loss: 0.7991
2024-06-24 14:43:09,281 Epoch [2/8], Batch [201/748], Loss: 0.6176
2024-06-24 14:44:00,290 Epoch [2/8], Batch [251/748], Loss: 0.7712
2024-06-24 14:44:51,385 Epoch [2/8], Batch [301/748], Loss: 0.9012
2024-06-24 14:45:42,487 Epoch [2/8], Batch [351/748], Loss: 0.9283
2024-06-24 14:46:33,330 Epoch [2/8], Batch [401/748], Loss: 0.6628
2024-06-24 14:47:24,333 Epoch [2/8], Batch [451/748], Loss: 0.7929
2024-06-24 14:48:15,375 Epoch [2/8], Batch [501/748], Loss: 0.8645
2024-06-24 14:49:06,675 Epoch [2/8], Batch [551/748], Loss: 0.8844
2024-06-24 14:49:57,524 Epoch [2/8], Batch [601/748], Loss: 0.8585
2024-06-24 14:50:48,727 Epoch [2/8], Batch [651/748], Loss: 0.7068
2024-06-24 14:51:39,897 Epoch [2/8], Batch [701/748], Loss: 0.9660
2024-06-24 14:52:27,956 Epoch 2/8, Train Loss: 0.8216, Train Accuracy: 0.6358
2024-06-24 14:53:49,860 Epoch 2/8, Val Loss: 0.8256, Val Accuracy: 0.6357
2024-06-24 14:53:50,865 Epoch [3/8], Batch [1/748], Loss: 0.7057
2024-06-24 14:54:41,646 Epoch [3/8], Batch [51/748], Loss: 0.8428
2024-06-24 14:55:32,717 Epoch [3/8], Batch [101/748], Loss: 0.6197
2024-06-24 14:56:23,293 Epoch [3/8], Batch [151/748], Loss: 0.8276
2024-06-24 14:57:14,483 Epoch [3/8], Batch [201/748], Loss: 0.6608
2024-06-24 14:58:05,225 Epoch [3/8], Batch [251/748], Loss: 0.8598
2024-06-24 14:58:55,908 Epoch [3/8], Batch [301/748], Loss: 0.8384
2024-06-24 14:59:46,685 Epoch [3/8], Batch [351/748], Loss: 0.8807
2024-06-24 15:00:37,134 Epoch [3/8], Batch [401/748], Loss: 0.7043
2024-06-24 15:01:27,945 Epoch [3/8], Batch [451/748], Loss: 0.7086
2024-06-24 15:02:18,571 Epoch [3/8], Batch [501/748], Loss: 0.8588
2024-06-24 15:03:09,297 Epoch [3/8], Batch [551/748], Loss: 0.6094
2024-06-24 15:04:00,047 Epoch [3/8], Batch [601/748], Loss: 0.6414
2024-06-24 15:04:51,009 Epoch [3/8], Batch [651/748], Loss: 0.6879
2024-06-24 15:05:41,729 Epoch [3/8], Batch [701/748], Loss: 0.4783
2024-06-24 15:06:29,017 Epoch 3/8, Train Loss: 0.7133, Train Accuracy: 0.6839
2024-06-24 15:07:49,811 Epoch 3/8, Val Loss: 0.7919, Val Accuracy: 0.6549
2024-06-24 15:07:50,805 Epoch [4/8], Batch [1/748], Loss: 0.5289
2024-06-24 15:08:41,395 Epoch [4/8], Batch [51/748], Loss: 0.6235
2024-06-24 15:09:32,243 Epoch [4/8], Batch [101/748], Loss: 0.5712
2024-06-24 15:10:23,355 Epoch [4/8], Batch [151/748], Loss: 0.5123
2024-06-24 15:11:14,337 Epoch [4/8], Batch [201/748], Loss: 0.4744
2024-06-24 15:12:05,214 Epoch [4/8], Batch [251/748], Loss: 0.6283
2024-06-24 15:12:56,191 Epoch [4/8], Batch [301/748], Loss: 0.5236
2024-06-24 15:13:47,255 Epoch [4/8], Batch [351/748], Loss: 0.6778
2024-06-24 15:14:38,176 Epoch [4/8], Batch [401/748], Loss: 0.6356
2024-06-24 15:15:28,975 Epoch [4/8], Batch [451/748], Loss: 0.3746
2024-06-24 15:16:19,843 Epoch [4/8], Batch [501/748], Loss: 0.5882
2024-06-24 15:17:10,816 Epoch [4/8], Batch [551/748], Loss: 0.4375
2024-06-24 15:18:02,123 Epoch [4/8], Batch [601/748], Loss: 0.9400
2024-06-24 15:18:53,430 Epoch [4/8], Batch [651/748], Loss: 0.5283
2024-06-24 15:19:44,899 Epoch [4/8], Batch [701/748], Loss: 0.5854
2024-06-24 15:20:32,773 Epoch 4/8, Train Loss: 0.6209, Train Accuracy: 0.7272
2024-06-24 15:21:55,158 Epoch 4/8, Val Loss: 0.8389, Val Accuracy: 0.6544
2024-06-24 15:21:56,174 Epoch [5/8], Batch [1/748], Loss: 0.5128
2024-06-24 15:22:47,270 Epoch [5/8], Batch [51/748], Loss: 0.4827
2024-06-24 15:23:38,665 Epoch [5/8], Batch [101/748], Loss: 0.5495
2024-06-24 15:24:29,780 Epoch [5/8], Batch [151/748], Loss: 0.4341
2024-06-24 15:25:21,224 Epoch [5/8], Batch [201/748], Loss: 0.6144
2024-06-24 15:26:12,520 Epoch [5/8], Batch [251/748], Loss: 0.7586
2024-06-24 15:27:03,703 Epoch [5/8], Batch [301/748], Loss: 0.6078
2024-06-24 15:27:55,228 Epoch [5/8], Batch [351/748], Loss: 0.6220
2024-06-24 15:28:46,316 Epoch [5/8], Batch [401/748], Loss: 0.5301
2024-06-24 15:29:37,072 Epoch [5/8], Batch [451/748], Loss: 0.5703
2024-06-24 15:30:27,901 Epoch [5/8], Batch [501/748], Loss: 0.5059
2024-06-24 15:31:18,834 Epoch [5/8], Batch [551/748], Loss: 0.7196
2024-06-24 15:32:09,511 Epoch [5/8], Batch [601/748], Loss: 0.4539
2024-06-24 15:33:00,255 Epoch [5/8], Batch [651/748], Loss: 0.6439
2024-06-24 15:33:51,276 Epoch [5/8], Batch [701/748], Loss: 0.6447
2024-06-24 15:34:38,561 Epoch 5/8, Train Loss: 0.5259, Train Accuracy: 0.7684
2024-06-24 15:35:58,755 Epoch 5/8, Val Loss: 0.9687, Val Accuracy: 0.6323
2024-06-24 15:35:59,769 Epoch [6/8], Batch [1/748], Loss: 0.2937
2024-06-24 15:36:50,184 Epoch [6/8], Batch [51/748], Loss: 0.3083
2024-06-24 15:37:40,797 Epoch [6/8], Batch [101/748], Loss: 0.4143
2024-06-24 15:38:31,430 Epoch [6/8], Batch [151/748], Loss: 0.2979
2024-06-24 15:39:22,296 Epoch [6/8], Batch [201/748], Loss: 0.4811
2024-06-24 15:40:12,808 Epoch [6/8], Batch [251/748], Loss: 0.3202
2024-06-24 15:41:03,562 Epoch [6/8], Batch [301/748], Loss: 0.3065
2024-06-24 15:41:54,207 Epoch [6/8], Batch [351/748], Loss: 0.4327
2024-06-24 15:42:45,130 Epoch [6/8], Batch [401/748], Loss: 0.7573
2024-06-24 15:43:36,061 Epoch [6/8], Batch [451/748], Loss: 0.9211
2024-06-24 15:44:26,709 Epoch [6/8], Batch [501/748], Loss: 0.3947
2024-06-24 15:45:17,361 Epoch [6/8], Batch [551/748], Loss: 0.3987
2024-06-24 15:46:07,977 Epoch [6/8], Batch [601/748], Loss: 0.5849
2024-06-24 15:46:58,709 Epoch [6/8], Batch [651/748], Loss: 0.2319
2024-06-24 15:47:49,502 Epoch [6/8], Batch [701/748], Loss: 0.3675
2024-06-24 15:48:36,652 Epoch 6/8, Train Loss: 0.4366, Train Accuracy: 0.8119
2024-06-24 15:49:56,653 Epoch 6/8, Val Loss: 0.9873, Val Accuracy: 0.6581
2024-06-24 15:49:57,645 Epoch [7/8], Batch [1/748], Loss: 0.4239
2024-06-24 15:50:48,157 Epoch [7/8], Batch [51/748], Loss: 0.4070
2024-06-24 15:51:38,780 Epoch [7/8], Batch [101/748], Loss: 0.2404
2024-06-24 15:52:29,228 Epoch [7/8], Batch [151/748], Loss: 0.3022
2024-06-24 15:53:19,721 Epoch [7/8], Batch [201/748], Loss: 0.3119
2024-06-24 15:54:10,298 Epoch [7/8], Batch [251/748], Loss: 0.5131
2024-06-24 15:55:00,797 Epoch [7/8], Batch [301/748], Loss: 0.2762
2024-06-24 15:55:51,306 Epoch [7/8], Batch [351/748], Loss: 0.3484
2024-06-24 15:56:41,759 Epoch [7/8], Batch [401/748], Loss: 0.2887
2024-06-24 15:57:32,350 Epoch [7/8], Batch [451/748], Loss: 0.4204
2024-06-24 15:58:22,968 Epoch [7/8], Batch [501/748], Loss: 0.6182
2024-06-24 15:59:13,588 Epoch [7/8], Batch [551/748], Loss: 0.2465
2024-06-24 16:00:04,223 Epoch [7/8], Batch [601/748], Loss: 0.5630
2024-06-24 16:00:55,116 Epoch [7/8], Batch [651/748], Loss: 0.3277
2024-06-24 16:01:45,984 Epoch [7/8], Batch [701/748], Loss: 0.3740
2024-06-24 16:02:33,318 Epoch 7/8, Train Loss: 0.3681, Train Accuracy: 0.8427
2024-06-24 16:03:54,364 Epoch 7/8, Val Loss: 0.9516, Val Accuracy: 0.6706
2024-06-24 16:03:55,405 Epoch [8/8], Batch [1/748], Loss: 0.2397
2024-06-24 16:04:46,135 Epoch [8/8], Batch [51/748], Loss: 0.2197
2024-06-24 16:05:36,923 Epoch [8/8], Batch [101/748], Loss: 0.2945
2024-06-24 16:06:27,730 Epoch [8/8], Batch [151/748], Loss: 0.3302
2024-06-24 16:07:18,789 Epoch [8/8], Batch [201/748], Loss: 0.2989
2024-06-24 16:08:09,703 Epoch [8/8], Batch [251/748], Loss: 0.3038
2024-06-24 16:09:00,639 Epoch [8/8], Batch [301/748], Loss: 0.4300
2024-06-24 16:09:51,773 Epoch [8/8], Batch [351/748], Loss: 0.5911
2024-06-24 16:10:42,353 Epoch [8/8], Batch [401/748], Loss: 0.1801
2024-06-24 16:11:33,028 Epoch [8/8], Batch [451/748], Loss: 0.4850
2024-06-24 16:12:23,881 Epoch [8/8], Batch [501/748], Loss: 0.2761
2024-06-24 16:13:14,633 Epoch [8/8], Batch [551/748], Loss: 0.5142
2024-06-24 16:14:05,327 Epoch [8/8], Batch [601/748], Loss: 0.3542
2024-06-24 16:14:55,934 Epoch [8/8], Batch [651/748], Loss: 0.2739
2024-06-24 16:15:46,702 Epoch [8/8], Batch [701/748], Loss: 0.2536
2024-06-24 16:16:34,007 Epoch 8/8, Train Loss: 0.3089, Train Accuracy: 0.8735
2024-06-24 16:17:55,494 Epoch 8/8, Val Loss: 1.1044, Val Accuracy: 0.6567
2024-06-24 16:17:55,497 Training finished!
2024-06-24 16:17:55,497 ==================================================
2024-06-24 16:18:21,589 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d512,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T16:18:21.589249', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 16:18:21,589 collecting all words and their counts
2024-06-24 16:18:21,589 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 16:18:21,837 PROGRESS: at example #10000, processed 1168609 words (4708902 words/s), 72028 word types, 0 tags
2024-06-24 16:18:22,123 PROGRESS: at example #20000, processed 2388715 words (4272937 words/s), 103898 word types, 0 tags
2024-06-24 16:18:22,373 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 16:18:22,373 Creating a fresh vocabulary
2024-06-24 16:18:22,823 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T16:18:22.823419', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 16:18:22,823 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T16:18:22.823645', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 16:18:23,574 deleting the raw counts dictionary of 133984 items
2024-06-24 16:18:23,576 sample=0.001 downsamples 6 most-common words
2024-06-24 16:18:23,576 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T16:18:23.576787', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 16:18:24,833 estimated required memory for 133984 words and 512 dimensions: 615801704 bytes
2024-06-24 16:18:24,833 resetting layer weights
2024-06-24 16:18:25,243 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 512 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T16:18:25.243319', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 16:18:26,259 EPOCH 0 - PROGRESS: at 10.84% examples, 365312 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:27,269 EPOCH 0 - PROGRESS: at 23.49% examples, 405046 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:28,278 EPOCH 0 - PROGRESS: at 36.60% examples, 425215 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:29,281 EPOCH 0 - PROGRESS: at 50.26% examples, 438320 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:30,289 EPOCH 0 - PROGRESS: at 62.48% examples, 441798 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:31,302 EPOCH 0 - PROGRESS: at 74.25% examples, 445177 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:32,330 EPOCH 0 - PROGRESS: at 88.09% examples, 446726 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:33,081 EPOCH 0: training on 3499793 raw words (3519668 effective words) took 7.8s, 449270 effective words/s
2024-06-24 16:18:34,107 EPOCH 1 - PROGRESS: at 13.64% examples, 449827 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:35,117 EPOCH 1 - PROGRESS: at 26.58% examples, 457119 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:36,127 EPOCH 1 - PROGRESS: at 38.54% examples, 446565 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:37,141 EPOCH 1 - PROGRESS: at 51.58% examples, 445879 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:38,143 EPOCH 1 - PROGRESS: at 63.77% examples, 450210 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:39,156 EPOCH 1 - PROGRESS: at 75.73% examples, 453915 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:40,174 EPOCH 1 - PROGRESS: at 89.42% examples, 450560 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:40,938 EPOCH 1: training on 3499793 raw words (3519390 effective words) took 7.9s, 448168 effective words/s
2024-06-24 16:18:41,953 EPOCH 2 - PROGRESS: at 12.68% examples, 415283 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:42,962 EPOCH 2 - PROGRESS: at 24.05% examples, 415319 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:43,964 EPOCH 2 - PROGRESS: at 35.48% examples, 413216 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:44,966 EPOCH 2 - PROGRESS: at 48.24% examples, 422112 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:45,990 EPOCH 2 - PROGRESS: at 61.03% examples, 429445 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:47,030 EPOCH 2 - PROGRESS: at 73.03% examples, 434592 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:48,054 EPOCH 2 - PROGRESS: at 86.41% examples, 437859 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:48,907 EPOCH 2: training on 3499793 raw words (3519646 effective words) took 8.0s, 441877 effective words/s
2024-06-24 16:18:49,923 EPOCH 3 - PROGRESS: at 13.64% examples, 454139 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:50,948 EPOCH 3 - PROGRESS: at 27.43% examples, 470480 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:51,949 EPOCH 3 - PROGRESS: at 40.76% examples, 473454 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:52,959 EPOCH 3 - PROGRESS: at 54.62% examples, 476277 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:53,975 EPOCH 3 - PROGRESS: at 66.99% examples, 475206 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:54,979 EPOCH 3 - PROGRESS: at 77.47% examples, 465534 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:55,987 EPOCH 3 - PROGRESS: at 90.96% examples, 458430 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:18:56,641 EPOCH 3: training on 3499793 raw words (3519524 effective words) took 7.7s, 455276 effective words/s
2024-06-24 16:18:57,656 EPOCH 4 - PROGRESS: at 13.41% examples, 444596 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:58,664 EPOCH 4 - PROGRESS: at 26.58% examples, 459814 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:18:59,686 EPOCH 4 - PROGRESS: at 39.67% examples, 459724 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:00,710 EPOCH 4 - PROGRESS: at 53.46% examples, 461990 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:01,736 EPOCH 4 - PROGRESS: at 65.80% examples, 462865 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:02,750 EPOCH 4 - PROGRESS: at 77.24% examples, 461064 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:03,761 EPOCH 4 - PROGRESS: at 90.96% examples, 455811 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:04,415 EPOCH 4: training on 3499793 raw words (3519476 effective words) took 7.8s, 452895 effective words/s
2024-06-24 16:19:05,446 EPOCH 5 - PROGRESS: at 13.41% examples, 437861 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:06,484 EPOCH 5 - PROGRESS: at 26.58% examples, 449608 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:07,491 EPOCH 5 - PROGRESS: at 40.45% examples, 464959 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:08,494 EPOCH 5 - PROGRESS: at 53.71% examples, 463368 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:09,510 EPOCH 5 - PROGRESS: at 66.02% examples, 464844 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:10,527 EPOCH 5 - PROGRESS: at 78.25% examples, 467361 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:11,540 EPOCH 5 - PROGRESS: at 93.65% examples, 466808 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:11,935 EPOCH 5: training on 3499793 raw words (3519567 effective words) took 7.5s, 468239 effective words/s
2024-06-24 16:19:12,941 EPOCH 6 - PROGRESS: at 13.64% examples, 458071 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:13,979 EPOCH 6 - PROGRESS: at 27.71% examples, 474608 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:15,013 EPOCH 6 - PROGRESS: at 41.93% examples, 480708 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:16,022 EPOCH 6 - PROGRESS: at 55.40% examples, 479415 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:17,022 EPOCH 6 - PROGRESS: at 68.06% examples, 481264 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:18,032 EPOCH 6 - PROGRESS: at 79.99% examples, 479884 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:19,045 EPOCH 6 - PROGRESS: at 96.14% examples, 478957 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:19,270 EPOCH 6: training on 3499793 raw words (3519518 effective words) took 7.3s, 480005 effective words/s
2024-06-24 16:19:20,323 EPOCH 7 - PROGRESS: at 14.43% examples, 466324 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:21,337 EPOCH 7 - PROGRESS: at 27.71% examples, 469114 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:22,348 EPOCH 7 - PROGRESS: at 41.00% examples, 470937 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:23,364 EPOCH 7 - PROGRESS: at 54.62% examples, 471294 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:24,378 EPOCH 7 - PROGRESS: at 67.29% examples, 473380 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:25,392 EPOCH 7 - PROGRESS: at 79.49% examples, 474701 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:26,401 EPOCH 7 - PROGRESS: at 95.56% examples, 474776 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:26,676 EPOCH 7: training on 3499793 raw words (3519623 effective words) took 7.4s, 475402 effective words/s
2024-06-24 16:19:27,697 EPOCH 8 - PROGRESS: at 13.16% examples, 431945 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:28,735 EPOCH 8 - PROGRESS: at 26.86% examples, 456561 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:29,796 EPOCH 8 - PROGRESS: at 40.69% examples, 461355 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:30,837 EPOCH 8 - PROGRESS: at 54.40% examples, 461301 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:31,843 EPOCH 8 - PROGRESS: at 66.75% examples, 464135 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:32,864 EPOCH 8 - PROGRESS: at 78.74% examples, 464811 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:33,867 EPOCH 8 - PROGRESS: at 94.61% examples, 466664 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:34,203 EPOCH 8: training on 3499793 raw words (3519761 effective words) took 7.5s, 467759 effective words/s
2024-06-24 16:19:35,214 EPOCH 9 - PROGRESS: at 13.41% examples, 446818 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:36,256 EPOCH 9 - PROGRESS: at 27.13% examples, 462965 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:37,261 EPOCH 9 - PROGRESS: at 40.69% examples, 470975 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:38,287 EPOCH 9 - PROGRESS: at 54.62% examples, 472584 words/s, in_qsize 7, out_qsize 0
2024-06-24 16:19:39,292 EPOCH 9 - PROGRESS: at 67.55% examples, 477227 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:40,295 EPOCH 9 - PROGRESS: at 79.72% examples, 478756 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:41,329 EPOCH 9 - PROGRESS: at 95.89% examples, 476605 words/s, in_qsize 8, out_qsize 0
2024-06-24 16:19:41,571 EPOCH 9: training on 3499793 raw words (3519622 effective words) took 7.4s, 477950 effective words/s
2024-06-24 16:19:41,571 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195795 effective words) took 76.3s, 461111 effective words/s', 'datetime': '2024-06-24T16:19:41.571816', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 16:22:15,677 ==================================================
2024-06-24 16:22:15,678 Training BERT + Doc2Vec features with Dimension-512...
2024-06-24 16:22:16,650 Epoch [1/8], Batch [1/748], Loss: 1.5963
2024-06-24 16:23:06,204 Epoch [1/8], Batch [51/748], Loss: 1.4347
2024-06-24 16:23:56,588 Epoch [1/8], Batch [101/748], Loss: 1.2745
2024-06-24 16:24:47,130 Epoch [1/8], Batch [151/748], Loss: 1.2106
2024-06-24 16:25:38,191 Epoch [1/8], Batch [201/748], Loss: 1.1104
2024-06-24 16:26:29,219 Epoch [1/8], Batch [251/748], Loss: 0.9722
2024-06-24 16:27:20,371 Epoch [1/8], Batch [301/748], Loss: 1.0332
2024-06-24 16:28:11,218 Epoch [1/8], Batch [351/748], Loss: 0.9154
2024-06-24 16:29:02,112 Epoch [1/8], Batch [401/748], Loss: 1.1819
2024-06-24 16:29:53,183 Epoch [1/8], Batch [451/748], Loss: 0.8916
2024-06-24 16:30:43,809 Epoch [1/8], Batch [501/748], Loss: 0.8049
2024-06-24 16:31:34,616 Epoch [1/8], Batch [551/748], Loss: 1.0295
2024-06-24 16:32:25,456 Epoch [1/8], Batch [601/748], Loss: 0.7673
2024-06-24 16:33:16,422 Epoch [1/8], Batch [651/748], Loss: 1.0120
2024-06-24 16:34:07,552 Epoch [1/8], Batch [701/748], Loss: 0.8460
2024-06-24 16:34:55,293 Epoch 1/8, Train Loss: 1.0548, Train Accuracy: 0.5481
2024-06-24 16:36:17,075 Epoch 1/8, Val Loss: 0.9365, Val Accuracy: 0.5962
2024-06-24 16:36:18,075 Epoch [2/8], Batch [1/748], Loss: 0.8991
2024-06-24 16:37:08,848 Epoch [2/8], Batch [51/748], Loss: 0.9713
2024-06-24 16:37:59,452 Epoch [2/8], Batch [101/748], Loss: 1.1308
2024-06-24 16:38:50,423 Epoch [2/8], Batch [151/748], Loss: 0.8039
2024-06-24 16:39:41,335 Epoch [2/8], Batch [201/748], Loss: 0.9147
2024-06-24 16:40:32,070 Epoch [2/8], Batch [251/748], Loss: 0.9316
2024-06-24 16:41:22,852 Epoch [2/8], Batch [301/748], Loss: 0.7571
2024-06-24 16:42:13,388 Epoch [2/8], Batch [351/748], Loss: 0.8792
2024-06-24 16:43:04,127 Epoch [2/8], Batch [401/748], Loss: 0.6911
2024-06-24 16:43:54,944 Epoch [2/8], Batch [451/748], Loss: 0.8931
2024-06-24 16:44:45,727 Epoch [2/8], Batch [501/748], Loss: 0.7880
2024-06-24 16:45:36,753 Epoch [2/8], Batch [551/748], Loss: 0.7069
2024-06-24 16:46:27,380 Epoch [2/8], Batch [601/748], Loss: 0.8737
2024-06-24 16:47:18,090 Epoch [2/8], Batch [651/748], Loss: 0.6430
2024-06-24 16:48:08,909 Epoch [2/8], Batch [701/748], Loss: 0.8351
2024-06-24 16:48:56,112 Epoch 2/8, Train Loss: 0.8149, Train Accuracy: 0.6390
2024-06-24 16:50:16,859 Epoch 2/8, Val Loss: 0.8614, Val Accuracy: 0.6240
2024-06-24 16:50:17,900 Epoch [3/8], Batch [1/748], Loss: 0.6552
2024-06-24 16:51:08,575 Epoch [3/8], Batch [51/748], Loss: 0.6477
2024-06-24 16:51:59,055 Epoch [3/8], Batch [101/748], Loss: 0.6669
2024-06-24 16:52:49,898 Epoch [3/8], Batch [151/748], Loss: 0.6665
2024-06-24 16:53:40,780 Epoch [3/8], Batch [201/748], Loss: 0.8734
2024-06-24 16:54:31,535 Epoch [3/8], Batch [251/748], Loss: 0.7682
2024-06-24 16:55:22,275 Epoch [3/8], Batch [301/748], Loss: 0.6232
2024-06-24 16:56:12,791 Epoch [3/8], Batch [351/748], Loss: 0.8244
2024-06-24 16:57:03,466 Epoch [3/8], Batch [401/748], Loss: 0.8165
2024-06-24 16:57:54,115 Epoch [3/8], Batch [451/748], Loss: 0.6710
2024-06-24 16:58:44,871 Epoch [3/8], Batch [501/748], Loss: 0.8908
2024-06-24 16:59:35,369 Epoch [3/8], Batch [551/748], Loss: 0.9886
2024-06-24 17:00:25,937 Epoch [3/8], Batch [601/748], Loss: 0.9531
2024-06-24 17:01:16,517 Epoch [3/8], Batch [651/748], Loss: 0.4524
2024-06-24 17:02:07,145 Epoch [3/8], Batch [701/748], Loss: 0.6524
2024-06-24 17:02:54,406 Epoch 3/8, Train Loss: 0.7050, Train Accuracy: 0.6903
2024-06-24 17:04:15,505 Epoch 3/8, Val Loss: 0.8767, Val Accuracy: 0.6362
2024-06-24 17:04:16,516 Epoch [4/8], Batch [1/748], Loss: 0.4069
2024-06-24 17:05:06,935 Epoch [4/8], Batch [51/748], Loss: 0.8644
2024-06-24 17:05:57,500 Epoch [4/8], Batch [101/748], Loss: 0.8496
2024-06-24 17:06:48,185 Epoch [4/8], Batch [151/748], Loss: 0.5983
2024-06-24 17:07:39,204 Epoch [4/8], Batch [201/748], Loss: 0.8612
2024-06-24 17:08:29,974 Epoch [4/8], Batch [251/748], Loss: 0.8430
2024-06-24 17:09:20,971 Epoch [4/8], Batch [301/748], Loss: 0.4701
2024-06-24 17:10:11,876 Epoch [4/8], Batch [351/748], Loss: 0.5520
2024-06-24 17:11:02,841 Epoch [4/8], Batch [401/748], Loss: 0.7254
2024-06-24 17:11:53,732 Epoch [4/8], Batch [451/748], Loss: 0.4345
2024-06-24 17:12:44,701 Epoch [4/8], Batch [501/748], Loss: 0.5231
2024-06-24 17:13:35,634 Epoch [4/8], Batch [551/748], Loss: 0.5353
2024-06-24 17:14:26,446 Epoch [4/8], Batch [601/748], Loss: 0.5672
2024-06-24 17:15:17,481 Epoch [4/8], Batch [651/748], Loss: 0.8542
2024-06-24 17:16:08,164 Epoch [4/8], Batch [701/748], Loss: 0.5499
2024-06-24 17:16:55,633 Epoch 4/8, Train Loss: 0.6006, Train Accuracy: 0.7401
2024-06-24 17:18:18,060 Epoch 4/8, Val Loss: 0.8912, Val Accuracy: 0.6417
2024-06-24 17:18:19,089 Epoch [5/8], Batch [1/748], Loss: 0.6318
2024-06-24 17:19:10,290 Epoch [5/8], Batch [51/748], Loss: 0.4895
2024-06-24 17:20:01,286 Epoch [5/8], Batch [101/748], Loss: 0.5714
2024-06-24 17:20:52,271 Epoch [5/8], Batch [151/748], Loss: 0.4764
2024-06-24 17:21:43,464 Epoch [5/8], Batch [201/748], Loss: 0.5370
2024-06-24 17:22:34,265 Epoch [5/8], Batch [251/748], Loss: 0.4684
2024-06-24 17:23:25,179 Epoch [5/8], Batch [301/748], Loss: 0.4580
2024-06-24 17:24:15,994 Epoch [5/8], Batch [351/748], Loss: 0.5826
2024-06-24 17:25:06,840 Epoch [5/8], Batch [401/748], Loss: 0.6246
2024-06-24 17:25:57,344 Epoch [5/8], Batch [451/748], Loss: 0.5881
2024-06-24 17:26:47,994 Epoch [5/8], Batch [501/748], Loss: 0.5051
2024-06-24 17:27:38,722 Epoch [5/8], Batch [551/748], Loss: 0.3598
2024-06-24 17:28:29,315 Epoch [5/8], Batch [601/748], Loss: 0.3206
2024-06-24 17:29:20,170 Epoch [5/8], Batch [651/748], Loss: 0.5915
2024-06-24 17:30:10,984 Epoch [5/8], Batch [701/748], Loss: 0.4101
2024-06-24 17:30:58,231 Epoch 5/8, Train Loss: 0.4965, Train Accuracy: 0.7926
2024-06-24 17:32:18,800 Epoch 5/8, Val Loss: 0.8908, Val Accuracy: 0.6676
2024-06-24 17:32:19,841 Epoch [6/8], Batch [1/748], Loss: 0.3989
2024-06-24 17:33:10,591 Epoch [6/8], Batch [51/748], Loss: 0.4890
2024-06-24 17:34:01,295 Epoch [6/8], Batch [101/748], Loss: 0.4188
2024-06-24 17:34:51,696 Epoch [6/8], Batch [151/748], Loss: 0.5601
2024-06-24 17:35:42,242 Epoch [6/8], Batch [201/748], Loss: 0.2784
2024-06-24 17:36:32,786 Epoch [6/8], Batch [251/748], Loss: 0.4030
2024-06-24 17:37:23,590 Epoch [6/8], Batch [301/748], Loss: 0.3633
2024-06-24 17:38:14,318 Epoch [6/8], Batch [351/748], Loss: 0.4106
2024-06-24 17:39:05,312 Epoch [6/8], Batch [401/748], Loss: 0.5785
2024-06-24 17:39:56,210 Epoch [6/8], Batch [451/748], Loss: 0.3044
2024-06-24 17:40:46,687 Epoch [6/8], Batch [501/748], Loss: 0.3741
2024-06-24 17:41:37,393 Epoch [6/8], Batch [551/748], Loss: 0.2572
2024-06-24 17:42:27,945 Epoch [6/8], Batch [601/748], Loss: 0.6678
2024-06-24 17:43:18,701 Epoch [6/8], Batch [651/748], Loss: 0.4154
2024-06-24 17:44:09,255 Epoch [6/8], Batch [701/748], Loss: 0.5301
2024-06-24 17:44:56,387 Epoch 6/8, Train Loss: 0.4070, Train Accuracy: 0.8333
2024-06-24 17:46:17,292 Epoch 6/8, Val Loss: 0.9942, Val Accuracy: 0.6534
2024-06-24 17:46:18,303 Epoch [7/8], Batch [1/748], Loss: 0.3465
2024-06-24 17:47:08,966 Epoch [7/8], Batch [51/748], Loss: 0.2493
2024-06-24 17:47:59,735 Epoch [7/8], Batch [101/748], Loss: 0.3060
2024-06-24 17:48:50,455 Epoch [7/8], Batch [151/748], Loss: 0.3568
2024-06-24 17:49:41,124 Epoch [7/8], Batch [201/748], Loss: 0.3248
2024-06-24 17:50:31,784 Epoch [7/8], Batch [251/748], Loss: 0.3160
2024-06-24 17:51:22,363 Epoch [7/8], Batch [301/748], Loss: 0.3522
2024-06-24 17:52:13,111 Epoch [7/8], Batch [351/748], Loss: 0.3545
2024-06-24 17:53:03,936 Epoch [7/8], Batch [401/748], Loss: 0.2014
2024-06-24 17:53:54,545 Epoch [7/8], Batch [451/748], Loss: 0.3735
2024-06-24 17:54:45,118 Epoch [7/8], Batch [501/748], Loss: 0.4132
2024-06-24 17:55:35,775 Epoch [7/8], Batch [551/748], Loss: 0.2926
2024-06-24 17:56:26,729 Epoch [7/8], Batch [601/748], Loss: 0.1850
2024-06-24 17:57:17,521 Epoch [7/8], Batch [651/748], Loss: 0.2836
2024-06-24 17:58:08,284 Epoch [7/8], Batch [701/748], Loss: 0.4026
2024-06-24 17:58:55,430 Epoch 7/8, Train Loss: 0.3318, Train Accuracy: 0.8708
2024-06-24 18:00:16,263 Epoch 7/8, Val Loss: 1.0982, Val Accuracy: 0.6491
2024-06-24 18:00:17,275 Epoch [8/8], Batch [1/748], Loss: 0.3062
2024-06-24 18:01:08,120 Epoch [8/8], Batch [51/748], Loss: 0.3597
2024-06-24 18:01:58,931 Epoch [8/8], Batch [101/748], Loss: 0.1349
2024-06-24 18:02:49,905 Epoch [8/8], Batch [151/748], Loss: 0.2715
2024-06-24 18:03:41,237 Epoch [8/8], Batch [201/748], Loss: 0.1921
2024-06-24 18:04:32,341 Epoch [8/8], Batch [251/748], Loss: 0.3447
2024-06-24 18:05:23,504 Epoch [8/8], Batch [301/748], Loss: 0.3189
2024-06-24 18:06:14,372 Epoch [8/8], Batch [351/748], Loss: 0.3414
2024-06-24 18:07:05,425 Epoch [8/8], Batch [401/748], Loss: 0.0500
2024-06-24 18:07:56,298 Epoch [8/8], Batch [451/748], Loss: 0.3160
2024-06-24 18:08:46,914 Epoch [8/8], Batch [501/748], Loss: 0.4486
2024-06-24 18:09:37,675 Epoch [8/8], Batch [551/748], Loss: 0.1258
2024-06-24 18:10:28,151 Epoch [8/8], Batch [601/748], Loss: 0.2381
2024-06-24 18:11:18,695 Epoch [8/8], Batch [651/748], Loss: 0.1439
2024-06-24 18:12:09,127 Epoch [8/8], Batch [701/748], Loss: 0.1984
2024-06-24 18:12:56,009 Epoch 8/8, Train Loss: 0.2516, Train Accuracy: 0.9066
2024-06-24 18:14:16,303 Epoch 8/8, Val Loss: 1.0955, Val Accuracy: 0.6663
2024-06-24 18:14:16,305 Training finished!
2024-06-24 18:14:16,306 ==================================================
2024-06-24 18:14:40,604 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d256,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T18:14:40.604646', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 18:14:40,604 collecting all words and their counts
2024-06-24 18:14:40,604 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 18:14:40,848 PROGRESS: at example #10000, processed 1168609 words (4797123 words/s), 72028 word types, 0 tags
2024-06-24 18:14:41,122 PROGRESS: at example #20000, processed 2388715 words (4463175 words/s), 103898 word types, 0 tags
2024-06-24 18:14:41,354 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 18:14:41,354 Creating a fresh vocabulary
2024-06-24 18:14:41,814 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T18:14:41.814721', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 18:14:41,814 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T18:14:41.814927', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 18:14:42,518 deleting the raw counts dictionary of 133984 items
2024-06-24 18:14:42,520 sample=0.001 downsamples 6 most-common words
2024-06-24 18:14:42,520 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T18:14:42.520303', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 18:14:43,706 estimated required memory for 133984 words and 256 dimensions: 341397352 bytes
2024-06-24 18:14:43,706 resetting layer weights
2024-06-24 18:14:43,891 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T18:14:43.891186', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 18:14:44,905 EPOCH 0 - PROGRESS: at 17.73% examples, 603394 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:14:45,925 EPOCH 0 - PROGRESS: at 36.87% examples, 639591 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:14:46,936 EPOCH 0 - PROGRESS: at 56.41% examples, 656880 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:14:47,972 EPOCH 0 - PROGRESS: at 74.25% examples, 661103 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:14:48,998 EPOCH 0 - PROGRESS: at 94.61% examples, 657305 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:14:49,240 EPOCH 0: training on 3499793 raw words (3519603 effective words) took 5.3s, 658469 effective words/s
2024-06-24 18:14:50,266 EPOCH 1 - PROGRESS: at 17.99% examples, 605432 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:14:51,274 EPOCH 1 - PROGRESS: at 35.20% examples, 609969 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:14:52,304 EPOCH 1 - PROGRESS: at 52.65% examples, 603832 words/s, in_qsize 8, out_qsize 1
2024-06-24 18:14:53,304 EPOCH 1 - PROGRESS: at 68.32% examples, 604945 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:14:54,325 EPOCH 1 - PROGRESS: at 85.46% examples, 606789 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:14:55,021 EPOCH 1: training on 3499793 raw words (3519497 effective words) took 5.8s, 609076 effective words/s
2024-06-24 18:14:56,042 EPOCH 2 - PROGRESS: at 18.49% examples, 629011 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:14:57,046 EPOCH 2 - PROGRESS: at 37.42% examples, 652186 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:14:58,052 EPOCH 2 - PROGRESS: at 56.64% examples, 663172 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:14:59,054 EPOCH 2 - PROGRESS: at 74.01% examples, 666519 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:00,078 EPOCH 2 - PROGRESS: at 92.70% examples, 651906 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:00,412 EPOCH 2: training on 3499793 raw words (3519655 effective words) took 5.4s, 653271 effective words/s
2024-06-24 18:15:01,455 EPOCH 3 - PROGRESS: at 18.99% examples, 634359 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:02,469 EPOCH 3 - PROGRESS: at 36.03% examples, 617811 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:03,497 EPOCH 3 - PROGRESS: at 53.71% examples, 612812 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:04,497 EPOCH 3 - PROGRESS: at 70.10% examples, 619112 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:05,518 EPOCH 3 - PROGRESS: at 88.09% examples, 620150 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:06,018 EPOCH 3: training on 3499793 raw words (3519554 effective words) took 5.6s, 628209 effective words/s
2024-06-24 18:15:07,022 EPOCH 4 - PROGRESS: at 19.62% examples, 679474 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:08,032 EPOCH 4 - PROGRESS: at 38.26% examples, 670666 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:09,051 EPOCH 4 - PROGRESS: at 57.34% examples, 669353 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:10,063 EPOCH 4 - PROGRESS: at 74.54% examples, 669478 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:11,083 EPOCH 4 - PROGRESS: at 94.87% examples, 664680 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:11,294 EPOCH 4: training on 3499793 raw words (3519465 effective words) took 5.3s, 667582 effective words/s
2024-06-24 18:15:12,300 EPOCH 5 - PROGRESS: at 19.01% examples, 658294 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:13,343 EPOCH 5 - PROGRESS: at 38.54% examples, 664136 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:14,346 EPOCH 5 - PROGRESS: at 57.58% examples, 668663 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:15,371 EPOCH 5 - PROGRESS: at 74.50% examples, 664194 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:16,374 EPOCH 5 - PROGRESS: at 93.65% examples, 654940 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:16,691 EPOCH 5: training on 3499793 raw words (3519574 effective words) took 5.4s, 652602 effective words/s
2024-06-24 18:15:17,706 EPOCH 6 - PROGRESS: at 18.23% examples, 623225 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:18,717 EPOCH 6 - PROGRESS: at 36.33% examples, 632500 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:19,719 EPOCH 6 - PROGRESS: at 54.86% examples, 641006 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:20,725 EPOCH 6 - PROGRESS: at 71.14% examples, 637017 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:21,753 EPOCH 6 - PROGRESS: at 89.75% examples, 633500 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:22,234 EPOCH 6: training on 3499793 raw words (3519597 effective words) took 5.5s, 635402 effective words/s
2024-06-24 18:15:23,239 EPOCH 7 - PROGRESS: at 19.01% examples, 659135 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:24,243 EPOCH 7 - PROGRESS: at 38.54% examples, 677533 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:25,256 EPOCH 7 - PROGRESS: at 57.84% examples, 678538 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:26,286 EPOCH 7 - PROGRESS: at 75.73% examples, 680715 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:27,288 EPOCH 7 - PROGRESS: at 96.87% examples, 678126 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:27,421 EPOCH 7: training on 3499793 raw words (3519544 effective words) took 5.2s, 679023 effective words/s
2024-06-24 18:15:28,434 EPOCH 8 - PROGRESS: at 19.01% examples, 653333 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:29,446 EPOCH 8 - PROGRESS: at 37.71% examples, 657399 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:30,461 EPOCH 8 - PROGRESS: at 56.64% examples, 661466 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:31,462 EPOCH 8 - PROGRESS: at 74.25% examples, 667784 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:32,471 EPOCH 8 - PROGRESS: at 94.31% examples, 662788 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:32,716 EPOCH 8: training on 3499793 raw words (3519701 effective words) took 5.3s, 665199 effective words/s
2024-06-24 18:15:33,723 EPOCH 9 - PROGRESS: at 18.23% examples, 628063 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:34,735 EPOCH 9 - PROGRESS: at 37.98% examples, 664235 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:35,755 EPOCH 9 - PROGRESS: at 57.81% examples, 674753 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:36,758 EPOCH 9 - PROGRESS: at 75.47% examples, 679926 words/s, in_qsize 8, out_qsize 0
2024-06-24 18:15:37,781 EPOCH 9 - PROGRESS: at 96.14% examples, 672689 words/s, in_qsize 7, out_qsize 0
2024-06-24 18:15:37,952 EPOCH 9: training on 3499793 raw words (3519652 effective words) took 5.2s, 672699 effective words/s
2024-06-24 18:15:37,953 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195842 effective words) took 54.1s, 651032 effective words/s', 'datetime': '2024-06-24T18:15:37.953079', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 18:17:22,381 ==================================================
2024-06-24 18:17:22,381 Training BERT + Doc2Vec features with Dimension-256...
2024-06-24 18:17:23,379 Epoch [1/8], Batch [1/748], Loss: 1.6011
2024-06-24 18:18:12,446 Epoch [1/8], Batch [51/748], Loss: 1.4744
2024-06-24 18:19:02,484 Epoch [1/8], Batch [101/748], Loss: 1.4230
2024-06-24 18:19:53,039 Epoch [1/8], Batch [151/748], Loss: 1.2345
2024-06-24 18:20:43,625 Epoch [1/8], Batch [201/748], Loss: 1.2291
2024-06-24 18:21:34,038 Epoch [1/8], Batch [251/748], Loss: 1.0192
2024-06-24 18:22:24,572 Epoch [1/8], Batch [301/748], Loss: 1.0731
2024-06-24 18:23:15,302 Epoch [1/8], Batch [351/748], Loss: 0.9427
2024-06-24 18:24:05,816 Epoch [1/8], Batch [401/748], Loss: 0.8966
2024-06-24 18:24:56,325 Epoch [1/8], Batch [451/748], Loss: 0.9470
2024-06-24 18:25:46,600 Epoch [1/8], Batch [501/748], Loss: 0.9850
2024-06-24 18:26:36,994 Epoch [1/8], Batch [551/748], Loss: 0.9766
2024-06-24 18:27:27,599 Epoch [1/8], Batch [601/748], Loss: 0.8787
2024-06-24 18:28:17,720 Epoch [1/8], Batch [651/748], Loss: 0.5885
2024-06-24 18:29:08,392 Epoch [1/8], Batch [701/748], Loss: 0.9585
2024-06-24 18:29:55,606 Epoch 1/8, Train Loss: 1.0571, Train Accuracy: 0.5482
2024-06-24 18:31:15,639 Epoch 1/8, Val Loss: 0.9160, Val Accuracy: 0.6006
2024-06-24 18:31:16,666 Epoch [2/8], Batch [1/748], Loss: 0.8052
2024-06-24 18:32:06,987 Epoch [2/8], Batch [51/748], Loss: 0.7126
2024-06-24 18:32:57,433 Epoch [2/8], Batch [101/748], Loss: 0.7420
2024-06-24 18:33:48,190 Epoch [2/8], Batch [151/748], Loss: 0.7448
2024-06-24 18:34:38,892 Epoch [2/8], Batch [201/748], Loss: 0.7385
2024-06-24 18:35:29,366 Epoch [2/8], Batch [251/748], Loss: 0.8097
2024-06-24 18:36:20,017 Epoch [2/8], Batch [301/748], Loss: 0.7708
2024-06-24 18:37:10,740 Epoch [2/8], Batch [351/748], Loss: 0.7721
2024-06-24 18:38:01,397 Epoch [2/8], Batch [401/748], Loss: 0.6140
2024-06-24 18:38:52,050 Epoch [2/8], Batch [451/748], Loss: 0.6675
2024-06-24 18:39:42,620 Epoch [2/8], Batch [501/748], Loss: 0.6229
2024-06-24 18:40:33,168 Epoch [2/8], Batch [551/748], Loss: 0.6929
2024-06-24 18:41:23,790 Epoch [2/8], Batch [601/748], Loss: 0.6330
2024-06-24 18:42:14,070 Epoch [2/8], Batch [651/748], Loss: 0.8365
2024-06-24 18:43:04,683 Epoch [2/8], Batch [701/748], Loss: 0.8311
2024-06-24 18:43:51,683 Epoch 2/8, Train Loss: 0.8061, Train Accuracy: 0.6459
2024-06-24 18:45:11,407 Epoch 2/8, Val Loss: 0.8294, Val Accuracy: 0.6270
2024-06-24 18:45:12,428 Epoch [3/8], Batch [1/748], Loss: 0.8922
2024-06-24 18:46:02,837 Epoch [3/8], Batch [51/748], Loss: 0.8735
2024-06-24 18:46:53,419 Epoch [3/8], Batch [101/748], Loss: 0.5925
2024-06-24 18:47:44,010 Epoch [3/8], Batch [151/748], Loss: 0.6712
2024-06-24 18:48:34,724 Epoch [3/8], Batch [201/748], Loss: 0.5852
2024-06-24 18:49:25,292 Epoch [3/8], Batch [251/748], Loss: 0.6135
2024-06-24 18:50:15,734 Epoch [3/8], Batch [301/748], Loss: 0.6082
2024-06-24 18:51:06,248 Epoch [3/8], Batch [351/748], Loss: 0.7346
2024-06-24 18:51:56,729 Epoch [3/8], Batch [401/748], Loss: 0.6937
2024-06-24 18:52:47,067 Epoch [3/8], Batch [451/748], Loss: 0.5946
2024-06-24 18:53:37,768 Epoch [3/8], Batch [501/748], Loss: 0.7332
2024-06-24 18:54:28,123 Epoch [3/8], Batch [551/748], Loss: 0.7476
2024-06-24 18:55:18,701 Epoch [3/8], Batch [601/748], Loss: 0.6927
2024-06-24 18:56:09,114 Epoch [3/8], Batch [651/748], Loss: 0.4400
2024-06-24 18:56:59,693 Epoch [3/8], Batch [701/748], Loss: 0.5396
2024-06-24 18:57:46,855 Epoch 3/8, Train Loss: 0.6967, Train Accuracy: 0.6971
2024-06-24 18:59:06,760 Epoch 3/8, Val Loss: 0.7897, Val Accuracy: 0.6671
2024-06-24 18:59:07,762 Epoch [4/8], Batch [1/748], Loss: 0.5615
2024-06-24 18:59:57,933 Epoch [4/8], Batch [51/748], Loss: 0.5663
2024-06-24 19:00:48,260 Epoch [4/8], Batch [101/748], Loss: 0.7340
2024-06-24 19:01:38,783 Epoch [4/8], Batch [151/748], Loss: 0.8523
2024-06-24 19:02:29,168 Epoch [4/8], Batch [201/748], Loss: 0.6821
2024-06-24 19:03:19,650 Epoch [4/8], Batch [251/748], Loss: 0.6837
2024-06-24 19:04:10,308 Epoch [4/8], Batch [301/748], Loss: 0.4259
2024-06-24 19:05:00,993 Epoch [4/8], Batch [351/748], Loss: 0.4790
2024-06-24 19:05:51,594 Epoch [4/8], Batch [401/748], Loss: 0.6029
2024-06-24 19:06:42,057 Epoch [4/8], Batch [451/748], Loss: 0.3620
2024-06-24 19:07:32,678 Epoch [4/8], Batch [501/748], Loss: 0.6854
2024-06-24 19:08:23,238 Epoch [4/8], Batch [551/748], Loss: 0.5707
2024-06-24 19:09:13,719 Epoch [4/8], Batch [601/748], Loss: 0.6504
2024-06-24 19:10:04,175 Epoch [4/8], Batch [651/748], Loss: 0.6391
2024-06-24 19:10:54,472 Epoch [4/8], Batch [701/748], Loss: 0.7622
2024-06-24 19:11:41,759 Epoch 4/8, Train Loss: 0.5963, Train Accuracy: 0.7462
2024-06-24 19:13:02,059 Epoch 4/8, Val Loss: 0.8437, Val Accuracy: 0.6557
2024-06-24 19:13:03,098 Epoch [5/8], Batch [1/748], Loss: 0.4102
2024-06-24 19:13:53,511 Epoch [5/8], Batch [51/748], Loss: 0.5581
2024-06-24 19:14:43,903 Epoch [5/8], Batch [101/748], Loss: 0.5167
2024-06-24 19:15:34,448 Epoch [5/8], Batch [151/748], Loss: 0.5669
2024-06-24 19:16:24,933 Epoch [5/8], Batch [201/748], Loss: 0.4975
2024-06-24 19:17:15,482 Epoch [5/8], Batch [251/748], Loss: 0.5322
2024-06-24 19:18:05,956 Epoch [5/8], Batch [301/748], Loss: 0.4691
2024-06-24 19:18:56,321 Epoch [5/8], Batch [351/748], Loss: 0.3627
2024-06-24 19:19:47,025 Epoch [5/8], Batch [401/748], Loss: 0.3260
2024-06-24 19:20:37,501 Epoch [5/8], Batch [451/748], Loss: 0.2985
2024-06-24 19:21:28,172 Epoch [5/8], Batch [501/748], Loss: 0.2687
2024-06-24 19:22:18,644 Epoch [5/8], Batch [551/748], Loss: 0.4551
2024-06-24 19:23:09,566 Epoch [5/8], Batch [601/748], Loss: 0.5874
2024-06-24 19:24:00,111 Epoch [5/8], Batch [651/748], Loss: 0.4373
2024-06-24 19:24:50,538 Epoch [5/8], Batch [701/748], Loss: 0.5386
2024-06-24 19:25:37,732 Epoch 5/8, Train Loss: 0.4994, Train Accuracy: 0.7930
2024-06-24 19:26:57,366 Epoch 5/8, Val Loss: 0.8893, Val Accuracy: 0.6586
2024-06-24 19:26:58,379 Epoch [6/8], Batch [1/748], Loss: 0.2423
2024-06-24 19:27:48,786 Epoch [6/8], Batch [51/748], Loss: 0.4154
2024-06-24 19:28:39,281 Epoch [6/8], Batch [101/748], Loss: 0.2710
2024-06-24 19:29:29,824 Epoch [6/8], Batch [151/748], Loss: 0.3601
2024-06-24 19:30:20,386 Epoch [6/8], Batch [201/748], Loss: 0.4926
2024-06-24 19:31:10,801 Epoch [6/8], Batch [251/748], Loss: 0.2998
2024-06-24 19:32:01,369 Epoch [6/8], Batch [301/748], Loss: 0.4162
2024-06-24 19:32:51,704 Epoch [6/8], Batch [351/748], Loss: 0.3259
2024-06-24 19:33:42,229 Epoch [6/8], Batch [401/748], Loss: 0.4481
2024-06-24 19:34:32,464 Epoch [6/8], Batch [451/748], Loss: 0.2695
2024-06-24 19:35:22,854 Epoch [6/8], Batch [501/748], Loss: 0.5077
2024-06-24 19:36:13,211 Epoch [6/8], Batch [551/748], Loss: 0.4062
2024-06-24 19:37:03,652 Epoch [6/8], Batch [601/748], Loss: 0.5853
2024-06-24 19:37:54,132 Epoch [6/8], Batch [651/748], Loss: 0.3944
2024-06-24 19:38:44,800 Epoch [6/8], Batch [701/748], Loss: 0.4960
2024-06-24 19:39:31,843 Epoch 6/8, Train Loss: 0.4094, Train Accuracy: 0.8352
2024-06-24 19:40:51,205 Epoch 6/8, Val Loss: 0.9537, Val Accuracy: 0.6710
2024-06-24 19:40:52,197 Epoch [7/8], Batch [1/748], Loss: 0.3268
2024-06-24 19:41:42,471 Epoch [7/8], Batch [51/748], Loss: 0.4285
2024-06-24 19:42:32,833 Epoch [7/8], Batch [101/748], Loss: 0.2935
2024-06-24 19:43:23,474 Epoch [7/8], Batch [151/748], Loss: 0.3651
2024-06-24 19:44:13,885 Epoch [7/8], Batch [201/748], Loss: 0.2755
2024-06-24 19:45:04,484 Epoch [7/8], Batch [251/748], Loss: 0.3723
2024-06-24 19:45:55,125 Epoch [7/8], Batch [301/748], Loss: 0.1620
2024-06-24 19:46:45,582 Epoch [7/8], Batch [351/748], Loss: 0.6291
2024-06-24 19:47:36,072 Epoch [7/8], Batch [401/748], Loss: 0.5363
2024-06-24 19:48:26,321 Epoch [7/8], Batch [451/748], Loss: 0.2591
2024-06-24 19:49:16,817 Epoch [7/8], Batch [501/748], Loss: 0.3491
2024-06-24 19:50:07,341 Epoch [7/8], Batch [551/748], Loss: 0.2018
2024-06-24 19:50:57,666 Epoch [7/8], Batch [601/748], Loss: 0.3833
2024-06-24 19:51:48,209 Epoch [7/8], Batch [651/748], Loss: 0.4375
2024-06-24 19:52:38,415 Epoch [7/8], Batch [701/748], Loss: 0.3731
2024-06-24 19:53:25,539 Epoch 7/8, Train Loss: 0.3303, Train Accuracy: 0.8706
2024-06-24 19:54:45,449 Epoch 7/8, Val Loss: 1.0245, Val Accuracy: 0.6611
2024-06-24 19:54:46,452 Epoch [8/8], Batch [1/748], Loss: 0.2253
2024-06-24 19:55:36,878 Epoch [8/8], Batch [51/748], Loss: 0.2756
2024-06-24 19:56:27,376 Epoch [8/8], Batch [101/748], Loss: 0.2863
2024-06-24 19:57:18,114 Epoch [8/8], Batch [151/748], Loss: 0.3541
2024-06-24 19:58:08,433 Epoch [8/8], Batch [201/748], Loss: 0.2581
2024-06-24 19:58:58,892 Epoch [8/8], Batch [251/748], Loss: 0.3635
2024-06-24 19:59:49,387 Epoch [8/8], Batch [301/748], Loss: 0.3162
2024-06-24 20:00:39,887 Epoch [8/8], Batch [351/748], Loss: 0.1909
2024-06-24 20:01:30,352 Epoch [8/8], Batch [401/748], Loss: 0.2078
2024-06-24 20:02:20,838 Epoch [8/8], Batch [451/748], Loss: 0.1956
2024-06-24 20:03:11,577 Epoch [8/8], Batch [501/748], Loss: 0.3453
2024-06-24 20:04:02,213 Epoch [8/8], Batch [551/748], Loss: 0.3452
2024-06-24 20:04:52,525 Epoch [8/8], Batch [601/748], Loss: 0.1434
2024-06-24 20:05:42,991 Epoch [8/8], Batch [651/748], Loss: 0.3726
2024-06-24 20:06:33,333 Epoch [8/8], Batch [701/748], Loss: 0.2372
2024-06-24 20:07:20,800 Epoch 8/8, Train Loss: 0.2735, Train Accuracy: 0.8973
2024-06-24 20:08:41,568 Epoch 8/8, Val Loss: 1.0956, Val Accuracy: 0.6626
2024-06-24 20:08:41,571 Training finished!
2024-06-24 20:08:41,571 ==================================================
2024-06-24 20:09:06,169 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d64,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T20:09:06.169082', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 20:09:06,169 collecting all words and their counts
2024-06-24 20:09:06,169 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 20:09:06,413 PROGRESS: at example #10000, processed 1168609 words (4794797 words/s), 72028 word types, 0 tags
2024-06-24 20:09:06,683 PROGRESS: at example #20000, processed 2388715 words (4514982 words/s), 103898 word types, 0 tags
2024-06-24 20:09:06,912 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 20:09:06,912 Creating a fresh vocabulary
2024-06-24 20:09:07,328 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T20:09:07.328208', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 20:09:07,328 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T20:09:07.328418', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 20:09:08,047 deleting the raw counts dictionary of 133984 items
2024-06-24 20:09:08,048 sample=0.001 downsamples 6 most-common words
2024-06-24 20:09:08,049 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T20:09:08.049070', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 20:09:09,227 estimated required memory for 133984 words and 64 dimensions: 135594088 bytes
2024-06-24 20:09:09,227 resetting layer weights
2024-06-24 20:09:09,273 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 64 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T20:09:09.273161', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 20:09:10,296 EPOCH 0 - PROGRESS: at 19.01% examples, 646515 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:11,311 EPOCH 0 - PROGRESS: at 39.67% examples, 687275 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:12,314 EPOCH 0 - PROGRESS: at 58.52% examples, 683963 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:13,328 EPOCH 0 - PROGRESS: at 74.01% examples, 662767 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:14,340 EPOCH 0 - PROGRESS: at 90.96% examples, 640568 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:14,788 EPOCH 0: training on 3499793 raw words (3519576 effective words) took 5.5s, 638581 effective words/s
2024-06-24 20:09:15,804 EPOCH 1 - PROGRESS: at 18.47% examples, 632423 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:16,815 EPOCH 1 - PROGRESS: at 36.32% examples, 632220 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:17,834 EPOCH 1 - PROGRESS: at 56.18% examples, 653534 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:18,847 EPOCH 1 - PROGRESS: at 73.76% examples, 659926 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:19,867 EPOCH 1 - PROGRESS: at 93.65% examples, 655028 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:20,144 EPOCH 1: training on 3499793 raw words (3519456 effective words) took 5.4s, 657613 effective words/s
2024-06-24 20:09:21,163 EPOCH 2 - PROGRESS: at 19.27% examples, 659713 words/s, in_qsize 8, out_qsize 1
2024-06-24 20:09:22,183 EPOCH 2 - PROGRESS: at 39.39% examples, 682396 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:23,184 EPOCH 2 - PROGRESS: at 58.32% examples, 681096 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:24,187 EPOCH 2 - PROGRESS: at 75.27% examples, 677306 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:25,191 EPOCH 2 - PROGRESS: at 92.05% examples, 649311 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:25,608 EPOCH 2: training on 3499793 raw words (3519479 effective words) took 5.5s, 644649 effective words/s
2024-06-24 20:09:26,626 EPOCH 3 - PROGRESS: at 18.00% examples, 611135 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:27,638 EPOCH 3 - PROGRESS: at 35.48% examples, 616335 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:28,649 EPOCH 3 - PROGRESS: at 56.18% examples, 654511 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:29,653 EPOCH 3 - PROGRESS: at 72.54% examples, 649925 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:30,663 EPOCH 3 - PROGRESS: at 91.70% examples, 646260 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:31,068 EPOCH 3: training on 3499793 raw words (3519474 effective words) took 5.5s, 645059 effective words/s
2024-06-24 20:09:32,072 EPOCH 4 - PROGRESS: at 19.27% examples, 669493 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:33,113 EPOCH 4 - PROGRESS: at 40.45% examples, 699748 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:34,134 EPOCH 4 - PROGRESS: at 60.45% examples, 701302 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:35,148 EPOCH 4 - PROGRESS: at 77.75% examples, 695386 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:36,169 EPOCH 4 - PROGRESS: at 98.93% examples, 684534 words/s, in_qsize 3, out_qsize 1
2024-06-24 20:09:36,185 EPOCH 4: training on 3499793 raw words (3519568 effective words) took 5.1s, 688337 effective words/s
2024-06-24 20:09:37,196 EPOCH 5 - PROGRESS: at 19.92% examples, 684006 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:38,207 EPOCH 5 - PROGRESS: at 35.48% examples, 618543 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:39,212 EPOCH 5 - PROGRESS: at 52.90% examples, 614623 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:40,215 EPOCH 5 - PROGRESS: at 70.90% examples, 634873 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:41,245 EPOCH 5 - PROGRESS: at 88.09% examples, 625731 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:41,814 EPOCH 5: training on 3499793 raw words (3519538 effective words) took 5.6s, 625566 effective words/s
2024-06-24 20:09:42,842 EPOCH 6 - PROGRESS: at 19.62% examples, 663709 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:43,843 EPOCH 6 - PROGRESS: at 38.27% examples, 665951 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:44,870 EPOCH 6 - PROGRESS: at 57.12% examples, 664470 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:45,871 EPOCH 6 - PROGRESS: at 72.80% examples, 650268 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:46,883 EPOCH 6 - PROGRESS: at 88.84% examples, 628652 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:47,479 EPOCH 6: training on 3499793 raw words (3519576 effective words) took 5.7s, 621677 effective words/s
2024-06-24 20:09:48,487 EPOCH 7 - PROGRESS: at 18.23% examples, 627258 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:49,495 EPOCH 7 - PROGRESS: at 38.54% examples, 675347 words/s, in_qsize 6, out_qsize 1
2024-06-24 20:09:50,539 EPOCH 7 - PROGRESS: at 57.12% examples, 663534 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:51,539 EPOCH 7 - PROGRESS: at 73.28% examples, 654757 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:52,542 EPOCH 7 - PROGRESS: at 89.98% examples, 635317 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:53,056 EPOCH 7: training on 3499793 raw words (3519552 effective words) took 5.6s, 631509 effective words/s
2024-06-24 20:09:54,072 EPOCH 8 - PROGRESS: at 18.49% examples, 632800 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:55,080 EPOCH 8 - PROGRESS: at 37.16% examples, 648153 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:56,082 EPOCH 8 - PROGRESS: at 56.18% examples, 657964 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:57,089 EPOCH 8 - PROGRESS: at 72.10% examples, 647152 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:09:58,108 EPOCH 8 - PROGRESS: at 90.59% examples, 640803 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:09:58,540 EPOCH 8: training on 3499793 raw words (3519544 effective words) took 5.5s, 642366 effective words/s
2024-06-24 20:09:59,549 EPOCH 9 - PROGRESS: at 18.47% examples, 636455 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:10:00,554 EPOCH 9 - PROGRESS: at 37.42% examples, 656070 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:10:01,558 EPOCH 9 - PROGRESS: at 56.88% examples, 669378 words/s, in_qsize 7, out_qsize 0
2024-06-24 20:10:02,603 EPOCH 9 - PROGRESS: at 73.75% examples, 659148 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:10:03,612 EPOCH 9 - PROGRESS: at 93.38% examples, 654006 words/s, in_qsize 8, out_qsize 0
2024-06-24 20:10:03,902 EPOCH 9: training on 3499793 raw words (3519656 effective words) took 5.4s, 656905 effective words/s
2024-06-24 20:10:03,902 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195419 effective words) took 54.6s, 644263 effective words/s', 'datetime': '2024-06-24T20:10:03.902445', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 20:11:17,165 ==================================================
2024-06-24 20:11:17,165 Training BERT + Doc2Vec features with Dimension-64...
2024-06-24 20:11:18,180 Epoch [1/8], Batch [1/748], Loss: 1.6126
2024-06-24 20:12:07,371 Epoch [1/8], Batch [51/748], Loss: 1.5200
2024-06-24 20:12:57,483 Epoch [1/8], Batch [101/748], Loss: 1.2845
2024-06-24 20:13:47,867 Epoch [1/8], Batch [151/748], Loss: 1.3667
2024-06-24 20:14:38,265 Epoch [1/8], Batch [201/748], Loss: 0.9169
2024-06-24 20:15:28,858 Epoch [1/8], Batch [251/748], Loss: 1.0835
2024-06-24 20:16:19,282 Epoch [1/8], Batch [301/748], Loss: 1.1177
2024-06-24 20:17:09,790 Epoch [1/8], Batch [351/748], Loss: 0.9719
2024-06-24 20:18:00,312 Epoch [1/8], Batch [401/748], Loss: 0.9330
2024-06-24 20:18:50,942 Epoch [1/8], Batch [451/748], Loss: 1.0740
2024-06-24 20:19:41,544 Epoch [1/8], Batch [501/748], Loss: 0.7160
2024-06-24 20:20:31,886 Epoch [1/8], Batch [551/748], Loss: 0.6822
2024-06-24 20:21:22,382 Epoch [1/8], Batch [601/748], Loss: 0.7055
2024-06-24 20:22:12,670 Epoch [1/8], Batch [651/748], Loss: 0.9124
2024-06-24 20:23:03,204 Epoch [1/8], Batch [701/748], Loss: 0.7224
2024-06-24 20:23:50,365 Epoch 1/8, Train Loss: 1.0442, Train Accuracy: 0.5620
2024-06-24 20:25:10,640 Epoch 1/8, Val Loss: 0.8722, Val Accuracy: 0.6126
2024-06-24 20:25:11,634 Epoch [2/8], Batch [1/748], Loss: 0.8486
2024-06-24 20:26:01,796 Epoch [2/8], Batch [51/748], Loss: 0.5395
2024-06-24 20:26:52,220 Epoch [2/8], Batch [101/748], Loss: 1.0511
2024-06-24 20:27:42,877 Epoch [2/8], Batch [151/748], Loss: 1.0271
2024-06-24 20:28:33,335 Epoch [2/8], Batch [201/748], Loss: 0.6920
2024-06-24 20:29:23,823 Epoch [2/8], Batch [251/748], Loss: 0.6461
2024-06-24 20:30:14,189 Epoch [2/8], Batch [301/748], Loss: 0.7248
2024-06-24 20:31:04,996 Epoch [2/8], Batch [351/748], Loss: 0.7030
2024-06-24 20:31:55,485 Epoch [2/8], Batch [401/748], Loss: 0.9263
2024-06-24 20:32:45,806 Epoch [2/8], Batch [451/748], Loss: 0.8914
2024-06-24 20:33:36,364 Epoch [2/8], Batch [501/748], Loss: 0.7033
2024-06-24 20:34:26,809 Epoch [2/8], Batch [551/748], Loss: 0.9147
2024-06-24 20:35:17,532 Epoch [2/8], Batch [601/748], Loss: 0.6621
2024-06-24 20:36:07,924 Epoch [2/8], Batch [651/748], Loss: 0.5848
2024-06-24 20:36:58,867 Epoch [2/8], Batch [701/748], Loss: 0.5829
2024-06-24 20:37:46,001 Epoch 2/8, Train Loss: 0.7871, Train Accuracy: 0.6528
2024-06-24 20:39:05,675 Epoch 2/8, Val Loss: 0.8058, Val Accuracy: 0.6536
2024-06-24 20:39:06,687 Epoch [3/8], Batch [1/748], Loss: 0.5603
2024-06-24 20:39:56,985 Epoch [3/8], Batch [51/748], Loss: 0.7772
2024-06-24 20:40:47,438 Epoch [3/8], Batch [101/748], Loss: 0.7535
2024-06-24 20:41:38,231 Epoch [3/8], Batch [151/748], Loss: 0.7462
2024-06-24 20:42:28,593 Epoch [3/8], Batch [201/748], Loss: 0.6996
2024-06-24 20:43:19,171 Epoch [3/8], Batch [251/748], Loss: 0.7298
2024-06-24 20:44:09,665 Epoch [3/8], Batch [301/748], Loss: 0.7051
2024-06-24 20:45:00,197 Epoch [3/8], Batch [351/748], Loss: 0.8652
2024-06-24 20:45:50,682 Epoch [3/8], Batch [401/748], Loss: 0.7784
2024-06-24 20:46:41,147 Epoch [3/8], Batch [451/748], Loss: 0.6151
2024-06-24 20:47:31,556 Epoch [3/8], Batch [501/748], Loss: 0.8600
2024-06-24 20:48:21,845 Epoch [3/8], Batch [551/748], Loss: 0.6338
2024-06-24 20:49:12,256 Epoch [3/8], Batch [601/748], Loss: 0.5589
2024-06-24 20:50:02,601 Epoch [3/8], Batch [651/748], Loss: 0.6641
2024-06-24 20:50:53,115 Epoch [3/8], Batch [701/748], Loss: 0.4988
2024-06-24 20:51:40,276 Epoch 3/8, Train Loss: 0.6678, Train Accuracy: 0.7094
2024-06-24 20:53:00,468 Epoch 3/8, Val Loss: 0.8926, Val Accuracy: 0.6455
2024-06-24 20:53:01,490 Epoch [4/8], Batch [1/748], Loss: 0.5148
2024-06-24 20:53:51,829 Epoch [4/8], Batch [51/748], Loss: 0.7375
2024-06-24 20:54:42,125 Epoch [4/8], Batch [101/748], Loss: 0.5614
2024-06-24 20:55:32,627 Epoch [4/8], Batch [151/748], Loss: 0.5782
2024-06-24 20:56:22,992 Epoch [4/8], Batch [201/748], Loss: 0.5388
2024-06-24 20:57:13,346 Epoch [4/8], Batch [251/748], Loss: 0.3851
2024-06-24 20:58:03,753 Epoch [4/8], Batch [301/748], Loss: 0.5894
2024-06-24 20:58:54,065 Epoch [4/8], Batch [351/748], Loss: 0.3730
2024-06-24 20:59:44,673 Epoch [4/8], Batch [401/748], Loss: 0.6374
2024-06-24 21:00:35,313 Epoch [4/8], Batch [451/748], Loss: 0.5931
2024-06-24 21:01:25,724 Epoch [4/8], Batch [501/748], Loss: 0.5744
2024-06-24 21:02:16,108 Epoch [4/8], Batch [551/748], Loss: 0.9242
2024-06-24 21:03:06,682 Epoch [4/8], Batch [601/748], Loss: 0.5711
2024-06-24 21:03:57,348 Epoch [4/8], Batch [651/748], Loss: 0.7212
2024-06-24 21:04:47,847 Epoch [4/8], Batch [701/748], Loss: 0.7084
2024-06-24 21:05:35,131 Epoch 4/8, Train Loss: 0.5508, Train Accuracy: 0.7673
2024-06-24 21:06:55,154 Epoch 4/8, Val Loss: 0.8710, Val Accuracy: 0.6544
2024-06-24 21:06:56,141 Epoch [5/8], Batch [1/748], Loss: 0.5890
2024-06-24 21:07:46,619 Epoch [5/8], Batch [51/748], Loss: 0.4533
2024-06-24 21:08:37,100 Epoch [5/8], Batch [101/748], Loss: 0.3743
2024-06-24 21:09:28,096 Epoch [5/8], Batch [151/748], Loss: 0.4567
2024-06-24 21:10:18,768 Epoch [5/8], Batch [201/748], Loss: 0.5543
2024-06-24 21:11:09,501 Epoch [5/8], Batch [251/748], Loss: 0.4245
2024-06-24 21:12:00,182 Epoch [5/8], Batch [301/748], Loss: 0.3359
2024-06-24 21:12:50,856 Epoch [5/8], Batch [351/748], Loss: 0.3933
2024-06-24 21:13:41,597 Epoch [5/8], Batch [401/748], Loss: 0.4229
2024-06-24 21:14:32,104 Epoch [5/8], Batch [451/748], Loss: 0.2744
2024-06-24 21:15:22,898 Epoch [5/8], Batch [501/748], Loss: 0.3552
2024-06-24 21:16:13,348 Epoch [5/8], Batch [551/748], Loss: 0.4918
2024-06-24 21:17:04,165 Epoch [5/8], Batch [601/748], Loss: 0.3750
2024-06-24 21:17:54,965 Epoch [5/8], Batch [651/748], Loss: 0.4046
2024-06-24 21:18:45,712 Epoch [5/8], Batch [701/748], Loss: 0.3548
2024-06-24 21:19:33,079 Epoch 5/8, Train Loss: 0.4477, Train Accuracy: 0.8134
2024-06-24 21:20:53,714 Epoch 5/8, Val Loss: 0.8525, Val Accuracy: 0.6793
2024-06-24 21:20:54,727 Epoch [6/8], Batch [1/748], Loss: 0.3197
2024-06-24 21:21:45,148 Epoch [6/8], Batch [51/748], Loss: 0.1301
2024-06-24 21:22:35,447 Epoch [6/8], Batch [101/748], Loss: 0.3718
2024-06-24 21:23:26,215 Epoch [6/8], Batch [151/748], Loss: 0.3548
2024-06-24 21:24:16,899 Epoch [6/8], Batch [201/748], Loss: 0.4128
2024-06-24 21:25:07,560 Epoch [6/8], Batch [251/748], Loss: 0.4714
2024-06-24 21:25:58,281 Epoch [6/8], Batch [301/748], Loss: 0.2510
2024-06-24 21:26:48,936 Epoch [6/8], Batch [351/748], Loss: 0.3368
2024-06-24 21:27:39,664 Epoch [6/8], Batch [401/748], Loss: 0.2447
2024-06-24 21:28:30,084 Epoch [6/8], Batch [451/748], Loss: 0.2947
2024-06-24 21:29:20,607 Epoch [6/8], Batch [501/748], Loss: 0.4401
2024-06-24 21:30:11,062 Epoch [6/8], Batch [551/748], Loss: 0.3433
2024-06-24 21:31:01,395 Epoch [6/8], Batch [601/748], Loss: 0.4014
2024-06-24 21:31:52,012 Epoch [6/8], Batch [651/748], Loss: 0.3263
2024-06-24 21:32:42,373 Epoch [6/8], Batch [701/748], Loss: 0.2681
2024-06-24 21:33:29,626 Epoch 6/8, Train Loss: 0.3574, Train Accuracy: 0.8539
2024-06-24 21:34:49,702 Epoch 6/8, Val Loss: 0.9338, Val Accuracy: 0.6793
2024-06-24 21:34:50,725 Epoch [7/8], Batch [1/748], Loss: 0.4742
2024-06-24 21:35:41,281 Epoch [7/8], Batch [51/748], Loss: 0.2439
2024-06-24 21:36:31,711 Epoch [7/8], Batch [101/748], Loss: 0.2840
2024-06-24 21:37:22,610 Epoch [7/8], Batch [151/748], Loss: 0.3799
2024-06-24 21:38:13,058 Epoch [7/8], Batch [201/748], Loss: 0.4132
2024-06-24 21:39:03,611 Epoch [7/8], Batch [251/748], Loss: 0.4772
2024-06-24 21:39:54,298 Epoch [7/8], Batch [301/748], Loss: 0.1364
2024-06-24 21:40:44,974 Epoch [7/8], Batch [351/748], Loss: 0.2274
2024-06-24 21:41:35,608 Epoch [7/8], Batch [401/748], Loss: 0.1777
2024-06-24 21:42:26,302 Epoch [7/8], Batch [451/748], Loss: 0.3776
2024-06-24 21:43:17,199 Epoch [7/8], Batch [501/748], Loss: 0.1688
2024-06-24 21:44:07,753 Epoch [7/8], Batch [551/748], Loss: 0.1939
2024-06-24 21:44:58,441 Epoch [7/8], Batch [601/748], Loss: 0.4572
2024-06-24 21:45:49,096 Epoch [7/8], Batch [651/748], Loss: 0.2683
2024-06-24 21:46:39,776 Epoch [7/8], Batch [701/748], Loss: 0.3269
2024-06-24 21:47:27,357 Epoch 7/8, Train Loss: 0.2898, Train Accuracy: 0.8848
2024-06-24 21:48:49,402 Epoch 7/8, Val Loss: 1.0531, Val Accuracy: 0.6698
2024-06-24 21:48:50,422 Epoch [8/8], Batch [1/748], Loss: 0.1755
2024-06-24 21:49:41,050 Epoch [8/8], Batch [51/748], Loss: 0.2413
2024-06-24 21:50:31,979 Epoch [8/8], Batch [101/748], Loss: 0.1703
2024-06-24 21:51:22,931 Epoch [8/8], Batch [151/748], Loss: 0.3422
2024-06-24 21:52:13,619 Epoch [8/8], Batch [201/748], Loss: 0.3049
2024-06-24 21:53:04,687 Epoch [8/8], Batch [251/748], Loss: 0.1909
2024-06-24 21:53:55,644 Epoch [8/8], Batch [301/748], Loss: 0.2084
2024-06-24 21:54:46,292 Epoch [8/8], Batch [351/748], Loss: 0.1159
2024-06-24 21:55:37,046 Epoch [8/8], Batch [401/748], Loss: 0.1804
2024-06-24 21:56:27,783 Epoch [8/8], Batch [451/748], Loss: 0.2091
2024-06-24 21:57:18,716 Epoch [8/8], Batch [501/748], Loss: 0.2777
2024-06-24 21:58:09,778 Epoch [8/8], Batch [551/748], Loss: 0.3710
2024-06-24 21:59:00,560 Epoch [8/8], Batch [601/748], Loss: 0.3272
2024-06-24 21:59:51,372 Epoch [8/8], Batch [651/748], Loss: 0.1789
2024-06-24 22:00:41,785 Epoch [8/8], Batch [701/748], Loss: 0.3624
2024-06-24 22:01:29,420 Epoch 8/8, Train Loss: 0.2372, Train Accuracy: 0.9108
2024-06-24 22:02:50,459 Epoch 8/8, Val Loss: 1.1151, Val Accuracy: 0.6718
2024-06-24 22:02:50,461 Training finished!
2024-06-24 22:02:50,461 ==================================================
2024-06-24 22:03:17,782 Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d8,n5,w2,s0.001,t4>', 'datetime': '2024-06-24T22:03:17.782716', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'created'}
2024-06-24 22:03:17,782 collecting all words and their counts
2024-06-24 22:03:17,782 PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2024-06-24 22:03:18,026 PROGRESS: at example #10000, processed 1168609 words (4798345 words/s), 72028 word types, 0 tags
2024-06-24 22:03:18,289 PROGRESS: at example #20000, processed 2388715 words (4640586 words/s), 103898 word types, 0 tags
2024-06-24 22:03:18,530 collected 133984 word types and 5 unique tags from a corpus of 29904 examples and 3499793 words
2024-06-24 22:03:18,530 Creating a fresh vocabulary
2024-06-24 22:03:18,959 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 133984 unique words (100.00% of original 133984, drops 0)', 'datetime': '2024-06-24T22:03:18.959244', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 22:03:18,959 Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3499793 word corpus (100.00% of original 3499793, drops 0)', 'datetime': '2024-06-24T22:03:18.959474', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 22:03:19,692 deleting the raw counts dictionary of 133984 items
2024-06-24 22:03:19,694 sample=0.001 downsamples 6 most-common words
2024-06-24 22:03:19,694 Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3489663.383565615 word corpus (99.7%% of prior 3499793)', 'datetime': '2024-06-24T22:03:19.694904', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2024-06-24 22:03:20,880 estimated required memory for 133984 words and 8 dimensions: 75568136 bytes
2024-06-24 22:03:20,880 resetting layer weights
2024-06-24 22:03:20,887 Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 133984 vocabulary and 8 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-24T22:03:20.887256', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 22:03:21,912 EPOCH 0 - PROGRESS: at 17.20% examples, 577027 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:22,948 EPOCH 0 - PROGRESS: at 34.67% examples, 592272 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:23,962 EPOCH 0 - PROGRESS: at 52.39% examples, 598390 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:24,974 EPOCH 0 - PROGRESS: at 68.06% examples, 599071 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:26,026 EPOCH 0 - PROGRESS: at 84.13% examples, 592695 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:26,899 EPOCH 0: training on 3499793 raw words (3519509 effective words) took 6.0s, 585747 effective words/s
2024-06-24 22:03:27,911 EPOCH 1 - PROGRESS: at 16.80% examples, 574958 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:28,912 EPOCH 1 - PROGRESS: at 33.82% examples, 591840 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:29,926 EPOCH 1 - PROGRESS: at 51.03% examples, 594809 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:30,932 EPOCH 1 - PROGRESS: at 67.29% examples, 599860 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:31,932 EPOCH 1 - PROGRESS: at 83.87% examples, 603266 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:32,799 EPOCH 1: training on 3499793 raw words (3519523 effective words) took 5.9s, 596921 effective words/s
2024-06-24 22:03:33,806 EPOCH 2 - PROGRESS: at 17.46% examples, 598352 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:34,823 EPOCH 2 - PROGRESS: at 34.95% examples, 608330 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:35,837 EPOCH 2 - PROGRESS: at 52.90% examples, 612490 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:36,845 EPOCH 2 - PROGRESS: at 70.38% examples, 627785 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:37,852 EPOCH 2 - PROGRESS: at 87.67% examples, 624765 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:38,502 EPOCH 2: training on 3499793 raw words (3519566 effective words) took 5.7s, 617565 effective words/s
2024-06-24 22:03:39,546 EPOCH 3 - PROGRESS: at 18.00% examples, 595955 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:40,559 EPOCH 3 - PROGRESS: at 34.95% examples, 598525 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:41,586 EPOCH 3 - PROGRESS: at 52.65% examples, 600125 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:42,594 EPOCH 3 - PROGRESS: at 69.11% examples, 608394 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:43,594 EPOCH 3 - PROGRESS: at 86.02% examples, 610015 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:44,377 EPOCH 3: training on 3499793 raw words (3519520 effective words) took 5.9s, 599522 effective words/s
2024-06-24 22:03:45,388 EPOCH 4 - PROGRESS: at 16.80% examples, 575213 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:46,389 EPOCH 4 - PROGRESS: at 32.42% examples, 567034 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:47,398 EPOCH 4 - PROGRESS: at 47.61% examples, 556368 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:48,398 EPOCH 4 - PROGRESS: at 63.77% examples, 566820 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:49,416 EPOCH 4 - PROGRESS: at 79.48% examples, 576838 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:50,418 EPOCH 4 - PROGRESS: at 97.16% examples, 568924 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:50,551 EPOCH 4: training on 3499793 raw words (3519656 effective words) took 6.2s, 570467 effective words/s
2024-06-24 22:03:51,569 EPOCH 5 - PROGRESS: at 16.52% examples, 561830 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:52,570 EPOCH 5 - PROGRESS: at 32.42% examples, 565034 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:53,572 EPOCH 5 - PROGRESS: at 48.51% examples, 566310 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:54,577 EPOCH 5 - PROGRESS: at 65.28% examples, 580998 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:03:55,578 EPOCH 5 - PROGRESS: at 81.29% examples, 589928 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:56,569 EPOCH 5: training on 3499793 raw words (3519614 effective words) took 6.0s, 585166 effective words/s
2024-06-24 22:03:57,592 EPOCH 6 - PROGRESS: at 16.52% examples, 559108 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:58,608 EPOCH 6 - PROGRESS: at 33.26% examples, 574219 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:03:59,624 EPOCH 6 - PROGRESS: at 50.26% examples, 579592 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:00,637 EPOCH 6 - PROGRESS: at 65.80% examples, 579877 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:01,664 EPOCH 6 - PROGRESS: at 81.29% examples, 582120 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:02,629 EPOCH 6: training on 3499793 raw words (3519571 effective words) took 6.1s, 581124 effective words/s
2024-06-24 22:04:03,664 EPOCH 7 - PROGRESS: at 16.77% examples, 561909 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:04,673 EPOCH 7 - PROGRESS: at 33.82% examples, 582769 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:05,685 EPOCH 7 - PROGRESS: at 50.73% examples, 585867 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:06,690 EPOCH 7 - PROGRESS: at 67.81% examples, 600691 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:07,698 EPOCH 7 - PROGRESS: at 84.77% examples, 604941 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:08,533 EPOCH 7: training on 3499793 raw words (3519400 effective words) took 5.9s, 596489 effective words/s
2024-06-24 22:04:09,546 EPOCH 8 - PROGRESS: at 18.00% examples, 613719 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:10,559 EPOCH 8 - PROGRESS: at 33.82% examples, 587734 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:11,567 EPOCH 8 - PROGRESS: at 48.87% examples, 567145 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:12,597 EPOCH 8 - PROGRESS: at 66.02% examples, 582981 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:13,606 EPOCH 8 - PROGRESS: at 81.29% examples, 584641 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:14,556 EPOCH 8: training on 3499793 raw words (3519548 effective words) took 6.0s, 584711 effective words/s
2024-06-24 22:04:15,562 EPOCH 9 - PROGRESS: at 17.73% examples, 608221 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:16,586 EPOCH 9 - PROGRESS: at 34.38% examples, 596427 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:17,586 EPOCH 9 - PROGRESS: at 51.03% examples, 594084 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:18,596 EPOCH 9 - PROGRESS: at 67.29% examples, 598722 words/s, in_qsize 7, out_qsize 0
2024-06-24 22:04:19,605 EPOCH 9 - PROGRESS: at 83.02% examples, 597323 words/s, in_qsize 8, out_qsize 0
2024-06-24 22:04:20,530 EPOCH 9: training on 3499793 raw words (3519585 effective words) took 6.0s, 589411 effective words/s
2024-06-24 22:04:20,531 Doc2Vec lifecycle event {'msg': 'training on 34997930 raw words (35195492 effective words) took 59.6s, 590095 effective words/s', 'datetime': '2024-06-24T22:04:20.531326', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-128-generic-x86_64-with-glibc2.31', 'event': 'train'}
2024-06-24 22:05:23,163 ==================================================
2024-06-24 22:05:23,163 Training BERT + Doc2Vec features with Dimension-8...
2024-06-24 22:05:24,147 Epoch [1/8], Batch [1/748], Loss: 1.6942
2024-06-24 22:06:13,522 Epoch [1/8], Batch [51/748], Loss: 1.4423
2024-06-24 22:07:04,042 Epoch [1/8], Batch [101/748], Loss: 1.2536
2024-06-24 22:07:54,783 Epoch [1/8], Batch [151/748], Loss: 1.2630
2024-06-24 22:08:45,564 Epoch [1/8], Batch [201/748], Loss: 0.9885
2024-06-24 22:09:36,092 Epoch [1/8], Batch [251/748], Loss: 1.1611
2024-06-24 22:10:26,698 Epoch [1/8], Batch [301/748], Loss: 1.1270
2024-06-24 22:11:17,531 Epoch [1/8], Batch [351/748], Loss: 0.9933
2024-06-24 22:12:08,042 Epoch [1/8], Batch [401/748], Loss: 1.0436
2024-06-24 22:12:58,686 Epoch [1/8], Batch [451/748], Loss: 1.0234
2024-06-24 22:13:49,588 Epoch [1/8], Batch [501/748], Loss: 0.9331
2024-06-24 22:14:40,531 Epoch [1/8], Batch [551/748], Loss: 0.9871
2024-06-24 22:15:31,501 Epoch [1/8], Batch [601/748], Loss: 0.9446
2024-06-24 22:16:22,325 Epoch [1/8], Batch [651/748], Loss: 0.9260
2024-06-24 22:17:13,410 Epoch [1/8], Batch [701/748], Loss: 0.6975
2024-06-24 22:18:00,858 Epoch 1/8, Train Loss: 1.0733, Train Accuracy: 0.5413
2024-06-24 22:19:23,542 Epoch 1/8, Val Loss: 0.8709, Val Accuracy: 0.6163
2024-06-24 22:19:24,551 Epoch [2/8], Batch [1/748], Loss: 0.9788
2024-06-24 22:20:15,366 Epoch [2/8], Batch [51/748], Loss: 0.8920
2024-06-24 22:21:06,811 Epoch [2/8], Batch [101/748], Loss: 0.5989
2024-06-24 22:21:58,060 Epoch [2/8], Batch [151/748], Loss: 0.7693
2024-06-24 22:22:49,278 Epoch [2/8], Batch [201/748], Loss: 0.7197
2024-06-24 22:23:40,466 Epoch [2/8], Batch [251/748], Loss: 0.8531
2024-06-24 22:24:31,573 Epoch [2/8], Batch [301/748], Loss: 0.8131
2024-06-24 22:25:22,990 Epoch [2/8], Batch [351/748], Loss: 0.7235
2024-06-24 22:26:14,279 Epoch [2/8], Batch [401/748], Loss: 0.7370
2024-06-24 22:27:05,728 Epoch [2/8], Batch [451/748], Loss: 0.7216
2024-06-24 22:27:56,877 Epoch [2/8], Batch [501/748], Loss: 0.9597
2024-06-24 22:28:48,046 Epoch [2/8], Batch [551/748], Loss: 0.8461
2024-06-24 22:29:39,159 Epoch [2/8], Batch [601/748], Loss: 0.6829
2024-06-24 22:30:30,280 Epoch [2/8], Batch [651/748], Loss: 0.7961
2024-06-24 22:31:21,736 Epoch [2/8], Batch [701/748], Loss: 0.7862
2024-06-24 22:32:09,985 Epoch 2/8, Train Loss: 0.8114, Train Accuracy: 0.6457
2024-06-24 22:33:34,384 Epoch 2/8, Val Loss: 0.8883, Val Accuracy: 0.6258
2024-06-24 22:33:35,413 Epoch [3/8], Batch [1/748], Loss: 0.7594
2024-06-24 22:34:26,827 Epoch [3/8], Batch [51/748], Loss: 0.5754
2024-06-24 22:35:18,656 Epoch [3/8], Batch [101/748], Loss: 0.9143
2024-06-24 22:36:09,859 Epoch [3/8], Batch [151/748], Loss: 0.7012
2024-06-24 22:37:00,980 Epoch [3/8], Batch [201/748], Loss: 0.8954
2024-06-24 22:37:52,242 Epoch [3/8], Batch [251/748], Loss: 0.6838
2024-06-24 22:38:43,489 Epoch [3/8], Batch [301/748], Loss: 0.9050
2024-06-24 22:39:34,730 Epoch [3/8], Batch [351/748], Loss: 0.6361
2024-06-24 22:40:25,619 Epoch [3/8], Batch [401/748], Loss: 0.8982
2024-06-24 22:41:16,722 Epoch [3/8], Batch [451/748], Loss: 0.6139
2024-06-24 22:42:07,716 Epoch [3/8], Batch [501/748], Loss: 0.6037
2024-06-24 22:42:59,081 Epoch [3/8], Batch [551/748], Loss: 0.6795
2024-06-24 22:43:50,710 Epoch [3/8], Batch [601/748], Loss: 0.5195
2024-06-24 22:44:42,263 Epoch [3/8], Batch [651/748], Loss: 0.6138
2024-06-24 22:45:33,863 Epoch [3/8], Batch [701/748], Loss: 0.7204
2024-06-24 22:46:21,950 Epoch 3/8, Train Loss: 0.7016, Train Accuracy: 0.6917
2024-06-24 22:47:45,323 Epoch 3/8, Val Loss: 0.8029, Val Accuracy: 0.6546
2024-06-24 22:47:46,332 Epoch [4/8], Batch [1/748], Loss: 0.7051
2024-06-24 22:48:37,546 Epoch [4/8], Batch [51/748], Loss: 0.5789
2024-06-24 22:49:29,060 Epoch [4/8], Batch [101/748], Loss: 0.6151
2024-06-24 22:50:20,279 Epoch [4/8], Batch [151/748], Loss: 0.4955
2024-06-24 22:51:11,643 Epoch [4/8], Batch [201/748], Loss: 0.8703
2024-06-24 22:52:02,862 Epoch [4/8], Batch [251/748], Loss: 0.4289
2024-06-24 22:52:54,180 Epoch [4/8], Batch [301/748], Loss: 0.5915
2024-06-24 22:53:45,824 Epoch [4/8], Batch [351/748], Loss: 0.5227
2024-06-24 22:54:37,287 Epoch [4/8], Batch [401/748], Loss: 0.4954
2024-06-24 22:55:28,846 Epoch [4/8], Batch [451/748], Loss: 0.6315
2024-06-24 22:56:20,245 Epoch [4/8], Batch [501/748], Loss: 0.7915
2024-06-24 22:57:11,859 Epoch [4/8], Batch [551/748], Loss: 0.5168
2024-06-24 22:58:03,205 Epoch [4/8], Batch [601/748], Loss: 0.6050
2024-06-24 22:58:54,629 Epoch [4/8], Batch [651/748], Loss: 0.4815
2024-06-24 22:59:46,021 Epoch [4/8], Batch [701/748], Loss: 0.7186
2024-06-24 23:00:34,018 Epoch 4/8, Train Loss: 0.5852, Train Accuracy: 0.7496
2024-06-24 23:01:57,976 Epoch 4/8, Val Loss: 0.7951, Val Accuracy: 0.6735
2024-06-24 23:01:59,017 Epoch [5/8], Batch [1/748], Loss: 0.4433
2024-06-24 23:02:50,206 Epoch [5/8], Batch [51/748], Loss: 0.4159
2024-06-24 23:03:41,752 Epoch [5/8], Batch [101/748], Loss: 0.5215
2024-06-24 23:04:33,218 Epoch [5/8], Batch [151/748], Loss: 0.6010
2024-06-24 23:05:24,532 Epoch [5/8], Batch [201/748], Loss: 0.4836
2024-06-24 23:06:15,976 Epoch [5/8], Batch [251/748], Loss: 0.3520
2024-06-24 23:07:07,162 Epoch [5/8], Batch [301/748], Loss: 0.4308
2024-06-24 23:07:58,220 Epoch [5/8], Batch [351/748], Loss: 0.5170
2024-06-24 23:08:49,364 Epoch [5/8], Batch [401/748], Loss: 0.4394
2024-06-24 23:09:40,497 Epoch [5/8], Batch [451/748], Loss: 0.5159
2024-06-24 23:10:31,630 Epoch [5/8], Batch [501/748], Loss: 0.3718
2024-06-24 23:11:22,760 Epoch [5/8], Batch [551/748], Loss: 0.4775
2024-06-24 23:12:13,655 Epoch [5/8], Batch [601/748], Loss: 0.3466
2024-06-24 23:13:04,725 Epoch [5/8], Batch [651/748], Loss: 0.4834
2024-06-24 23:13:55,726 Epoch [5/8], Batch [701/748], Loss: 0.4247
2024-06-24 23:14:43,262 Epoch 5/8, Train Loss: 0.4873, Train Accuracy: 0.7944
2024-06-24 23:16:05,914 Epoch 5/8, Val Loss: 0.8523, Val Accuracy: 0.6771
2024-06-24 23:16:06,932 Epoch [6/8], Batch [1/748], Loss: 0.4012
2024-06-24 23:16:57,641 Epoch [6/8], Batch [51/748], Loss: 0.2803
2024-06-24 23:17:48,603 Epoch [6/8], Batch [101/748], Loss: 0.3469
2024-06-24 23:18:39,571 Epoch [6/8], Batch [151/748], Loss: 0.3891
2024-06-24 23:19:30,749 Epoch [6/8], Batch [201/748], Loss: 0.4560
2024-06-24 23:20:21,728 Epoch [6/8], Batch [251/748], Loss: 0.3523
2024-06-24 23:21:12,834 Epoch [6/8], Batch [301/748], Loss: 0.3321
2024-06-24 23:22:04,055 Epoch [6/8], Batch [351/748], Loss: 0.3526
2024-06-24 23:22:55,269 Epoch [6/8], Batch [401/748], Loss: 0.3082
2024-06-24 23:23:46,746 Epoch [6/8], Batch [451/748], Loss: 0.4978
2024-06-24 23:24:38,038 Epoch [6/8], Batch [501/748], Loss: 0.4408
2024-06-24 23:25:29,436 Epoch [6/8], Batch [551/748], Loss: 0.4391
2024-06-24 23:26:20,783 Epoch [6/8], Batch [601/748], Loss: 0.4116
2024-06-24 23:27:12,215 Epoch [6/8], Batch [651/748], Loss: 0.4788
2024-06-24 23:28:03,330 Epoch [6/8], Batch [701/748], Loss: 0.4502
2024-06-24 23:28:51,452 Epoch 6/8, Train Loss: 0.3921, Train Accuracy: 0.8371
2024-06-24 23:30:15,427 Epoch 6/8, Val Loss: 0.9253, Val Accuracy: 0.6730
2024-06-24 23:30:16,453 Epoch [7/8], Batch [1/748], Loss: 0.2653
2024-06-24 23:31:07,595 Epoch [7/8], Batch [51/748], Loss: 0.4121
2024-06-24 23:31:59,069 Epoch [7/8], Batch [101/748], Loss: 0.1824
2024-06-24 23:32:50,483 Epoch [7/8], Batch [151/748], Loss: 0.3100
2024-06-24 23:33:41,715 Epoch [7/8], Batch [201/748], Loss: 0.2674
2024-06-24 23:34:32,882 Epoch [7/8], Batch [251/748], Loss: 0.2201
2024-06-24 23:35:24,333 Epoch [7/8], Batch [301/748], Loss: 0.2906
2024-06-24 23:36:15,302 Epoch [7/8], Batch [351/748], Loss: 0.2648
2024-06-24 23:37:06,407 Epoch [7/8], Batch [401/748], Loss: 0.3166
2024-06-24 23:37:57,684 Epoch [7/8], Batch [451/748], Loss: 0.4239
2024-06-24 23:38:49,078 Epoch [7/8], Batch [501/748], Loss: 0.2009
2024-06-24 23:39:40,160 Epoch [7/8], Batch [551/748], Loss: 0.2923
2024-06-24 23:40:31,089 Epoch [7/8], Batch [601/748], Loss: 0.5522
2024-06-24 23:41:22,070 Epoch [7/8], Batch [651/748], Loss: 0.4166
2024-06-24 23:42:13,562 Epoch [7/8], Batch [701/748], Loss: 0.3721
2024-06-24 23:43:01,517 Epoch 7/8, Train Loss: 0.3257, Train Accuracy: 0.8665
2024-06-24 23:44:24,276 Epoch 7/8, Val Loss: 1.0018, Val Accuracy: 0.6808
2024-06-24 23:44:25,298 Epoch [8/8], Batch [1/748], Loss: 0.1613
2024-06-24 23:45:16,490 Epoch [8/8], Batch [51/748], Loss: 0.2112
2024-06-24 23:46:07,922 Epoch [8/8], Batch [101/748], Loss: 0.2003
2024-06-24 23:46:59,204 Epoch [8/8], Batch [151/748], Loss: 0.1734
2024-06-24 23:47:50,324 Epoch [8/8], Batch [201/748], Loss: 0.3490
2024-06-24 23:48:41,538 Epoch [8/8], Batch [251/748], Loss: 0.2890
2024-06-24 23:49:32,442 Epoch [8/8], Batch [301/748], Loss: 0.1817
2024-06-24 23:50:23,623 Epoch [8/8], Batch [351/748], Loss: 0.2667
2024-06-24 23:51:14,734 Epoch [8/8], Batch [401/748], Loss: 0.3656
2024-06-24 23:52:05,649 Epoch [8/8], Batch [451/748], Loss: 0.2577
2024-06-24 23:52:56,407 Epoch [8/8], Batch [501/748], Loss: 0.3732
2024-06-24 23:53:47,532 Epoch [8/8], Batch [551/748], Loss: 0.3538
2024-06-24 23:54:38,402 Epoch [8/8], Batch [601/748], Loss: 0.2785
2024-06-24 23:55:29,492 Epoch [8/8], Batch [651/748], Loss: 0.2264
2024-06-24 23:56:20,263 Epoch [8/8], Batch [701/748], Loss: 0.2795
2024-06-24 23:57:08,057 Epoch 8/8, Train Loss: 0.2630, Train Accuracy: 0.8952
2024-06-24 23:58:30,714 Epoch 8/8, Val Loss: 1.1374, Val Accuracy: 0.6576
2024-06-24 23:58:30,716 Training finished!
2024-06-24 23:58:30,717 ==================================================
