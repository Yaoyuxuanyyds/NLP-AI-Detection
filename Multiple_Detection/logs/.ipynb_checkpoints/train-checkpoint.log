2024-06-22 08:47:55,694 ==================================================
2024-06-22 08:47:55,694 Training with Guassian Noise of 1 length...
2024-06-22 08:47:57,208 Epoch [1/8], Batch [1/748], Loss: 1.6309
2024-06-22 08:48:21,592 Epoch [1/8], Batch [51/748], Loss: 1.5795
2024-06-22 08:48:46,236 Epoch [1/8], Batch [101/748], Loss: 1.5978
2024-06-22 08:49:10,617 Epoch [1/8], Batch [151/748], Loss: 1.6197
2024-06-22 08:49:35,402 Epoch [1/8], Batch [201/748], Loss: 1.6121
2024-06-22 08:50:00,258 Epoch [1/8], Batch [251/748], Loss: 1.5556
2024-06-22 08:50:24,930 Epoch [1/8], Batch [301/748], Loss: 1.5435
2024-06-22 08:50:50,301 Epoch [1/8], Batch [351/748], Loss: 1.5389
2024-06-22 08:51:15,021 Epoch [1/8], Batch [401/748], Loss: 1.5790
2024-06-22 08:51:39,958 Epoch [1/8], Batch [451/748], Loss: 1.6348
2024-06-22 08:52:04,515 Epoch [1/8], Batch [501/748], Loss: 1.6184
2024-06-22 08:52:29,427 Epoch [1/8], Batch [551/748], Loss: 1.5580
2024-06-22 08:52:54,529 Epoch [1/8], Batch [601/748], Loss: 1.5328
2024-06-22 08:53:19,452 Epoch [1/8], Batch [651/748], Loss: 1.5003
2024-06-22 08:53:44,396 Epoch [1/8], Batch [701/748], Loss: 1.5472
2024-06-22 08:54:07,430 Epoch 1/8, Train Loss: 1.5753, Train Accuracy: 0.2667
2024-06-22 08:55:37,175 Epoch 1/8, Val Loss: 1.5333, Val Accuracy: 0.3125
2024-06-22 08:55:37,711 Epoch [2/8], Batch [1/748], Loss: 1.4685
2024-06-22 08:56:02,204 Epoch [2/8], Batch [51/748], Loss: 1.5072
2024-06-22 08:56:27,071 Epoch [2/8], Batch [101/748], Loss: 1.5637
2024-06-22 08:56:52,025 Epoch [2/8], Batch [151/748], Loss: 1.5169
2024-06-22 08:57:16,875 Epoch [2/8], Batch [201/748], Loss: 1.5803
2024-06-22 08:57:41,525 Epoch [2/8], Batch [251/748], Loss: 1.5357
2024-06-22 08:58:06,153 Epoch [2/8], Batch [301/748], Loss: 1.5761
2024-06-22 08:58:31,291 Epoch [2/8], Batch [351/748], Loss: 1.4746
2024-06-22 08:58:56,043 Epoch [2/8], Batch [401/748], Loss: 1.5553
2024-06-22 08:59:21,006 Epoch [2/8], Batch [451/748], Loss: 1.5120
2024-06-22 08:59:46,093 Epoch [2/8], Batch [501/748], Loss: 1.5364
2024-06-22 09:00:10,985 Epoch [2/8], Batch [551/748], Loss: 1.5653
2024-06-22 09:00:35,700 Epoch [2/8], Batch [601/748], Loss: 1.5129
2024-06-22 09:01:00,490 Epoch [2/8], Batch [651/748], Loss: 1.6044
2024-06-22 09:01:25,480 Epoch [2/8], Batch [701/748], Loss: 1.3962
2024-06-22 09:01:48,702 Epoch 2/8, Train Loss: 1.5279, Train Accuracy: 0.3305
2024-06-22 09:03:18,389 Epoch 2/8, Val Loss: 1.4867, Val Accuracy: 0.3690
2024-06-22 09:03:18,870 Epoch [3/8], Batch [1/748], Loss: 1.5102
2024-06-22 09:03:43,153 Epoch [3/8], Batch [51/748], Loss: 1.5210
2024-06-22 09:04:07,652 Epoch [3/8], Batch [101/748], Loss: 1.5707
2024-06-22 09:04:32,263 Epoch [3/8], Batch [151/748], Loss: 1.6005
2024-06-22 09:04:56,787 Epoch [3/8], Batch [201/748], Loss: 1.3900
2024-06-22 09:05:21,421 Epoch [3/8], Batch [251/748], Loss: 1.5557
2024-06-22 09:05:45,767 Epoch [3/8], Batch [301/748], Loss: 1.5165
2024-06-22 09:06:09,941 Epoch [3/8], Batch [351/748], Loss: 1.5254
2024-06-22 09:06:34,495 Epoch [3/8], Batch [401/748], Loss: 1.5179
2024-06-22 09:06:59,090 Epoch [3/8], Batch [451/748], Loss: 1.4401
2024-06-22 09:07:23,453 Epoch [3/8], Batch [501/748], Loss: 1.4805
2024-06-22 09:07:48,121 Epoch [3/8], Batch [551/748], Loss: 1.4671
2024-06-22 09:08:12,449 Epoch [3/8], Batch [601/748], Loss: 1.5289
2024-06-22 09:08:37,292 Epoch [3/8], Batch [651/748], Loss: 1.4655
2024-06-22 09:09:01,645 Epoch [3/8], Batch [701/748], Loss: 1.4286
2024-06-22 09:09:24,380 Epoch 3/8, Train Loss: 1.4934, Train Accuracy: 0.3668
2024-06-22 09:10:53,497 Epoch 3/8, Val Loss: 1.4457, Val Accuracy: 0.4125
2024-06-22 09:10:53,976 Epoch [4/8], Batch [1/748], Loss: 1.4247
2024-06-22 09:11:18,486 Epoch [4/8], Batch [51/748], Loss: 1.4692
2024-06-22 09:11:43,071 Epoch [4/8], Batch [101/748], Loss: 1.5225
2024-06-22 09:12:07,777 Epoch [4/8], Batch [151/748], Loss: 1.4436
2024-06-22 09:28:08,256 ==================================================
2024-06-22 09:28:08,256 Training with Guassian Noise of 1 length...
2024-06-22 09:35:51,621 ==================================================
2024-06-22 09:35:51,622 Training with Guassian Noise of 1 length...
2024-06-22 09:39:27,972 ==================================================
2024-06-22 09:39:27,972 Training with Guassian Noise of 1 length...
2024-06-22 09:39:30,006 Epoch [1/8], Batch [1/374], Loss: 1.6544
2024-06-22 09:40:21,090 Epoch [1/8], Batch [51/374], Loss: 1.4753
2024-06-22 09:41:12,641 Epoch [1/8], Batch [101/374], Loss: 1.2630
2024-06-22 09:42:04,852 Epoch [1/8], Batch [151/374], Loss: 1.1806
2024-06-22 09:42:57,365 Epoch [1/8], Batch [201/374], Loss: 1.1001
2024-06-22 09:43:49,409 Epoch [1/8], Batch [251/374], Loss: 1.0324
2024-06-22 09:44:41,668 Epoch [1/8], Batch [301/374], Loss: 1.1968
2024-06-22 09:45:33,814 Epoch [1/8], Batch [351/374], Loss: 0.9831
2024-06-22 09:45:57,725 Epoch 1/8, Train Loss: 1.2087, Train Accuracy: 0.4827
2024-06-22 09:46:43,414 Epoch 1/8, Val Loss: 1.0383, Val Accuracy: 0.5462
2024-06-22 09:46:44,482 Epoch [2/8], Batch [1/374], Loss: 0.9405
2024-06-22 09:47:36,603 Epoch [2/8], Batch [51/374], Loss: 0.8878
2024-06-22 09:48:28,589 Epoch [2/8], Batch [101/374], Loss: 0.8520
2024-06-22 09:49:20,340 Epoch [2/8], Batch [151/374], Loss: 0.9065
2024-06-22 09:50:12,298 Epoch [2/8], Batch [201/374], Loss: 0.8695
2024-06-22 09:51:04,395 Epoch [2/8], Batch [251/374], Loss: 1.0106
2024-06-22 09:51:56,263 Epoch [2/8], Batch [301/374], Loss: 0.9979
2024-06-22 09:52:48,179 Epoch [2/8], Batch [351/374], Loss: 0.8872
2024-06-22 09:53:11,913 Epoch 2/8, Train Loss: 0.9080, Train Accuracy: 0.6056
2024-06-22 09:53:56,965 Epoch 2/8, Val Loss: 0.9047, Val Accuracy: 0.6110
2024-06-22 09:53:58,005 Epoch [3/8], Batch [1/374], Loss: 0.7214
2024-06-22 09:54:50,096 Epoch [3/8], Batch [51/374], Loss: 1.0209
2024-06-22 09:55:42,176 Epoch [3/8], Batch [101/374], Loss: 0.7839
2024-06-22 09:56:34,374 Epoch [3/8], Batch [151/374], Loss: 0.8576
2024-06-22 09:57:26,389 Epoch [3/8], Batch [201/374], Loss: 0.7624
2024-06-22 09:58:18,153 Epoch [3/8], Batch [251/374], Loss: 0.7954
2024-06-22 09:59:10,094 Epoch [3/8], Batch [301/374], Loss: 0.7891
2024-06-22 10:00:01,629 Epoch [3/8], Batch [351/374], Loss: 0.7038
2024-06-22 10:00:25,272 Epoch 3/8, Train Loss: 0.7945, Train Accuracy: 0.6516
2024-06-22 10:01:10,062 Epoch 3/8, Val Loss: 0.8982, Val Accuracy: 0.6187
2024-06-22 10:01:11,069 Epoch [4/8], Batch [1/374], Loss: 1.0155
2024-06-22 10:02:02,640 Epoch [4/8], Batch [51/374], Loss: 0.9558
2024-06-22 10:02:54,895 Epoch [4/8], Batch [101/374], Loss: 0.6274
2024-06-22 10:03:46,419 Epoch [4/8], Batch [151/374], Loss: 0.7256
2024-06-22 10:04:38,223 Epoch [4/8], Batch [201/374], Loss: 0.6209
2024-06-22 10:05:30,540 Epoch [4/8], Batch [251/374], Loss: 0.6366
2024-06-22 10:06:22,708 Epoch [4/8], Batch [301/374], Loss: 0.9544
2024-06-22 10:07:14,968 Epoch [4/8], Batch [351/374], Loss: 0.6582
2024-06-22 10:07:38,537 Epoch 4/8, Train Loss: 0.6900, Train Accuracy: 0.6963
2024-06-22 10:08:23,875 Epoch 4/8, Val Loss: 0.8797, Val Accuracy: 0.6207
2024-06-22 10:08:24,921 Epoch [5/8], Batch [1/374], Loss: 0.6220
2024-06-22 10:09:16,650 Epoch [5/8], Batch [51/374], Loss: 0.6476
2024-06-22 10:10:08,586 Epoch [5/8], Batch [101/374], Loss: 0.5935
2024-06-22 10:11:01,151 Epoch [5/8], Batch [151/374], Loss: 0.6544
2024-06-22 10:11:53,763 Epoch [5/8], Batch [201/374], Loss: 0.4186
2024-06-22 10:12:46,377 Epoch [5/8], Batch [251/374], Loss: 0.6522
2024-06-22 10:13:39,047 Epoch [5/8], Batch [301/374], Loss: 0.4577
2024-06-22 10:14:31,664 Epoch [5/8], Batch [351/374], Loss: 0.6949
2024-06-22 10:14:55,764 Epoch 5/8, Train Loss: 0.6106, Train Accuracy: 0.7309
2024-06-22 10:15:42,082 Epoch 5/8, Val Loss: 0.8694, Val Accuracy: 0.6445
2024-06-22 10:15:43,137 Epoch [6/8], Batch [1/374], Loss: 0.6854
2024-06-22 10:16:35,265 Epoch [6/8], Batch [51/374], Loss: 0.2833
2024-06-22 10:17:27,469 Epoch [6/8], Batch [101/374], Loss: 0.4719
2024-06-22 10:18:19,807 Epoch [6/8], Batch [151/374], Loss: 0.5602
2024-06-22 10:19:13,073 Epoch [6/8], Batch [201/374], Loss: 0.5186
2024-06-22 10:20:06,435 Epoch [6/8], Batch [251/374], Loss: 0.6467
2024-06-22 10:20:59,852 Epoch [6/8], Batch [301/374], Loss: 0.5155
2024-06-22 10:21:52,940 Epoch [6/8], Batch [351/374], Loss: 0.5937
2024-06-22 10:22:17,192 Epoch 6/8, Train Loss: 0.5179, Train Accuracy: 0.7774
2024-06-22 10:23:04,916 Epoch 6/8, Val Loss: 0.9833, Val Accuracy: 0.6334
2024-06-22 10:23:05,974 Epoch [7/8], Batch [1/374], Loss: 0.4329
2024-06-22 10:23:59,079 Epoch [7/8], Batch [51/374], Loss: 0.3831
2024-06-22 10:24:52,366 Epoch [7/8], Batch [101/374], Loss: 0.3174
2024-06-22 10:25:45,716 Epoch [7/8], Batch [151/374], Loss: 0.3843
2024-06-22 10:26:38,916 Epoch [7/8], Batch [201/374], Loss: 0.2852
2024-06-22 10:27:31,791 Epoch [7/8], Batch [251/374], Loss: 0.2905
2024-06-22 10:28:24,290 Epoch [7/8], Batch [301/374], Loss: 0.4573
2024-06-22 10:29:17,181 Epoch [7/8], Batch [351/374], Loss: 0.2526
2024-06-22 10:29:41,261 Epoch 7/8, Train Loss: 0.4276, Train Accuracy: 0.8222
2024-06-22 10:30:27,916 Epoch 7/8, Val Loss: 1.0477, Val Accuracy: 0.6107
2024-06-22 10:30:28,959 Epoch [8/8], Batch [1/374], Loss: 0.2861
2024-06-22 10:31:21,522 Epoch [8/8], Batch [51/374], Loss: 0.2371
2024-06-22 10:32:14,020 Epoch [8/8], Batch [101/374], Loss: 0.3257
2024-06-22 10:33:07,129 Epoch [8/8], Batch [151/374], Loss: 0.4387
2024-06-22 10:33:59,821 Epoch [8/8], Batch [201/374], Loss: 0.4315
2024-06-22 10:34:52,840 Epoch [8/8], Batch [251/374], Loss: 0.4331
2024-06-22 10:35:45,371 Epoch [8/8], Batch [301/374], Loss: 0.5547
2024-06-22 10:36:38,106 Epoch [8/8], Batch [351/374], Loss: 0.4141
2024-06-22 10:37:02,027 Epoch 8/8, Train Loss: 0.3651, Train Accuracy: 0.8549
2024-06-22 10:37:48,476 Epoch 8/8, Val Loss: 1.0186, Val Accuracy: 0.6405
2024-06-22 10:37:48,477 Training finished!
2024-06-22 10:37:48,477 ==================================================
2024-06-22 10:37:49,108 ==================================================
2024-06-22 10:37:49,108 Training with Guassian Noise of 16 length...
2024-06-22 10:37:50,204 Epoch [1/8], Batch [1/374], Loss: 1.6261
2024-06-22 10:38:42,877 Epoch [1/8], Batch [51/374], Loss: 1.4978
2024-06-22 10:39:35,609 Epoch [1/8], Batch [101/374], Loss: 1.2382
2024-06-22 10:40:28,505 Epoch [1/8], Batch [151/374], Loss: 1.0523
2024-06-22 10:41:21,270 Epoch [1/8], Batch [201/374], Loss: 1.0712
2024-06-22 10:42:14,119 Epoch [1/8], Batch [251/374], Loss: 1.0781
2024-06-22 10:43:07,100 Epoch [1/8], Batch [301/374], Loss: 0.8509
2024-06-22 10:43:59,786 Epoch [1/8], Batch [351/374], Loss: 1.1207
2024-06-22 10:44:23,984 Epoch 1/8, Train Loss: 1.1717, Train Accuracy: 0.5125
2024-06-22 10:45:10,233 Epoch 1/8, Val Loss: 0.9480, Val Accuracy: 0.5883
2024-06-22 10:45:11,276 Epoch [2/8], Batch [1/374], Loss: 0.9443
2024-06-22 10:46:03,854 Epoch [2/8], Batch [51/374], Loss: 0.8271
2024-06-22 10:46:56,567 Epoch [2/8], Batch [101/374], Loss: 0.6608
2024-06-22 10:47:49,316 Epoch [2/8], Batch [151/374], Loss: 0.9649
2024-06-22 10:48:42,421 Epoch [2/8], Batch [201/374], Loss: 0.9152
2024-06-22 10:49:35,958 Epoch [2/8], Batch [251/374], Loss: 0.7430
2024-06-22 10:50:28,676 Epoch [2/8], Batch [301/374], Loss: 0.9483
2024-06-22 10:51:21,525 Epoch [2/8], Batch [351/374], Loss: 0.8388
2024-06-22 10:51:45,614 Epoch 2/8, Train Loss: 0.8671, Train Accuracy: 0.6248
2024-06-22 10:52:32,405 Epoch 2/8, Val Loss: 0.9643, Val Accuracy: 0.5756
2024-06-22 10:52:33,474 Epoch [3/8], Batch [1/374], Loss: 0.7128
2024-06-22 10:53:26,190 Epoch [3/8], Batch [51/374], Loss: 0.6132
2024-06-22 10:54:19,057 Epoch [3/8], Batch [101/374], Loss: 0.6701
2024-06-22 10:55:11,918 Epoch [3/8], Batch [151/374], Loss: 0.7004
2024-06-22 10:56:04,867 Epoch [3/8], Batch [201/374], Loss: 0.6214
2024-06-22 10:56:57,796 Epoch [3/8], Batch [251/374], Loss: 0.7713
2024-06-22 10:57:50,567 Epoch [3/8], Batch [301/374], Loss: 0.9212
2024-06-22 10:58:43,935 Epoch [3/8], Batch [351/374], Loss: 0.8304
2024-06-22 10:59:07,983 Epoch 3/8, Train Loss: 0.7517, Train Accuracy: 0.6775
2024-06-22 10:59:54,663 Epoch 3/8, Val Loss: 0.9020, Val Accuracy: 0.6154
2024-06-22 10:59:55,688 Epoch [4/8], Batch [1/374], Loss: 0.7192
2024-06-22 11:00:48,369 Epoch [4/8], Batch [51/374], Loss: 0.9472
2024-06-22 11:01:40,895 Epoch [4/8], Batch [101/374], Loss: 0.6690
2024-06-22 11:02:33,942 Epoch [4/8], Batch [151/374], Loss: 0.6325
2024-06-22 11:03:26,814 Epoch [4/8], Batch [201/374], Loss: 0.4350
2024-06-22 11:04:19,565 Epoch [4/8], Batch [251/374], Loss: 0.7762
2024-06-22 11:05:12,556 Epoch [4/8], Batch [301/374], Loss: 0.6751
2024-06-22 11:06:05,496 Epoch [4/8], Batch [351/374], Loss: 0.7329
2024-06-22 11:06:29,830 Epoch 4/8, Train Loss: 0.6463, Train Accuracy: 0.7259
2024-06-22 11:07:16,800 Epoch 4/8, Val Loss: 0.8511, Val Accuracy: 0.6498
2024-06-22 11:07:17,832 Epoch [5/8], Batch [1/374], Loss: 0.4590
2024-06-22 11:08:10,637 Epoch [5/8], Batch [51/374], Loss: 0.6872
2024-06-22 11:09:03,586 Epoch [5/8], Batch [101/374], Loss: 0.6418
2024-06-22 11:09:56,256 Epoch [5/8], Batch [151/374], Loss: 0.7941
2024-06-22 11:10:49,027 Epoch [5/8], Batch [201/374], Loss: 0.5828
2024-06-22 11:11:42,133 Epoch [5/8], Batch [251/374], Loss: 0.4393
2024-06-22 11:12:35,078 Epoch [5/8], Batch [301/374], Loss: 0.6034
2024-06-22 11:13:28,210 Epoch [5/8], Batch [351/374], Loss: 0.6599
2024-06-22 11:13:52,326 Epoch 5/8, Train Loss: 0.5389, Train Accuracy: 0.7756
2024-06-22 11:14:39,291 Epoch 5/8, Val Loss: 0.9703, Val Accuracy: 0.6311
2024-06-22 11:14:40,361 Epoch [6/8], Batch [1/374], Loss: 0.4055
2024-06-22 11:15:33,122 Epoch [6/8], Batch [51/374], Loss: 0.4271
2024-06-22 11:16:25,852 Epoch [6/8], Batch [101/374], Loss: 0.3383
2024-06-22 11:17:18,969 Epoch [6/8], Batch [151/374], Loss: 0.3978
2024-06-22 11:18:12,079 Epoch [6/8], Batch [201/374], Loss: 0.4276
2024-06-22 11:19:05,263 Epoch [6/8], Batch [251/374], Loss: 0.7633
2024-06-22 11:19:58,326 Epoch [6/8], Batch [301/374], Loss: 0.4099
2024-06-22 11:20:51,127 Epoch [6/8], Batch [351/374], Loss: 0.5681
2024-06-22 11:21:15,173 Epoch 6/8, Train Loss: 0.4491, Train Accuracy: 0.8172
2024-06-22 11:22:01,585 Epoch 6/8, Val Loss: 0.9497, Val Accuracy: 0.6498
2024-06-22 11:22:02,625 Epoch [7/8], Batch [1/374], Loss: 0.3730
2024-06-22 11:22:55,581 Epoch [7/8], Batch [51/374], Loss: 0.3589
2024-06-22 11:23:48,219 Epoch [7/8], Batch [101/374], Loss: 0.2974
2024-06-22 11:24:40,994 Epoch [7/8], Batch [151/374], Loss: 0.3175
2024-06-22 11:25:33,918 Epoch [7/8], Batch [201/374], Loss: 0.2328
2024-06-22 11:26:27,030 Epoch [7/8], Batch [251/374], Loss: 0.2255
2024-06-22 11:27:19,970 Epoch [7/8], Batch [301/374], Loss: 0.3474
2024-06-22 11:28:12,520 Epoch [7/8], Batch [351/374], Loss: 0.3199
2024-06-22 11:28:36,629 Epoch 7/8, Train Loss: 0.3657, Train Accuracy: 0.8576
2024-06-22 11:29:23,202 Epoch 7/8, Val Loss: 0.9950, Val Accuracy: 0.6431
2024-06-22 11:29:24,271 Epoch [8/8], Batch [1/374], Loss: 0.2258
2024-06-22 11:30:16,899 Epoch [8/8], Batch [51/374], Loss: 0.2984
2024-06-22 11:31:09,912 Epoch [8/8], Batch [101/374], Loss: 0.2769
2024-06-22 11:32:02,645 Epoch [8/8], Batch [151/374], Loss: 0.2245
2024-06-22 11:32:55,539 Epoch [8/8], Batch [201/374], Loss: 0.2218
2024-06-22 11:33:48,316 Epoch [8/8], Batch [251/374], Loss: 0.2379
2024-06-22 11:34:41,516 Epoch [8/8], Batch [301/374], Loss: 0.3656
2024-06-22 11:35:34,025 Epoch [8/8], Batch [351/374], Loss: 0.2713
2024-06-22 11:35:57,888 Epoch 8/8, Train Loss: 0.2943, Train Accuracy: 0.8916
2024-06-22 11:36:44,242 Epoch 8/8, Val Loss: 1.1702, Val Accuracy: 0.6294
2024-06-22 11:36:44,243 Training finished!
2024-06-22 11:36:44,243 ==================================================
2024-06-22 11:36:44,922 ==================================================
2024-06-22 11:36:44,922 Training with Guassian Noise of 64 length...
2024-06-22 11:36:45,979 Epoch [1/8], Batch [1/374], Loss: 1.6007
2024-06-22 11:37:38,670 Epoch [1/8], Batch [51/374], Loss: 1.5464
2024-06-22 11:38:30,927 Epoch [1/8], Batch [101/374], Loss: 1.2754
