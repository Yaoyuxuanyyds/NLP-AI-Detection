2024-06-23 16:02:49,185 ==================================================
2024-06-23 16:02:49,186 Training BERT + TF-IDF features with Dimension-4096...
2024-06-23 16:02:51,000 Epoch [1/8], Batch [1/748], Loss: 1.6043
2024-06-23 16:03:40,064 Epoch [1/8], Batch [51/748], Loss: 1.5688
2024-06-23 16:04:30,193 Epoch [1/8], Batch [101/748], Loss: 1.3628
2024-06-23 16:05:20,690 Epoch [1/8], Batch [151/748], Loss: 1.3361
2024-06-23 16:06:11,017 Epoch [1/8], Batch [201/748], Loss: 1.2770
2024-06-23 16:07:01,798 Epoch [1/8], Batch [251/748], Loss: 0.9839
2024-06-23 16:07:52,293 Epoch [1/8], Batch [301/748], Loss: 1.0429
2024-06-23 16:08:42,708 Epoch [1/8], Batch [351/748], Loss: 1.0235
2024-06-23 16:09:33,285 Epoch [1/8], Batch [401/748], Loss: 0.9958
2024-06-23 16:10:23,928 Epoch [1/8], Batch [451/748], Loss: 1.0011
2024-06-23 16:11:14,531 Epoch [1/8], Batch [501/748], Loss: 0.9191
2024-06-23 16:12:05,507 Epoch [1/8], Batch [551/748], Loss: 1.0187
2024-06-23 16:12:56,484 Epoch [1/8], Batch [601/748], Loss: 0.8703
2024-06-23 16:13:46,931 Epoch [1/8], Batch [651/748], Loss: 0.7106
2024-06-23 16:14:37,396 Epoch [1/8], Batch [701/748], Loss: 0.6072
2024-06-23 16:15:24,747 Epoch 1/8, Train Loss: 1.0957, Train Accuracy: 0.5395
2024-06-23 16:16:49,338 Epoch 1/8, Val Loss: 0.9200, Val Accuracy: 0.5952
2024-06-23 16:16:50,361 Epoch [2/8], Batch [1/748], Loss: 0.8043
2024-06-23 16:17:40,852 Epoch [2/8], Batch [51/748], Loss: 0.7355
2024-06-23 16:18:31,835 Epoch [2/8], Batch [101/748], Loss: 0.7132
2024-06-23 16:19:22,628 Epoch [2/8], Batch [151/748], Loss: 0.7560
2024-06-23 16:20:13,209 Epoch [2/8], Batch [201/748], Loss: 0.9016
2024-06-23 16:21:03,583 Epoch [2/8], Batch [251/748], Loss: 0.9075
2024-06-23 16:21:54,413 Epoch [2/8], Batch [301/748], Loss: 1.2599
2024-06-23 16:22:44,891 Epoch [2/8], Batch [351/748], Loss: 0.8304
2024-06-23 16:23:35,621 Epoch [2/8], Batch [401/748], Loss: 1.0818
2024-06-23 16:24:26,335 Epoch [2/8], Batch [451/748], Loss: 0.7139
2024-06-23 16:25:17,010 Epoch [2/8], Batch [501/748], Loss: 1.0659
2024-06-23 16:26:07,506 Epoch [2/8], Batch [551/748], Loss: 0.8348
2024-06-23 16:26:58,332 Epoch [2/8], Batch [601/748], Loss: 0.6911
2024-06-23 16:27:49,147 Epoch [2/8], Batch [651/748], Loss: 0.7950
2024-06-23 16:28:40,099 Epoch [2/8], Batch [701/748], Loss: 0.7007
2024-06-23 16:29:27,612 Epoch 2/8, Train Loss: 0.8105, Train Accuracy: 0.6434
2024-06-23 16:30:52,199 Epoch 2/8, Val Loss: 0.8456, Val Accuracy: 0.6195
2024-06-23 16:30:53,227 Epoch [3/8], Batch [1/748], Loss: 0.7870
2024-06-23 16:31:43,670 Epoch [3/8], Batch [51/748], Loss: 0.8568
2024-06-23 16:32:34,646 Epoch [3/8], Batch [101/748], Loss: 0.6644
2024-06-23 16:33:25,480 Epoch [3/8], Batch [151/748], Loss: 0.8279
2024-06-23 16:34:16,094 Epoch [3/8], Batch [201/748], Loss: 0.8575
2024-06-23 16:35:06,548 Epoch [3/8], Batch [251/748], Loss: 0.5560
2024-06-23 16:35:57,148 Epoch [3/8], Batch [301/748], Loss: 0.6595
2024-06-23 16:36:47,888 Epoch [3/8], Batch [351/748], Loss: 0.9506
2024-06-23 16:37:38,404 Epoch [3/8], Batch [401/748], Loss: 0.8708
2024-06-23 16:38:29,172 Epoch [3/8], Batch [451/748], Loss: 0.7744
2024-06-23 16:39:19,890 Epoch [3/8], Batch [501/748], Loss: 0.4975
2024-06-23 16:40:10,914 Epoch [3/8], Batch [551/748], Loss: 0.5585
2024-06-23 16:41:02,001 Epoch [3/8], Batch [601/748], Loss: 0.6651
2024-06-23 16:41:52,874 Epoch [3/8], Batch [651/748], Loss: 0.6737
2024-06-23 16:42:43,949 Epoch [3/8], Batch [701/748], Loss: 0.8788
2024-06-23 16:43:31,275 Epoch 3/8, Train Loss: 0.7062, Train Accuracy: 0.6881
2024-06-23 16:44:56,453 Epoch 3/8, Val Loss: 0.8401, Val Accuracy: 0.6288
2024-06-23 16:44:57,501 Epoch [4/8], Batch [1/748], Loss: 0.5576
2024-06-23 16:45:48,104 Epoch [4/8], Batch [51/748], Loss: 0.6792
2024-06-23 16:46:39,209 Epoch [4/8], Batch [101/748], Loss: 0.4999
2024-06-23 16:47:30,446 Epoch [4/8], Batch [151/748], Loss: 0.5102
2024-06-23 16:48:21,161 Epoch [4/8], Batch [201/748], Loss: 0.8192
2024-06-23 16:49:12,190 Epoch [4/8], Batch [251/748], Loss: 0.6797
2024-06-23 16:50:02,872 Epoch [4/8], Batch [301/748], Loss: 0.8848
2024-06-23 16:50:53,823 Epoch [4/8], Batch [351/748], Loss: 0.4297
2024-06-23 16:51:44,782 Epoch [4/8], Batch [401/748], Loss: 0.4586
2024-06-23 16:52:35,850 Epoch [4/8], Batch [451/748], Loss: 0.7408
2024-06-23 16:53:26,523 Epoch [4/8], Batch [501/748], Loss: 0.6725
2024-06-23 16:54:17,569 Epoch [4/8], Batch [551/748], Loss: 0.5798
2024-06-23 16:55:08,341 Epoch [4/8], Batch [601/748], Loss: 0.8126
2024-06-23 16:55:58,892 Epoch [4/8], Batch [651/748], Loss: 0.4134
2024-06-23 16:56:49,614 Epoch [4/8], Batch [701/748], Loss: 0.6370
2024-06-23 16:57:36,820 Epoch 4/8, Train Loss: 0.6118, Train Accuracy: 0.7350
2024-06-23 16:59:02,282 Epoch 4/8, Val Loss: 0.8739, Val Accuracy: 0.6374
2024-06-23 16:59:03,269 Epoch [5/8], Batch [1/748], Loss: 0.3541
2024-06-23 16:59:54,062 Epoch [5/8], Batch [51/748], Loss: 0.5036
2024-06-23 17:00:44,763 Epoch [5/8], Batch [101/748], Loss: 0.5059
2024-06-23 17:01:35,572 Epoch [5/8], Batch [151/748], Loss: 0.3315
2024-06-23 17:02:26,554 Epoch [5/8], Batch [201/748], Loss: 0.5165
2024-06-23 17:03:17,588 Epoch [5/8], Batch [251/748], Loss: 0.5210
2024-06-23 17:04:08,400 Epoch [5/8], Batch [301/748], Loss: 0.3757
2024-06-23 17:04:59,367 Epoch [5/8], Batch [351/748], Loss: 0.4459
2024-06-23 17:05:50,165 Epoch [5/8], Batch [401/748], Loss: 0.4332
2024-06-23 17:06:41,336 Epoch [5/8], Batch [451/748], Loss: 0.6490
2024-06-23 17:07:32,268 Epoch [5/8], Batch [501/748], Loss: 0.5234
2024-06-23 17:08:23,097 Epoch [5/8], Batch [551/748], Loss: 0.3330
2024-06-23 17:09:14,063 Epoch [5/8], Batch [601/748], Loss: 0.4959
2024-06-23 17:10:05,025 Epoch [5/8], Batch [651/748], Loss: 0.4989
2024-06-23 17:10:55,903 Epoch [5/8], Batch [701/748], Loss: 0.3394
2024-06-23 17:11:43,454 Epoch 5/8, Train Loss: 0.5109, Train Accuracy: 0.7844
2024-06-23 17:13:08,702 Epoch 5/8, Val Loss: 0.8792, Val Accuracy: 0.6544
2024-06-23 17:13:09,715 Epoch [6/8], Batch [1/748], Loss: 0.3526
2024-06-23 17:14:00,389 Epoch [6/8], Batch [51/748], Loss: 0.3984
2024-06-23 17:14:51,186 Epoch [6/8], Batch [101/748], Loss: 0.3543
2024-06-23 17:15:42,253 Epoch [6/8], Batch [151/748], Loss: 0.3700
2024-06-23 17:16:33,427 Epoch [6/8], Batch [201/748], Loss: 0.3931
2024-06-23 17:17:24,155 Epoch [6/8], Batch [251/748], Loss: 0.3015
2024-06-23 17:18:15,056 Epoch [6/8], Batch [301/748], Loss: 0.3442
2024-06-23 17:19:06,270 Epoch [6/8], Batch [351/748], Loss: 0.7296
2024-06-23 17:19:57,009 Epoch [6/8], Batch [401/748], Loss: 0.7487
2024-06-23 17:20:47,937 Epoch [6/8], Batch [451/748], Loss: 0.3349
2024-06-23 17:21:38,851 Epoch [6/8], Batch [501/748], Loss: 0.3168
2024-06-23 17:22:30,061 Epoch [6/8], Batch [551/748], Loss: 0.2073
2024-06-23 17:23:20,862 Epoch [6/8], Batch [601/748], Loss: 0.2999
2024-06-23 17:24:11,766 Epoch [6/8], Batch [651/748], Loss: 0.5200
2024-06-23 17:25:02,842 Epoch [6/8], Batch [701/748], Loss: 0.5414
2024-06-23 17:25:50,318 Epoch 6/8, Train Loss: 0.4186, Train Accuracy: 0.8285
2024-06-23 17:27:15,676 Epoch 6/8, Val Loss: 0.9563, Val Accuracy: 0.6541
2024-06-23 17:27:16,662 Epoch [7/8], Batch [1/748], Loss: 0.1759
2024-06-23 17:28:07,208 Epoch [7/8], Batch [51/748], Loss: 0.3157
2024-06-23 17:28:58,115 Epoch [7/8], Batch [101/748], Loss: 0.3672
2024-06-23 17:29:49,086 Epoch [7/8], Batch [151/748], Loss: 0.3339
2024-06-23 17:30:40,194 Epoch [7/8], Batch [201/748], Loss: 0.4668
2024-06-23 17:31:31,094 Epoch [7/8], Batch [251/748], Loss: 0.3817
2024-06-23 17:32:21,981 Epoch [7/8], Batch [301/748], Loss: 0.2880
2024-06-23 17:33:12,879 Epoch [7/8], Batch [351/748], Loss: 0.2807
2024-06-23 17:34:03,980 Epoch [7/8], Batch [401/748], Loss: 0.6320
2024-06-23 17:34:54,783 Epoch [7/8], Batch [451/748], Loss: 0.7601
2024-06-23 17:35:45,870 Epoch [7/8], Batch [501/748], Loss: 0.3876
2024-06-23 17:36:36,858 Epoch [7/8], Batch [551/748], Loss: 0.3764
2024-06-23 17:37:27,722 Epoch [7/8], Batch [601/748], Loss: 0.5025
2024-06-23 17:38:18,678 Epoch [7/8], Batch [651/748], Loss: 0.2462
2024-06-23 17:39:09,603 Epoch [7/8], Batch [701/748], Loss: 0.4173
2024-06-23 17:39:57,128 Epoch 7/8, Train Loss: 0.3536, Train Accuracy: 0.8590
2024-06-23 17:41:22,599 Epoch 7/8, Val Loss: 0.9858, Val Accuracy: 0.6646
2024-06-23 17:41:23,592 Epoch [8/8], Batch [1/748], Loss: 0.1543
2024-06-23 17:42:13,962 Epoch [8/8], Batch [51/748], Loss: 0.2427
2024-06-23 17:43:04,911 Epoch [8/8], Batch [101/748], Loss: 0.1363
2024-06-23 17:43:55,838 Epoch [8/8], Batch [151/748], Loss: 0.2973
2024-06-23 17:44:46,851 Epoch [8/8], Batch [201/748], Loss: 0.3351
2024-06-23 17:45:37,706 Epoch [8/8], Batch [251/748], Loss: 0.3421
2024-06-23 17:46:28,690 Epoch [8/8], Batch [301/748], Loss: 0.0990
2024-06-23 17:47:19,369 Epoch [8/8], Batch [351/748], Loss: 0.2987
2024-06-23 17:48:09,853 Epoch [8/8], Batch [401/748], Loss: 0.3398
2024-06-23 17:49:00,535 Epoch [8/8], Batch [451/748], Loss: 0.2139
2024-06-23 17:49:51,047 Epoch [8/8], Batch [501/748], Loss: 0.3236
2024-06-23 17:50:41,940 Epoch [8/8], Batch [551/748], Loss: 0.3190
2024-06-23 17:51:32,458 Epoch [8/8], Batch [601/748], Loss: 0.1641
2024-06-23 17:52:22,998 Epoch [8/8], Batch [651/748], Loss: 0.4335
2024-06-23 17:53:13,976 Epoch [8/8], Batch [701/748], Loss: 0.3610
2024-06-23 17:54:00,923 Epoch 8/8, Train Loss: 0.2893, Train Accuracy: 0.8855
2024-06-23 17:55:25,320 Epoch 8/8, Val Loss: 1.0870, Val Accuracy: 0.6554
2024-06-23 17:55:25,322 Training finished!
2024-06-23 17:55:25,322 ==================================================
2024-06-23 17:55:31,296 ==================================================
2024-06-23 17:55:31,297 Training BERT + TF-IDF features with Dimension-2048...
2024-06-23 17:55:32,300 Epoch [1/8], Batch [1/748], Loss: 1.6117
2024-06-23 17:56:22,549 Epoch [1/8], Batch [51/748], Loss: 1.5431
2024-06-23 17:57:13,199 Epoch [1/8], Batch [101/748], Loss: 1.2855
2024-06-23 17:58:03,687 Epoch [1/8], Batch [151/748], Loss: 1.1031
2024-06-23 17:58:54,396 Epoch [1/8], Batch [201/748], Loss: 1.2629
2024-06-23 17:59:45,036 Epoch [1/8], Batch [251/748], Loss: 1.0177
2024-06-23 18:00:35,714 Epoch [1/8], Batch [301/748], Loss: 0.9976
2024-06-23 18:01:26,197 Epoch [1/8], Batch [351/748], Loss: 0.9819
2024-06-23 18:02:16,697 Epoch [1/8], Batch [401/748], Loss: 1.2102
2024-06-23 18:03:07,617 Epoch [1/8], Batch [451/748], Loss: 0.9247
2024-06-23 18:03:57,955 Epoch [1/8], Batch [501/748], Loss: 0.9089
2024-06-23 18:04:48,406 Epoch [1/8], Batch [551/748], Loss: 0.9853
2024-06-23 18:05:38,853 Epoch [1/8], Batch [601/748], Loss: 0.7694
2024-06-23 18:06:29,452 Epoch [1/8], Batch [651/748], Loss: 0.7630
2024-06-23 18:07:19,746 Epoch [1/8], Batch [701/748], Loss: 0.8383
2024-06-23 18:08:06,875 Epoch 1/8, Train Loss: 1.0831, Train Accuracy: 0.5307
2024-06-23 18:09:31,386 Epoch 1/8, Val Loss: 0.9850, Val Accuracy: 0.5962
2024-06-23 18:09:32,413 Epoch [2/8], Batch [1/748], Loss: 0.9662
2024-06-23 18:10:22,806 Epoch [2/8], Batch [51/748], Loss: 0.8296
2024-06-23 18:11:13,511 Epoch [2/8], Batch [101/748], Loss: 0.8285
2024-06-23 18:12:03,978 Epoch [2/8], Batch [151/748], Loss: 0.6083
2024-06-23 18:12:54,645 Epoch [2/8], Batch [201/748], Loss: 0.9252
2024-06-23 18:13:45,061 Epoch [2/8], Batch [251/748], Loss: 0.7090
2024-06-23 18:14:35,608 Epoch [2/8], Batch [301/748], Loss: 0.9758
2024-06-23 18:15:25,910 Epoch [2/8], Batch [351/748], Loss: 0.9650
2024-06-23 18:16:16,440 Epoch [2/8], Batch [401/748], Loss: 0.4501
2024-06-23 18:17:07,133 Epoch [2/8], Batch [451/748], Loss: 0.4586
2024-06-23 18:17:57,434 Epoch [2/8], Batch [501/748], Loss: 0.6633
2024-06-23 18:18:48,345 Epoch [2/8], Batch [551/748], Loss: 0.7063
2024-06-23 18:19:38,846 Epoch [2/8], Batch [601/748], Loss: 0.8491
2024-06-23 18:20:29,363 Epoch [2/8], Batch [651/748], Loss: 0.9802
2024-06-23 18:21:19,854 Epoch [2/8], Batch [701/748], Loss: 0.7260
2024-06-23 18:22:06,685 Epoch 2/8, Train Loss: 0.8090, Train Accuracy: 0.6406
2024-06-23 18:23:31,434 Epoch 2/8, Val Loss: 0.8222, Val Accuracy: 0.6422
2024-06-23 18:23:32,458 Epoch [3/8], Batch [1/748], Loss: 0.7402
2024-06-23 18:24:22,593 Epoch [3/8], Batch [51/748], Loss: 0.4584
2024-06-23 18:25:13,329 Epoch [3/8], Batch [101/748], Loss: 0.6510
2024-06-23 18:26:03,580 Epoch [3/8], Batch [151/748], Loss: 0.7770
2024-06-23 18:26:54,404 Epoch [3/8], Batch [201/748], Loss: 0.6151
2024-06-23 18:27:45,200 Epoch [3/8], Batch [251/748], Loss: 0.8241
2024-06-23 18:28:35,721 Epoch [3/8], Batch [301/748], Loss: 0.7650
2024-06-23 18:29:26,323 Epoch [3/8], Batch [351/748], Loss: 0.7371
2024-06-23 18:30:16,810 Epoch [3/8], Batch [401/748], Loss: 0.6166
2024-06-23 18:31:07,275 Epoch [3/8], Batch [451/748], Loss: 0.6486
2024-06-23 18:31:57,634 Epoch [3/8], Batch [501/748], Loss: 0.4739
2024-06-23 18:32:48,302 Epoch [3/8], Batch [551/748], Loss: 0.6801
2024-06-23 18:33:39,020 Epoch [3/8], Batch [601/748], Loss: 0.5913
2024-06-23 18:34:29,608 Epoch [3/8], Batch [651/748], Loss: 0.9442
2024-06-23 18:35:19,789 Epoch [3/8], Batch [701/748], Loss: 0.6192
2024-06-23 18:36:06,841 Epoch 3/8, Train Loss: 0.7019, Train Accuracy: 0.6924
2024-06-23 18:37:31,217 Epoch 3/8, Val Loss: 0.8509, Val Accuracy: 0.6439
2024-06-23 18:37:32,208 Epoch [4/8], Batch [1/748], Loss: 0.8150
2024-06-23 18:38:22,245 Epoch [4/8], Batch [51/748], Loss: 0.4499
2024-06-23 18:39:12,668 Epoch [4/8], Batch [101/748], Loss: 0.7327
2024-06-23 18:40:03,249 Epoch [4/8], Batch [151/748], Loss: 0.7086
2024-06-23 18:40:54,056 Epoch [4/8], Batch [201/748], Loss: 0.5991
2024-06-23 18:41:44,366 Epoch [4/8], Batch [251/748], Loss: 0.3714
2024-06-23 18:42:35,343 Epoch [4/8], Batch [301/748], Loss: 0.5556
2024-06-23 18:43:25,949 Epoch [4/8], Batch [351/748], Loss: 0.6213
2024-06-23 18:44:16,797 Epoch [4/8], Batch [401/748], Loss: 0.5482
2024-06-23 18:45:07,296 Epoch [4/8], Batch [451/748], Loss: 0.5996
2024-06-23 18:45:57,780 Epoch [4/8], Batch [501/748], Loss: 0.5116
2024-06-23 18:46:48,693 Epoch [4/8], Batch [551/748], Loss: 0.5557
2024-06-23 18:47:39,163 Epoch [4/8], Batch [601/748], Loss: 0.5920
2024-06-23 18:48:29,892 Epoch [4/8], Batch [651/748], Loss: 0.6920
2024-06-23 18:49:20,718 Epoch [4/8], Batch [701/748], Loss: 0.7065
2024-06-23 18:50:07,828 Epoch 4/8, Train Loss: 0.5958, Train Accuracy: 0.7485
2024-06-23 18:51:32,425 Epoch 4/8, Val Loss: 0.8609, Val Accuracy: 0.6542
2024-06-23 18:51:33,433 Epoch [5/8], Batch [1/748], Loss: 0.4056
2024-06-23 18:52:23,743 Epoch [5/8], Batch [51/748], Loss: 0.4525
2024-06-23 18:53:14,886 Epoch [5/8], Batch [101/748], Loss: 0.4945
2024-06-23 18:54:05,952 Epoch [5/8], Batch [151/748], Loss: 0.3674
2024-06-23 18:54:56,951 Epoch [5/8], Batch [201/748], Loss: 0.8069
2024-06-23 18:55:47,929 Epoch [5/8], Batch [251/748], Loss: 0.6521
2024-06-23 18:56:38,793 Epoch [5/8], Batch [301/748], Loss: 0.5003
2024-06-23 18:57:29,687 Epoch [5/8], Batch [351/748], Loss: 0.3420
2024-06-23 18:58:20,564 Epoch [5/8], Batch [401/748], Loss: 0.5800
2024-06-23 18:59:11,592 Epoch [5/8], Batch [451/748], Loss: 0.5789
2024-06-23 19:00:02,496 Epoch [5/8], Batch [501/748], Loss: 0.4195
2024-06-23 19:00:53,482 Epoch [5/8], Batch [551/748], Loss: 0.5555
2024-06-23 19:01:44,424 Epoch [5/8], Batch [601/748], Loss: 0.5492
2024-06-23 19:02:35,595 Epoch [5/8], Batch [651/748], Loss: 0.6713
2024-06-23 19:03:26,445 Epoch [5/8], Batch [701/748], Loss: 0.3316
2024-06-23 19:04:13,803 Epoch 5/8, Train Loss: 0.5056, Train Accuracy: 0.7913
2024-06-23 19:05:38,875 Epoch 5/8, Val Loss: 0.9263, Val Accuracy: 0.6572
2024-06-23 19:05:39,879 Epoch [6/8], Batch [1/748], Loss: 0.3907
2024-06-23 19:06:30,819 Epoch [6/8], Batch [51/748], Loss: 0.2668
2024-06-23 19:07:21,692 Epoch [6/8], Batch [101/748], Loss: 0.4391
2024-06-23 19:08:12,670 Epoch [6/8], Batch [151/748], Loss: 0.3669
2024-06-23 19:09:03,595 Epoch [6/8], Batch [201/748], Loss: 0.1701
2024-06-23 19:09:54,536 Epoch [6/8], Batch [251/748], Loss: 0.4348
2024-06-23 19:10:45,311 Epoch [6/8], Batch [301/748], Loss: 0.1539
2024-06-23 19:11:36,354 Epoch [6/8], Batch [351/748], Loss: 0.4984
2024-06-23 19:12:27,277 Epoch [6/8], Batch [401/748], Loss: 0.3470
2024-06-23 19:13:18,253 Epoch [6/8], Batch [451/748], Loss: 0.5300
2024-06-23 19:14:09,168 Epoch [6/8], Batch [501/748], Loss: 0.4454
2024-06-23 19:15:00,088 Epoch [6/8], Batch [551/748], Loss: 0.4224
2024-06-23 19:15:51,032 Epoch [6/8], Batch [601/748], Loss: 0.4327
2024-06-23 19:16:41,887 Epoch [6/8], Batch [651/748], Loss: 0.2087
2024-06-23 19:17:32,807 Epoch [6/8], Batch [701/748], Loss: 0.3232
2024-06-23 19:18:20,338 Epoch 6/8, Train Loss: 0.4125, Train Accuracy: 0.8371
2024-06-23 19:19:45,568 Epoch 6/8, Val Loss: 0.9358, Val Accuracy: 0.6644
2024-06-23 19:19:46,584 Epoch [7/8], Batch [1/748], Loss: 0.3510
2024-06-23 19:20:37,445 Epoch [7/8], Batch [51/748], Loss: 0.4417
2024-06-23 19:21:28,290 Epoch [7/8], Batch [101/748], Loss: 0.2959
2024-06-23 19:22:19,125 Epoch [7/8], Batch [151/748], Loss: 0.3263
2024-06-23 19:23:10,433 Epoch [7/8], Batch [201/748], Loss: 0.2859
2024-06-23 19:24:01,307 Epoch [7/8], Batch [251/748], Loss: 0.3682
2024-06-23 19:24:51,971 Epoch [7/8], Batch [301/748], Loss: 0.2685
2024-06-23 19:25:42,820 Epoch [7/8], Batch [351/748], Loss: 0.3495
2024-06-23 19:26:33,832 Epoch [7/8], Batch [401/748], Loss: 0.1575
2024-06-23 19:27:24,661 Epoch [7/8], Batch [451/748], Loss: 0.5379
2024-06-23 19:28:15,574 Epoch [7/8], Batch [501/748], Loss: 0.2405
2024-06-23 19:29:06,360 Epoch [7/8], Batch [551/748], Loss: 0.2540
2024-06-23 19:29:56,913 Epoch [7/8], Batch [601/748], Loss: 0.2187
2024-06-23 19:30:47,617 Epoch [7/8], Batch [651/748], Loss: 0.2293
2024-06-23 19:31:38,355 Epoch [7/8], Batch [701/748], Loss: 0.3309
2024-06-23 19:32:25,933 Epoch 7/8, Train Loss: 0.3306, Train Accuracy: 0.8744
2024-06-23 19:33:51,158 Epoch 7/8, Val Loss: 1.0277, Val Accuracy: 0.6628
2024-06-23 19:33:52,160 Epoch [8/8], Batch [1/748], Loss: 0.1092
2024-06-23 19:34:42,826 Epoch [8/8], Batch [51/748], Loss: 0.2818
2024-06-23 19:35:33,754 Epoch [8/8], Batch [101/748], Loss: 0.1925
2024-06-23 19:36:24,876 Epoch [8/8], Batch [151/748], Loss: 0.1908
2024-06-23 19:37:15,656 Epoch [8/8], Batch [201/748], Loss: 0.2831
2024-06-23 19:38:06,612 Epoch [8/8], Batch [251/748], Loss: 0.2939
2024-06-23 19:38:57,515 Epoch [8/8], Batch [301/748], Loss: 0.5352
2024-06-23 19:39:48,438 Epoch [8/8], Batch [351/748], Loss: 0.4681
2024-06-23 19:40:39,681 Epoch [8/8], Batch [401/748], Loss: 0.1041
2024-06-23 19:41:30,280 Epoch [8/8], Batch [451/748], Loss: 0.3971
2024-06-23 19:42:21,248 Epoch [8/8], Batch [501/748], Loss: 0.2503
2024-06-23 19:43:12,415 Epoch [8/8], Batch [551/748], Loss: 0.1318
2024-06-23 19:44:03,213 Epoch [8/8], Batch [601/748], Loss: 0.3335
2024-06-23 19:44:54,288 Epoch [8/8], Batch [651/748], Loss: 0.5315
2024-06-23 19:45:45,087 Epoch [8/8], Batch [701/748], Loss: 0.4607
2024-06-23 19:46:32,756 Epoch 8/8, Train Loss: 0.2609, Train Accuracy: 0.9062
2024-06-23 19:47:57,803 Epoch 8/8, Val Loss: 1.1062, Val Accuracy: 0.6634
2024-06-23 19:47:57,805 Training finished!
2024-06-23 19:47:57,805 ==================================================
2024-06-23 19:48:03,820 ==================================================
2024-06-23 19:48:03,820 Training BERT + TF-IDF features with Dimension-1024...
2024-06-23 19:48:04,855 Epoch [1/8], Batch [1/748], Loss: 1.6254
2024-06-23 19:48:55,698 Epoch [1/8], Batch [51/748], Loss: 1.5792
2024-06-23 19:49:46,657 Epoch [1/8], Batch [101/748], Loss: 1.4162
2024-06-23 19:50:37,627 Epoch [1/8], Batch [151/748], Loss: 1.1415
2024-06-23 19:51:28,588 Epoch [1/8], Batch [201/748], Loss: 1.1351
2024-06-23 19:52:19,604 Epoch [1/8], Batch [251/748], Loss: 1.1353
2024-06-23 19:53:10,407 Epoch [1/8], Batch [301/748], Loss: 1.3458
2024-06-23 19:54:01,407 Epoch [1/8], Batch [351/748], Loss: 1.1906
2024-06-23 19:54:52,176 Epoch [1/8], Batch [401/748], Loss: 0.9021
2024-06-23 19:55:43,077 Epoch [1/8], Batch [451/748], Loss: 1.2432
2024-06-23 19:56:34,406 Epoch [1/8], Batch [501/748], Loss: 1.0780
2024-06-23 19:57:25,053 Epoch [1/8], Batch [551/748], Loss: 0.7355
2024-06-23 19:58:16,086 Epoch [1/8], Batch [601/748], Loss: 0.8618
2024-06-23 19:59:06,984 Epoch [1/8], Batch [651/748], Loss: 0.9124
2024-06-23 19:59:58,013 Epoch [1/8], Batch [701/748], Loss: 0.7429
2024-06-23 20:00:45,600 Epoch 1/8, Train Loss: 1.1215, Train Accuracy: 0.5022
2024-06-23 20:02:10,616 Epoch 1/8, Val Loss: 0.9339, Val Accuracy: 0.5899
2024-06-23 20:02:11,607 Epoch [2/8], Batch [1/748], Loss: 1.1274
2024-06-23 20:03:02,276 Epoch [2/8], Batch [51/748], Loss: 0.7201
2024-06-23 20:03:53,120 Epoch [2/8], Batch [101/748], Loss: 0.8039
2024-06-23 20:04:43,715 Epoch [2/8], Batch [151/748], Loss: 0.9502
2024-06-23 20:05:34,249 Epoch [2/8], Batch [201/748], Loss: 0.6988
2024-06-23 20:06:24,837 Epoch [2/8], Batch [251/748], Loss: 0.7994
2024-06-23 20:07:15,602 Epoch [2/8], Batch [301/748], Loss: 0.7083
2024-06-23 20:08:06,180 Epoch [2/8], Batch [351/748], Loss: 0.7843
2024-06-23 20:08:57,063 Epoch [2/8], Batch [401/748], Loss: 0.7432
2024-06-23 20:09:47,260 Epoch [2/8], Batch [451/748], Loss: 0.8291
2024-06-23 20:10:38,004 Epoch [2/8], Batch [501/748], Loss: 0.8836
2024-06-23 20:11:28,493 Epoch [2/8], Batch [551/748], Loss: 1.1749
2024-06-23 20:12:18,994 Epoch [2/8], Batch [601/748], Loss: 0.7113
2024-06-23 20:13:09,857 Epoch [2/8], Batch [651/748], Loss: 0.9051
2024-06-23 20:14:00,421 Epoch [2/8], Batch [701/748], Loss: 0.8584
2024-06-23 20:14:47,567 Epoch 2/8, Train Loss: 0.8624, Train Accuracy: 0.6143
2024-06-23 20:16:11,683 Epoch 2/8, Val Loss: 0.9175, Val Accuracy: 0.5932
2024-06-23 20:16:12,682 Epoch [3/8], Batch [1/748], Loss: 0.8634
2024-06-23 20:17:03,052 Epoch [3/8], Batch [51/748], Loss: 0.6805
2024-06-23 20:17:53,295 Epoch [3/8], Batch [101/748], Loss: 0.8119
2024-06-23 20:18:44,270 Epoch [3/8], Batch [151/748], Loss: 0.8559
2024-06-23 20:19:35,067 Epoch [3/8], Batch [201/748], Loss: 0.6593
2024-06-23 20:20:25,578 Epoch [3/8], Batch [251/748], Loss: 0.9025
2024-06-23 20:21:16,069 Epoch [3/8], Batch [301/748], Loss: 0.6172
2024-06-23 20:22:06,881 Epoch [3/8], Batch [351/748], Loss: 0.6630
2024-06-23 20:22:57,857 Epoch [3/8], Batch [401/748], Loss: 0.9536
2024-06-23 20:23:48,421 Epoch [3/8], Batch [451/748], Loss: 0.7507
2024-06-23 20:24:38,864 Epoch [3/8], Batch [501/748], Loss: 0.7849
2024-06-23 20:25:29,689 Epoch [3/8], Batch [551/748], Loss: 0.7358
2024-06-23 20:26:20,236 Epoch [3/8], Batch [601/748], Loss: 0.6542
2024-06-23 20:27:10,672 Epoch [3/8], Batch [651/748], Loss: 0.7798
2024-06-23 20:28:01,543 Epoch [3/8], Batch [701/748], Loss: 0.8727
2024-06-23 20:28:48,997 Epoch 3/8, Train Loss: 0.7602, Train Accuracy: 0.6554
2024-06-23 20:30:13,248 Epoch 3/8, Val Loss: 0.8880, Val Accuracy: 0.6111
2024-06-23 20:30:14,265 Epoch [4/8], Batch [1/748], Loss: 0.7095
2024-06-23 20:31:04,524 Epoch [4/8], Batch [51/748], Loss: 0.9450
2024-06-23 20:31:55,039 Epoch [4/8], Batch [101/748], Loss: 0.7666
2024-06-23 20:32:46,248 Epoch [4/8], Batch [151/748], Loss: 0.7243
2024-06-23 20:33:36,665 Epoch [4/8], Batch [201/748], Loss: 0.8786
2024-06-23 20:34:27,287 Epoch [4/8], Batch [251/748], Loss: 0.5732
2024-06-23 20:35:17,947 Epoch [4/8], Batch [301/748], Loss: 0.6662
2024-06-23 20:36:08,530 Epoch [4/8], Batch [351/748], Loss: 0.5816
2024-06-23 20:36:59,197 Epoch [4/8], Batch [401/748], Loss: 0.6635
2024-06-23 20:37:49,803 Epoch [4/8], Batch [451/748], Loss: 0.7867
2024-06-23 20:38:40,724 Epoch [4/8], Batch [501/748], Loss: 0.4616
2024-06-23 20:39:31,201 Epoch [4/8], Batch [551/748], Loss: 0.5407
2024-06-23 20:40:21,643 Epoch [4/8], Batch [601/748], Loss: 0.8736
2024-06-23 20:41:12,440 Epoch [4/8], Batch [651/748], Loss: 0.6621
2024-06-23 20:42:03,051 Epoch [4/8], Batch [701/748], Loss: 0.7187
2024-06-23 20:42:50,381 Epoch 4/8, Train Loss: 0.6852, Train Accuracy: 0.6891
2024-06-23 20:44:14,791 Epoch 4/8, Val Loss: 0.8377, Val Accuracy: 0.6348
2024-06-23 20:44:15,764 Epoch [5/8], Batch [1/748], Loss: 0.5325
2024-06-23 20:45:06,100 Epoch [5/8], Batch [51/748], Loss: 0.5991
2024-06-23 20:45:56,748 Epoch [5/8], Batch [101/748], Loss: 0.6836
2024-06-23 20:46:47,249 Epoch [5/8], Batch [151/748], Loss: 0.5501
2024-06-23 20:47:37,902 Epoch [5/8], Batch [201/748], Loss: 0.7800
2024-06-23 20:48:28,761 Epoch [5/8], Batch [251/748], Loss: 0.6989
2024-06-23 20:49:19,593 Epoch [5/8], Batch [301/748], Loss: 0.4886
2024-06-23 20:50:10,583 Epoch [5/8], Batch [351/748], Loss: 0.5078
2024-06-23 20:51:01,488 Epoch [5/8], Batch [401/748], Loss: 0.5989
2024-06-23 20:51:52,373 Epoch [5/8], Batch [451/748], Loss: 0.7914
2024-06-23 20:52:42,919 Epoch [5/8], Batch [501/748], Loss: 0.5431
2024-06-23 20:53:33,355 Epoch [5/8], Batch [551/748], Loss: 0.4738
2024-06-23 20:54:23,701 Epoch [5/8], Batch [601/748], Loss: 0.5099
2024-06-23 20:55:14,217 Epoch [5/8], Batch [651/748], Loss: 0.5395
2024-06-23 20:56:04,644 Epoch [5/8], Batch [701/748], Loss: 0.5305
2024-06-23 20:56:51,513 Epoch 5/8, Train Loss: 0.6032, Train Accuracy: 0.7288
2024-06-23 20:58:15,852 Epoch 5/8, Val Loss: 0.8758, Val Accuracy: 0.6449
2024-06-23 20:58:16,885 Epoch [6/8], Batch [1/748], Loss: 0.3829
2024-06-23 20:59:07,631 Epoch [6/8], Batch [51/748], Loss: 0.5319
2024-06-23 20:59:58,182 Epoch [6/8], Batch [101/748], Loss: 0.3716
2024-06-23 21:00:48,737 Epoch [6/8], Batch [151/748], Loss: 0.5019
2024-06-23 21:01:39,509 Epoch [6/8], Batch [201/748], Loss: 0.4946
2024-06-23 21:02:30,368 Epoch [6/8], Batch [251/748], Loss: 0.5416
2024-06-23 21:03:20,559 Epoch [6/8], Batch [301/748], Loss: 0.5619
2024-06-23 21:04:11,127 Epoch [6/8], Batch [351/748], Loss: 0.6166
2024-06-23 21:05:01,540 Epoch [6/8], Batch [401/748], Loss: 0.5795
2024-06-23 21:05:52,078 Epoch [6/8], Batch [451/748], Loss: 0.5582
2024-06-23 21:06:42,570 Epoch [6/8], Batch [501/748], Loss: 0.5837
2024-06-23 21:07:33,166 Epoch [6/8], Batch [551/748], Loss: 0.5200
2024-06-23 21:08:24,229 Epoch [6/8], Batch [601/748], Loss: 0.4372
2024-06-23 21:09:15,055 Epoch [6/8], Batch [651/748], Loss: 0.9638
2024-06-23 21:10:05,849 Epoch [6/8], Batch [701/748], Loss: 0.5097
2024-06-23 21:10:53,382 Epoch 6/8, Train Loss: 0.5244, Train Accuracy: 0.7671
2024-06-23 21:12:18,417 Epoch 6/8, Val Loss: 0.8493, Val Accuracy: 0.6552
2024-06-23 21:12:19,427 Epoch [7/8], Batch [1/748], Loss: 0.3566
2024-06-23 21:13:10,183 Epoch [7/8], Batch [51/748], Loss: 0.6746
2024-06-23 21:14:01,115 Epoch [7/8], Batch [101/748], Loss: 0.4713
2024-06-23 21:14:52,034 Epoch [7/8], Batch [151/748], Loss: 0.6001
2024-06-23 21:15:43,026 Epoch [7/8], Batch [201/748], Loss: 0.4893
2024-06-23 21:16:33,968 Epoch [7/8], Batch [251/748], Loss: 0.2942
2024-06-23 21:17:24,775 Epoch [7/8], Batch [301/748], Loss: 0.4686
2024-06-23 21:18:15,804 Epoch [7/8], Batch [351/748], Loss: 0.3075
2024-06-23 21:19:06,750 Epoch [7/8], Batch [401/748], Loss: 0.3101
2024-06-23 21:19:57,687 Epoch [7/8], Batch [451/748], Loss: 0.5013
2024-06-23 21:20:48,589 Epoch [7/8], Batch [501/748], Loss: 0.3787
2024-06-23 21:21:39,585 Epoch [7/8], Batch [551/748], Loss: 0.5806
2024-06-23 21:22:30,499 Epoch [7/8], Batch [601/748], Loss: 0.2864
2024-06-23 21:23:21,311 Epoch [7/8], Batch [651/748], Loss: 0.5002
2024-06-23 21:24:12,257 Epoch [7/8], Batch [701/748], Loss: 0.3608
2024-06-23 21:24:59,812 Epoch 7/8, Train Loss: 0.4456, Train Accuracy: 0.8061
2024-06-23 21:26:25,409 Epoch 7/8, Val Loss: 0.9068, Val Accuracy: 0.6700
2024-06-23 21:26:26,432 Epoch [8/8], Batch [1/748], Loss: 0.3633
2024-06-23 21:27:17,635 Epoch [8/8], Batch [51/748], Loss: 0.3530
2024-06-23 21:28:08,634 Epoch [8/8], Batch [101/748], Loss: 0.2031
2024-06-23 21:28:59,560 Epoch [8/8], Batch [151/748], Loss: 0.4017
2024-06-23 21:29:50,439 Epoch [8/8], Batch [201/748], Loss: 0.4183
2024-06-23 21:30:41,490 Epoch [8/8], Batch [251/748], Loss: 0.3828
2024-06-23 21:31:32,378 Epoch [8/8], Batch [301/748], Loss: 0.3851
2024-06-23 21:32:23,324 Epoch [8/8], Batch [351/748], Loss: 0.2914
2024-06-23 21:33:14,418 Epoch [8/8], Batch [401/748], Loss: 0.3585
2024-06-23 21:34:05,253 Epoch [8/8], Batch [451/748], Loss: 0.3962
2024-06-23 21:34:56,261 Epoch [8/8], Batch [501/748], Loss: 0.3294
2024-06-23 21:35:47,096 Epoch [8/8], Batch [551/748], Loss: 0.3110
2024-06-23 21:36:38,082 Epoch [8/8], Batch [601/748], Loss: 0.3446
2024-06-23 21:37:28,986 Epoch [8/8], Batch [651/748], Loss: 0.3981
2024-06-23 21:38:19,931 Epoch [8/8], Batch [701/748], Loss: 0.2420
2024-06-23 21:39:07,389 Epoch 8/8, Train Loss: 0.3660, Train Accuracy: 0.8488
2024-06-23 21:40:33,138 Epoch 8/8, Val Loss: 0.9678, Val Accuracy: 0.6728
2024-06-23 21:40:33,139 Training finished!
2024-06-23 21:40:33,140 ==================================================
2024-06-23 21:40:38,802 ==================================================
2024-06-23 21:40:38,802 Training BERT + TF-IDF features with Dimension-512...
2024-06-23 21:40:39,813 Epoch [1/8], Batch [1/748], Loss: 1.6365
2024-06-23 21:41:30,350 Epoch [1/8], Batch [51/748], Loss: 1.4807
2024-06-23 21:42:21,280 Epoch [1/8], Batch [101/748], Loss: 1.3389
2024-06-23 21:43:12,358 Epoch [1/8], Batch [151/748], Loss: 1.1690
2024-06-23 21:44:03,409 Epoch [1/8], Batch [201/748], Loss: 0.9779
2024-06-23 21:44:54,366 Epoch [1/8], Batch [251/748], Loss: 0.8446
2024-06-23 21:45:45,153 Epoch [1/8], Batch [301/748], Loss: 1.1374
2024-06-23 21:46:36,071 Epoch [1/8], Batch [351/748], Loss: 1.2289
2024-06-23 21:47:26,967 Epoch [1/8], Batch [401/748], Loss: 1.0646
2024-06-23 21:48:17,940 Epoch [1/8], Batch [451/748], Loss: 0.9364
2024-06-23 21:49:09,052 Epoch [1/8], Batch [501/748], Loss: 0.8745
2024-06-23 21:49:59,789 Epoch [1/8], Batch [551/748], Loss: 0.7708
2024-06-23 21:50:50,759 Epoch [1/8], Batch [601/748], Loss: 1.0319
2024-06-23 21:51:41,704 Epoch [1/8], Batch [651/748], Loss: 0.9982
2024-06-23 21:52:32,732 Epoch [1/8], Batch [701/748], Loss: 1.0733
2024-06-23 21:53:20,146 Epoch 1/8, Train Loss: 1.0734, Train Accuracy: 0.5317
2024-06-23 21:54:45,809 Epoch 1/8, Val Loss: 0.9145, Val Accuracy: 0.5999
2024-06-23 21:54:46,838 Epoch [2/8], Batch [1/748], Loss: 0.7970
2024-06-23 21:55:37,224 Epoch [2/8], Batch [51/748], Loss: 0.5629
2024-06-23 21:56:28,145 Epoch [2/8], Batch [101/748], Loss: 1.0323
2024-06-23 21:57:18,809 Epoch [2/8], Batch [151/748], Loss: 1.0853
2024-06-23 21:58:09,790 Epoch [2/8], Batch [201/748], Loss: 0.6104
2024-06-23 21:59:00,845 Epoch [2/8], Batch [251/748], Loss: 0.7587
2024-06-23 21:59:51,590 Epoch [2/8], Batch [301/748], Loss: 0.6512
2024-06-23 22:00:42,582 Epoch [2/8], Batch [351/748], Loss: 1.0214
2024-06-23 22:01:33,496 Epoch [2/8], Batch [401/748], Loss: 0.5796
2024-06-23 22:02:24,486 Epoch [2/8], Batch [451/748], Loss: 0.9203
2024-06-23 22:03:15,244 Epoch [2/8], Batch [501/748], Loss: 0.7279
2024-06-23 22:04:06,305 Epoch [2/8], Batch [551/748], Loss: 0.6999
2024-06-23 22:04:57,305 Epoch [2/8], Batch [601/748], Loss: 0.7008
2024-06-23 22:05:48,236 Epoch [2/8], Batch [651/748], Loss: 0.8802
2024-06-23 22:06:39,107 Epoch [2/8], Batch [701/748], Loss: 0.8555
2024-06-23 22:07:26,658 Epoch 2/8, Train Loss: 0.8122, Train Accuracy: 0.6402
2024-06-23 22:08:52,378 Epoch 2/8, Val Loss: 0.8231, Val Accuracy: 0.6424
2024-06-23 22:08:53,433 Epoch [3/8], Batch [1/748], Loss: 0.7315
2024-06-23 22:09:43,764 Epoch [3/8], Batch [51/748], Loss: 0.6731
2024-06-23 22:10:34,563 Epoch [3/8], Batch [101/748], Loss: 0.5266
2024-06-23 22:11:25,604 Epoch [3/8], Batch [151/748], Loss: 0.5151
2024-06-23 22:12:16,485 Epoch [3/8], Batch [201/748], Loss: 0.7685
2024-06-23 22:13:07,526 Epoch [3/8], Batch [251/748], Loss: 0.6894
2024-06-23 22:13:58,359 Epoch [3/8], Batch [301/748], Loss: 0.5506
2024-06-23 22:14:49,328 Epoch [3/8], Batch [351/748], Loss: 0.6854
2024-06-23 22:15:40,276 Epoch [3/8], Batch [401/748], Loss: 0.5608
2024-06-23 22:16:31,249 Epoch [3/8], Batch [451/748], Loss: 0.7100
2024-06-23 22:17:22,073 Epoch [3/8], Batch [501/748], Loss: 1.0951
2024-06-23 22:18:12,912 Epoch [3/8], Batch [551/748], Loss: 0.9028
2024-06-23 22:19:03,925 Epoch [3/8], Batch [601/748], Loss: 0.6755
2024-06-23 22:19:54,811 Epoch [3/8], Batch [651/748], Loss: 0.7163
2024-06-23 22:20:45,748 Epoch [3/8], Batch [701/748], Loss: 0.5962
2024-06-23 22:21:32,895 Epoch 3/8, Train Loss: 0.7090, Train Accuracy: 0.6891
2024-06-23 22:22:57,763 Epoch 3/8, Val Loss: 0.8333, Val Accuracy: 0.6365
2024-06-23 22:22:58,765 Epoch [4/8], Batch [1/748], Loss: 0.6992
2024-06-23 22:23:49,234 Epoch [4/8], Batch [51/748], Loss: 0.6097
2024-06-23 22:24:40,160 Epoch [4/8], Batch [101/748], Loss: 0.5883
2024-06-23 22:25:31,218 Epoch [4/8], Batch [151/748], Loss: 0.5826
2024-06-23 22:26:21,709 Epoch [4/8], Batch [201/748], Loss: 0.5233
2024-06-23 22:27:12,190 Epoch [4/8], Batch [251/748], Loss: 0.4791
2024-06-23 22:28:02,915 Epoch [4/8], Batch [301/748], Loss: 0.5484
2024-06-23 22:28:53,405 Epoch [4/8], Batch [351/748], Loss: 0.4870
2024-06-23 22:29:44,010 Epoch [4/8], Batch [401/748], Loss: 0.7713
2024-06-23 22:30:34,511 Epoch [4/8], Batch [451/748], Loss: 0.6628
2024-06-23 22:31:24,779 Epoch [4/8], Batch [501/748], Loss: 0.5548
2024-06-23 22:32:15,209 Epoch [4/8], Batch [551/748], Loss: 0.3896
2024-06-23 22:33:05,720 Epoch [4/8], Batch [601/748], Loss: 0.6810
2024-06-23 22:33:56,613 Epoch [4/8], Batch [651/748], Loss: 0.5670
2024-06-23 22:34:47,503 Epoch [4/8], Batch [701/748], Loss: 0.6384
2024-06-23 22:35:34,794 Epoch 4/8, Train Loss: 0.6056, Train Accuracy: 0.7354
2024-06-23 22:36:59,269 Epoch 4/8, Val Loss: 0.9287, Val Accuracy: 0.6151
2024-06-23 22:37:00,263 Epoch [5/8], Batch [1/748], Loss: 0.3903
2024-06-23 22:37:50,877 Epoch [5/8], Batch [51/748], Loss: 0.5392
2024-06-23 22:38:41,335 Epoch [5/8], Batch [101/748], Loss: 0.5006
2024-06-23 22:39:31,698 Epoch [5/8], Batch [151/748], Loss: 0.6861
2024-06-23 22:40:22,303 Epoch [5/8], Batch [201/748], Loss: 0.4675
2024-06-23 22:41:12,976 Epoch [5/8], Batch [251/748], Loss: 0.4901
2024-06-23 22:42:03,795 Epoch [5/8], Batch [301/748], Loss: 0.6079
2024-06-23 22:42:54,755 Epoch [5/8], Batch [351/748], Loss: 0.4321
2024-06-23 22:43:45,706 Epoch [5/8], Batch [401/748], Loss: 0.5267
2024-06-23 22:44:36,657 Epoch [5/8], Batch [451/748], Loss: 0.4125
2024-06-23 22:45:27,451 Epoch [5/8], Batch [501/748], Loss: 0.5317
2024-06-23 22:46:17,989 Epoch [5/8], Batch [551/748], Loss: 0.3215
2024-06-23 22:47:08,631 Epoch [5/8], Batch [601/748], Loss: 0.6150
2024-06-23 22:47:59,379 Epoch [5/8], Batch [651/748], Loss: 0.5145
2024-06-23 22:48:49,714 Epoch [5/8], Batch [701/748], Loss: 0.4489
2024-06-23 22:49:36,802 Epoch 5/8, Train Loss: 0.5041, Train Accuracy: 0.7925
2024-06-23 22:51:01,404 Epoch 5/8, Val Loss: 0.8675, Val Accuracy: 0.6695
2024-06-23 22:51:02,425 Epoch [6/8], Batch [1/748], Loss: 0.5542
2024-06-23 22:51:52,832 Epoch [6/8], Batch [51/748], Loss: 0.4916
2024-06-23 22:52:43,812 Epoch [6/8], Batch [101/748], Loss: 0.3165
2024-06-23 22:53:34,636 Epoch [6/8], Batch [151/748], Loss: 0.3556
2024-06-23 22:54:25,329 Epoch [6/8], Batch [201/748], Loss: 0.4009
2024-06-23 22:55:15,948 Epoch [6/8], Batch [251/748], Loss: 0.3091
2024-06-23 22:56:06,535 Epoch [6/8], Batch [301/748], Loss: 0.4855
2024-06-23 22:56:57,493 Epoch [6/8], Batch [351/748], Loss: 0.3086
2024-06-23 22:57:48,331 Epoch [6/8], Batch [401/748], Loss: 0.3140
2024-06-23 22:58:38,933 Epoch [6/8], Batch [451/748], Loss: 0.4736
2024-06-23 22:59:29,446 Epoch [6/8], Batch [501/748], Loss: 0.3234
2024-06-23 23:00:20,405 Epoch [6/8], Batch [551/748], Loss: 0.3469
2024-06-23 23:01:11,374 Epoch [6/8], Batch [601/748], Loss: 0.2615
2024-06-23 23:02:01,691 Epoch [6/8], Batch [651/748], Loss: 0.4644
2024-06-23 23:02:52,351 Epoch [6/8], Batch [701/748], Loss: 0.4339
2024-06-23 23:03:39,547 Epoch 6/8, Train Loss: 0.4089, Train Accuracy: 0.8325
2024-06-23 23:05:04,292 Epoch 6/8, Val Loss: 0.9416, Val Accuracy: 0.6613
2024-06-23 23:05:05,316 Epoch [7/8], Batch [1/748], Loss: 0.2550
2024-06-23 23:05:55,676 Epoch [7/8], Batch [51/748], Loss: 0.1287
2024-06-23 23:06:46,398 Epoch [7/8], Batch [101/748], Loss: 0.4484
2024-06-23 23:07:37,141 Epoch [7/8], Batch [151/748], Loss: 0.3324
2024-06-23 23:08:27,754 Epoch [7/8], Batch [201/748], Loss: 0.4148
2024-06-23 23:09:18,539 Epoch [7/8], Batch [251/748], Loss: 0.4532
2024-06-23 23:10:08,968 Epoch [7/8], Batch [301/748], Loss: 0.5781
2024-06-23 23:10:59,490 Epoch [7/8], Batch [351/748], Loss: 0.5152
2024-06-23 23:11:50,409 Epoch [7/8], Batch [401/748], Loss: 0.2917
2024-06-23 23:12:41,347 Epoch [7/8], Batch [451/748], Loss: 0.2527
2024-06-23 23:13:32,326 Epoch [7/8], Batch [501/748], Loss: 0.1305
2024-06-23 23:14:23,021 Epoch [7/8], Batch [551/748], Loss: 0.3232
2024-06-23 23:15:13,627 Epoch [7/8], Batch [601/748], Loss: 0.5917
2024-06-23 23:16:04,164 Epoch [7/8], Batch [651/748], Loss: 0.2546
2024-06-23 23:16:55,081 Epoch [7/8], Batch [701/748], Loss: 0.3063
2024-06-23 23:17:42,135 Epoch 7/8, Train Loss: 0.3211, Train Accuracy: 0.8758
2024-06-23 23:19:06,481 Epoch 7/8, Val Loss: 1.0296, Val Accuracy: 0.6676
2024-06-23 23:19:07,472 Epoch [8/8], Batch [1/748], Loss: 0.2257
2024-06-23 23:19:57,763 Epoch [8/8], Batch [51/748], Loss: 0.2896
2024-06-23 23:20:48,683 Epoch [8/8], Batch [101/748], Loss: 0.4210
2024-06-23 23:21:39,307 Epoch [8/8], Batch [151/748], Loss: 0.3127
2024-06-23 23:22:29,850 Epoch [8/8], Batch [201/748], Loss: 0.3329
2024-06-23 23:23:20,494 Epoch [8/8], Batch [251/748], Loss: 0.2073
2024-06-23 23:24:11,361 Epoch [8/8], Batch [301/748], Loss: 0.2548
2024-06-23 23:25:02,424 Epoch [8/8], Batch [351/748], Loss: 0.1846
2024-06-23 23:25:53,162 Epoch [8/8], Batch [401/748], Loss: 0.4904
2024-06-23 23:26:44,158 Epoch [8/8], Batch [451/748], Loss: 0.1436
2024-06-23 23:27:35,063 Epoch [8/8], Batch [501/748], Loss: 0.1277
2024-06-23 23:28:26,096 Epoch [8/8], Batch [551/748], Loss: 0.3011
2024-06-23 23:29:17,062 Epoch [8/8], Batch [601/748], Loss: 0.1932
2024-06-23 23:30:07,908 Epoch [8/8], Batch [651/748], Loss: 0.2414
2024-06-23 23:30:58,850 Epoch [8/8], Batch [701/748], Loss: 0.3122
2024-06-23 23:31:46,300 Epoch 8/8, Train Loss: 0.2488, Train Accuracy: 0.9068
2024-06-23 23:33:11,731 Epoch 8/8, Val Loss: 1.2073, Val Accuracy: 0.6486
2024-06-23 23:33:11,733 Training finished!
2024-06-23 23:33:11,733 ==================================================
2024-06-23 23:33:17,417 ==================================================
2024-06-23 23:33:17,417 Training BERT + TF-IDF features with Dimension-256...
2024-06-23 23:33:18,467 Epoch [1/8], Batch [1/748], Loss: 1.7093
2024-06-23 23:34:08,688 Epoch [1/8], Batch [51/748], Loss: 1.5727
2024-06-23 23:34:59,506 Epoch [1/8], Batch [101/748], Loss: 1.3418
2024-06-23 23:35:50,270 Epoch [1/8], Batch [151/748], Loss: 1.2746
2024-06-23 23:36:41,386 Epoch [1/8], Batch [201/748], Loss: 1.1561
2024-06-23 23:37:32,229 Epoch [1/8], Batch [251/748], Loss: 1.0352
2024-06-23 23:38:23,291 Epoch [1/8], Batch [301/748], Loss: 0.9685
2024-06-23 23:39:14,130 Epoch [1/8], Batch [351/748], Loss: 0.9797
2024-06-23 23:40:04,998 Epoch [1/8], Batch [401/748], Loss: 0.9370
2024-06-23 23:40:55,978 Epoch [1/8], Batch [451/748], Loss: 0.8589
2024-06-23 23:41:46,928 Epoch [1/8], Batch [501/748], Loss: 0.9929
2024-06-23 23:42:38,110 Epoch [1/8], Batch [551/748], Loss: 0.9040
2024-06-23 23:43:28,850 Epoch [1/8], Batch [601/748], Loss: 0.7543
2024-06-23 23:44:19,851 Epoch [1/8], Batch [651/748], Loss: 1.0842
2024-06-23 23:45:10,864 Epoch [1/8], Batch [701/748], Loss: 0.8892
2024-06-23 23:45:58,331 Epoch 1/8, Train Loss: 1.1106, Train Accuracy: 0.5278
2024-06-23 23:47:23,763 Epoch 1/8, Val Loss: 0.9196, Val Accuracy: 0.6073
2024-06-23 23:47:24,810 Epoch [2/8], Batch [1/748], Loss: 0.7654
2024-06-23 23:48:15,157 Epoch [2/8], Batch [51/748], Loss: 0.5367
2024-06-23 23:49:06,116 Epoch [2/8], Batch [101/748], Loss: 0.7035
2024-06-23 23:49:57,048 Epoch [2/8], Batch [151/748], Loss: 1.1758
2024-06-23 23:50:48,019 Epoch [2/8], Batch [201/748], Loss: 0.5349
2024-06-23 23:51:39,000 Epoch [2/8], Batch [251/748], Loss: 0.9233
2024-06-23 23:52:30,101 Epoch [2/8], Batch [301/748], Loss: 0.9842
2024-06-23 23:53:20,871 Epoch [2/8], Batch [351/748], Loss: 0.9970
2024-06-23 23:54:11,790 Epoch [2/8], Batch [401/748], Loss: 0.8661
2024-06-23 23:55:02,712 Epoch [2/8], Batch [451/748], Loss: 0.8920
2024-06-23 23:55:53,582 Epoch [2/8], Batch [501/748], Loss: 0.8008
2024-06-23 23:56:44,539 Epoch [2/8], Batch [551/748], Loss: 0.7991
2024-06-23 23:57:35,610 Epoch [2/8], Batch [601/748], Loss: 0.9564
2024-06-23 23:58:26,528 Epoch [2/8], Batch [651/748], Loss: 0.9661
2024-06-23 23:59:17,464 Epoch [2/8], Batch [701/748], Loss: 1.0107
2024-06-24 00:00:04,993 Epoch 2/8, Train Loss: 0.8405, Train Accuracy: 0.6313
2024-06-24 00:01:30,143 Epoch 2/8, Val Loss: 0.8545, Val Accuracy: 0.6251
2024-06-24 00:01:31,131 Epoch [3/8], Batch [1/748], Loss: 0.9134
2024-06-24 00:02:21,800 Epoch [3/8], Batch [51/748], Loss: 0.8643
2024-06-24 00:03:12,764 Epoch [3/8], Batch [101/748], Loss: 0.6988
2024-06-24 00:04:03,715 Epoch [3/8], Batch [151/748], Loss: 0.5555
2024-06-24 00:04:54,578 Epoch [3/8], Batch [201/748], Loss: 0.8560
2024-06-24 00:05:45,584 Epoch [3/8], Batch [251/748], Loss: 0.8188
2024-06-24 00:06:36,534 Epoch [3/8], Batch [301/748], Loss: 0.6554
2024-06-24 00:07:27,633 Epoch [3/8], Batch [351/748], Loss: 0.6319
2024-06-24 00:08:18,355 Epoch [3/8], Batch [401/748], Loss: 0.8699
2024-06-24 00:09:09,472 Epoch [3/8], Batch [451/748], Loss: 0.8285
2024-06-24 00:10:00,371 Epoch [3/8], Batch [501/748], Loss: 0.8022
2024-06-24 00:10:51,295 Epoch [3/8], Batch [551/748], Loss: 0.7308
2024-06-24 00:11:42,198 Epoch [3/8], Batch [601/748], Loss: 0.8596
2024-06-24 00:12:33,457 Epoch [3/8], Batch [651/748], Loss: 0.7721
2024-06-24 00:13:24,238 Epoch [3/8], Batch [701/748], Loss: 0.7210
2024-06-24 00:14:11,717 Epoch 3/8, Train Loss: 0.7337, Train Accuracy: 0.6778
2024-06-24 00:15:37,100 Epoch 3/8, Val Loss: 0.8467, Val Accuracy: 0.6322
2024-06-24 00:15:38,096 Epoch [4/8], Batch [1/748], Loss: 0.6187
2024-06-24 00:16:28,650 Epoch [4/8], Batch [51/748], Loss: 0.8450
2024-06-24 00:17:19,653 Epoch [4/8], Batch [101/748], Loss: 0.5519
2024-06-24 00:18:10,627 Epoch [4/8], Batch [151/748], Loss: 0.7440
2024-06-24 00:19:01,735 Epoch [4/8], Batch [201/748], Loss: 0.4024
2024-06-24 00:19:52,425 Epoch [4/8], Batch [251/748], Loss: 0.8333
2024-06-24 00:20:43,424 Epoch [4/8], Batch [301/748], Loss: 0.3876
2024-06-24 00:21:34,406 Epoch [4/8], Batch [351/748], Loss: 0.6067
2024-06-24 00:22:25,424 Epoch [4/8], Batch [401/748], Loss: 0.8339
2024-06-24 00:23:16,363 Epoch [4/8], Batch [451/748], Loss: 0.7041
2024-06-24 00:24:07,476 Epoch [4/8], Batch [501/748], Loss: 0.5486
2024-06-24 00:24:58,372 Epoch [4/8], Batch [551/748], Loss: 0.6840
2024-06-24 00:25:49,265 Epoch [4/8], Batch [601/748], Loss: 0.8154
2024-06-24 00:26:40,154 Epoch [4/8], Batch [651/748], Loss: 0.9462
2024-06-24 00:27:31,024 Epoch [4/8], Batch [701/748], Loss: 0.6464
2024-06-24 00:28:18,506 Epoch 4/8, Train Loss: 0.6326, Train Accuracy: 0.7274
2024-06-24 00:29:43,943 Epoch 4/8, Val Loss: 0.7731, Val Accuracy: 0.6690
2024-06-24 00:29:44,956 Epoch [5/8], Batch [1/748], Loss: 0.3239
2024-06-24 00:30:35,740 Epoch [5/8], Batch [51/748], Loss: 0.5413
2024-06-24 00:31:26,571 Epoch [5/8], Batch [101/748], Loss: 0.4167
2024-06-24 00:32:17,400 Epoch [5/8], Batch [151/748], Loss: 0.6280
2024-06-24 00:33:08,313 Epoch [5/8], Batch [201/748], Loss: 0.7192
2024-06-24 00:33:59,131 Epoch [5/8], Batch [251/748], Loss: 0.6471
2024-06-24 00:34:50,146 Epoch [5/8], Batch [301/748], Loss: 0.5895
2024-06-24 00:35:41,026 Epoch [5/8], Batch [351/748], Loss: 0.4179
2024-06-24 00:36:32,095 Epoch [5/8], Batch [401/748], Loss: 0.5501
2024-06-24 00:37:22,440 Epoch [5/8], Batch [451/748], Loss: 0.5569
2024-06-24 00:38:13,040 Epoch [5/8], Batch [501/748], Loss: 0.5185
2024-06-24 00:39:03,764 Epoch [5/8], Batch [551/748], Loss: 0.5230
2024-06-24 00:39:54,443 Epoch [5/8], Batch [601/748], Loss: 0.4376
2024-06-24 00:40:44,889 Epoch [5/8], Batch [651/748], Loss: 0.5767
2024-06-24 00:41:35,438 Epoch [5/8], Batch [701/748], Loss: 0.6055
2024-06-24 00:42:22,434 Epoch 5/8, Train Loss: 0.5339, Train Accuracy: 0.7731
2024-06-24 00:43:47,204 Epoch 5/8, Val Loss: 0.8503, Val Accuracy: 0.6579
2024-06-24 00:43:48,235 Epoch [6/8], Batch [1/748], Loss: 0.4195
2024-06-24 00:44:38,710 Epoch [6/8], Batch [51/748], Loss: 0.5158
2024-06-24 00:45:29,221 Epoch [6/8], Batch [101/748], Loss: 0.4025
2024-06-24 00:46:20,191 Epoch [6/8], Batch [151/748], Loss: 0.4845
2024-06-24 00:47:11,043 Epoch [6/8], Batch [201/748], Loss: 0.4087
2024-06-24 00:48:01,586 Epoch [6/8], Batch [251/748], Loss: 0.4586
2024-06-24 00:48:52,215 Epoch [6/8], Batch [301/748], Loss: 0.4718
2024-06-24 00:49:43,103 Epoch [6/8], Batch [351/748], Loss: 0.3297
2024-06-24 00:50:33,689 Epoch [6/8], Batch [401/748], Loss: 0.3905
2024-06-24 00:51:24,198 Epoch [6/8], Batch [451/748], Loss: 0.5060
2024-06-24 00:52:14,760 Epoch [6/8], Batch [501/748], Loss: 0.5373
2024-06-24 00:53:05,641 Epoch [6/8], Batch [551/748], Loss: 0.6748
2024-06-24 00:53:55,981 Epoch [6/8], Batch [601/748], Loss: 0.4366
2024-06-24 00:54:46,699 Epoch [6/8], Batch [651/748], Loss: 0.4254
2024-06-24 00:55:37,336 Epoch [6/8], Batch [701/748], Loss: 0.3435
2024-06-24 00:56:24,158 Epoch 6/8, Train Loss: 0.4395, Train Accuracy: 0.8211
2024-06-24 00:57:48,569 Epoch 6/8, Val Loss: 0.8828, Val Accuracy: 0.6696
2024-06-24 00:57:49,597 Epoch [7/8], Batch [1/748], Loss: 0.4459
2024-06-24 00:58:40,187 Epoch [7/8], Batch [51/748], Loss: 0.2653
2024-06-24 00:59:30,445 Epoch [7/8], Batch [101/748], Loss: 0.2973
2024-06-24 01:00:20,887 Epoch [7/8], Batch [151/748], Loss: 0.3675
2024-06-24 01:01:11,626 Epoch [7/8], Batch [201/748], Loss: 0.2152
2024-06-24 01:02:01,940 Epoch [7/8], Batch [251/748], Loss: 0.4721
2024-06-24 01:02:52,898 Epoch [7/8], Batch [301/748], Loss: 0.1499
2024-06-24 01:03:43,886 Epoch [7/8], Batch [351/748], Loss: 0.3145
2024-06-24 01:04:34,963 Epoch [7/8], Batch [401/748], Loss: 0.3440
2024-06-24 01:05:25,817 Epoch [7/8], Batch [451/748], Loss: 0.3299
2024-06-24 01:06:16,457 Epoch [7/8], Batch [501/748], Loss: 0.5183
2024-06-24 01:07:06,919 Epoch [7/8], Batch [551/748], Loss: 0.3078
2024-06-24 01:07:57,725 Epoch [7/8], Batch [601/748], Loss: 0.2482
2024-06-24 01:08:48,605 Epoch [7/8], Batch [651/748], Loss: 0.2647
2024-06-24 01:09:39,543 Epoch [7/8], Batch [701/748], Loss: 0.4305
2024-06-24 01:10:26,920 Epoch 7/8, Train Loss: 0.3603, Train Accuracy: 0.8606
2024-06-24 01:11:51,901 Epoch 7/8, Val Loss: 0.9165, Val Accuracy: 0.6775
2024-06-24 01:11:52,918 Epoch [8/8], Batch [1/748], Loss: 0.5019
2024-06-24 01:12:43,825 Epoch [8/8], Batch [51/748], Loss: 0.3144
2024-06-24 01:13:34,844 Epoch [8/8], Batch [101/748], Loss: 0.1444
2024-06-24 01:14:25,773 Epoch [8/8], Batch [151/748], Loss: 0.1186
2024-06-24 01:15:16,704 Epoch [8/8], Batch [201/748], Loss: 0.2338
2024-06-24 01:16:07,603 Epoch [8/8], Batch [251/748], Loss: 0.2517
2024-06-24 01:16:58,629 Epoch [8/8], Batch [301/748], Loss: 0.1956
2024-06-24 01:17:49,464 Epoch [8/8], Batch [351/748], Loss: 0.3987
2024-06-24 01:18:40,434 Epoch [8/8], Batch [401/748], Loss: 0.3270
2024-06-24 01:19:31,350 Epoch [8/8], Batch [451/748], Loss: 0.2584
2024-06-24 01:20:22,208 Epoch [8/8], Batch [501/748], Loss: 0.2470
2024-06-24 01:21:13,297 Epoch [8/8], Batch [551/748], Loss: 0.4971
2024-06-24 01:22:04,078 Epoch [8/8], Batch [601/748], Loss: 0.3984
2024-06-24 01:22:55,107 Epoch [8/8], Batch [651/748], Loss: 0.3526
2024-06-24 01:23:46,015 Epoch [8/8], Batch [701/748], Loss: 0.5128
2024-06-24 01:24:33,616 Epoch 8/8, Train Loss: 0.2925, Train Accuracy: 0.8885
2024-06-24 01:25:58,466 Epoch 8/8, Val Loss: 0.9894, Val Accuracy: 0.6786
2024-06-24 01:25:58,468 Training finished!
2024-06-24 01:25:58,468 ==================================================
2024-06-24 01:26:04,005 ==================================================
2024-06-24 01:26:04,005 Training BERT + TF-IDF features with Dimension-64...
2024-06-24 01:26:04,999 Epoch [1/8], Batch [1/748], Loss: 1.6461
2024-06-24 01:26:55,508 Epoch [1/8], Batch [51/748], Loss: 1.5227
2024-06-24 01:27:46,410 Epoch [1/8], Batch [101/748], Loss: 1.3201
2024-06-24 01:28:37,326 Epoch [1/8], Batch [151/748], Loss: 1.1407
2024-06-24 01:29:28,255 Epoch [1/8], Batch [201/748], Loss: 1.1855
2024-06-24 01:30:19,300 Epoch [1/8], Batch [251/748], Loss: 0.9821
2024-06-24 01:31:10,358 Epoch [1/8], Batch [301/748], Loss: 1.0021
2024-06-24 01:32:01,140 Epoch [1/8], Batch [351/748], Loss: 0.9675
2024-06-24 01:32:52,129 Epoch [1/8], Batch [401/748], Loss: 0.9481
2024-06-24 01:33:42,960 Epoch [1/8], Batch [451/748], Loss: 0.7169
2024-06-24 01:34:33,932 Epoch [1/8], Batch [501/748], Loss: 1.1058
2024-06-24 01:35:24,987 Epoch [1/8], Batch [551/748], Loss: 1.1531
2024-06-24 01:36:16,374 Epoch [1/8], Batch [601/748], Loss: 1.0597
2024-06-24 01:37:07,623 Epoch [1/8], Batch [651/748], Loss: 0.9647
2024-06-24 01:37:58,385 Epoch [1/8], Batch [701/748], Loss: 1.1662
2024-06-24 01:38:46,071 Epoch 1/8, Train Loss: 1.0698, Train Accuracy: 0.5446
2024-06-24 01:40:11,545 Epoch 1/8, Val Loss: 0.8782, Val Accuracy: 0.6235
2024-06-24 01:40:12,548 Epoch [2/8], Batch [1/748], Loss: 0.8766
2024-06-24 01:41:03,149 Epoch [2/8], Batch [51/748], Loss: 0.6152
2024-06-24 01:41:54,053 Epoch [2/8], Batch [101/748], Loss: 0.8064
2024-06-24 01:42:44,963 Epoch [2/8], Batch [151/748], Loss: 0.8351
2024-06-24 01:43:35,728 Epoch [2/8], Batch [201/748], Loss: 0.6215
2024-06-24 01:44:26,812 Epoch [2/8], Batch [251/748], Loss: 0.6955
2024-06-24 01:45:17,597 Epoch [2/8], Batch [301/748], Loss: 0.8324
2024-06-24 01:46:08,576 Epoch [2/8], Batch [351/748], Loss: 0.7437
2024-06-24 01:46:59,541 Epoch [2/8], Batch [401/748], Loss: 0.6627
2024-06-24 01:47:50,450 Epoch [2/8], Batch [451/748], Loss: 0.8405
2024-06-24 01:48:41,346 Epoch [2/8], Batch [501/748], Loss: 0.7323
2024-06-24 01:49:32,321 Epoch [2/8], Batch [551/748], Loss: 0.6458
2024-06-24 01:50:23,070 Epoch [2/8], Batch [601/748], Loss: 0.6260
2024-06-24 01:51:14,300 Epoch [2/8], Batch [651/748], Loss: 0.5940
2024-06-24 01:52:05,719 Epoch [2/8], Batch [701/748], Loss: 0.6695
2024-06-24 01:52:53,324 Epoch 2/8, Train Loss: 0.8176, Train Accuracy: 0.6377
2024-06-24 01:54:19,247 Epoch 2/8, Val Loss: 0.8345, Val Accuracy: 0.6390
2024-06-24 01:54:20,270 Epoch [3/8], Batch [1/748], Loss: 0.5919
2024-06-24 01:55:10,758 Epoch [3/8], Batch [51/748], Loss: 0.7216
2024-06-24 01:56:01,620 Epoch [3/8], Batch [101/748], Loss: 0.7772
2024-06-24 01:56:52,549 Epoch [3/8], Batch [151/748], Loss: 0.8299
2024-06-24 01:57:43,587 Epoch [3/8], Batch [201/748], Loss: 0.8671
2024-06-24 01:58:34,496 Epoch [3/8], Batch [251/748], Loss: 0.7926
2024-06-24 01:59:25,454 Epoch [3/8], Batch [301/748], Loss: 0.6996
2024-06-24 02:00:16,405 Epoch [3/8], Batch [351/748], Loss: 0.8362
2024-06-24 02:01:07,261 Epoch [3/8], Batch [401/748], Loss: 0.7929
2024-06-24 02:01:58,170 Epoch [3/8], Batch [451/748], Loss: 0.8490
2024-06-24 02:02:49,200 Epoch [3/8], Batch [501/748], Loss: 0.5099
2024-06-24 02:03:40,251 Epoch [3/8], Batch [551/748], Loss: 0.7554
2024-06-24 02:04:31,080 Epoch [3/8], Batch [601/748], Loss: 0.6183
2024-06-24 02:05:22,016 Epoch [3/8], Batch [651/748], Loss: 0.8139
2024-06-24 02:06:12,988 Epoch [3/8], Batch [701/748], Loss: 0.5613
2024-06-24 02:07:00,904 Epoch 3/8, Train Loss: 0.7112, Train Accuracy: 0.6888
2024-06-24 02:08:26,692 Epoch 3/8, Val Loss: 0.7838, Val Accuracy: 0.6668
2024-06-24 02:08:27,718 Epoch [4/8], Batch [1/748], Loss: 0.6302
2024-06-24 02:09:18,578 Epoch [4/8], Batch [51/748], Loss: 0.6733
2024-06-24 02:10:09,604 Epoch [4/8], Batch [101/748], Loss: 0.5239
2024-06-24 02:11:00,659 Epoch [4/8], Batch [151/748], Loss: 0.6040
2024-06-24 02:11:51,518 Epoch [4/8], Batch [201/748], Loss: 0.5651
2024-06-24 02:12:42,633 Epoch [4/8], Batch [251/748], Loss: 0.6730
2024-06-24 02:13:33,314 Epoch [4/8], Batch [301/748], Loss: 0.6644
2024-06-24 02:14:24,305 Epoch [4/8], Batch [351/748], Loss: 0.5605
2024-06-24 02:15:15,314 Epoch [4/8], Batch [401/748], Loss: 0.6899
2024-06-24 02:16:06,183 Epoch [4/8], Batch [451/748], Loss: 0.6318
2024-06-24 02:16:57,074 Epoch [4/8], Batch [501/748], Loss: 0.4930
2024-06-24 02:17:47,425 Epoch [4/8], Batch [551/748], Loss: 0.4527
2024-06-24 02:18:37,904 Epoch [4/8], Batch [601/748], Loss: 0.5748
2024-06-24 02:19:28,268 Epoch [4/8], Batch [651/748], Loss: 0.5373
2024-06-24 02:20:18,966 Epoch [4/8], Batch [701/748], Loss: 0.4617
2024-06-24 02:21:06,138 Epoch 4/8, Train Loss: 0.5982, Train Accuracy: 0.7455
2024-06-24 02:22:31,186 Epoch 4/8, Val Loss: 0.7694, Val Accuracy: 0.6803
2024-06-24 02:22:32,206 Epoch [5/8], Batch [1/748], Loss: 0.4958
2024-06-24 02:23:22,556 Epoch [5/8], Batch [51/748], Loss: 0.3965
2024-06-24 02:24:13,250 Epoch [5/8], Batch [101/748], Loss: 0.3292
2024-06-24 02:25:04,238 Epoch [5/8], Batch [151/748], Loss: 0.3969
2024-06-24 02:25:55,224 Epoch [5/8], Batch [201/748], Loss: 0.4531
2024-06-24 02:26:45,781 Epoch [5/8], Batch [251/748], Loss: 0.3859
2024-06-24 02:27:36,632 Epoch [5/8], Batch [301/748], Loss: 0.3049
2024-06-24 02:28:27,327 Epoch [5/8], Batch [351/748], Loss: 0.5878
2024-06-24 02:29:17,806 Epoch [5/8], Batch [401/748], Loss: 0.5326
2024-06-24 02:30:08,269 Epoch [5/8], Batch [451/748], Loss: 0.4812
2024-06-24 02:30:58,690 Epoch [5/8], Batch [501/748], Loss: 0.5348
2024-06-24 02:31:49,294 Epoch [5/8], Batch [551/748], Loss: 0.6461
2024-06-24 02:32:40,150 Epoch [5/8], Batch [601/748], Loss: 0.5509
2024-06-24 02:33:30,864 Epoch [5/8], Batch [651/748], Loss: 0.5762
2024-06-24 02:34:21,095 Epoch [5/8], Batch [701/748], Loss: 0.4644
2024-06-24 02:35:08,330 Epoch 5/8, Train Loss: 0.5036, Train Accuracy: 0.7892
2024-06-24 02:36:33,169 Epoch 5/8, Val Loss: 0.7977, Val Accuracy: 0.6893
2024-06-24 02:36:34,178 Epoch [6/8], Batch [1/748], Loss: 0.4737
2024-06-24 02:37:24,264 Epoch [6/8], Batch [51/748], Loss: 0.3913
2024-06-24 02:38:14,654 Epoch [6/8], Batch [101/748], Loss: 0.5529
2024-06-24 02:39:05,433 Epoch [6/8], Batch [151/748], Loss: 0.3399
2024-06-24 02:39:56,078 Epoch [6/8], Batch [201/748], Loss: 0.2526
2024-06-24 02:40:46,985 Epoch [6/8], Batch [251/748], Loss: 0.4129
2024-06-24 02:41:37,365 Epoch [6/8], Batch [301/748], Loss: 0.4762
2024-06-24 02:42:28,105 Epoch [6/8], Batch [351/748], Loss: 0.5138
2024-06-24 02:43:18,842 Epoch [6/8], Batch [401/748], Loss: 0.5780
2024-06-24 02:44:09,400 Epoch [6/8], Batch [451/748], Loss: 0.4910
2024-06-24 02:45:00,119 Epoch [6/8], Batch [501/748], Loss: 0.4986
2024-06-24 02:45:50,593 Epoch [6/8], Batch [551/748], Loss: 0.2668
2024-06-24 02:46:41,183 Epoch [6/8], Batch [601/748], Loss: 0.3266
2024-06-24 02:47:31,758 Epoch [6/8], Batch [651/748], Loss: 0.4189
2024-06-24 02:48:22,335 Epoch [6/8], Batch [701/748], Loss: 0.6557
2024-06-24 02:49:09,428 Epoch 6/8, Train Loss: 0.4123, Train Accuracy: 0.8313
2024-06-24 02:50:34,073 Epoch 6/8, Val Loss: 0.8955, Val Accuracy: 0.6795
2024-06-24 02:50:35,076 Epoch [7/8], Batch [1/748], Loss: 0.2585
2024-06-24 02:51:25,246 Epoch [7/8], Batch [51/748], Loss: 0.3672
2024-06-24 02:52:15,984 Epoch [7/8], Batch [101/748], Loss: 0.4096
2024-06-24 02:53:06,803 Epoch [7/8], Batch [151/748], Loss: 0.3217
2024-06-24 02:53:57,418 Epoch [7/8], Batch [201/748], Loss: 0.3336
2024-06-24 02:54:47,788 Epoch [7/8], Batch [251/748], Loss: 0.6025
2024-06-24 02:55:38,714 Epoch [7/8], Batch [301/748], Loss: 0.1458
2024-06-24 02:56:29,796 Epoch [7/8], Batch [351/748], Loss: 0.1163
2024-06-24 02:57:20,688 Epoch [7/8], Batch [401/748], Loss: 0.2468
2024-06-24 02:58:11,624 Epoch [7/8], Batch [451/748], Loss: 0.1295
2024-06-24 02:59:02,610 Epoch [7/8], Batch [501/748], Loss: 0.4729
2024-06-24 02:59:53,430 Epoch [7/8], Batch [551/748], Loss: 0.3832
2024-06-24 03:00:44,618 Epoch [7/8], Batch [601/748], Loss: 0.3071
2024-06-24 03:01:35,562 Epoch [7/8], Batch [651/748], Loss: 0.2483
2024-06-24 03:02:26,601 Epoch [7/8], Batch [701/748], Loss: 0.1826
2024-06-24 03:03:13,970 Epoch 7/8, Train Loss: 0.3312, Train Accuracy: 0.8706
2024-06-24 03:04:38,700 Epoch 7/8, Val Loss: 0.9558, Val Accuracy: 0.6818
2024-06-24 03:04:39,731 Epoch [8/8], Batch [1/748], Loss: 0.2083
2024-06-24 03:05:30,052 Epoch [8/8], Batch [51/748], Loss: 0.2625
2024-06-24 03:06:20,908 Epoch [8/8], Batch [101/748], Loss: 0.1959
2024-06-24 03:07:11,823 Epoch [8/8], Batch [151/748], Loss: 0.2230
2024-06-24 03:08:02,787 Epoch [8/8], Batch [201/748], Loss: 0.1452
2024-06-24 03:08:53,673 Epoch [8/8], Batch [251/748], Loss: 0.1829
2024-06-24 03:09:44,620 Epoch [8/8], Batch [301/748], Loss: 0.0893
2024-06-24 03:10:35,538 Epoch [8/8], Batch [351/748], Loss: 0.3214
2024-06-24 03:11:26,499 Epoch [8/8], Batch [401/748], Loss: 0.2963
2024-06-24 03:12:17,549 Epoch [8/8], Batch [451/748], Loss: 0.1818
2024-06-24 03:13:08,475 Epoch [8/8], Batch [501/748], Loss: 0.1614
2024-06-24 03:13:59,135 Epoch [8/8], Batch [551/748], Loss: 0.2911
2024-06-24 03:14:49,551 Epoch [8/8], Batch [601/748], Loss: 0.1566
2024-06-24 03:15:40,307 Epoch [8/8], Batch [651/748], Loss: 0.2065
2024-06-24 03:16:30,848 Epoch [8/8], Batch [701/748], Loss: 0.5381
2024-06-24 03:17:17,859 Epoch 8/8, Train Loss: 0.2670, Train Accuracy: 0.8984
2024-06-24 03:18:42,775 Epoch 8/8, Val Loss: 1.0674, Val Accuracy: 0.6674
2024-06-24 03:18:42,777 Training finished!
2024-06-24 03:18:42,777 ==================================================
2024-06-24 03:18:48,186 ==================================================
2024-06-24 03:18:48,186 Training BERT + TF-IDF features with Dimension-8...
2024-06-24 03:18:49,179 Epoch [1/8], Batch [1/748], Loss: 1.6700
2024-06-24 03:19:39,349 Epoch [1/8], Batch [51/748], Loss: 1.5489
2024-06-24 03:20:30,125 Epoch [1/8], Batch [101/748], Loss: 1.4046
2024-06-24 03:21:20,840 Epoch [1/8], Batch [151/748], Loss: 1.2535
2024-06-24 03:22:11,737 Epoch [1/8], Batch [201/748], Loss: 1.0019
2024-06-24 03:23:02,695 Epoch [1/8], Batch [251/748], Loss: 1.0920
2024-06-24 03:23:53,106 Epoch [1/8], Batch [301/748], Loss: 1.0760
2024-06-24 03:24:43,691 Epoch [1/8], Batch [351/748], Loss: 1.0650
2024-06-24 03:25:34,502 Epoch [1/8], Batch [401/748], Loss: 1.1026
2024-06-24 03:26:25,031 Epoch [1/8], Batch [451/748], Loss: 0.9363
2024-06-24 03:27:15,617 Epoch [1/8], Batch [501/748], Loss: 0.8585
2024-06-24 03:28:06,386 Epoch [1/8], Batch [551/748], Loss: 0.8459
2024-06-24 03:28:57,512 Epoch [1/8], Batch [601/748], Loss: 1.0791
2024-06-24 03:29:48,396 Epoch [1/8], Batch [651/748], Loss: 1.0313
2024-06-24 03:30:39,417 Epoch [1/8], Batch [701/748], Loss: 0.9679
2024-06-24 03:31:26,699 Epoch 1/8, Train Loss: 1.1006, Train Accuracy: 0.5299
2024-06-24 03:32:51,944 Epoch 1/8, Val Loss: 0.8632, Val Accuracy: 0.6258
2024-06-24 03:32:53,013 Epoch [2/8], Batch [1/748], Loss: 0.8955
2024-06-24 03:33:43,773 Epoch [2/8], Batch [51/748], Loss: 0.8922
2024-06-24 03:34:34,907 Epoch [2/8], Batch [101/748], Loss: 0.8734
2024-06-24 03:35:25,787 Epoch [2/8], Batch [151/748], Loss: 0.8226
2024-06-24 03:36:16,772 Epoch [2/8], Batch [201/748], Loss: 0.7080
2024-06-24 03:37:07,669 Epoch [2/8], Batch [251/748], Loss: 0.5374
2024-06-24 03:37:58,589 Epoch [2/8], Batch [301/748], Loss: 0.9686
2024-06-24 03:38:49,182 Epoch [2/8], Batch [351/748], Loss: 1.0539
2024-06-24 03:39:39,604 Epoch [2/8], Batch [401/748], Loss: 1.0674
2024-06-24 03:40:30,190 Epoch [2/8], Batch [451/748], Loss: 0.8209
2024-06-24 03:41:20,714 Epoch [2/8], Batch [501/748], Loss: 0.8393
2024-06-24 03:42:11,405 Epoch [2/8], Batch [551/748], Loss: 0.7026
2024-06-24 03:43:02,257 Epoch [2/8], Batch [601/748], Loss: 0.6845
2024-06-24 03:43:52,849 Epoch [2/8], Batch [651/748], Loss: 0.6670
2024-06-24 03:44:43,497 Epoch [2/8], Batch [701/748], Loss: 0.8515
2024-06-24 03:45:30,780 Epoch 2/8, Train Loss: 0.8080, Train Accuracy: 0.6480
2024-06-24 03:46:56,101 Epoch 2/8, Val Loss: 0.8044, Val Accuracy: 0.6387
2024-06-24 03:46:57,125 Epoch [3/8], Batch [1/748], Loss: 0.7382
2024-06-24 03:47:47,760 Epoch [3/8], Batch [51/748], Loss: 0.3846
2024-06-24 03:48:38,403 Epoch [3/8], Batch [101/748], Loss: 0.8134
2024-06-24 03:49:28,852 Epoch [3/8], Batch [151/748], Loss: 0.5653
2024-06-24 03:50:19,465 Epoch [3/8], Batch [201/748], Loss: 0.7809
2024-06-24 03:51:10,265 Epoch [3/8], Batch [251/748], Loss: 0.7574
2024-06-24 03:52:00,629 Epoch [3/8], Batch [301/748], Loss: 0.8287
2024-06-24 03:52:51,543 Epoch [3/8], Batch [351/748], Loss: 0.7202
2024-06-24 03:53:42,387 Epoch [3/8], Batch [401/748], Loss: 0.5412
2024-06-24 03:54:33,125 Epoch [3/8], Batch [451/748], Loss: 0.6502
2024-06-24 03:55:23,784 Epoch [3/8], Batch [501/748], Loss: 0.7356
2024-06-24 03:56:14,207 Epoch [3/8], Batch [551/748], Loss: 0.7563
2024-06-24 03:57:05,189 Epoch [3/8], Batch [601/748], Loss: 0.7189
2024-06-24 03:57:56,220 Epoch [3/8], Batch [651/748], Loss: 0.7502
2024-06-24 03:58:46,818 Epoch [3/8], Batch [701/748], Loss: 0.6930
2024-06-24 03:59:33,837 Epoch 3/8, Train Loss: 0.6834, Train Accuracy: 0.7052
2024-06-24 04:00:58,807 Epoch 3/8, Val Loss: 0.7975, Val Accuracy: 0.6636
2024-06-24 04:00:59,790 Epoch [4/8], Batch [1/748], Loss: 0.4950
2024-06-24 04:01:50,236 Epoch [4/8], Batch [51/748], Loss: 0.4260
2024-06-24 04:02:40,975 Epoch [4/8], Batch [101/748], Loss: 0.6168
2024-06-24 04:03:31,509 Epoch [4/8], Batch [151/748], Loss: 0.5729
2024-06-24 04:04:21,771 Epoch [4/8], Batch [201/748], Loss: 0.4413
2024-06-24 04:05:12,539 Epoch [4/8], Batch [251/748], Loss: 0.4475
2024-06-24 04:06:03,041 Epoch [4/8], Batch [301/748], Loss: 0.5940
2024-06-24 04:06:53,506 Epoch [4/8], Batch [351/748], Loss: 0.4322
2024-06-24 04:07:44,395 Epoch [4/8], Batch [401/748], Loss: 0.3357
2024-06-24 04:08:34,753 Epoch [4/8], Batch [451/748], Loss: 0.7267
2024-06-24 04:09:25,441 Epoch [4/8], Batch [501/748], Loss: 0.5177
2024-06-24 04:10:16,221 Epoch [4/8], Batch [551/748], Loss: 0.5696
2024-06-24 04:11:06,539 Epoch [4/8], Batch [601/748], Loss: 0.6584
2024-06-24 04:11:57,222 Epoch [4/8], Batch [651/748], Loss: 0.8781
2024-06-24 04:12:47,818 Epoch [4/8], Batch [701/748], Loss: 0.5255
2024-06-24 04:13:34,889 Epoch 4/8, Train Loss: 0.5722, Train Accuracy: 0.7567
2024-06-24 04:14:59,755 Epoch 4/8, Val Loss: 0.8145, Val Accuracy: 0.6616
2024-06-24 04:15:00,769 Epoch [5/8], Batch [1/748], Loss: 0.8226
2024-06-24 04:15:51,489 Epoch [5/8], Batch [51/748], Loss: 0.3899
2024-06-24 04:16:41,983 Epoch [5/8], Batch [101/748], Loss: 0.5525
2024-06-24 04:17:32,658 Epoch [5/8], Batch [151/748], Loss: 0.6273
2024-06-24 04:18:23,487 Epoch [5/8], Batch [201/748], Loss: 0.2213
2024-06-24 04:19:14,364 Epoch [5/8], Batch [251/748], Loss: 0.6452
2024-06-24 04:20:05,030 Epoch [5/8], Batch [301/748], Loss: 0.4168
2024-06-24 04:20:55,428 Epoch [5/8], Batch [351/748], Loss: 0.8331
2024-06-24 04:21:46,272 Epoch [5/8], Batch [401/748], Loss: 0.4237
