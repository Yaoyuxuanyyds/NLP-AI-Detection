2024-06-23 04:33:39,413 ==================================================
2024-06-23 04:33:39,413 Training BERT + TF-IDF features with Dimension-5000...
2024-06-23 04:33:41,240 Epoch [1/8], Batch [1/748], Loss: 1.6330
2024-06-23 04:34:30,282 Epoch [1/8], Batch [51/748], Loss: 1.5778
2024-06-23 04:35:20,153 Epoch [1/8], Batch [101/748], Loss: 1.4155
2024-06-23 04:36:10,634 Epoch [1/8], Batch [151/748], Loss: 1.4033
2024-06-23 04:37:01,389 Epoch [1/8], Batch [201/748], Loss: 1.1810
2024-06-23 04:37:51,872 Epoch [1/8], Batch [251/748], Loss: 1.1467
2024-06-23 04:38:42,620 Epoch [1/8], Batch [301/748], Loss: 1.1357
2024-06-23 04:39:33,171 Epoch [1/8], Batch [351/748], Loss: 1.0836
2024-06-23 04:40:23,671 Epoch [1/8], Batch [401/748], Loss: 0.9507
2024-06-23 04:41:14,236 Epoch [1/8], Batch [451/748], Loss: 1.1017
2024-06-23 04:42:04,615 Epoch [1/8], Batch [501/748], Loss: 0.9560
2024-06-23 04:42:55,402 Epoch [1/8], Batch [551/748], Loss: 0.9964
2024-06-23 04:43:45,731 Epoch [1/8], Batch [601/748], Loss: 0.8879
2024-06-23 04:44:36,510 Epoch [1/8], Batch [651/748], Loss: 1.1179
2024-06-23 04:45:27,085 Epoch [1/8], Batch [701/748], Loss: 1.1066
2024-06-23 04:46:14,368 Epoch 1/8, Train Loss: 1.1550, Train Accuracy: 0.5035
2024-06-23 04:47:38,947 Epoch 1/8, Val Loss: 0.9314, Val Accuracy: 0.5910
2024-06-23 04:47:40,005 Epoch [2/8], Batch [1/748], Loss: 0.9833
2024-06-23 04:48:30,737 Epoch [2/8], Batch [51/748], Loss: 0.9177
2024-06-23 04:49:21,678 Epoch [2/8], Batch [101/748], Loss: 0.8931
2024-06-23 04:50:12,636 Epoch [2/8], Batch [151/748], Loss: 1.0516
2024-06-23 04:51:03,273 Epoch [2/8], Batch [201/748], Loss: 0.7612
2024-06-23 04:51:53,747 Epoch [2/8], Batch [251/748], Loss: 0.8762
2024-06-23 04:52:44,250 Epoch [2/8], Batch [301/748], Loss: 1.0828
2024-06-23 04:53:34,818 Epoch [2/8], Batch [351/748], Loss: 0.9467
2024-06-23 04:54:25,464 Epoch [2/8], Batch [401/748], Loss: 0.9076
2024-06-23 04:55:16,446 Epoch [2/8], Batch [451/748], Loss: 0.9903
2024-06-23 04:56:07,190 Epoch [2/8], Batch [501/748], Loss: 0.7734
2024-06-23 04:56:57,845 Epoch [2/8], Batch [551/748], Loss: 1.0608
2024-06-23 04:57:48,243 Epoch [2/8], Batch [601/748], Loss: 0.7967
2024-06-23 04:58:39,010 Epoch [2/8], Batch [651/748], Loss: 0.8852
2024-06-23 04:59:29,458 Epoch [2/8], Batch [701/748], Loss: 0.7918
2024-06-23 05:00:16,606 Epoch 2/8, Train Loss: 0.8704, Train Accuracy: 0.6171
2024-06-23 05:01:40,984 Epoch 2/8, Val Loss: 0.9060, Val Accuracy: 0.6026
2024-06-23 05:01:41,972 Epoch [3/8], Batch [1/748], Loss: 0.8093
2024-06-23 05:02:32,671 Epoch [3/8], Batch [51/748], Loss: 0.5774
2024-06-23 05:03:23,492 Epoch [3/8], Batch [101/748], Loss: 0.8508
2024-06-23 05:04:13,934 Epoch [3/8], Batch [151/748], Loss: 0.7304
2024-06-23 05:05:04,556 Epoch [3/8], Batch [201/748], Loss: 0.6085
2024-06-23 05:05:55,275 Epoch [3/8], Batch [251/748], Loss: 0.7467
2024-06-23 05:06:46,046 Epoch [3/8], Batch [301/748], Loss: 0.6051
2024-06-23 05:07:36,560 Epoch [3/8], Batch [351/748], Loss: 0.8431
2024-06-23 05:08:27,355 Epoch [3/8], Batch [401/748], Loss: 1.0319
2024-06-23 05:09:17,805 Epoch [3/8], Batch [451/748], Loss: 0.7366
2024-06-23 05:10:08,181 Epoch [3/8], Batch [501/748], Loss: 0.6926
2024-06-23 05:10:58,582 Epoch [3/8], Batch [551/748], Loss: 0.7632
2024-06-23 05:11:49,098 Epoch [3/8], Batch [601/748], Loss: 0.9184
2024-06-23 05:12:39,981 Epoch [3/8], Batch [651/748], Loss: 0.8343
2024-06-23 05:13:30,416 Epoch [3/8], Batch [701/748], Loss: 0.6838
2024-06-23 05:14:17,356 Epoch 3/8, Train Loss: 0.7617, Train Accuracy: 0.6647
2024-06-23 05:15:41,676 Epoch 3/8, Val Loss: 0.9292, Val Accuracy: 0.6091
2024-06-23 05:15:42,684 Epoch [4/8], Batch [1/748], Loss: 0.6889
2024-06-23 05:16:33,697 Epoch [4/8], Batch [51/748], Loss: 0.7048
2024-06-23 05:17:24,560 Epoch [4/8], Batch [101/748], Loss: 0.6689
2024-06-23 05:18:15,585 Epoch [4/8], Batch [151/748], Loss: 0.4656
2024-06-23 05:19:06,405 Epoch [4/8], Batch [201/748], Loss: 0.7957
2024-06-23 05:19:57,425 Epoch [4/8], Batch [251/748], Loss: 0.7457
2024-06-23 05:20:48,459 Epoch [4/8], Batch [301/748], Loss: 0.8523
2024-06-23 05:21:39,364 Epoch [4/8], Batch [351/748], Loss: 1.0191
2024-06-23 05:22:30,216 Epoch [4/8], Batch [401/748], Loss: 0.6629
2024-06-23 05:23:20,909 Epoch [4/8], Batch [451/748], Loss: 0.7673
2024-06-23 05:24:11,723 Epoch [4/8], Batch [501/748], Loss: 0.6372
2024-06-23 05:25:02,385 Epoch [4/8], Batch [551/748], Loss: 0.6551
2024-06-23 05:25:52,995 Epoch [4/8], Batch [601/748], Loss: 0.6638
2024-06-23 05:26:43,886 Epoch [4/8], Batch [651/748], Loss: 0.7413
2024-06-23 05:27:34,875 Epoch [4/8], Batch [701/748], Loss: 0.4679
2024-06-23 05:28:22,351 Epoch 4/8, Train Loss: 0.6673, Train Accuracy: 0.7071
2024-06-23 05:29:46,986 Epoch 4/8, Val Loss: 0.8272, Val Accuracy: 0.6399
2024-06-23 05:29:47,998 Epoch [5/8], Batch [1/748], Loss: 0.6255
2024-06-23 05:30:38,731 Epoch [5/8], Batch [51/748], Loss: 0.7284
2024-06-23 05:31:29,308 Epoch [5/8], Batch [101/748], Loss: 0.4127
2024-06-23 05:32:20,297 Epoch [5/8], Batch [151/748], Loss: 0.4601
2024-06-23 05:33:11,323 Epoch [5/8], Batch [201/748], Loss: 0.5685
2024-06-23 05:34:02,127 Epoch [5/8], Batch [251/748], Loss: 0.5288
2024-06-23 05:34:53,150 Epoch [5/8], Batch [301/748], Loss: 0.6245
2024-06-23 05:35:43,872 Epoch [5/8], Batch [351/748], Loss: 0.3431
2024-06-23 05:36:34,650 Epoch [5/8], Batch [401/748], Loss: 0.8136
2024-06-23 05:37:25,463 Epoch [5/8], Batch [451/748], Loss: 0.5361
2024-06-23 05:38:16,415 Epoch [5/8], Batch [501/748], Loss: 0.5928
2024-06-23 05:39:07,123 Epoch [5/8], Batch [551/748], Loss: 0.5584
2024-06-23 05:39:57,714 Epoch [5/8], Batch [601/748], Loss: 0.4893
2024-06-23 05:40:48,796 Epoch [5/8], Batch [651/748], Loss: 0.2434
2024-06-23 05:41:39,648 Epoch [5/8], Batch [701/748], Loss: 0.4606
2024-06-23 05:42:27,235 Epoch 5/8, Train Loss: 0.5726, Train Accuracy: 0.7521
2024-06-23 05:43:52,363 Epoch 5/8, Val Loss: 0.8475, Val Accuracy: 0.6499
2024-06-23 05:43:53,354 Epoch [6/8], Batch [1/748], Loss: 0.5359
2024-06-23 05:44:44,004 Epoch [6/8], Batch [51/748], Loss: 0.3396
2024-06-23 05:45:35,014 Epoch [6/8], Batch [101/748], Loss: 0.5366
2024-06-23 05:46:25,890 Epoch [6/8], Batch [151/748], Loss: 0.5838
2024-06-23 05:47:16,875 Epoch [6/8], Batch [201/748], Loss: 0.4359
2024-06-23 05:48:07,793 Epoch [6/8], Batch [251/748], Loss: 0.3582
2024-06-23 05:48:58,740 Epoch [6/8], Batch [301/748], Loss: 0.3743
2024-06-23 05:49:49,754 Epoch [6/8], Batch [351/748], Loss: 0.5858
2024-06-23 05:50:40,591 Epoch [6/8], Batch [401/748], Loss: 0.6832
2024-06-23 05:51:31,540 Epoch [6/8], Batch [451/748], Loss: 0.4221
2024-06-23 05:52:22,421 Epoch [6/8], Batch [501/748], Loss: 0.6044
2024-06-23 05:53:13,356 Epoch [6/8], Batch [551/748], Loss: 0.3676
2024-06-23 05:54:04,342 Epoch [6/8], Batch [601/748], Loss: 0.3865
2024-06-23 05:54:55,346 Epoch [6/8], Batch [651/748], Loss: 0.4531
2024-06-23 05:55:46,265 Epoch [6/8], Batch [701/748], Loss: 0.4365
2024-06-23 05:56:33,787 Epoch 6/8, Train Loss: 0.4997, Train Accuracy: 0.7884
2024-06-23 05:57:58,180 Epoch 6/8, Val Loss: 0.9040, Val Accuracy: 0.6663
2024-06-23 05:57:59,183 Epoch [7/8], Batch [1/748], Loss: 0.3983
2024-06-23 05:58:49,649 Epoch [7/8], Batch [51/748], Loss: 0.2479
2024-06-23 05:59:40,599 Epoch [7/8], Batch [101/748], Loss: 0.4103
2024-06-23 06:00:31,673 Epoch [7/8], Batch [151/748], Loss: 0.5319
2024-06-23 06:01:22,374 Epoch [7/8], Batch [201/748], Loss: 0.2727
2024-06-23 06:02:13,395 Epoch [7/8], Batch [251/748], Loss: 0.2766
2024-06-23 06:03:04,342 Epoch [7/8], Batch [301/748], Loss: 0.2788
2024-06-23 06:03:55,263 Epoch [7/8], Batch [351/748], Loss: 0.3592
2024-06-23 06:04:46,249 Epoch [7/8], Batch [401/748], Loss: 0.5932
2024-06-23 06:05:37,068 Epoch [7/8], Batch [451/748], Loss: 0.4470
2024-06-23 06:06:28,237 Epoch [7/8], Batch [501/748], Loss: 0.4216
2024-06-23 06:07:19,126 Epoch [7/8], Batch [551/748], Loss: 0.5172
2024-06-23 06:08:09,976 Epoch [7/8], Batch [601/748], Loss: 0.3369
2024-06-23 06:09:00,951 Epoch [7/8], Batch [651/748], Loss: 0.5746
2024-06-23 06:09:51,592 Epoch [7/8], Batch [701/748], Loss: 0.6508
2024-06-23 06:10:38,929 Epoch 7/8, Train Loss: 0.4215, Train Accuracy: 0.8263
2024-06-23 06:12:03,511 Epoch 7/8, Val Loss: 0.9057, Val Accuracy: 0.6681
2024-06-23 06:12:04,529 Epoch [8/8], Batch [1/748], Loss: 0.2745
2024-06-23 06:12:55,185 Epoch [8/8], Batch [51/748], Loss: 0.3728
2024-06-23 06:13:46,058 Epoch [8/8], Batch [101/748], Loss: 0.4127
2024-06-23 06:14:37,134 Epoch [8/8], Batch [151/748], Loss: 0.3000
2024-06-23 06:15:27,954 Epoch [8/8], Batch [201/748], Loss: 0.5831
2024-06-23 06:16:18,830 Epoch [8/8], Batch [251/748], Loss: 0.3937
2024-06-23 06:17:09,985 Epoch [8/8], Batch [301/748], Loss: 0.3574
2024-06-23 06:18:00,887 Epoch [8/8], Batch [351/748], Loss: 0.3645
2024-06-23 06:18:51,963 Epoch [8/8], Batch [401/748], Loss: 0.2607
2024-06-23 06:19:42,824 Epoch [8/8], Batch [451/748], Loss: 0.2079
2024-06-23 06:20:33,843 Epoch [8/8], Batch [501/748], Loss: 0.3755
2024-06-23 06:21:24,676 Epoch [8/8], Batch [551/748], Loss: 0.2924
2024-06-23 06:22:15,602 Epoch [8/8], Batch [601/748], Loss: 0.1304
2024-06-23 06:23:06,673 Epoch [8/8], Batch [651/748], Loss: 0.2845
2024-06-23 06:23:57,596 Epoch [8/8], Batch [701/748], Loss: 0.1570
2024-06-23 06:24:45,109 Epoch 8/8, Train Loss: 0.3549, Train Accuracy: 0.8588
2024-06-23 06:26:09,930 Epoch 8/8, Val Loss: 1.0477, Val Accuracy: 0.6425
2024-06-23 06:26:09,932 Training finished!
2024-06-23 06:26:09,932 ==================================================
2024-06-23 06:36:19,994 ==================================================
2024-06-23 06:36:19,994 Training BERT + TF-IDF features with Dimension-1000...
2024-06-23 06:36:21,003 Epoch [1/8], Batch [1/748], Loss: 1.6125
2024-06-23 06:37:09,965 Epoch [1/8], Batch [51/748], Loss: 1.4981
2024-06-23 06:38:00,024 Epoch [1/8], Batch [101/748], Loss: 1.3995
2024-06-23 06:38:50,335 Epoch [1/8], Batch [151/748], Loss: 1.0775
2024-06-23 06:39:40,905 Epoch [1/8], Batch [201/748], Loss: 1.0830
2024-06-23 06:40:31,710 Epoch [1/8], Batch [251/748], Loss: 1.0534
2024-06-23 06:41:22,105 Epoch [1/8], Batch [301/748], Loss: 0.9656
2024-06-23 06:42:12,555 Epoch [1/8], Batch [351/748], Loss: 1.0545
2024-06-23 06:43:03,172 Epoch [1/8], Batch [401/748], Loss: 0.7951
2024-06-23 06:43:53,716 Epoch [1/8], Batch [451/748], Loss: 0.9575
2024-06-23 06:44:44,509 Epoch [1/8], Batch [501/748], Loss: 0.9299
2024-06-23 06:45:35,063 Epoch [1/8], Batch [551/748], Loss: 0.9659
2024-06-23 06:46:25,508 Epoch [1/8], Batch [601/748], Loss: 0.9726
2024-06-23 06:47:15,963 Epoch [1/8], Batch [651/748], Loss: 0.7636
2024-06-23 06:48:06,507 Epoch [1/8], Batch [701/748], Loss: 1.0483
2024-06-23 06:48:53,958 Epoch 1/8, Train Loss: 1.0717, Train Accuracy: 0.5492
2024-06-23 06:50:18,181 Epoch 1/8, Val Loss: 0.8963, Val Accuracy: 0.6151
2024-06-23 06:50:19,159 Epoch [2/8], Batch [1/748], Loss: 0.8171
2024-06-23 06:51:09,599 Epoch [2/8], Batch [51/748], Loss: 0.6440
2024-06-23 06:52:00,331 Epoch [2/8], Batch [101/748], Loss: 0.9324
2024-06-23 06:52:50,804 Epoch [2/8], Batch [151/748], Loss: 0.8756
2024-06-23 06:53:41,376 Epoch [2/8], Batch [201/748], Loss: 0.7960
2024-06-23 06:54:31,908 Epoch [2/8], Batch [251/748], Loss: 0.9313
2024-06-23 06:55:22,541 Epoch [2/8], Batch [301/748], Loss: 0.7867
2024-06-23 06:56:13,030 Epoch [2/8], Batch [351/748], Loss: 0.7834
2024-06-23 06:57:03,589 Epoch [2/8], Batch [401/748], Loss: 0.7431
2024-06-23 06:57:54,313 Epoch [2/8], Batch [451/748], Loss: 1.0760
2024-06-23 06:58:44,972 Epoch [2/8], Batch [501/748], Loss: 0.8121
2024-06-23 06:59:35,424 Epoch [2/8], Batch [551/748], Loss: 0.8922
2024-06-23 07:00:26,264 Epoch [2/8], Batch [601/748], Loss: 0.9047
2024-06-23 07:01:16,543 Epoch [2/8], Batch [651/748], Loss: 0.7047
2024-06-23 07:02:07,184 Epoch [2/8], Batch [701/748], Loss: 0.6374
2024-06-23 07:02:54,383 Epoch 2/8, Train Loss: 0.8042, Train Accuracy: 0.6448
2024-06-23 07:04:19,212 Epoch 2/8, Val Loss: 0.8081, Val Accuracy: 0.6427
2024-06-23 07:04:20,232 Epoch [3/8], Batch [1/748], Loss: 0.8624
2024-06-23 07:05:10,562 Epoch [3/8], Batch [51/748], Loss: 0.8285
2024-06-23 07:06:00,967 Epoch [3/8], Batch [101/748], Loss: 0.8092
2024-06-23 07:06:51,698 Epoch [3/8], Batch [151/748], Loss: 0.9053
2024-06-23 07:07:42,217 Epoch [3/8], Batch [201/748], Loss: 0.4462
2024-06-23 07:08:32,771 Epoch [3/8], Batch [251/748], Loss: 1.0348
2024-06-23 07:09:23,543 Epoch [3/8], Batch [301/748], Loss: 0.5974
2024-06-23 07:10:14,116 Epoch [3/8], Batch [351/748], Loss: 0.6106
2024-06-23 07:11:04,475 Epoch [3/8], Batch [401/748], Loss: 0.6045
2024-06-23 07:11:55,256 Epoch [3/8], Batch [451/748], Loss: 0.7381
2024-06-23 07:12:46,089 Epoch [3/8], Batch [501/748], Loss: 0.6248
2024-06-23 07:13:36,439 Epoch [3/8], Batch [551/748], Loss: 0.7667
2024-06-23 07:14:27,335 Epoch [3/8], Batch [601/748], Loss: 0.8661
2024-06-23 07:15:17,702 Epoch [3/8], Batch [651/748], Loss: 0.6230
2024-06-23 07:16:08,233 Epoch [3/8], Batch [701/748], Loss: 0.7276
2024-06-23 07:16:55,210 Epoch 3/8, Train Loss: 0.6950, Train Accuracy: 0.6950
2024-06-23 07:18:19,446 Epoch 3/8, Val Loss: 0.8701, Val Accuracy: 0.6273
2024-06-23 07:18:20,449 Epoch [4/8], Batch [1/748], Loss: 0.5692
2024-06-23 07:19:10,821 Epoch [4/8], Batch [51/748], Loss: 0.7984
2024-06-23 07:20:01,295 Epoch [4/8], Batch [101/748], Loss: 0.5781
2024-06-23 07:20:51,897 Epoch [4/8], Batch [151/748], Loss: 0.7310
2024-06-23 07:21:42,674 Epoch [4/8], Batch [201/748], Loss: 0.5413
2024-06-23 07:22:33,339 Epoch [4/8], Batch [251/748], Loss: 0.5574
2024-06-23 07:23:23,881 Epoch [4/8], Batch [301/748], Loss: 0.6189
2024-06-23 07:24:14,596 Epoch [4/8], Batch [351/748], Loss: 0.6870
2024-06-23 07:25:05,538 Epoch [4/8], Batch [401/748], Loss: 0.5964
2024-06-23 07:25:56,000 Epoch [4/8], Batch [451/748], Loss: 0.7707
2024-06-23 07:26:46,670 Epoch [4/8], Batch [501/748], Loss: 0.5138
2024-06-23 07:27:37,092 Epoch [4/8], Batch [551/748], Loss: 0.8137
2024-06-23 07:28:27,375 Epoch [4/8], Batch [601/748], Loss: 0.6828
2024-06-23 07:29:18,182 Epoch [4/8], Batch [651/748], Loss: 0.3417
2024-06-23 07:30:08,693 Epoch [4/8], Batch [701/748], Loss: 0.5209
2024-06-23 07:30:55,901 Epoch 4/8, Train Loss: 0.5971, Train Accuracy: 0.7408
2024-06-23 07:32:20,365 Epoch 4/8, Val Loss: 0.8278, Val Accuracy: 0.6606
2024-06-23 07:32:21,348 Epoch [5/8], Batch [1/748], Loss: 0.4079
2024-06-23 07:33:11,848 Epoch [5/8], Batch [51/748], Loss: 0.5192
2024-06-23 07:34:02,777 Epoch [5/8], Batch [101/748], Loss: 0.6139
2024-06-23 07:34:53,716 Epoch [5/8], Batch [151/748], Loss: 0.5079
2024-06-23 07:35:44,773 Epoch [5/8], Batch [201/748], Loss: 0.5546
2024-06-23 07:36:35,756 Epoch [5/8], Batch [251/748], Loss: 0.3593
2024-06-23 07:37:26,708 Epoch [5/8], Batch [301/748], Loss: 0.5082
2024-06-23 07:38:17,492 Epoch [5/8], Batch [351/748], Loss: 0.5872
2024-06-23 07:39:08,380 Epoch [5/8], Batch [401/748], Loss: 0.4520
2024-06-23 07:39:59,360 Epoch [5/8], Batch [451/748], Loss: 0.4398
2024-06-23 07:40:50,311 Epoch [5/8], Batch [501/748], Loss: 0.3307
2024-06-23 07:41:41,223 Epoch [5/8], Batch [551/748], Loss: 0.4242
2024-06-23 07:42:32,183 Epoch [5/8], Batch [601/748], Loss: 0.6206
2024-06-23 07:43:23,294 Epoch [5/8], Batch [651/748], Loss: 0.6464
2024-06-23 07:44:13,836 Epoch [5/8], Batch [701/748], Loss: 0.4733
2024-06-23 07:45:01,569 Epoch 5/8, Train Loss: 0.5008, Train Accuracy: 0.7907
2024-06-23 07:46:26,510 Epoch 5/8, Val Loss: 0.8531, Val Accuracy: 0.6636
2024-06-23 07:46:27,588 Epoch [6/8], Batch [1/748], Loss: 0.3246
2024-06-23 07:47:18,488 Epoch [6/8], Batch [51/748], Loss: 0.3368
2024-06-23 07:48:09,476 Epoch [6/8], Batch [101/748], Loss: 0.3370
2024-06-23 07:49:00,378 Epoch [6/8], Batch [151/748], Loss: 0.4555
2024-06-23 07:49:51,269 Epoch [6/8], Batch [201/748], Loss: 0.3754
2024-06-23 07:50:42,400 Epoch [6/8], Batch [251/748], Loss: 0.4454
2024-06-23 07:51:33,222 Epoch [6/8], Batch [301/748], Loss: 0.2067
2024-06-23 07:52:24,097 Epoch [6/8], Batch [351/748], Loss: 0.5053
2024-06-23 07:53:15,047 Epoch [6/8], Batch [401/748], Loss: 0.4542
2024-06-23 07:54:05,960 Epoch [6/8], Batch [451/748], Loss: 0.3386
2024-06-23 07:54:56,929 Epoch [6/8], Batch [501/748], Loss: 0.4407
2024-06-23 07:55:47,825 Epoch [6/8], Batch [551/748], Loss: 0.3272
2024-06-23 07:56:38,761 Epoch [6/8], Batch [601/748], Loss: 0.5296
2024-06-23 07:57:29,663 Epoch [6/8], Batch [651/748], Loss: 0.4754
2024-06-23 07:58:20,679 Epoch [6/8], Batch [701/748], Loss: 0.4995
2024-06-23 07:59:08,160 Epoch 6/8, Train Loss: 0.4137, Train Accuracy: 0.8308
2024-06-23 08:00:33,251 Epoch 6/8, Val Loss: 0.9339, Val Accuracy: 0.6626
2024-06-23 08:00:34,271 Epoch [7/8], Batch [1/748], Loss: 0.5072
2024-06-23 08:01:24,879 Epoch [7/8], Batch [51/748], Loss: 0.3626
2024-06-23 08:02:15,736 Epoch [7/8], Batch [101/748], Loss: 0.2718
2024-06-23 08:03:06,554 Epoch [7/8], Batch [151/748], Loss: 0.3172
2024-06-23 08:03:57,149 Epoch [7/8], Batch [201/748], Loss: 0.4184
2024-06-23 08:04:47,962 Epoch [7/8], Batch [251/748], Loss: 0.4454
2024-06-23 08:05:38,905 Epoch [7/8], Batch [301/748], Loss: 0.4646
2024-06-23 08:06:29,795 Epoch [7/8], Batch [351/748], Loss: 0.2651
2024-06-23 08:07:20,766 Epoch [7/8], Batch [401/748], Loss: 0.3290
2024-06-23 08:08:11,723 Epoch [7/8], Batch [451/748], Loss: 0.3280
2024-06-23 08:09:02,640 Epoch [7/8], Batch [501/748], Loss: 0.2919
2024-06-23 08:09:53,506 Epoch [7/8], Batch [551/748], Loss: 0.2572
2024-06-23 08:10:44,550 Epoch [7/8], Batch [601/748], Loss: 0.5105
2024-06-23 08:11:35,472 Epoch [7/8], Batch [651/748], Loss: 0.2783
2024-06-23 08:12:26,393 Epoch [7/8], Batch [701/748], Loss: 0.3075
2024-06-23 08:13:14,108 Epoch 7/8, Train Loss: 0.3382, Train Accuracy: 0.8691
2024-06-23 08:14:39,477 Epoch 7/8, Val Loss: 0.9680, Val Accuracy: 0.6688
2024-06-23 08:14:40,474 Epoch [8/8], Batch [1/748], Loss: 0.3010
2024-06-23 08:15:30,947 Epoch [8/8], Batch [51/748], Loss: 0.1492
2024-06-23 08:16:21,856 Epoch [8/8], Batch [101/748], Loss: 0.5056
2024-06-23 08:17:12,753 Epoch [8/8], Batch [151/748], Loss: 0.1346
2024-06-23 08:18:03,663 Epoch [8/8], Batch [201/748], Loss: 0.5422
2024-06-23 08:18:54,769 Epoch [8/8], Batch [251/748], Loss: 0.2680
2024-06-23 08:19:45,544 Epoch [8/8], Batch [301/748], Loss: 0.2489
2024-06-23 08:20:36,579 Epoch [8/8], Batch [351/748], Loss: 0.3715
2024-06-23 08:21:27,407 Epoch [8/8], Batch [401/748], Loss: 0.2762
2024-06-23 08:22:18,375 Epoch [8/8], Batch [451/748], Loss: 0.3558
2024-06-23 08:23:09,444 Epoch [8/8], Batch [501/748], Loss: 0.4446
2024-06-23 08:24:00,284 Epoch [8/8], Batch [551/748], Loss: 0.4950
2024-06-23 08:24:51,217 Epoch [8/8], Batch [601/748], Loss: 0.2152
2024-06-23 08:25:42,104 Epoch [8/8], Batch [651/748], Loss: 0.2871
2024-06-23 08:26:33,326 Epoch [8/8], Batch [701/748], Loss: 0.2042
2024-06-23 08:27:20,593 Epoch 8/8, Train Loss: 0.2724, Train Accuracy: 0.8983
2024-06-23 08:28:45,869 Epoch 8/8, Val Loss: 1.0558, Val Accuracy: 0.6671
2024-06-23 08:28:45,870 Training finished!
2024-06-23 08:28:45,870 ==================================================
2024-06-23 08:35:07,697 ==================================================
2024-06-23 08:35:07,697 Training BERT + TF-IDF features with Dimension-256...
2024-06-23 08:35:08,679 Epoch [1/8], Batch [1/748], Loss: 1.5987
2024-06-23 08:35:57,864 Epoch [1/8], Batch [51/748], Loss: 1.4786
2024-06-23 08:36:48,456 Epoch [1/8], Batch [101/748], Loss: 1.3479
2024-06-23 08:37:39,442 Epoch [1/8], Batch [151/748], Loss: 1.2476
2024-06-23 08:38:30,603 Epoch [1/8], Batch [201/748], Loss: 1.1939
2024-06-23 08:39:21,447 Epoch [1/8], Batch [251/748], Loss: 1.0233
2024-06-23 08:40:12,394 Epoch [1/8], Batch [301/748], Loss: 0.9647
2024-06-23 08:41:03,293 Epoch [1/8], Batch [351/748], Loss: 0.9335
2024-06-23 08:41:54,085 Epoch [1/8], Batch [401/748], Loss: 1.1426
2024-06-23 08:42:45,232 Epoch [1/8], Batch [451/748], Loss: 0.8947
2024-06-23 08:43:36,098 Epoch [1/8], Batch [501/748], Loss: 0.8765
2024-06-23 08:44:27,082 Epoch [1/8], Batch [551/748], Loss: 1.0298
2024-06-23 08:45:17,807 Epoch [1/8], Batch [601/748], Loss: 0.9758
2024-06-23 08:46:08,397 Epoch [1/8], Batch [651/748], Loss: 0.8528
2024-06-23 08:46:59,034 Epoch [1/8], Batch [701/748], Loss: 0.7362
2024-06-23 08:47:46,286 Epoch 1/8, Train Loss: 1.0763, Train Accuracy: 0.5411
2024-06-23 08:49:10,550 Epoch 1/8, Val Loss: 0.9712, Val Accuracy: 0.5882
2024-06-23 08:49:11,591 Epoch [2/8], Batch [1/748], Loss: 1.0618
2024-06-23 08:50:01,979 Epoch [2/8], Batch [51/748], Loss: 0.8914
2024-06-23 08:50:52,697 Epoch [2/8], Batch [101/748], Loss: 0.8313
2024-06-23 08:51:43,390 Epoch [2/8], Batch [151/748], Loss: 0.8101
2024-06-23 08:52:34,314 Epoch [2/8], Batch [201/748], Loss: 0.6446
2024-06-23 08:53:25,083 Epoch [2/8], Batch [251/748], Loss: 0.6582
2024-06-23 08:54:15,609 Epoch [2/8], Batch [301/748], Loss: 0.8786
2024-06-23 08:55:06,255 Epoch [2/8], Batch [351/748], Loss: 0.9237
2024-06-23 08:55:57,192 Epoch [2/8], Batch [401/748], Loss: 0.9164
2024-06-23 08:56:48,035 Epoch [2/8], Batch [451/748], Loss: 0.7988
2024-06-23 08:57:38,507 Epoch [2/8], Batch [501/748], Loss: 0.8711
2024-06-23 08:58:29,270 Epoch [2/8], Batch [551/748], Loss: 0.8203
2024-06-23 08:59:19,951 Epoch [2/8], Batch [601/748], Loss: 0.7784
2024-06-23 09:00:10,413 Epoch [2/8], Batch [651/748], Loss: 0.9219
2024-06-23 09:01:01,022 Epoch [2/8], Batch [701/748], Loss: 0.7700
2024-06-23 09:01:47,914 Epoch 2/8, Train Loss: 0.8170, Train Accuracy: 0.6379
2024-06-23 09:03:12,650 Epoch 2/8, Val Loss: 0.8471, Val Accuracy: 0.6250
2024-06-23 09:03:13,662 Epoch [3/8], Batch [1/748], Loss: 0.6081
2024-06-23 09:04:03,857 Epoch [3/8], Batch [51/748], Loss: 0.7571
2024-06-23 09:04:54,449 Epoch [3/8], Batch [101/748], Loss: 0.7682
2024-06-23 09:05:45,340 Epoch [3/8], Batch [151/748], Loss: 0.5154
2024-06-23 09:06:36,338 Epoch [3/8], Batch [201/748], Loss: 0.7937
2024-06-23 09:07:27,300 Epoch [3/8], Batch [251/748], Loss: 0.8139
2024-06-23 09:08:18,099 Epoch [3/8], Batch [301/748], Loss: 0.7599
2024-06-23 09:09:08,746 Epoch [3/8], Batch [351/748], Loss: 0.6360
2024-06-23 09:09:59,310 Epoch [3/8], Batch [401/748], Loss: 0.6215
2024-06-23 09:10:50,190 Epoch [3/8], Batch [451/748], Loss: 0.7038
2024-06-23 09:11:40,895 Epoch [3/8], Batch [501/748], Loss: 0.5677
2024-06-23 09:12:31,462 Epoch [3/8], Batch [551/748], Loss: 0.7106
2024-06-23 09:13:22,056 Epoch [3/8], Batch [601/748], Loss: 0.8593
2024-06-23 09:14:13,018 Epoch [3/8], Batch [651/748], Loss: 0.8420
2024-06-23 09:15:03,902 Epoch [3/8], Batch [701/748], Loss: 0.5794
2024-06-23 09:15:51,185 Epoch 3/8, Train Loss: 0.7144, Train Accuracy: 0.6807
2024-06-23 09:17:15,809 Epoch 3/8, Val Loss: 0.8045, Val Accuracy: 0.6594
2024-06-23 09:17:16,817 Epoch [4/8], Batch [1/748], Loss: 0.7594
2024-06-23 09:18:07,085 Epoch [4/8], Batch [51/748], Loss: 0.6139
2024-06-23 09:18:57,833 Epoch [4/8], Batch [101/748], Loss: 0.4998
2024-06-23 09:19:48,408 Epoch [4/8], Batch [151/748], Loss: 0.5643
2024-06-23 09:20:39,365 Epoch [4/8], Batch [201/748], Loss: 0.7261
2024-06-23 09:21:30,005 Epoch [4/8], Batch [251/748], Loss: 0.5342
2024-06-23 09:22:20,551 Epoch [4/8], Batch [301/748], Loss: 0.6131
2024-06-23 09:23:11,358 Epoch [4/8], Batch [351/748], Loss: 0.4143
2024-06-23 09:24:01,957 Epoch [4/8], Batch [401/748], Loss: 0.7502
2024-06-23 09:24:52,441 Epoch [4/8], Batch [451/748], Loss: 0.7309
2024-06-23 09:25:43,168 Epoch [4/8], Batch [501/748], Loss: 0.5156
2024-06-23 09:26:33,790 Epoch [4/8], Batch [551/748], Loss: 0.5593
2024-06-23 09:27:24,171 Epoch [4/8], Batch [601/748], Loss: 0.8990
2024-06-23 09:28:14,502 Epoch [4/8], Batch [651/748], Loss: 0.7737
2024-06-23 09:29:05,186 Epoch [4/8], Batch [701/748], Loss: 0.6740
2024-06-23 09:29:52,318 Epoch 4/8, Train Loss: 0.6148, Train Accuracy: 0.7270
2024-06-23 09:31:16,866 Epoch 4/8, Val Loss: 0.8718, Val Accuracy: 0.6497
2024-06-23 09:31:17,860 Epoch [5/8], Batch [1/748], Loss: 0.4691
2024-06-23 09:32:08,261 Epoch [5/8], Batch [51/748], Loss: 0.4923
2024-06-23 09:32:58,801 Epoch [5/8], Batch [101/748], Loss: 0.5347
2024-06-23 09:33:49,426 Epoch [5/8], Batch [151/748], Loss: 0.4904
2024-06-23 09:34:40,235 Epoch [5/8], Batch [201/748], Loss: 0.4558
2024-06-23 09:35:30,896 Epoch [5/8], Batch [251/748], Loss: 0.7804
2024-06-23 09:36:21,252 Epoch [5/8], Batch [301/748], Loss: 0.9740
2024-06-23 09:37:12,071 Epoch [5/8], Batch [351/748], Loss: 0.4640
2024-06-23 09:38:02,627 Epoch [5/8], Batch [401/748], Loss: 0.4981
2024-06-23 09:38:53,132 Epoch [5/8], Batch [451/748], Loss: 0.5500
2024-06-23 09:39:43,993 Epoch [5/8], Batch [501/748], Loss: 0.5338
2024-06-23 09:40:34,505 Epoch [5/8], Batch [551/748], Loss: 0.4531
2024-06-23 09:41:24,983 Epoch [5/8], Batch [601/748], Loss: 0.5117
2024-06-23 09:42:15,472 Epoch [5/8], Batch [651/748], Loss: 0.7897
2024-06-23 09:43:06,332 Epoch [5/8], Batch [701/748], Loss: 0.6233
2024-06-23 09:43:53,403 Epoch 5/8, Train Loss: 0.5318, Train Accuracy: 0.7669
2024-06-23 09:45:17,825 Epoch 5/8, Val Loss: 0.8274, Val Accuracy: 0.6770
2024-06-23 09:45:18,822 Epoch [6/8], Batch [1/748], Loss: 0.4946
2024-06-23 09:46:09,317 Epoch [6/8], Batch [51/748], Loss: 0.5000
2024-06-23 09:46:59,836 Epoch [6/8], Batch [101/748], Loss: 0.4213
2024-06-23 09:47:50,204 Epoch [6/8], Batch [151/748], Loss: 0.4476
2024-06-23 09:48:40,965 Epoch [6/8], Batch [201/748], Loss: 0.4301
2024-06-23 09:49:31,490 Epoch [6/8], Batch [251/748], Loss: 0.4181
2024-06-23 09:50:22,200 Epoch [6/8], Batch [301/748], Loss: 0.3937
2024-06-23 09:51:13,191 Epoch [6/8], Batch [351/748], Loss: 0.4657
2024-06-23 09:52:03,995 Epoch [6/8], Batch [401/748], Loss: 0.3198
2024-06-23 09:52:54,919 Epoch [6/8], Batch [451/748], Loss: 0.5325
2024-06-23 09:53:45,466 Epoch [6/8], Batch [501/748], Loss: 0.4897
2024-06-23 09:54:36,305 Epoch [6/8], Batch [551/748], Loss: 0.2756
2024-06-23 09:55:27,012 Epoch [6/8], Batch [601/748], Loss: 0.3918
2024-06-23 09:56:17,738 Epoch [6/8], Batch [651/748], Loss: 0.5490
2024-06-23 09:57:08,692 Epoch [6/8], Batch [701/748], Loss: 0.5673
2024-06-23 09:57:56,231 Epoch 6/8, Train Loss: 0.4455, Train Accuracy: 0.8065
2024-06-23 09:59:21,428 Epoch 6/8, Val Loss: 0.9703, Val Accuracy: 0.6465
2024-06-23 09:59:22,426 Epoch [7/8], Batch [1/748], Loss: 0.2935
2024-06-23 10:00:13,105 Epoch [7/8], Batch [51/748], Loss: 0.2290
2024-06-23 10:01:04,031 Epoch [7/8], Batch [101/748], Loss: 0.4127
2024-06-23 10:01:55,189 Epoch [7/8], Batch [151/748], Loss: 0.2908
2024-06-23 10:02:46,080 Epoch [7/8], Batch [201/748], Loss: 0.3710
2024-06-23 10:03:37,209 Epoch [7/8], Batch [251/748], Loss: 0.4519
2024-06-23 10:04:28,129 Epoch [7/8], Batch [301/748], Loss: 0.2966
2024-06-23 10:05:18,936 Epoch [7/8], Batch [351/748], Loss: 0.2483
2024-06-23 10:06:09,784 Epoch [7/8], Batch [401/748], Loss: 0.3686
2024-06-23 10:07:00,706 Epoch [7/8], Batch [451/748], Loss: 0.3133
2024-06-23 10:07:51,597 Epoch [7/8], Batch [501/748], Loss: 0.5412
2024-06-23 10:08:42,579 Epoch [7/8], Batch [551/748], Loss: 0.2385
2024-06-23 10:09:33,603 Epoch [7/8], Batch [601/748], Loss: 0.3120
2024-06-23 10:10:24,466 Epoch [7/8], Batch [651/748], Loss: 0.3252
2024-06-23 10:11:15,278 Epoch [7/8], Batch [701/748], Loss: 0.2331
2024-06-23 10:12:02,857 Epoch 7/8, Train Loss: 0.3720, Train Accuracy: 0.8453
2024-06-23 10:13:28,335 Epoch 7/8, Val Loss: 1.0211, Val Accuracy: 0.6537
2024-06-23 10:13:29,360 Epoch [8/8], Batch [1/748], Loss: 0.4814
2024-06-23 10:14:19,825 Epoch [8/8], Batch [51/748], Loss: 0.2928
2024-06-23 10:15:10,752 Epoch [8/8], Batch [101/748], Loss: 0.3483
2024-06-23 10:16:01,561 Epoch [8/8], Batch [151/748], Loss: 0.4404
2024-06-23 10:16:52,528 Epoch [8/8], Batch [201/748], Loss: 0.2767
2024-06-23 10:17:43,484 Epoch [8/8], Batch [251/748], Loss: 0.3895
2024-06-23 10:18:34,603 Epoch [8/8], Batch [301/748], Loss: 0.3298
2024-06-23 10:19:25,627 Epoch [8/8], Batch [351/748], Loss: 0.2648
2024-06-23 10:20:16,499 Epoch [8/8], Batch [401/748], Loss: 0.0795
2024-06-23 10:21:07,268 Epoch [8/8], Batch [451/748], Loss: 0.3834
2024-06-23 10:21:58,292 Epoch [8/8], Batch [501/748], Loss: 0.2072
2024-06-23 10:22:49,380 Epoch [8/8], Batch [551/748], Loss: 0.2223
2024-06-23 10:23:40,170 Epoch [8/8], Batch [601/748], Loss: 0.3446
2024-06-23 10:24:31,128 Epoch [8/8], Batch [651/748], Loss: 0.3275
2024-06-23 10:25:21,923 Epoch [8/8], Batch [701/748], Loss: 0.2288
2024-06-23 10:26:09,571 Epoch 8/8, Train Loss: 0.3076, Train Accuracy: 0.8761
2024-06-23 10:27:34,707 Epoch 8/8, Val Loss: 1.0284, Val Accuracy: 0.6716
2024-06-23 10:27:34,708 Training finished!
2024-06-23 10:27:34,708 ==================================================
2024-06-23 10:30:30,293 ==================================================
2024-06-23 10:30:30,293 Training BERT + TF-IDF features with Dimension-64...
2024-06-23 10:30:31,322 Epoch [1/8], Batch [1/748], Loss: 1.6831
2024-06-23 10:31:20,816 Epoch [1/8], Batch [51/748], Loss: 1.5879
2024-06-23 10:32:11,290 Epoch [1/8], Batch [101/748], Loss: 1.4688
2024-06-23 10:33:02,378 Epoch [1/8], Batch [151/748], Loss: 1.3941
2024-06-23 10:33:53,114 Epoch [1/8], Batch [201/748], Loss: 1.1814
2024-06-23 10:34:44,223 Epoch [1/8], Batch [251/748], Loss: 1.2724
2024-06-23 10:35:35,173 Epoch [1/8], Batch [301/748], Loss: 0.9998
2024-06-23 10:36:26,107 Epoch [1/8], Batch [351/748], Loss: 0.9945
2024-06-23 10:37:17,089 Epoch [1/8], Batch [401/748], Loss: 0.9685
2024-06-23 10:38:07,973 Epoch [1/8], Batch [451/748], Loss: 0.9266
2024-06-23 10:38:58,882 Epoch [1/8], Batch [501/748], Loss: 0.8323
2024-06-23 10:39:49,690 Epoch [1/8], Batch [551/748], Loss: 0.9185
2024-06-23 10:40:40,678 Epoch [1/8], Batch [601/748], Loss: 0.8317
2024-06-23 10:41:31,726 Epoch [1/8], Batch [651/748], Loss: 0.9012
2024-06-23 10:42:22,568 Epoch [1/8], Batch [701/748], Loss: 0.7821
2024-06-23 10:43:10,148 Epoch 1/8, Train Loss: 1.0980, Train Accuracy: 0.5377
2024-06-23 10:44:35,906 Epoch 1/8, Val Loss: 0.8945, Val Accuracy: 0.6076
2024-06-23 10:44:36,882 Epoch [2/8], Batch [1/748], Loss: 0.9827
2024-06-23 10:45:27,172 Epoch [2/8], Batch [51/748], Loss: 0.8486
2024-06-23 10:46:18,130 Epoch [2/8], Batch [101/748], Loss: 0.8293
2024-06-23 10:47:09,038 Epoch [2/8], Batch [151/748], Loss: 0.5665
2024-06-23 10:48:00,035 Epoch [2/8], Batch [201/748], Loss: 0.7534
2024-06-23 10:48:50,752 Epoch [2/8], Batch [251/748], Loss: 0.9741
2024-06-23 10:49:41,716 Epoch [2/8], Batch [301/748], Loss: 0.9647
2024-06-23 10:50:32,817 Epoch [2/8], Batch [351/748], Loss: 0.5781
2024-06-23 10:51:23,683 Epoch [2/8], Batch [401/748], Loss: 0.6829
2024-06-23 10:52:14,648 Epoch [2/8], Batch [451/748], Loss: 0.7141
2024-06-23 10:53:05,898 Epoch [2/8], Batch [501/748], Loss: 0.7103
2024-06-23 10:53:56,782 Epoch [2/8], Batch [551/748], Loss: 0.6754
2024-06-23 10:54:47,680 Epoch [2/8], Batch [601/748], Loss: 0.7927
2024-06-23 10:55:38,617 Epoch [2/8], Batch [651/748], Loss: 0.6236
2024-06-23 10:56:29,687 Epoch [2/8], Batch [701/748], Loss: 0.9268
2024-06-23 10:57:17,049 Epoch 2/8, Train Loss: 0.7937, Train Accuracy: 0.6541
2024-06-23 10:58:42,574 Epoch 2/8, Val Loss: 0.7850, Val Accuracy: 0.6631
2024-06-23 10:58:43,596 Epoch [3/8], Batch [1/748], Loss: 0.6138
2024-06-23 10:59:33,806 Epoch [3/8], Batch [51/748], Loss: 0.5603
2024-06-23 11:00:24,226 Epoch [3/8], Batch [101/748], Loss: 0.6163
2024-06-23 11:01:14,699 Epoch [3/8], Batch [151/748], Loss: 0.6538
2024-06-23 11:02:05,080 Epoch [3/8], Batch [201/748], Loss: 0.7462
2024-06-23 11:02:55,746 Epoch [3/8], Batch [251/748], Loss: 0.5480
2024-06-23 11:03:46,079 Epoch [3/8], Batch [301/748], Loss: 0.4691
2024-06-23 11:04:36,639 Epoch [3/8], Batch [351/748], Loss: 0.7090
2024-06-23 11:05:27,338 Epoch [3/8], Batch [401/748], Loss: 0.7078
2024-06-23 11:06:18,167 Epoch [3/8], Batch [451/748], Loss: 0.6365
2024-06-23 11:07:08,795 Epoch [3/8], Batch [501/748], Loss: 0.9095
2024-06-23 11:07:59,387 Epoch [3/8], Batch [551/748], Loss: 0.8527
2024-06-23 11:08:50,080 Epoch [3/8], Batch [601/748], Loss: 0.8676
2024-06-23 11:09:40,621 Epoch [3/8], Batch [651/748], Loss: 0.6099
2024-06-23 11:10:31,295 Epoch [3/8], Batch [701/748], Loss: 0.5054
2024-06-23 11:11:18,604 Epoch 3/8, Train Loss: 0.6640, Train Accuracy: 0.7172
2024-06-23 11:12:43,401 Epoch 3/8, Val Loss: 0.7899, Val Accuracy: 0.6691
2024-06-23 11:12:44,395 Epoch [4/8], Batch [1/748], Loss: 0.5747
2024-06-23 11:13:34,692 Epoch [4/8], Batch [51/748], Loss: 0.7580
2024-06-23 11:14:24,948 Epoch [4/8], Batch [101/748], Loss: 0.6450
2024-06-23 11:15:15,683 Epoch [4/8], Batch [151/748], Loss: 0.4764
2024-06-23 11:16:06,229 Epoch [4/8], Batch [201/748], Loss: 0.7324
2024-06-23 11:16:57,035 Epoch [4/8], Batch [251/748], Loss: 0.3522
2024-06-23 11:17:47,528 Epoch [4/8], Batch [301/748], Loss: 0.5430
2024-06-23 11:18:37,991 Epoch [4/8], Batch [351/748], Loss: 0.4826
2024-06-23 11:19:28,556 Epoch [4/8], Batch [401/748], Loss: 0.9452
2024-06-23 11:20:19,043 Epoch [4/8], Batch [451/748], Loss: 0.6716
2024-06-23 11:21:09,470 Epoch [4/8], Batch [501/748], Loss: 0.4160
2024-06-23 11:22:00,033 Epoch [4/8], Batch [551/748], Loss: 0.3440
2024-06-23 11:22:50,915 Epoch [4/8], Batch [601/748], Loss: 0.6108
2024-06-23 11:23:41,597 Epoch [4/8], Batch [651/748], Loss: 0.4947
2024-06-23 11:24:32,192 Epoch [4/8], Batch [701/748], Loss: 0.5547
2024-06-23 11:25:19,165 Epoch 4/8, Train Loss: 0.5458, Train Accuracy: 0.7742
2024-06-23 11:26:43,941 Epoch 4/8, Val Loss: 0.7854, Val Accuracy: 0.6885
2024-06-23 11:26:44,942 Epoch [5/8], Batch [1/748], Loss: 0.4638
2024-06-23 11:27:35,279 Epoch [5/8], Batch [51/748], Loss: 0.4590
2024-06-23 11:28:25,512 Epoch [5/8], Batch [101/748], Loss: 0.2827
2024-06-23 11:29:16,399 Epoch [5/8], Batch [151/748], Loss: 0.4697
2024-06-23 11:30:06,734 Epoch [5/8], Batch [201/748], Loss: 0.3292
2024-06-23 11:30:57,126 Epoch [5/8], Batch [251/748], Loss: 0.3109
2024-06-23 11:31:47,476 Epoch [5/8], Batch [301/748], Loss: 0.4437
2024-06-23 11:32:38,297 Epoch [5/8], Batch [351/748], Loss: 0.4361
2024-06-23 11:33:28,866 Epoch [5/8], Batch [401/748], Loss: 0.2772
2024-06-23 11:34:19,186 Epoch [5/8], Batch [451/748], Loss: 0.2296
2024-06-23 11:35:09,745 Epoch [5/8], Batch [501/748], Loss: 0.2920
2024-06-23 11:36:00,536 Epoch [5/8], Batch [551/748], Loss: 0.7126
2024-06-23 11:36:51,590 Epoch [5/8], Batch [601/748], Loss: 0.5083
2024-06-23 11:37:42,283 Epoch [5/8], Batch [651/748], Loss: 0.5289
2024-06-23 11:38:32,657 Epoch [5/8], Batch [701/748], Loss: 0.3297
2024-06-23 11:39:19,922 Epoch 5/8, Train Loss: 0.4335, Train Accuracy: 0.8265
2024-06-23 11:40:44,364 Epoch 5/8, Val Loss: 0.9381, Val Accuracy: 0.6613
2024-06-23 11:40:45,362 Epoch [6/8], Batch [1/748], Loss: 0.2832
2024-06-23 11:41:35,717 Epoch [6/8], Batch [51/748], Loss: 0.5844
2024-06-23 11:42:26,209 Epoch [6/8], Batch [101/748], Loss: 0.3980
2024-06-23 11:43:16,660 Epoch [6/8], Batch [151/748], Loss: 0.3116
2024-06-23 11:44:07,314 Epoch [6/8], Batch [201/748], Loss: 0.2630
2024-06-23 11:44:57,923 Epoch [6/8], Batch [251/748], Loss: 0.3131
2024-06-23 11:45:48,540 Epoch [6/8], Batch [301/748], Loss: 0.5134
2024-06-23 11:46:39,065 Epoch [6/8], Batch [351/748], Loss: 0.2653
2024-06-23 11:47:29,643 Epoch [6/8], Batch [401/748], Loss: 0.0913
2024-06-23 11:48:20,065 Epoch [6/8], Batch [451/748], Loss: 0.3462
2024-06-23 11:49:10,538 Epoch [6/8], Batch [501/748], Loss: 0.3285
2024-06-23 11:50:01,382 Epoch [6/8], Batch [551/748], Loss: 0.2622
2024-06-23 11:50:51,948 Epoch [6/8], Batch [601/748], Loss: 0.5217
2024-06-23 11:51:42,306 Epoch [6/8], Batch [651/748], Loss: 0.5481
2024-06-23 11:52:33,027 Epoch [6/8], Batch [701/748], Loss: 0.1811
2024-06-23 11:53:20,144 Epoch 6/8, Train Loss: 0.3500, Train Accuracy: 0.8604
2024-06-23 11:54:44,755 Epoch 6/8, Val Loss: 0.9433, Val Accuracy: 0.6785
2024-06-23 11:54:45,748 Epoch [7/8], Batch [1/748], Loss: 0.5277
2024-06-23 11:55:36,195 Epoch [7/8], Batch [51/748], Loss: 0.2554
2024-06-23 11:56:26,582 Epoch [7/8], Batch [101/748], Loss: 0.2466
2024-06-23 11:57:17,052 Epoch [7/8], Batch [151/748], Loss: 0.3834
2024-06-23 11:58:07,766 Epoch [7/8], Batch [201/748], Loss: 0.1546
2024-06-23 11:58:58,014 Epoch [7/8], Batch [251/748], Loss: 0.2072
2024-06-23 11:59:48,639 Epoch [7/8], Batch [301/748], Loss: 0.1821
2024-06-23 12:00:39,392 Epoch [7/8], Batch [351/748], Loss: 0.4273
2024-06-23 12:01:29,848 Epoch [7/8], Batch [401/748], Loss: 0.1814
2024-06-23 12:02:20,114 Epoch [7/8], Batch [451/748], Loss: 0.1925
2024-06-23 12:03:10,747 Epoch [7/8], Batch [501/748], Loss: 0.3159
2024-06-23 12:04:01,432 Epoch [7/8], Batch [551/748], Loss: 0.2336
2024-06-23 12:04:52,345 Epoch [7/8], Batch [601/748], Loss: 0.1497
2024-06-23 12:05:42,625 Epoch [7/8], Batch [651/748], Loss: 0.1899
2024-06-23 12:06:33,554 Epoch [7/8], Batch [701/748], Loss: 0.2380
2024-06-23 12:07:20,969 Epoch 7/8, Train Loss: 0.2740, Train Accuracy: 0.8964
2024-06-23 12:08:46,243 Epoch 7/8, Val Loss: 1.0740, Val Accuracy: 0.6663
2024-06-23 12:08:47,281 Epoch [8/8], Batch [1/748], Loss: 0.2277
2024-06-23 12:09:37,997 Epoch [8/8], Batch [51/748], Loss: 0.1072
2024-06-23 12:10:29,190 Epoch [8/8], Batch [101/748], Loss: 0.2883
2024-06-23 12:11:19,951 Epoch [8/8], Batch [151/748], Loss: 0.1827
2024-06-23 12:12:10,777 Epoch [8/8], Batch [201/748], Loss: 0.1074
2024-06-23 12:13:01,700 Epoch [8/8], Batch [251/748], Loss: 0.1783
2024-06-23 12:13:52,621 Epoch [8/8], Batch [301/748], Loss: 0.4808
2024-06-23 12:14:43,603 Epoch [8/8], Batch [351/748], Loss: 0.2720
2024-06-23 12:15:34,543 Epoch [8/8], Batch [401/748], Loss: 0.2586
2024-06-23 12:16:25,561 Epoch [8/8], Batch [451/748], Loss: 0.1340
2024-06-23 12:17:16,105 Epoch [8/8], Batch [501/748], Loss: 0.2004
2024-06-23 12:18:06,732 Epoch [8/8], Batch [551/748], Loss: 0.1002
2024-06-23 12:18:57,299 Epoch [8/8], Batch [601/748], Loss: 0.3112
2024-06-23 12:19:48,195 Epoch [8/8], Batch [651/748], Loss: 0.2059
2024-06-23 12:20:39,203 Epoch [8/8], Batch [701/748], Loss: 0.3230
2024-06-23 12:21:26,630 Epoch 8/8, Train Loss: 0.2141, Train Accuracy: 0.9228
2024-06-23 12:22:51,651 Epoch 8/8, Val Loss: 1.1055, Val Accuracy: 0.6802
2024-06-23 12:22:51,652 Training finished!
2024-06-23 12:22:51,652 ==================================================
2024-06-23 12:24:07,197 ==================================================
2024-06-23 12:24:07,197 Training BERT + TF-IDF features with Dimension-8...
2024-06-23 12:24:08,168 Epoch [1/8], Batch [1/748], Loss: 1.6238
2024-06-23 12:24:58,074 Epoch [1/8], Batch [51/748], Loss: 1.4754
2024-06-23 12:25:48,702 Epoch [1/8], Batch [101/748], Loss: 1.3388
2024-06-23 12:26:39,648 Epoch [1/8], Batch [151/748], Loss: 1.2544
2024-06-23 12:27:30,548 Epoch [1/8], Batch [201/748], Loss: 1.0783
2024-06-23 12:28:21,372 Epoch [1/8], Batch [251/748], Loss: 1.0138
2024-06-23 12:29:12,498 Epoch [1/8], Batch [301/748], Loss: 1.0698
2024-06-23 12:30:03,414 Epoch [1/8], Batch [351/748], Loss: 0.9944
2024-06-23 12:30:54,439 Epoch [1/8], Batch [401/748], Loss: 0.9417
2024-06-23 12:31:45,317 Epoch [1/8], Batch [451/748], Loss: 1.0978
2024-06-23 12:32:36,297 Epoch [1/8], Batch [501/748], Loss: 0.9724
2024-06-23 12:33:27,318 Epoch [1/8], Batch [551/748], Loss: 1.0844
2024-06-23 12:34:18,160 Epoch [1/8], Batch [601/748], Loss: 0.9022
2024-06-23 12:35:09,158 Epoch [1/8], Batch [651/748], Loss: 0.6130
2024-06-23 12:36:00,101 Epoch [1/8], Batch [701/748], Loss: 0.9263
2024-06-23 12:36:47,646 Epoch 1/8, Train Loss: 1.0680, Train Accuracy: 0.5443
2024-06-23 12:38:12,933 Epoch 1/8, Val Loss: 0.8944, Val Accuracy: 0.6074
2024-06-23 12:38:13,915 Epoch [2/8], Batch [1/748], Loss: 0.8854
2024-06-23 12:39:04,591 Epoch [2/8], Batch [51/748], Loss: 0.9876
2024-06-23 12:39:55,458 Epoch [2/8], Batch [101/748], Loss: 0.7199
2024-06-23 12:40:46,446 Epoch [2/8], Batch [151/748], Loss: 0.8238
2024-06-23 12:41:37,394 Epoch [2/8], Batch [201/748], Loss: 0.7593
2024-06-23 12:42:28,475 Epoch [2/8], Batch [251/748], Loss: 1.0275
2024-06-23 12:43:19,632 Epoch [2/8], Batch [301/748], Loss: 0.7950
2024-06-23 12:44:10,392 Epoch [2/8], Batch [351/748], Loss: 0.6872
2024-06-23 12:45:01,292 Epoch [2/8], Batch [401/748], Loss: 1.0087
2024-06-23 12:45:52,398 Epoch [2/8], Batch [451/748], Loss: 0.7716
2024-06-23 12:46:43,472 Epoch [2/8], Batch [501/748], Loss: 0.7775
2024-06-23 12:47:34,309 Epoch [2/8], Batch [551/748], Loss: 0.9037
2024-06-23 12:48:25,106 Epoch [2/8], Batch [601/748], Loss: 0.7843
2024-06-23 12:49:16,008 Epoch [2/8], Batch [651/748], Loss: 0.5829
2024-06-23 12:50:06,970 Epoch [2/8], Batch [701/748], Loss: 0.9346
2024-06-23 12:50:54,368 Epoch 2/8, Train Loss: 0.8207, Train Accuracy: 0.6366
2024-06-23 12:52:19,796 Epoch 2/8, Val Loss: 0.8361, Val Accuracy: 0.6360
2024-06-23 12:52:20,782 Epoch [3/8], Batch [1/748], Loss: 0.6363
2024-06-23 12:53:11,776 Epoch [3/8], Batch [51/748], Loss: 0.7385
2024-06-23 12:54:02,379 Epoch [3/8], Batch [101/748], Loss: 0.8734
2024-06-23 12:54:53,374 Epoch [3/8], Batch [151/748], Loss: 0.7771
2024-06-23 12:55:44,316 Epoch [3/8], Batch [201/748], Loss: 0.6257
2024-06-23 12:56:35,399 Epoch [3/8], Batch [251/748], Loss: 0.6653
2024-06-23 12:57:26,264 Epoch [3/8], Batch [301/748], Loss: 0.7321
2024-06-23 12:58:17,226 Epoch [3/8], Batch [351/748], Loss: 0.9727
2024-06-23 12:59:07,847 Epoch [3/8], Batch [401/748], Loss: 0.8115
2024-06-23 12:59:58,422 Epoch [3/8], Batch [451/748], Loss: 0.6393
2024-06-23 13:00:49,132 Epoch [3/8], Batch [501/748], Loss: 0.7427
2024-06-23 13:01:39,990 Epoch [3/8], Batch [551/748], Loss: 0.3460
2024-06-23 13:02:31,038 Epoch [3/8], Batch [601/748], Loss: 0.6013
2024-06-23 13:03:21,858 Epoch [3/8], Batch [651/748], Loss: 0.6483
2024-06-23 13:04:12,883 Epoch [3/8], Batch [701/748], Loss: 0.7373
2024-06-23 13:05:00,506 Epoch 3/8, Train Loss: 0.7155, Train Accuracy: 0.6839
2024-06-23 13:06:25,763 Epoch 3/8, Val Loss: 0.7751, Val Accuracy: 0.6599
2024-06-23 13:06:26,793 Epoch [4/8], Batch [1/748], Loss: 0.4721
2024-06-23 13:07:17,679 Epoch [4/8], Batch [51/748], Loss: 0.6969
2024-06-23 13:08:08,365 Epoch [4/8], Batch [101/748], Loss: 0.8539
2024-06-23 13:08:59,309 Epoch [4/8], Batch [151/748], Loss: 0.7720
2024-06-23 13:09:50,238 Epoch [4/8], Batch [201/748], Loss: 0.6760
2024-06-23 13:10:41,314 Epoch [4/8], Batch [251/748], Loss: 0.7744
2024-06-23 13:11:32,143 Epoch [4/8], Batch [301/748], Loss: 0.6111
2024-06-23 13:12:23,050 Epoch [4/8], Batch [351/748], Loss: 0.4055
2024-06-23 13:13:14,094 Epoch [4/8], Batch [401/748], Loss: 0.5326
2024-06-23 13:14:05,119 Epoch [4/8], Batch [451/748], Loss: 0.4678
2024-06-23 13:14:56,086 Epoch [4/8], Batch [501/748], Loss: 0.8615
2024-06-23 13:15:46,807 Epoch [4/8], Batch [551/748], Loss: 0.6176
2024-06-23 13:16:37,728 Epoch [4/8], Batch [601/748], Loss: 0.4160
2024-06-23 13:17:28,137 Epoch [4/8], Batch [651/748], Loss: 0.5881
2024-06-23 13:18:18,507 Epoch [4/8], Batch [701/748], Loss: 0.5317
2024-06-23 13:19:05,561 Epoch 4/8, Train Loss: 0.6178, Train Accuracy: 0.7285
2024-06-23 13:20:30,409 Epoch 4/8, Val Loss: 0.8184, Val Accuracy: 0.6556
2024-06-23 13:20:31,422 Epoch [5/8], Batch [1/748], Loss: 0.3891
2024-06-23 13:21:21,504 Epoch [5/8], Batch [51/748], Loss: 0.3958
2024-06-23 13:22:12,034 Epoch [5/8], Batch [101/748], Loss: 0.4980
2024-06-23 13:23:02,715 Epoch [5/8], Batch [151/748], Loss: 0.5190
2024-06-23 13:23:53,125 Epoch [5/8], Batch [201/748], Loss: 0.5014
2024-06-23 13:24:43,895 Epoch [5/8], Batch [251/748], Loss: 0.6428
2024-06-23 13:25:34,290 Epoch [5/8], Batch [301/748], Loss: 0.5239
2024-06-23 13:26:25,013 Epoch [5/8], Batch [351/748], Loss: 0.4817
2024-06-23 13:27:15,594 Epoch [5/8], Batch [401/748], Loss: 0.4857
2024-06-23 13:28:06,179 Epoch [5/8], Batch [451/748], Loss: 0.7020
2024-06-23 13:28:56,901 Epoch [5/8], Batch [501/748], Loss: 0.5367
2024-06-23 13:29:47,466 Epoch [5/8], Batch [551/748], Loss: 0.4858
2024-06-23 13:30:37,890 Epoch [5/8], Batch [601/748], Loss: 0.3529
2024-06-23 13:31:28,466 Epoch [5/8], Batch [651/748], Loss: 0.6172
2024-06-23 13:32:18,815 Epoch [5/8], Batch [701/748], Loss: 0.6918
2024-06-23 13:33:06,283 Epoch 5/8, Train Loss: 0.5202, Train Accuracy: 0.7765
2024-06-23 13:34:30,967 Epoch 5/8, Val Loss: 0.8667, Val Accuracy: 0.6624
2024-06-23 13:34:31,958 Epoch [6/8], Batch [1/748], Loss: 0.4403
2024-06-23 13:35:21,975 Epoch [6/8], Batch [51/748], Loss: 0.5702
2024-06-23 13:36:12,390 Epoch [6/8], Batch [101/748], Loss: 0.5227
2024-06-23 13:37:02,745 Epoch [6/8], Batch [151/748], Loss: 0.4215
2024-06-23 13:37:53,108 Epoch [6/8], Batch [201/748], Loss: 0.3507
2024-06-23 13:38:43,556 Epoch [6/8], Batch [251/748], Loss: 0.4042
2024-06-23 13:39:34,014 Epoch [6/8], Batch [301/748], Loss: 0.4603
2024-06-23 13:40:24,642 Epoch [6/8], Batch [351/748], Loss: 0.5192
2024-06-23 13:41:15,123 Epoch [6/8], Batch [401/748], Loss: 0.4496
2024-06-23 13:42:05,906 Epoch [6/8], Batch [451/748], Loss: 0.3339
2024-06-23 13:42:56,890 Epoch [6/8], Batch [501/748], Loss: 0.4766
2024-06-23 13:43:47,283 Epoch [6/8], Batch [551/748], Loss: 0.4196
2024-06-23 13:44:37,878 Epoch [6/8], Batch [601/748], Loss: 0.2892
2024-06-23 13:45:28,424 Epoch [6/8], Batch [651/748], Loss: 0.2956
2024-06-23 13:46:18,886 Epoch [6/8], Batch [701/748], Loss: 0.6838
2024-06-23 13:47:06,444 Epoch 6/8, Train Loss: 0.4287, Train Accuracy: 0.8185
2024-06-23 13:48:31,048 Epoch 6/8, Val Loss: 0.9291, Val Accuracy: 0.6606
2024-06-23 13:48:32,052 Epoch [7/8], Batch [1/748], Loss: 0.4531
2024-06-23 13:49:22,281 Epoch [7/8], Batch [51/748], Loss: 0.3712
2024-06-23 13:50:12,664 Epoch [7/8], Batch [101/748], Loss: 0.2823
2024-06-23 13:51:03,167 Epoch [7/8], Batch [151/748], Loss: 0.4092
2024-06-23 13:51:53,584 Epoch [7/8], Batch [201/748], Loss: 0.5118
2024-06-23 13:52:44,076 Epoch [7/8], Batch [251/748], Loss: 0.2811
2024-06-23 13:53:34,331 Epoch [7/8], Batch [301/748], Loss: 0.2317
2024-06-23 13:54:24,916 Epoch [7/8], Batch [351/748], Loss: 0.2023
2024-06-23 13:55:15,635 Epoch [7/8], Batch [401/748], Loss: 0.2643
2024-06-23 13:56:06,056 Epoch [7/8], Batch [451/748], Loss: 0.2525
2024-06-23 13:56:56,730 Epoch [7/8], Batch [501/748], Loss: 0.2067
2024-06-23 13:57:47,307 Epoch [7/8], Batch [551/748], Loss: 0.3104
2024-06-23 13:58:37,834 Epoch [7/8], Batch [601/748], Loss: 0.4181
2024-06-23 13:59:28,459 Epoch [7/8], Batch [651/748], Loss: 0.2949
2024-06-23 14:00:19,079 Epoch [7/8], Batch [701/748], Loss: 0.4026
2024-06-23 14:01:06,210 Epoch 7/8, Train Loss: 0.3539, Train Accuracy: 0.8534
2024-06-23 14:02:31,009 Epoch 7/8, Val Loss: 0.9683, Val Accuracy: 0.6691
2024-06-23 14:02:32,000 Epoch [8/8], Batch [1/748], Loss: 0.2215
2024-06-23 14:03:22,322 Epoch [8/8], Batch [51/748], Loss: 0.3324
2024-06-23 14:04:12,823 Epoch [8/8], Batch [101/748], Loss: 0.2854
2024-06-23 14:05:03,541 Epoch [8/8], Batch [151/748], Loss: 0.2983
2024-06-23 14:05:53,990 Epoch [8/8], Batch [201/748], Loss: 0.8028
2024-06-23 14:06:44,408 Epoch [8/8], Batch [251/748], Loss: 0.3402
2024-06-23 14:07:34,794 Epoch [8/8], Batch [301/748], Loss: 0.2201
2024-06-23 14:08:25,242 Epoch [8/8], Batch [351/748], Loss: 0.3194
2024-06-23 14:09:15,585 Epoch [8/8], Batch [401/748], Loss: 0.3535
2024-06-23 14:10:06,070 Epoch [8/8], Batch [451/748], Loss: 0.1700
2024-06-23 14:10:56,522 Epoch [8/8], Batch [501/748], Loss: 0.2604
2024-06-23 14:11:46,779 Epoch [8/8], Batch [551/748], Loss: 0.3879
2024-06-23 14:12:37,712 Epoch [8/8], Batch [601/748], Loss: 0.3215
2024-06-23 14:13:28,284 Epoch [8/8], Batch [651/748], Loss: 0.1989
2024-06-23 14:14:18,647 Epoch [8/8], Batch [701/748], Loss: 0.4044
2024-06-23 14:15:05,910 Epoch 8/8, Train Loss: 0.2939, Train Accuracy: 0.8816
2024-06-23 14:16:30,786 Epoch 8/8, Val Loss: 1.0517, Val Accuracy: 0.6710
2024-06-23 14:16:30,788 Training finished!
2024-06-23 14:16:30,788 ==================================================
